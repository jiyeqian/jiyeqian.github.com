<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Jiye Qian" />
    <title>向量空间模型
    </title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <link href="/feed/" rel="alternate" title="Jiye Qian" type="application/atom+xml" />
    <link rel="stylesheet" href="/assets/css/style.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default_inline.css" />
    <link rel="stylesheet" href="/assets/css/coderay.css" />

    <script type="text/javascript" src="/assets/js/jquery-1.7.1.min.js"></script>
    <script type="text/javascript" src="/assets/js/outliner.js"></script>

    <!-- MathJax for LaTeX -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        "HTML-CSS": { extensions: ["handle-floats.js"] },
        TeX: { equationNumbers: { autoNumber: "AMS" } },
        tex2jax: {
            inlineMath: [['$$$', '$$$'], ['$', '$'], ['\\(', '\\)']],
            processEscapes: true
        }
    });
    </script>
    <script type="text/javascript" src="/assets/js/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
  <!-- <script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F0b514f17fd99b9fb4be74c94bdd2b7db' type='text/javascript'%3E%3C/script%3E"));
</script>
 -->
  </head>
<!--  <body>
-->
  <script type="text/javascript">
    function setTimeSpan(){
    	var date = new Date();
    	timeSpan.innerText=date.format('yyyy-MM-dd hh:mm:ss');
    }

    Date.prototype.format = function(format)
		{
    var o =
    	{
    	    "M+" : this.getMonth()+1, //month
    	    "d+" : this.getDate(),    //day
    	    "h+" : this.getHours(),   //hour
    	    "m+" : this.getMinutes(), //minute
    	    "s+" : this.getSeconds(), //second
    	    "q+" : Math.floor((this.getMonth()+3)/3),  //quarter
    	    "S" : this.getMilliseconds() //millisecond
    	}
    	if(/(y+)/.test(format))
    	format=format.replace(RegExp.$1,(this.getFullYear()+"").substr(4 - RegExp.$1.length));
    	for(var k in o)
    	if(new RegExp("("+ k +")").test(format))
    	format = format.replace(RegExp.$1,RegExp.$1.length==1 ? o[k] : ("00"+ o[k]).substr((""+ o[k]).length));
    	return format;
		}
  </script>

  <script type="text/javascript">
      (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
          (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
          e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
      })(window,document,'script','//s.swiftypecdn.com/install/v1/st.js','_st');

      _st('install','RFsGWEn74xUkvs4V5QRD');
  </script>

  <body onLoad="setInterval(setTimeSpan,1000);">
    <div id="container">
      <div id="main" role="main">
        <header>
        <h1>向量空间模型</h1>
        </header>
        <nav id="real_nav">
        
          <span><a title="Home" href="/">Home</a></span>
        
          <span><a title="Categories" href="/categories/">Categories</a></span>
        
          <span><a title="Tags" href="/tags/">Tags</a></span>
        
          <span><a title="Logs" href="/logs/">Logs</a></span>
        
          <span><a title="About" href="/about/">About</a></span>
        
          <span><a title="Subscribe" href="/feed/">Subscribe</a></span>
        
          <span><a title="Search" href="/search/">Search</a></span>
        
        </nav>
        <article class="content">
        <section class="meta">
<span class="time">
  <time datetime="2015-04-03">2015-04-03</time>
</span>

 |
<span class="categories">
  categories
  
  <a href="/categories/#研究学术" title="研究学术">研究学术</a>&nbsp;
  
</span>


 |
<span class="tags">
  tags
  
  <a href="/tags/#机器学习应用" title="机器学习应用">机器学习应用</a>&nbsp;
  
  <a href="/tags/#自然语言处理" title="自然语言处理">自然语言处理</a>&nbsp;
  
  <a href="/tags/#Python" title="Python">Python</a>&nbsp;
  
</span>

</section>
<section class="post">
<h2 id="section">基本概念</h2>

<p><strong>向量空间模型</strong>（VSM，vector space model）是用向量表示文本的代数模型，它将文本转换为向量，也称为<strong>词语向量模型</strong>（term vector model）<a href="#Salton:1975:VSM:361219.361220">[1]</a><sup id="fnref:tfidf"><a href="#fn:tfidf" class="footnote">1</a></sup>。最容易想到的方法就是利用词频（TF，term frequency）。</p>

<h3 id="section-1">词频</h3>

<p><strong>词频</strong>就是统计词语在文本中出现的次数。</p>

<div class="highlight"><pre><code class="language-python"><span class="n">mydoclist</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;Julie loves me more than Linda loves me&#39;</span><span class="p">,</span>
<span class="s">&#39;Jane likes me more than Julie loves me&#39;</span><span class="p">,</span>
<span class="s">&#39;He likes basketball more than baseball&#39;</span><span class="p">]</span>

<span class="c">#mydoclist = [&#39;sun sky bright&#39;, &#39;sun sun bright&#39;]</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">mydoclist</span><span class="p">:</span>
    <span class="n">tf</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="n">tf</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span><span class="mi">1</span>
    <span class="k">print</span> <span class="n">tf</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    
<span class="c"># Output:</span>
<span class="c"># [(&#39;me&#39;, 2), (&#39;Julie&#39;, 1), (&#39;loves&#39;, 2), (&#39;Linda&#39;, 1), (&#39;than&#39;, 1), (&#39;more&#39;, 1)]</span>
<span class="c"># [(&#39;me&#39;, 2), (&#39;Julie&#39;, 1), (&#39;likes&#39;, 1), (&#39;loves&#39;, 1), (&#39;Jane&#39;, 1), (&#39;than&#39;, 1), (&#39;more&#39;, 1)]</span>
<span class="c"># [(&#39;basketball&#39;, 1), (&#39;baseball&#39;, 1), (&#39;likes&#39;, 1), (&#39;He&#39;, 1), (&#39;than&#39;, 1), (&#39;more&#39;, 1)]</span></code></pre></div>

<p>以上代码统计了每个文本中词语出现的频率。虽然将文本量化，但是由于生成每个文本的字典不同，文本之间无法比较。因此，需要将每个文本表示成长度相同的向量，这个长度是由全体词语构成的<strong>语料库</strong>（corpus）决定的。</p>

<div class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">string</span> <span class="c">#allows for format()</span>
    
<span class="k">def</span> <span class="nf">build_lexicon</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="n">lexicon</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
        <span class="n">lexicon</span><span class="o">.</span><span class="n">update</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()])</span>
    <span class="k">return</span> <span class="n">lexicon</span>

<span class="k">def</span> <span class="nf">tf</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">document</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">freq</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">document</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">freq</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">document</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">document</span><span class="o">.</span><span class="n">split</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>

<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">build_lexicon</span><span class="p">(</span><span class="n">mydoclist</span><span class="p">)</span>

<span class="n">doc_term_matrix</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">print</span> <span class="s">&#39;Our vocabulary vector is [&#39;</span> <span class="o">+</span> <span class="s">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">))</span> <span class="o">+</span> <span class="s">&#39;]&#39;</span>
<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">mydoclist</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">&#39;The doc is &quot;&#39;</span> <span class="o">+</span> <span class="n">doc</span> <span class="o">+</span> <span class="s">&#39;&quot;&#39;</span>
    <span class="n">tf_vector</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">]</span>
    <span class="n">tf_vector_string</span> <span class="o">=</span> <span class="s">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="n">freq</span><span class="p">,</span> <span class="s">&#39;d&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">tf_vector</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&#39;The tf vector for Document </span><span class="si">%d</span><span class="s"> is [</span><span class="si">%s</span><span class="s">]&#39;</span> <span class="o">%</span> <span class="p">((</span><span class="n">mydoclist</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">tf_vector_string</span><span class="p">)</span>
    <span class="n">doc_term_matrix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf_vector</span><span class="p">)</span>
    
    <span class="c"># here&#39;s a test: why did I wrap mydoclist.index(doc)+1 in parens?  it returns an int...</span>
    <span class="c"># try it!  type(mydoclist.index(doc) + 1)</span>

<span class="k">print</span> <span class="s">&#39;All combined, here is our master document term matrix: &#39;</span>
<span class="k">print</span> <span class="n">doc_term_matrix</span>

<span class="c"># Output:</span>
<span class="c"># Our vocabulary vector is [me, basketball, Julie, baseball, likes, loves, Jane, Linda, He, than, more]</span>
<span class="c"># The doc is &quot;Julie loves me more than Linda loves me&quot;</span>
<span class="c"># The tf vector for Document 1 is [2, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1]</span>
<span class="c"># The doc is &quot;Jane likes me more than Julie loves me&quot;</span>
<span class="c"># The tf vector for Document 2 is [2, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]</span>
<span class="c"># The doc is &quot;He likes basketball more than baseball&quot;</span>
<span class="c"># The tf vector for Document 3 is [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]</span>
<span class="c"># All combined, here is our master document term matrix: </span>
<span class="c"># [[2, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1], [2, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]]</span></code></pre></div>

<p>通过这一过程，将文本转换到了向量空间。如果有一篇文本单词频率出现过高，会破坏分析，需将向量规范化，比如$L_2$规范化，使得向量元素的平方和为$1$。</p>

<div class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">l2_normalizer</span><span class="p">(</span><span class="n">vec</span><span class="p">):</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">el</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[(</span><span class="n">el</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">denom</span><span class="p">))</span> <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">]</span>

<span class="n">doc_term_matrix_l2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">vec</span> <span class="ow">in</span> <span class="n">doc_term_matrix</span><span class="p">:</span>
    <span class="n">doc_term_matrix_l2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l2_normalizer</span><span class="p">(</span><span class="n">vec</span><span class="p">))</span>

<span class="k">print</span> <span class="s">&#39;A regular old document term matrix: &#39;</span> 
<span class="k">print</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">doc_term_matrix</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&#39;</span><span class="se">\n</span><span class="s">A document term matrix with row-wise L2 norms of 1:&#39;</span>
<span class="k">print</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">doc_term_matrix_l2</span><span class="p">)</span>

<span class="c"># if you want to check this math, perform the following:</span>
<span class="c"># from numpy import linalg as la</span>
<span class="c"># la.norm(doc_term_matrix[0])</span>
<span class="c"># la.norm(doc_term_matrix_l2[0])</span>

<span class="c"># Output:</span>

<span class="c"># A regular old document term matrix: </span>
<span class="c"># [[2 0 1 0 0 2 0 1 0 1 1]</span>
<span class="c">#  [2 0 1 0 1 1 1 0 0 1 1]</span>
<span class="c">#  [0 1 0 1 1 0 0 0 1 1 1]]</span>

<span class="c"># A document term matrix with row-wise L2 norms of 1:</span>
<span class="c"># [[ 0.57735027  0.          0.28867513  0.          0.          0.57735027</span>
<span class="c">#    0.          0.28867513  0.          0.28867513  0.28867513]</span>
<span class="c">#  [ 0.63245553  0.          0.31622777  0.          0.31622777  0.31622777</span>
<span class="c">#    0.31622777  0.          0.          0.31622777  0.31622777]</span>
<span class="c">#  [ 0.          0.40824829  0.          0.40824829  0.40824829  0.          0.</span>
<span class="c">#    0.          0.40824829  0.40824829  0.40824829]]</span></code></pre></div>

<p>通过$L_2$规范化，向量元素的取值范围变为了$[0, 1]$。如果要提升某篇文本和主题的相关性，可以一遍遍重复单词，这种方法可以压低这样的频率提升。</p>

<h3 id="section-2">逆文档频率</h3>

<p>词频只考虑了词语在某个特定文档中出现的频率，并未考虑词语在所有文档中的价值。如果某个词比较少见，但是它在这篇文章中多次出现，那么它很可能就反映了这篇文章的特性，正是我们所需要的关键词。<a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html">例如</a>：一篇文本中“中国”、“蜜蜂”、“养殖”这三个词的出现次数一样多。这是不是意味着，作为关键词，它们的重要性是一样的？显然不是这样。因为“中国”是很常见的词，相对而言，“蜜蜂”和“养殖”不那么常见。如果这三个词在一篇文章的出现次数一样多，有理由认为，“蜜蜂”和“养殖”的重要程度要大于“中国”，也就是说，在关键词排序上面，“蜜蜂”和“养殖”应该排在“中国”的前面。</p>

<p>用统计学语言表达，就是在词频的基础上，要对每个词分配一个重要性权重。最常见的词给予最小的权重，较常见的词给予较小的权重，较少见的词给予较大的权重。这个权重叫做<strong>逆文档频率</strong>（IDF，inverse document frequency），它的大小与一个词的常见程度成反比<sup id="fnref:log-base"><a href="#fn:log-base" class="footnote">2</a></sup>，</p>

<p>\begin{equation}
IDF(\mbox{word}) = \log\left(\mbox{num of documents}\over\mbox{num of documents including word}+1\right)。
\end{equation}</p>

<div class="highlight"><pre><code class="language-python"><span class="k">def</span> <span class="nf">numDocsContaining</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">doclist</span><span class="p">):</span>
    <span class="n">doccount</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">doclist</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">freq</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">doccount</span> <span class="o">+=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">doccount</span> 

<span class="k">def</span> <span class="nf">idf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">doclist</span><span class="p">):</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">doclist</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">numDocsContaining</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">doclist</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span><span class="o">+</span><span class="n">df</span><span class="p">))</span>

<span class="n">my_idf_vector</span> <span class="o">=</span> <span class="p">[</span><span class="n">idf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">mydoclist</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">]</span>

<span class="k">print</span> <span class="s">&#39;Our vocabulary vector is [&#39;</span> <span class="o">+</span> <span class="s">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">))</span> <span class="o">+</span> <span class="s">&#39;]&#39;</span>
<span class="k">print</span> <span class="s">&#39;The inverse document frequency vector is [&#39;</span> <span class="o">+</span> <span class="s">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="n">freq</span><span class="p">,</span> <span class="s">&#39;f&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">my_idf_vector</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39;]&#39;</span>

<span class="c"># Output:</span>

<span class="c"># Our vocabulary vector is [me, basketball, Julie, baseball, likes, loves, Jane, Linda, He, than, more]</span>
<span class="c"># The inverse document frequency vector is [0.000000, 0.405465, 0.000000, 0.405465, 0.000000, 0.000000, 0.405465, 0.405465, 0.405465, -0.287682, -0.287682]</span></code></pre></div>

<p>如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）。</p>

<h3 id="tf-idf">TF-IDF</h3>

<p>\begin{equation}
TF-IDF(\mbox{word})=TF(\mbox{word})\times IDF(\mbox{word})。
\end{equation}</p>

<div class="highlight"><pre><code class="language-python"><span class="n">doc_term_matrix_tfidf</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c">#performing tf-idf matrix multiplication</span>
<span class="k">for</span> <span class="n">tf_vector</span> <span class="ow">in</span> <span class="n">doc_term_matrix</span><span class="p">:</span>
    <span class="n">doc_term_matrix_tfidf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf_vector</span><span class="p">,</span> <span class="n">my_idf_vector</span><span class="p">))</span>

<span class="c">#normalizing</span>
<span class="n">doc_term_matrix_tfidf_l2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">tf_vector</span> <span class="ow">in</span> <span class="n">doc_term_matrix_tfidf</span><span class="p">:</span>
    <span class="n">doc_term_matrix_tfidf_l2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l2_normalizer</span><span class="p">(</span><span class="n">tf_vector</span><span class="p">))</span>
                                    
<span class="k">print</span> <span class="n">vocabulary</span>
<span class="k">print</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">doc_term_matrix_tfidf_l2</span><span class="p">)</span> <span class="c"># np.matrix() just to make it easier to look at</span>

<span class="c"># Output:</span>
<span class="c"># </span>
<span class="c"># set([&#39;me&#39;, &#39;basketball&#39;, &#39;Julie&#39;, &#39;baseball&#39;, &#39;likes&#39;, &#39;loves&#39;, &#39;Jane&#39;, &#39;Linda&#39;, &#39;He&#39;, &#39;than&#39;, &#39;more&#39;])</span>
<span class="c"># [[ 0.          0.          0.          0.          0.          0.          0.</span>
<span class="c">#    0.70590555  0.         -0.50084796 -0.50084796]</span>
<span class="c">#  [ 0.          0.          0.          0.          0.          0.</span>
<span class="c">#    0.70590555  0.          0.         -0.50084796 -0.50084796]</span>
<span class="c">#  [ 0.          0.49957476  0.          0.49957476  0.          0.          0.</span>
<span class="c">#    0.          0.49957476 -0.35445393 -0.35445393]]</span></code></pre></div>

<p>事实上，scikits-learn包含了计算TF-IDF的算法，但由于处理除以0的问题，<code>TfidfVectorizer/TfidfTransformer</code>得到的<a href="http://stackoverflow.com/questions/18687879/error-in-computing-text-similarity-using-scikit-learn/18692538#18692538">结果与以上计算过程不同</a>。</p>

<div class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">term_freq_matrix</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">mydoclist</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Vocabulary:&quot;</span><span class="p">,</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>

<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="s">&quot;l2&quot;</span><span class="p">)</span>
<span class="n">tfidf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">term_freq_matrix</span><span class="p">)</span>

<span class="n">tf_idf_matrix</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">term_freq_matrix</span><span class="p">)</span>
<span class="k">print</span> <span class="n">tf_idf_matrix</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>

<span class="c"># Output:</span>
<span class="c"># Vocabulary: {u&#39;me&#39;: 8, u&#39;basketball&#39;: 1, u&#39;julie&#39;: 4, u&#39;baseball&#39;: 0, u&#39;likes&#39;: 5, u&#39;loves&#39;: 7, u&#39;jane&#39;: 3, u&#39;linda&#39;: 6, u&#39;more&#39;: 9, u&#39;than&#39;: 10, u&#39;he&#39;: 2}</span>
<span class="c"># [[ 0.          0.          0.          0.          0.28945906  0.</span>
<span class="c">#    0.38060387  0.57891811  0.57891811  0.22479078  0.22479078]</span>
<span class="c">#  [ 0.          0.          0.          0.41715759  0.3172591   0.3172591</span>
<span class="c">#    0.          0.3172591   0.6345182   0.24637999  0.24637999]</span>
<span class="c">#  [ 0.48359121  0.48359121  0.48359121  0.          0.          0.36778358</span>
<span class="c">#    0.          0.          0.          0.28561676  0.28561676]]</span></code></pre></div>

<h2 id="section-3">应用示例</h2>

<p>向量空间模型的TF-IDF可用于<a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html">自动提取关键词</a>、<a href="http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html">找出相似文章</a>和<a href="http://www.ruanyifeng.com/blog/2013/03/automatic_summarization.html">自动摘要</a>等。</p>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="Salton:1975:VSM:361219.361220">[1]G. Salton, A. Wong, and C.-S. Yang, “A Vector Space Model for Automatic Indexing,” <i>Communications of the ACM</i>, vol. 18, no. 11, pp. 613–620, Nov. 1975.</span>

[<a href="http://doi.acm.org/10.1145/361219.361220">Online</a>]

</li></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:tfidf">
      <p>代码主要参考了<a href="http://stanford.edu/~rjweiss/public_html/IRiSS2013/text2/notebooks/tfidf.html">“The Vector Space Model of text”</a>，但文中计算有错误。 <a href="#fnref:tfidf" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:log-base">
      <p>$\log$的底是多少？ <a href="#fnref:log-base" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

</section>
<section align="right">
<p>
<img/ src="/assets/images/alipay2me.png" alt="打赏作者" style="width: 200px">
</p>
<br/>
<span>
  <a  href="/2015/03/industrial-robot-technique-development" class="pageNav"  >上一篇</a>
  &nbsp;&nbsp;&nbsp;
  <a   class="pageNavInvalid"  >下一篇</a>
</span>
</section>

	
	<ul class="ds-recent-visitors"></ul>
	<div class="ds-thread" data-thread-key="/2015/04/vector-space-model" data-url="http://qianjiye.de/2015/04/vector-space-model" data-title="向量空间模型">
	</div>
	<script type="text/javascript">
	var first_image = document.getElementsByClassName("post")[0].getElementsByTagName("img")[0]; 
	if (first_image != undefined) {
	document.getElementsByClassName("ds-thread")[0].setAttribute("data-image", first_image.src);
	}
	</script>
		
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"jiyeqian"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>


<!-- <script type="text/javascript"> -->
<!-- $(function(){ -->
<!--   $(document).keydown(function(e) { -->
<!--     var url = false; -->
<!--         if (e.which == 37 || e.which == 72) {  // Left arrow and H -->
<!--          -->
<!--         url = '/2015/03/industrial-robot-technique-development'; -->
<!--          -->
<!--         } -->
<!--         else if (e.which == 39 || e.which == 76) {  // Right arrow and L -->
<!--          -->
<!--         } else if (e.which == 75) {  // K -->
<!--           url = '#'; -->
<!--         } else if (e.which == 74) { // J -->
<!--         url = '/2015/04/vector-space-model/#timeSpan'; -->
<!--         } -->
<!--         if (url) { -->
<!--             window.location = url; -->
<!--         } -->
<!--   }); -->
<!-- }) -->
<!-- </script> -->

        </article>
      </div>

    <footer>
        <p><small>
            Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a> | Copyright 2014 - 2015 by <a href="/about/">Jiye Qian</a> | <span class="label label-info" id="timeSpan"></span></small></p>
    </footer>

    </div>
  </body>
</html>
