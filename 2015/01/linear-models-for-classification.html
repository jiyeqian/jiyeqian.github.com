<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Jiye Qian" />
    <title>线性分类模型</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <link href="/feed/" rel="alternate" title="Jiye Qian" type="application/atom+xml" />
    <link rel="stylesheet" href="/assets/css/style.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default_inline.css" />
    <link rel="stylesheet" href="/assets/css/coderay.css" />
    <link rel="stylesheet" href="/assets/css/twemoji-awesome.css" />  
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
    <link href="/assets/css/jquery-ui-1.10.4.custom.min.css" rel="stylesheet" />
    <link href="/assets/css/ggvis.css" rel="stylesheet" />
    <link href="/assets/css/mermaid.css" rel="stylesheet" />
    <link rel="stylesheet" href="/assets/css/markdown-plus.css"/> 
    <link rel="stylesheet" href="/assets/css/flexslider.css" type="text/css" media="screen" />
      <style type="text/css">
        .flex-caption {
          width: 96%;
          padding: 2%;
          left: 0;
          bottom: 0;
          background: rgba(0,0,0,.5);
          color: #fff;
          text-shadow: 0 -1px 0 rgba(0,0,0,.3);
          font-size: 14px;
          line-height: 18px;
        }
        li.css a {
          border-radius: 0;
        }
      </style>

    <script type="text/javascript" src="/assets/js/jquery.min.js"></script>
    <script type="text/javascript" src="/assets/js/jquery-ui-1.10.4.custom.min.js"></script>
    <script type="text/javascript" src="/assets/js/d3.min.js"></script>
    <script type="text/javascript" src="/assets/js/vega.min.js"></script>
    <script type="text/javascript" src="/assets/js/lodash.min.js"></script>
    <script>var lodash = _.noConflict();</script>
    <script type="text/javascript" src="/assets/js/ggvis.js"></script>
    <script type="text/javascript" src="/assets/js/htmlwidgets.js"></script>
    <script type="text/javascript" src="/assets/js/echarts-all.js"></script>
    <script type="text/javascript" src="/assets/js/echarts.js"></script>
    <script defer src="/assets/js/jquery.flexslider-min.js"></script>
    <script type="text/javascript">
      // $(function(){
      //   SyntaxHighlighter.all();
      // });
      $(window).load(function(){
        $('.flexslider').flexslider({
          animation: "slide",
          start: function(slider){
            $('body').removeClass('loading');
          }
        });
      });
    </script>

    <script type="text/javascript">
      function setTimeSpan(){
        var date = new Date();
        timeSpan.innerText=date.format('yyyy-MM-dd hh:mm:ss');
      }

      Date.prototype.format = function(format)
      {
        var o =
        {
          "M+" : this.getMonth()+1, //month
          "d+" : this.getDate(),    //day
          "h+" : this.getHours(),   //hour
          "m+" : this.getMinutes(), //minute
          "s+" : this.getSeconds(), //second
          "q+" : Math.floor((this.getMonth()+3)/3),  //quarter
          "S" : this.getMilliseconds() //millisecond
        }
        if(/(y+)/.test(format))
          format=format.replace(RegExp.$1,(this.getFullYear()+"").substr(4 - RegExp.$1.length));
        for(var k in o)
          if(new RegExp("("+ k +")").test(format))
            format = format.replace(RegExp.$1,RegExp.$1.length==1 ? o[k] : ("00"+ o[k]).substr((""+ o[k]).length));
          return format;
        }
      </script>

    <!-- MathJax for LaTeX -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        "HTML-CSS": { extensions: ["handle-floats.js"] },
        TeX: { equationNumbers: { autoNumber: "AMS" } },
        tex2jax: {
            inlineMath: [['$$$', '$$$'], ['$', '$'], ['\\(', '\\)']],
            processEscapes: true
        }
    });
    </script>
    <!-- <script type="text/javascript" src="/assets/js/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  <!-- <script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F0b514f17fd99b9fb4be74c94bdd2b7db' type='text/javascript'%3E%3C/script%3E"));
</script>
 -->
  </head>
<!--  <body>
-->

  <body onLoad="setInterval(setTimeSpan,1000);">
    <div id="container">
      <div id="main" role="main">
        <header>
        <h1>线性分类模型</h1>
        </header>
        <nav id="real_nav">
        
          <span><a title="Home" href="/">Home</a></span>
        
          <span><a title="Categories" href="/categories/">Categories</a></span>
        
          <span><a title="Tags" href="/tags/">Tags</a></span>
        
          <span><a title="About" href="/about/">About</a></span>
        
          <span><a title="Search" href="/search/">Search</a></span>
        
        </nav>
        <article class="content">
        <script type="text/javascript" src="/assets/js/outliner.js"></script>

<section class="meta">
<span class="time">
  <time datetime="2015-01-25">2015-01-25</time>
</span>

 |
<span class="categories">
  <i class="fa fa-share-alt"></i>
  
  <a href="/categories/#研究学术" title="研究学术">研究学术</a>&nbsp;
  
</span>


 |
<span class="tags">
  <i class="fa fa-tags"></i>
  
  <a href="/tags/#机器学习基础" title="机器学习基础">机器学习基础</a>&nbsp;
  
  <a href="/tags/#梯度下降法" title="梯度下降法">梯度下降法</a>&nbsp;
  
  <a href="/tags/#在线学习" title="在线学习">在线学习</a>&nbsp;
  
</span>

</section>
<section class="post">
<h2 id="section">回归用于分类</h2>

<p>线性分类器、线性回归和logistic回归，都采用了同样的线性评分函数
\[
s=\mathbf w^T\mathbf x
\]
它们之间的对比如下：
<img src="/assets/images/2015-01-25-linear-models-for-classification-linear-models.png" alt="线性模型" id="linear-models" /></p>

<p>最小化线性分类器的$E_{in}(\mathbf w)$更困难，它是NP-Hard，能否用回归方法解决分类问题？✅</p>

<p>线性分类器、线性回归和logistic回归，它们的误差函数分别可记为
\[
\mbox{err}_{0/1}(s,y)=[[\mbox{sign}(ys)\neq 1]];\quad
\mbox{err}_{SQR}(s,y)=(ys-1)^2;\quad
\mbox{err}_{CE}(s,y)=\ln(1+\exp(-ys))。
\]</p>

<div class="image_line" id="error-bound"><div class="image_card"><a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png"><img src="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png" alt="误差曲线对比" /></a><div class="caption">图 1:  误差曲线对比 [<a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png">PNG</a>]</div></div></div>

<p>上图展示了误差曲线的对比，为了比较方便，用$\mbox{err}_{SCE}(s,y)=\log_2(1+\exp(-ys))$代替$\mbox{err}_{CE}$。从图中容易看出
\[
\mbox{err}_{0/1}(s,y)\leq\mbox{err}_{SCE}(s,y)={1\over\ln 2}\mbox{err}_{CE}(s,y)，
\]
因此可得
\[
E_{in}^{0/1}(\mathbf w)\leq E_{in}^{SCE}(\mathbf w)={1\over\ln 2}E_{in}^{CE}(\mathbf w)\quad\mbox{and}\quad
E_{out}^{0/1}(\mathbf w)\leq E_{out}^{SCE}(\mathbf w)={1\over\ln 2}E_{out}^{CE}(\mathbf w)，
\]
从而可得
\[
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+\Omega^{0/1}\quad\mbox{or}\quad
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+{1\over\ln 2}\Omega^{CE}，
\]
$E_{out}^{0/1}$和$E_{in}^{SQR}$之间也存在同样的关系。从以上关系可以看出，做到$E_{in}^{CE}(\mathbf w)$很小时也可使$E_{out}^{0/1}(\mathbf w)$很小，那么用线性或logistic回归也可解决线性分类问题，
\[
g(\mathbf x)=\mbox{sign}(\mathbf w_{REG}^T\mathbf x)。
\]</p>

<p>PLA在数据线性可分时效率较高否则需要采用pocket算法，线性或logistic回归“容易”优化但采用了比$err_{0/1}$松散的误差上限。</p>

<p>可用线性回归设置PLA、pocket或logistic回归的初始值$\mathbf w_0$，logistic回归的计算复杂度和pocket相当，通常logistic回归的性能优于pocket。</p>

<h2 id="section-1">随机梯度下降法</h2>

<p>迭代优化时，参数更新可以表示为
\begin{equation*}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\mathbf v\quad(t=0,1,\ldots)。
\end{equation*}
PLA每次采用一个数据更新参数，但logistic的梯度下降法每次采用全部数据更新参数，显然logistic更新过程计算量大很多。logistic回归和pocket效率差不多，能否使logistic回归和PLA一样快呢？✅</p>

<p>logistic回归采用的参数更新方法是
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta{1\over N}\sum_{n=1}^N\theta\left(-y_n\mathbf w^T\mathbf x_n\right)(y_n\mathbf x_n)，
\end{equation}
按梯度负方向$\mathbf v=-\nabla E_{in}(\mathbf w)$更新。通过$n$个点计算可估计梯度，极端情况用1个点计算估计梯度，称为随机梯度。随机梯度可视为真实梯度与零均值噪声之和，经过足够过的迭代次数，平均的真实梯度和平均的随机梯度基本相同，可利用随机梯度更新参数，
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)(y_n\mathbf x_n)，
\end{equation}
这就是<strong>随机梯度下降法</strong>（SGD，stochastic gradient descent）。</p>

<p>随机梯度法的优点是简单且计算量小，有利于大数据和在线学习；其缺点是稳定性欠佳，尤其是$\eta$很大时。随机梯度法实现时需要处理两个问题：</p>

<ol>
  <li>停止条件：梯度下降法可通过梯度是否接近零作为停止条件，但是随机梯度法没有梯度计算，难以确定停止条件，通常用足够大的迭代次数$t$作为停止条件；</li>
  <li>选择合适的$\eta$：通常利用交叉验证选择，经验表明$\eta=0.1$在大多数情况下是不错的选择。</li>
</ol>

<p>回顾PLA的参数更新过程
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+1\cdot\left[\left[-y_n\neq\mbox{sign}(\mathbf w_t^T\mathbf x_n)\right]\right](y_n\mathbf x_n)，
\end{equation}
随机梯度下降法的logistic回归想当于soft-PLA，用$\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)$表示更新的力度；当$\eta=1$并且$\mathbf w_t^T\mathbf x$很大时，PLA和随机梯度下降法的logistic回归相似。利用随机梯度下降法的线性回归可以表示为
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+2\eta\left(y_n-\mathbf w_t^T\mathbf x_n\right)\mathbf x_n，
\end{equation}
$y_n-\mathbf w_t^T\mathbf x_n$表示错得越多，更新力度越大。</p>

<h2 id="multiple-classes">多分类问题</h2>

<p>采用one-vs-all的数据分割策略，利用logistic回归进行软性（softly）分类，选择“概率”大的类别
\begin{equation}
g(\mathbf x)=\arg\max_{k\in\mathcal Y}\theta\left(\mathbf w_{[k]}^T\mathbf x\right)=\arg\max_{k\in\mathcal Y}\mathbf w_{[k]}^T\mathbf x。
\end{equation}
one-vs-all方式的优点是简单易推广，并且很容易并行化训练每个分类器；它的坏处是当类别数$K$很大时，数据集$\mathcal D_{[k]}$的不平衡（unbalance）问题凸显。不平衡数据导致logistic回归通过误差最小化求解参数时，倾向于选择有利于数据量多的类别的假设。事实上，有专门的多分类logistic模型，例如<a href="/2016/03/cs231n_loss-functions-and-optimization/#softmax-classifier">softmax分类器</a>。</p>

<p>one-vs-one的方法有利于克服one-vs-all的数据不平衡问题，采用投票机制判断类别，类似循环赛，
\begin{equation}
g(\mathbf x)=\mbox{tournament champion}\left\{\mathbf w_{[k,l]}^T\mathbf x\right\}。
\end{equation}
one-vs-one方式训练每个分类器数据量较少，因此比较有效率，它克服了数据不平衡，以及利用了循环赛机制，所以更稳定；它的坏处是分类器数目更多，导致空间存储增大，预测时间增加，需要更多的训练<sup id="fnref:need-more-training"><a href="#fn:need-more-training" class="footnote">1</a></sup>，并且存在<a href="/2014/10/multiple-classes/#anbiguous-regions">有争议的判别区间</a>。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:need-more-training">
      <p>每个分类器数据少了，训练时间复杂度会增加吗？ <a href="#fnref:need-more-training" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

</section>
<section align="left">
<p></p>
<hr>
  <p><img/ src="/assets/images/alipay2me.png" alt="打赏作者" style="height: 160px"></p>
  <p></p>
<hr>
  <ul>
    
    <li class="pageNav">2016-10-09 &raquo; <a href="/2016/10/s13000-model">鲁棒及自适应控制（2）：模型</a></li>
    
    <li class="pageNav">2016-10-09 &raquo; <a href="/2016/10/nnml_introduction">NNML（01）：引言</a></li>
    
    <li class="pageNav">2016-09-24 &raquo; <a href="/2016/09/feasibility-about-home-camera-in-power-syetem-monitoring">家用监控设备用于电网的可行性分析</a></li>
    
    <li class="pageNav">2016-09-19 &raquo; <a href="/2016/09/feasibility-about-uav-in-cable-tunnel">无人机电缆隧道巡检可行性调研报告</a></li>
    
    <li class="pageNav">2016-09-18 &raquo; <a href="/2016/09/S13000-Introduction">鲁棒及自适应控制（1）：概论</a></li>
    
    <li class="pageNav">2016-09-13 &raquo; <a href="/2016/09/LeNet-5-Lecun">Gradient-Based Learning Applied to Document Recognition</a></li>
    
    <li class="pageNav">2016-03-15 &raquo; <a href="/2016/03/cs231n_loss-functions-and-optimization">CS231n（3）：损失函数与最优化</a></li>
    
    <li class="pageNav">2016-03-14 &raquo; <a href="/2016/03/cs231n_image-classification-pipeline">CS231n（2）：图像分类流程</a></li>
    
  </ul>
<p></p>
<span>
  <a  href="/2015/01/random-forest" class="pageNav" style="float:left"   >上一篇：分类器融合（4）：随机森林 </a>
  &nbsp;&nbsp;&nbsp;
  <a  href="/2015/01/nonlinear-transformation" class="pageNav" style="float:right"   >下一篇：非线性特征变换 </a>  
</span>
</section>

	<script type="text/javascript">
	var first_image = document.getElementsByClassName("post")[0].getElementsByTagName("img")[0]; 
	if (first_image != undefined) {
	document.getElementsByClassName("ds-thread")[0].setAttribute("data-image", first_image.src);
	}
	</script>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"jiyeqian"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<ul class="ds-recent-visitors" data-num-items="16"></ul>
	<div class="ds-thread"  data-thread-key="/2015/01/linear-models-for-classification" 	data-url="http://qianjiye.de/2015/01/linear-models-for-classification" data-title="线性分类模型">
	</div>	


<!-- <script type="text/javascript"> -->
<!-- $(function(){ -->
<!--   $(document).keydown(function(e) { -->
<!--     var url = false; -->
<!--         if (e.which == 37 || e.which == 72) {  // Left arrow and H -->
<!--          -->
<!--         url = '/2015/01/random-forest'; -->
<!--          -->
<!--         } -->
<!--         else if (e.which == 39 || e.which == 76) {  // Right arrow and L -->
<!--          -->
<!--         <1!-- url = 'http://qianjiye.de/2015/01/nonlinear-transformation'; --1> -->
<!--         url = '/2015/01/nonlinear-transformation'; -->
<!--          -->
<!--         } else if (e.which == 75) {  // K -->
<!--           url = '#'; -->
<!--         } else if (e.which == 74) { // J -->
<!--         url = '/2015/01/linear-models-for-classification/#timeSpan'; -->
<!--         } -->
<!--         if (url) { -->
<!--             window.location = url; -->
<!--         } -->
<!--   }); -->
<!-- }) -->
<!-- </script> -->

        </article>
      </div>

    <footer>
        <p><small>
            Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a> | Copyright 2014 - 2016 by <a href="/about/">Jiye Qian</a> | <span class="label label-info" id="timeSpan"></span></small></p>
    </footer>

    </div>
  </body>
</html>
