<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Jiye Qian" />
    <title>支持向量机（6）：支持向量回归</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <link href="/feed/" rel="alternate" title="Jiye Qian" type="application/atom+xml" />
    <link rel="stylesheet" href="/assets/css/style.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default_inline.css" />
    <link rel="stylesheet" href="/assets/css/coderay.css" />
    <link rel="stylesheet" href="/assets/css/twemoji-awesome.css" />  
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
    <link href="/assets/css/jquery-ui-1.10.4.custom.min.css" rel="stylesheet" />
    <link href="/assets/css/ggvis.css" rel="stylesheet" />
    <link href="/assets/css/mermaid.css" rel="stylesheet" />
    <link rel="stylesheet" href="/assets/css/markdown-plus.css"/> 
    <link rel="stylesheet" href="/assets/css/flexslider.css" type="text/css" media="screen" />
      <style type="text/css">
        .flex-caption {
          width: 96%;
          padding: 2%;
          left: 0;
          bottom: 0;
          background: rgba(0,0,0,.5);
          color: #fff;
          text-shadow: 0 -1px 0 rgba(0,0,0,.3);
          font-size: 14px;
          line-height: 18px;
        }
        li.css a {
          border-radius: 0;
        }
      </style>

    <script type="text/javascript" src="/assets/js/jquery.min.js"></script>
    <script type="text/javascript" src="/assets/js/jquery-ui-1.10.4.custom.min.js"></script>
    <script type="text/javascript" src="/assets/js/d3.min.js"></script>
    <script type="text/javascript" src="/assets/js/vega.min.js"></script>
    <script type="text/javascript" src="/assets/js/lodash.min.js"></script>
    <script>var lodash = _.noConflict();</script>
    <script type="text/javascript" src="/assets/js/ggvis.js"></script>
    <script type="text/javascript" src="/assets/js/htmlwidgets.js"></script>
    <script type="text/javascript" src="/assets/js/echarts-all.js"></script>
    <script type="text/javascript" src="/assets/js/echarts.js"></script>
    <script defer src="/assets/js/jquery.flexslider-min.js"></script>
    <script type="text/javascript">
      // $(function(){
      //   SyntaxHighlighter.all();
      // });
      $(window).load(function(){
        $('.flexslider').flexslider({
          animation: "slide",
          start: function(slider){
            $('body').removeClass('loading');
          }
        });
      });
    </script>

    <script type="text/javascript">
      function setTimeSpan(){
        var date = new Date();
        timeSpan.innerText=date.format('yyyy-MM-dd hh:mm:ss');
      }

      Date.prototype.format = function(format)
      {
        var o =
        {
          "M+" : this.getMonth()+1, //month
          "d+" : this.getDate(),    //day
          "h+" : this.getHours(),   //hour
          "m+" : this.getMinutes(), //minute
          "s+" : this.getSeconds(), //second
          "q+" : Math.floor((this.getMonth()+3)/3),  //quarter
          "S" : this.getMilliseconds() //millisecond
        }
        if(/(y+)/.test(format))
          format=format.replace(RegExp.$1,(this.getFullYear()+"").substr(4 - RegExp.$1.length));
        for(var k in o)
          if(new RegExp("("+ k +")").test(format))
            format = format.replace(RegExp.$1,RegExp.$1.length==1 ? o[k] : ("00"+ o[k]).substr((""+ o[k]).length));
          return format;
        }
      </script>

    <!-- MathJax for LaTeX -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        "HTML-CSS": { extensions: ["handle-floats.js"] },
        TeX: { equationNumbers: { autoNumber: "AMS" } },
        tex2jax: {
            inlineMath: [['$$$', '$$$'], ['$', '$'], ['\\(', '\\)']],
            processEscapes: true
        }
    });
    </script>
    <!-- <script type="text/javascript" src="/assets/js/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  <!-- <script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F0b514f17fd99b9fb4be74c94bdd2b7db' type='text/javascript'%3E%3C/script%3E"));
</script>
 -->
  </head>
<!--  <body>
-->

  <body onLoad="setInterval(setTimeSpan,1000);">
    <div id="container">
      <div id="main" role="main">
        <header>
        <h1>支持向量机（6）：支持向量回归</h1>
        </header>
        <nav id="real_nav">
        
          <span><a title="Home" href="/">Home</a></span>
        
          <span><a title="Categories" href="/categories/">Categories</a></span>
        
          <span><a title="Tags" href="/tags/">Tags</a></span>
        
          <span><a title="About" href="/about/">About</a></span>
        
          <span><a title="Search" href="/search/">Search</a></span>
        
        </nav>
        <article class="content">
        <script type="text/javascript" src="/assets/js/outliner.js"></script>

<section class="meta">
<span class="time">
  <time datetime="2015-01-12">2015-01-12</time>
</span>

 |
<span class="categories">
  <i class="fa fa-share-alt"></i>
  
  <a href="/categories/#研究学术" title="研究学术">研究学术</a>&nbsp;
  
</span>


 |
<span class="tags">
  <i class="fa fa-tags"></i>
  
  <a href="/tags/#机器学习基础" title="机器学习基础">机器学习基础</a>&nbsp;
  
  <a href="/tags/#支持向量机" title="支持向量机">支持向量机</a>&nbsp;
  
  <a href="/tags/#核方法" title="核方法">核方法</a>&nbsp;
  
  <a href="/tags/#回归" title="回归">回归</a>&nbsp;
  
</span>

</section>
<section class="post">
<h2 id="section">脊回归</h2>

<p>有正则化项的回归称为<strong>脊回归</strong>（ridge regression）。脊回归的核模型有解析解么？</p>

<p>脊回归的最优化模型为
\[
\min_{\mathbf w}\left({\lambda\over N}\mathbf w^T\mathbf w+{1\over N}\sum_{n=1}^N\left(y_n-\mathbf w^T\mathbf z_n\right)^2\right)，
\]
根据表示定理可知，存在形如$\mathbf w_*=\sum_{n=1}^N\beta_n\mathbf z_n$的最优解，将其带入并表示为核形式
\begin{equation}
\min_\beta\left({\lambda\over N}\sum_{n=1}^N\sum_{m=1}^N\beta_n\beta_mK(\mathbf x_n,\mathbf x_m)+{1\over N}\sum_{n=1}^N\left(y_n-\sum_{n=1}^N\beta_mK(\mathbf x_n,\mathbf x_m)\right)\right)。
\end{equation}
<strong>脊回归的核模型</strong>就是利用表示定理将脊回归核化。目标函数写为矩阵的形式
\begin{equation}
E_{aug}(\boldsymbol\beta)={\lambda\over N}\boldsymbol\beta^T\mathbf K\boldsymbol\beta + {1\over N}\left(\boldsymbol\beta^T\mathbf K^T\mathbf K\boldsymbol\beta-2\boldsymbol\beta^T\mathbf K^T\mathbf y + \mathbf y^T\mathbf y\right)，
\end{equation}
无约束最优化问题可以通过
\[
\nabla E_{aug}(\boldsymbol\beta)={2\over N}\left(\lambda\mathbf K^T\mathbf I\boldsymbol\beta+\mathbf K^T\mathbf K\boldsymbol\beta-\mathbf K^T\right)={2\over N}\mathbf K^T\left((\lambda\mathbf I+\mathbf K)\boldsymbol\beta-\mathbf y\right)
\]
令$\nabla E_{aug}(\boldsymbol\beta)=0$求解，
\begin{equation}
\boldsymbol\beta=(\mathbf K+\lambda\mathbf I)^{-1}\mathbf y。
\label{eq:analytic-solution-ridge-regression}
\end{equation}
根据Mercer条件可知$\mathbf K$半正定，并且$\lambda&gt;0$，因此矩阵总可逆。稠密矩阵求逆的时间复杂度为$O\left(N^3\right)$。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-ridge-regression-compare.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-ridge-regression-compare.png" alt="［左］：脊回归的线性模型；［右］：脊回归的核模型" /></a><div class="caption">图 1:  ［左］：脊回归的线性模型；［右］：脊回归的核模型 [<a href="/assets/images/2015-01-12-svm-support-vector-regression-ridge-regression-compare.png">PNG</a>]</div></div></div>

<p>上图中的蓝线是脊回归的效果。线性模型与核模型的选择是速度与效率的折中权衡，它们之间的对比如下表：</p>

<table>
  <thead>
    <tr>
      <th>线性模型</th>
      <th>核模型</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$\mathbf w = (\lambda\mathbf I+\mathbf X^T\mathbf X)^{-1}\mathbf X^T\mathbf y$</td>
      <td>$\boldsymbol\beta=(\lambda\mathbf I+\mathbf K)^{-1}\mathbf y$</td>
    </tr>
    <tr>
      <td>功能受限</td>
      <td>通过$K$实现强大的功能</td>
    </tr>
    <tr>
      <td>训练时间复杂度为$O\left(d^3+d^2N\right)$</td>
      <td>训练时间复杂度为$O\left(N^3\right)$</td>
    </tr>
    <tr>
      <td>预测时间复杂度为$O(d)$，当$N\gg d$时效率高</td>
      <td>预测时间复杂度为$O(N)$，当训练样本大时效率低</td>
    </tr>
  </tbody>
</table>

<p>当参数获得后，回归函数就可以用核表示为
\begin{equation}
g(\mathbf x)=\sum_{n=1}^N\beta_nK\left(\mathbf x_n, \mathbf x\right)。
\end{equation}</p>

<p>将脊回归的核模型用于分类就是<strong>最小二乘支持向量机</strong>（LSSVM，least-squares SVM），也就是用回归解决分类问题，虽然分类性能可能不佳，但用解析方法\eqref{eq:analytic-solution-ridge-regression}可“容易”求解系数。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-svm-vs-lssvm.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-svm-vs-lssvm.png" alt="最小二乘与soft-margin支持向量机的对比" /></a><div class="caption">图 2:  最小二乘与soft-margin支持向量机的对比 [<a href="/assets/images/2015-01-12-svm-support-vector-regression-svm-vs-lssvm.png">PNG</a>]</div></div></div>

<p>上图可以看出，最小二乘与soft-margin支持向量机的分类面很相似，但是LSSVM的支持向量要多得多，预测速度会很慢。</p>

<p>LSSVM和logistic回归的核模型得到的参数$\boldsymbol\beta$是稠密的，标准支持向量机的参数$\boldsymbol\alpha$是稀疏的。能否得到像标准支持向量机一样稀疏的$\boldsymbol\beta$呢？</p>

<h2 id="section-1">支持向量回归</h2>

<p>定义tube回归的误差为
\begin{equation}
err(y, s) = \max(0, \lvert s-y\rvert-\epsilon)，
\end{equation}
在tube区域内不计误差，在该区域外到tube的距离记为误差。</p>

<div class="image_line" id="tube-error-illustration"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-tube-vs-square-error.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-tube-vs-square-error.png" alt="tube与平方误差对比" /></a><div class="caption">图 3:  tube与平方误差对比 [<a href="/assets/images/2015-01-12-svm-support-vector-regression-tube-vs-square-error.png">PNG</a>]</div></div></div>

<p>如上图所示，tube与平方误差很相似，尤其是在$\lvert s-y\rvert$很小的区域内，当$\lvert s-y\rvert$很大时，tube误差不如平方误差变化陡峭，因此受噪声影响更小。</p>

<p>基于tube误差的模型能否得到稀疏的系数呢？</p>

<p>基于$L_2$正则化的tube回归模型为
\begin{equation*}
\min\limits_{\mathbf w}\left({\lambda\over N}\mathbf w^T\mathbf w+{1\over N}\sum_{n=1}^N\max\left(0, \left\lvert \mathbf w^T\mathbf z_n-y_n\right\rvert-\epsilon\right)\right)，
\end{equation*}
虽无约束，但$\max$导致不可微；利用表示定理可核化，但无法明确得到稀疏的系数。仿照<a href="/2015/01/kernel-logistic-regression/#mjx-eqn-equniform-soft-margin-svm">无约束形式</a>的soft-margin支持向量机，分离出$b$后改写为
\begin{equation*}
\min\limits_{b,\mathbf w}\left({1\over 2}\mathbf w^T\mathbf w+C\sum_{n=1}^N\max\left(0, \left\lvert \mathbf w^T\mathbf z_n+b-y_n\right\rvert-\epsilon\right)\right)，
\end{equation*}
虽然不可微，但是QP问题；对偶问题可核化，KKT条件能得到系数稀疏。再对比<a href="/2015/01/soft-margin-svm/#mjx-eqn-eqsoft-margin-primal-svm">约束形式</a>的soft-margin支持向量机，改写为带约束的优化问题
\begin{equation*}
\begin{aligned}
\min\limits_{b,\mathbf w,\boldsymbol\xi}&amp;\quad\frac{1}{2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\xi_n\\
\mbox{s.t.}&amp;\quad \left\lvert\mathbf w^T\mathbf z_n+b-y_n\right\rvert\leq \epsilon+\xi_n\\
&amp;\quad\xi_n\geq 0 \mbox{ for all }n，
\end{aligned}
\end{equation*}
约束条件线性化
\begin{equation}
\begin{aligned}
\min\limits_{b,\mathbf w,\boldsymbol\xi^\vee,\boldsymbol\xi^\wedge}&amp;\quad\frac{1}{2}\mathbf w^T\mathbf w + C\sum_{n=1}^N\left(\xi_n^\vee+\xi_n^\wedge\right)\\
\mbox{s.t.}&amp;\quad -\epsilon-\xi_n^\vee\leq y_n - \mathbf w^T\mathbf z_n-b\leq \epsilon+\xi_n^\wedge\\
&amp;\quad\xi_n^\vee\geq 0,\xi_n^\wedge\geq 0\mbox{ for all }n，
\end{aligned}
\end{equation}
这就是标准的<strong>支持向量回归</strong>（SVR，support vector regression）原问题，$\xi_n^\vee$和$\xi_n^\wedge$分别记录tube下届和上界违规，如<a href="#tube-error-illustration">上图左</a>所示的分界线下边和上边标红的线段。通过$C$对正则化和tube违规进行折中，调节参数$\epsilon$可控制tube的高度。该QP模型有$\tilde d+1+2N$个变量，$2N+2N$个约束条件。</p>

<p>将支持向量回归的原问题转成对偶问题，可移除对$\tilde d$的依赖。</p>

<h2 id="section-2">支持向量回归的对偶模型</h2>

<p>通过拉格朗日乘子法的KKT条件${\partial\mathcal L\over\partial\mathbf w}=0$可得
\begin{equation}
\mathbf w = \sum_{n=1}^N\left(\alpha_n^\wedge-\alpha_n^\vee\right)\mathbf z_n = \sum_{n=1}^N\beta_n\mathbf z_n，
\end{equation}
通过${\partial\mathcal L\over\partial b}=0$可得
\[
\sum_{n=1}^N\left(\alpha_n^\wedge-\alpha_n^\vee\right)＝0，
\]
互补松弛条件（complementary slackness）为
\begin{equation}
\left\{
\begin{aligned}
\alpha_n^\wedge\left(\epsilon+\xi_n^\wedge-y_n+\mathbf w^T\mathbf z_n+b\right)=&amp;0\\
\alpha_n^\vee\left(\epsilon+\xi_n^\vee+y_n-\mathbf w^T\mathbf z_n-b\right)=&amp;0。
\end{aligned}
\right.
\label{eq:complementary-slackness-svm-regession}
\end{equation}</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-12-svm-support-vector-regression-primal-vs-dual-QP.png"><img src="/assets/images/2015-01-12-svm-support-vector-regression-primal-vs-dual-QP.png" alt="QP原问题与对偶问题的对比" /></a><div class="caption">图 4:  QP原问题与对偶问题的对比 [<a href="/assets/images/2015-01-12-svm-support-vector-regression-primal-vs-dual-QP.png">PNG</a>]</div></div></div>

<p>上图左上和左下分别表示soft-margin支持向量机的原问题和对偶问题的QP模型；上图右上和右下分别表示支持向量回归的原问题和对偶问题的QP模型。上图中，相同颜色的符号展示了如何从原问题变化到对偶问题。</p>

<p>当数据点位于tube中有$\left\lvert\mathbf w^T\mathbf z_n+b-y_n\right\rvert&lt;\epsilon$，不计误差，$\xi_n^\wedge=\xi_n^\vee=0$，根据互补松弛条件\eqref{eq:complementary-slackness-svm-regession}可知
\[
\left\{
\begin{aligned}
\epsilon+\xi_n^\wedge-y_n+\mathbf w^T\mathbf z_n+b\neq &amp;0\\
\epsilon+\xi_n^\vee+y_n-\mathbf w^T\mathbf z_n-b\neq &amp;0，
\end{aligned}
\right.
\]
以及$\alpha_n^\wedge=\alpha_n^\vee＝0$，因此可得$\beta_n=0$。由此可知，支持向量回归问题中$\beta_n\neq 0$的支持向量刚好位于tube的边界上或在tube之外。</p>

<p>参考<a href="/2015/01/soft-margin-svm/#mjx-eqn-eqsoft-margin-complementary-slackness">soft-margin支持向量机</a>可得
\begin{equation}
b=
\left\{
\begin{aligned}
y_n-\mathbf w^T\mathbf z_n-\epsilon&amp;\quad(0&lt;\alpha_n^\wedge&lt;C)\\
y_n-\mathbf w^T\mathbf z_n+\epsilon&amp;\quad(0&lt;\alpha_n^\vee&lt;C)。
\end{aligned}
\right.
\end{equation}</p>


</section>
<section align="left">
<p></p>
<hr>
  <p><img/ src="/assets/images/alipay2me.png" alt="打赏作者" style="height: 160px"></p>
  <p></p>
<hr>
  <ul>
    
    <li class="pageNav">2017-06-22 &raquo; <a href="/2017/06/a-byte-of-ct-uav">A Byte of CT UAV</a></li>
    
    <li class="pageNav">2016-10-24 &raquo; <a href="/2016/10/nnml-bp-learning">NNML（03）：BP 学习</a></li>
    
    <li class="pageNav">2016-10-16 &raquo; <a href="/2016/10/nnml-perceptron-learning">NNML（02）：感知器学习</a></li>
    
    <li class="pageNav">2016-10-09 &raquo; <a href="/2016/10/s13000-model">鲁棒及自适应控制（2）：模型</a></li>
    
    <li class="pageNav">2016-10-09 &raquo; <a href="/2016/10/nnml_introduction">NNML（01）：引言</a></li>
    
    <li class="pageNav">2016-09-24 &raquo; <a href="/2016/09/feasibility-about-home-camera-in-power-syetem-monitoring">家用监控设备用于电网的可行性分析</a></li>
    
    <li class="pageNav">2016-09-19 &raquo; <a href="/2016/09/feasibility-about-uav-in-cable-tunnel">无人机电缆隧道巡检可行性调研报告</a></li>
    
    <li class="pageNav">2016-09-18 &raquo; <a href="/2016/09/s13000-Introduction">鲁棒及自适应控制（1）：概论</a></li>
    
  </ul>
<p></p>
<span>
  <a  href="/2015/01/kernel-logistic-regression" class="pageNav" style="float:left"   >上一篇：支持向量机（5）：核logistic回归 </a>
  &nbsp;&nbsp;&nbsp;
  <a  href="/2015/01/linear-regression" class="pageNav" style="float:right"   >下一篇：线性回归 </a>  
</span>
</section>

	<script type="text/javascript">
	var first_image = document.getElementsByClassName("post")[0].getElementsByTagName("img")[0]; 
	if (first_image != undefined) {
	document.getElementsByClassName("ds-thread")[0].setAttribute("data-image", first_image.src);
	}
	</script>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"jiyeqian"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<ul class="ds-recent-visitors" data-num-items="16"></ul>
	<div class="ds-thread"  data-thread-key="/2015/01/support-vector-regression" 	data-url="http://qianjiye.de/2015/01/support-vector-regression" data-title="支持向量机（6）：支持向量回归">
	</div>	


<!-- <script type="text/javascript"> -->
<!-- $(function(){ -->
<!--   $(document).keydown(function(e) { -->
<!--     var url = false; -->
<!--         if (e.which == 37 || e.which == 72) {  // Left arrow and H -->
<!--          -->
<!--         url = '/2015/01/kernel-logistic-regression'; -->
<!--          -->
<!--         } -->
<!--         else if (e.which == 39 || e.which == 76) {  // Right arrow and L -->
<!--          -->
<!--         <1!-- url = 'http://qianjiye.de/2015/01/linear-regression'; --1> -->
<!--         url = '/2015/01/linear-regression'; -->
<!--          -->
<!--         } else if (e.which == 75) {  // K -->
<!--           url = '#'; -->
<!--         } else if (e.which == 74) { // J -->
<!--         url = '/2015/01/support-vector-regression/#timeSpan'; -->
<!--         } -->
<!--         if (url) { -->
<!--             window.location = url; -->
<!--         } -->
<!--   }); -->
<!-- }) -->
<!-- </script> -->

        </article>
      </div>

    <footer>
        <p><small>
            Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a> | Copyright 2014 - 2017 by <a href="/about/">Jiye Qian</a> | <span class="label label-info" id="timeSpan"></span></small></p>
    </footer>

    </div>
  </body>
</html>
