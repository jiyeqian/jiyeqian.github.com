<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Jiye Qian" />
    <title>机器学习：Logistic回归</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <link href="/feed/" rel="alternate" title="Jiye Qian" type="application/atom+xml" />
    <link rel="stylesheet" href="/assets/css/style.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default.css" />
    <link rel="stylesheet" href="/assets/css/pygments/default_inline.css" />
    <link rel="stylesheet" href="/assets/css/coderay.css" />

    <script type="text/javascript" src="/assets/js/jquery-1.7.1.min.js"></script>
    <script type="text/javascript" src="/assets/js/outliner.js"></script>

    <!-- MathJax for LaTeX -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        "HTML-CSS": { extensions: ["handle-floats.js"] },
        TeX: { equationNumbers: { autoNumber: "AMS" } },
        tex2jax: {
            inlineMath: [['$$$', '$$$'], ['$', '$'], ['\\(', '\\)']],
            processEscapes: true
        }
    });
    </script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F0b514f17fd99b9fb4be74c94bdd2b7db' type='text/javascript'%3E%3C/script%3E"));
</script>

  </head>
<!--  <body>
-->
  <script type="text/javascript">
    function setTimeSpan(){
    	var date = new Date();
    	timeSpan.innerText=date.format('yyyy-MM-dd hh:mm:ss');
    }

    Date.prototype.format = function(format)
		{
    var o =
    	{
    	    "M+" : this.getMonth()+1, //month
    	    "d+" : this.getDate(),    //day
    	    "h+" : this.getHours(),   //hour
    	    "m+" : this.getMinutes(), //minute
    	    "s+" : this.getSeconds(), //second
    	    "q+" : Math.floor((this.getMonth()+3)/3),  //quarter
    	    "S" : this.getMilliseconds() //millisecond
    	}
    	if(/(y+)/.test(format))
    	format=format.replace(RegExp.$1,(this.getFullYear()+"").substr(4 - RegExp.$1.length));
    	for(var k in o)
    	if(new RegExp("("+ k +")").test(format))
    	format = format.replace(RegExp.$1,RegExp.$1.length==1 ? o[k] : ("00"+ o[k]).substr((""+ o[k]).length));
    	return format;
		}
  </script>
  <body onLoad="setInterval(setTimeSpan,1000);">
    <div id="container">
      <div id="main" role="main">
        <header>
        <h1>机器学习：Logistic回归</h1>
        </header>
        <nav id="real_nav">
        
          <span><a title="Home" href="/">Home</a></span>
        
          <span><a title="Categories" href="/categories/">Categories</a></span>
        
          <span><a title="Tags" href="/tags/">Tags</a></span>
        
          <span><a title="Logs" href="/logs/">Logs</a></span>
        
          <span><a title="About" href="/about/">About</a></span>
        
          <span><a title="Subscribe" href="/feed/">Subscribe</a></span>
        
        </nav>
        <article class="content">
        <section class="meta">
<span class="time">
  <time datetime="2014-10-19">2014-10-19</time>
</span>

 |
<span class="categories">
  categories
  
  <a href="/categories/#研究学术" title="研究学术">研究学术</a>&nbsp;
  
</span>


 |
<span class="tags">
  tags
  
  <a href="/tags/#机器学习" title="机器学习">机器学习</a>&nbsp;
  
  <a href="/tags/#Logistic回归" title="Logistic回归">Logistic回归</a>&nbsp;
  
</span>

</section>
<section class="post">
<h2 id="section">模型介绍</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-10-19-logistic_regression_0.png"><img src="/assets/images/2014-10-19-logistic_regression_0.png" alt="Logistic函数" /></a><div class="caption">Figure 1:  Logistic函数 [<a href="/assets/images/2014-10-19-logistic_regression_0.png">PNG</a>]</div></div></div>

<p>Logistic回归（Logistic Regression）用于解决二分类问题，而非回归问题。Logistic函数将回归问题转化为了分类问题。</p>

<p>Logistic回归模型为
\begin{equation}
h_{\boldsymbol{\theta}}(\mathbf x) = g\left(\boldsymbol\theta^T\mathbf x\right),
\end{equation}
其中
\begin{equation}
g\left(z\right) = \frac{1}{1 + e^{-z}}.
\label{eq:sigmoid-function}
\end{equation}</p>

<p>上式也称为Sigmoid函数或Logistic函数，如<a href="#figure-1">图1</a>所示，其导数为
\begin{equation}
g’\left(z\right) = g\left(z\right)\left(1-g\left(z\right)\right).
\label{eq:d-sigmoid-function}
\end{equation}</p>

<p>分类问题的判别条件为
\begin{equation}
y = \left\{
\begin{aligned}
&amp; 1 &amp; h_\boldsymbol\theta(\mathbf x) \ge 0.5 \\
&amp; 0 &amp; h_\boldsymbol\theta(\mathbf x) &lt; 0.5
\end{aligned},
\right. 
\end{equation}
也就是，若$\boldsymbol\theta^T\mathbf x \ge 0$，则$y = 1$；若$\boldsymbol\theta^T\mathbf x &lt; 0$，则$y = 0$。Logistic回归模型可以看作是计算属于类别1的概率
\begin{equation}
h_\boldsymbol\theta\left(\mathbf x\right) = \frac{1}{1 + e^{-\boldsymbol\theta^T\mathbf x}} = P\left(y=1\big|\mathbf x; \boldsymbol\theta\right)
\end{equation}</p>

<p>因此，对于而分类问题，有
\begin{equation}
P\left(y=0\big|\mathbf x; \boldsymbol\theta\right) ＝ 1 - P\left(y=1\big|\mathbf x; \boldsymbol\theta\right) ＝ 1 - h_\boldsymbol\theta\left(\mathbf x\right)
\end{equation}</p>

<p>$\boldsymbol\theta^T\mathbf x = 0$称为决策界（Decision Boundary）。决策界可以时线性的，也可以是非线性的。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-10-19-logistic_regression_2.png"><img src="/assets/images/2014-10-19-logistic_regression_2.png" alt="线性决策界" /></a><div class="caption">Figure 2:  线性决策界 [<a href="/assets/images/2014-10-19-logistic_regression_2.png">PNG</a>]</div></div></div>
<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-10-19-logistic_regression_3.png"><img src="/assets/images/2014-10-19-logistic_regression_3.png" alt="非线性决策界" /></a><div class="caption">Figure 3:  非线性决策界 [<a href="/assets/images/2014-10-19-logistic_regression_3.png">PNG</a>]</div></div></div>

<h2 id="section-1">代价函数</h2>

<p>线性回归的代价函数框架为：</p>

<p>\begin{equation}
J(\boldsymbol\theta) = \frac{1}{m}\sum_{i=1}^{m}\frac{1}{2}{\left(h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)}\right)^2}
\end{equation}</p>

<p>令</p>

<p>\begin{equation}
\mbox{Cost}\left(h_\boldsymbol\theta(\mathbf x), y\right) = \frac{1}{2}\left( h_\boldsymbol\theta(\mathbf x) - y \right) ^ 2
\end{equation}</p>

<p>当$h_\boldsymbol\theta(\mathbf x)$为Logistic回归模型（<a href="#fig4">图4</a>左）和线性回归模型（<a href="#fig4">图4</a>右）时，分别为非凸函数和凸函数，非凸函数不能用梯度下降法找到全局最优解。因此，Logistic回归需要采用新的代价函数才能用梯度下降法求解。</p>

<div class="image_line" id="cost_function_curve"><div class="image_card"><a href="/assets/images/2014-10-19-logistic_regression_1.png"><img src="/assets/images/2014-10-19-logistic_regression_1.png" alt="代价函数" /></a><div class="caption">Figure 4:  代价函数 [<a href="/assets/images/2014-10-19-logistic_regression_1.png">PNG</a>]</div></div></div>

<p>Logistic回归采用</p>

<p>\begin{equation}
\mbox{Cost}\left(h_\boldsymbol\theta(\mathbf x), y\right) = \left\{
\begin{aligned}
&amp; -\log\left(h_\boldsymbol\theta(\mathbf x)\right) &amp; y=1 \\
&amp; -\log\left(1-h_\boldsymbol\theta(\mathbf x)\right) &amp; y=0
\end{aligned}
\right. 
\end{equation}</p>

<p>上式等价于</p>

<p>\begin{equation}
\mbox{Cost}\left(h_\boldsymbol\theta(\mathbf x), y\right) = -y\log\left(h_\boldsymbol\theta(\mathbf x)\right) - (1 - y)\log\left(1-h_\boldsymbol\theta(\mathbf x)\right)
\end{equation}</p>

<p>因此，Logistic回归的代价函数为</p>

<p>\begin{equation}
\begin{aligned}
J(\boldsymbol\theta)<br />
= &amp; \frac{1}{m}\sum_{i=1}^{m}\mbox{Cost}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right), y^{(i)}\right) \\
= &amp; -\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)\right)\right)
\end{aligned}
\label{eq:cost_function_logistic_regression}
\end{equation}</p>

<blockquote>
  <p>若套用线性回归的代价函数，则$J(\boldsymbol\theta)$非凸，不利于优化算法。该代价函数可从统计中最大似然估计（maximum likehood estimation）的角度推导。</p>
</blockquote>

<h2 id="section-2">参数估计</h2>

<p>参数估计是通过最小化代价函数\eqref{eq:cost_function_logistic_regression}，求解模型参数$\boldsymbol\theta$。</p>

<p>\[
\min_\boldsymbol\theta J(\boldsymbol\theta)
\]</p>

<h3 id="section-3">梯度下降法</h3>

<p>貌似线性回归的梯度下降法的结构，但注意$h_\theta$的定义不同。</p>

<p>repeat until convergence {
\[
\boldsymbol\theta_j := \boldsymbol\theta_j - \alpha\frac{1}{m}\sum_{i=1}^m\left(h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)-y^{(i)}\right)\mathbf x_j^{(i)}~~~~~~(j = 0, 1, \ldots, n)
\]
}</p>

<p><strong>注意事项</strong></p>

<ul>
  <li>特征尺度规范化对加速Logistic回归的梯度下降法依然有效；</li>
  <li>其它注意事项同梯度下降法求解线性回归参数。</li>
</ul>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2014-10-19-logistic_regression_4.png"><img src="/assets/images/2014-10-19-logistic_regression_4.png" alt="采用Matlab的优化框架求解模型参数" /></a><div class="caption">Figure 5:  采用Matlab的优化框架求解模型参数 [<a href="/assets/images/2014-10-19-logistic_regression_4.png">PNG</a>]</div></div></div>

<h3 id="section-4">其它算法</h3>

<ul>
  <li>Conjugate gradient</li>
  <li>BFGS</li>
  <li>L-BFGS</li>
</ul>

<blockquote>
  <p>这几种算法不需要手工选择学习率$\alpha$，通常比梯度下降法快，但是更复杂。</p>
</blockquote>

<h2 id="section-5">思考问题</h2>

<ol>
  <li>代价函数如何求偏导？</li>
</ol>

<h2 id="section-6">应用范例</h2>

<h2 id="section-7">参考资料</h2>

<ol>
  <li><a href="https://class.coursera.org/ml-007">Machine Learning （Andrew Ng）</a>  </li>
  <li><a href="http://en.wikipedia.org/wiki/Logistic_regression">Wikipedia: Logistic regression</a></li>
</ol>


</section>
<section align="right">
<br/>
<span>
  <a  href="/2014/10/machine-learning-linear-regression" class="pageNav"  >上一篇</a>
  &nbsp;&nbsp;&nbsp;
  <a  href="/2014/10/machine-learning-multiple-classification" class="pageNav"  >下一篇</a>
</span>
</section>

	
	<ul class="ds-recent-visitors"></ul>
	<div class="ds-thread" data-thread-key="/2014/10/machine-learning-logistic-regression" data-url="http://qianjiye.de/2014/10/machine-learning-logistic-regression" data-title="机器学习：Logistic回归">
	</div>
	<script type="text/javascript">
	var first_image = document.getElementsByClassName("post")[0].getElementsByTagName("img")[0]; 
	if (first_image != undefined) {
	document.getElementsByClassName("ds-thread")[0].setAttribute("data-image", first_image.src);
	}
	</script>
		
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"jiyeqian"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>


<!-- <script type="text/javascript"> -->
<!-- $(function(){ -->
<!--   $(document).keydown(function(e) { -->
<!--     var url = false; -->
<!--         if (e.which == 37 || e.which == 72) {  // Left arrow and H -->
<!--          -->
<!--         url = '/2014/10/machine-learning-linear-regression'; -->
<!--          -->
<!--         } -->
<!--         else if (e.which == 39 || e.which == 76) {  // Right arrow and L -->
<!--          -->
<!--         <1!-- url = 'http://qianjiye.de/2014/10/machine-learning-multiple-classification'; --1> -->
<!--         url = '/2014/10/machine-learning-multiple-classification'; -->
<!--          -->
<!--         } else if (e.which == 75) {  // K -->
<!--           url = '#'; -->
<!--         } else if (e.which == 74) { // J -->
<!--         url = '/2014/10/machine-learning-logistic-regression/#timeSpan'; -->
<!--         } -->
<!--         if (url) { -->
<!--             window.location = url; -->
<!--         } -->
<!--   }); -->
<!-- }) -->
<!-- </script> -->

        </article>
      </div>

    <footer>
        <p><small>
            Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a> | Copyright 2014 - 2014 by <a href="/about/">Jiye Qian</a> | <span class="label label-info" id="timeSpan"></span></small></p>
    </footer>

    </div>
  </body>
</html>
