<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2014-12-19T09:29:14+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>机器学习：训练与测试</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-training-versus-testing" />
      <pubdate>2014-12-18T04:32:08+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-training-versus-testing</guid>
      <content:encoded>&lt;![CDATA[<p>本节的主要内容来自Hsuan-Tien Lin的机器学习基石课程<a href="#lin_ml_tt_2014">[1]</a>。</p>

<p>学习的两个核心问题：</p>

<ol>
  <li>能确保$E_{out}(g)$接近$E_{in}(g)$么？</li>
  <li>能够使$E_{in}(g)$足够小么？</li>
</ol>

<p>$\lvert\mathcal H\rvert=M$与上述两个问题有什么关系？</p>

<p>太小的$M$使坏事儿发生的概率小，$E_{out}(g)$接近$E_{in}(g)$接近的概率大，但是不一定能找到很小的$E_{in}(g)$；太大的$M$使坏事儿发生的概率增大了。</p>

<h2 id="m">M的起源</h2>

<p>坏事情（$\mathcal B$AD Event）$\mathcal B_m~\left(\left\lvert E_{in}(h_m) - E_{out}(h_m)\right\rvert &gt; \epsilon\right)$发生的概率为</p>

<p>\begin{equation*}
\begin{aligned}
P(\mbox{BAD}) &amp; = P(\mathcal B_1 \mbox{ or }\mathcal B_2 \mbox{ or }\ldots\mathcal B_M) \\
&amp;\leq P(\mathcal B_1) + P(\mathcal B_2) + \ldots + P(\mathcal B_M)\\
&amp;\leq 2M\exp\left(-2\epsilon^2N\right)
\end{aligned}。
\end{equation*}</p>

<p>事实上，过高的估计了坏事情发生的概率上界，因为$\mathcal B_m$之间可能有很大的相似区域重叠，比如感知器算法两次的判别界很接近。因此，可以期望得到比$M$小得多的值约束这个概率上界，也就是$\mathcal H$中的元素个数不会太多。</p>

<h2 id="section">有效判别界</h2>

<p>在$H$中，对相似的假设（判别函数）进行分组合并，有效减少假设的数目$M$。以下两图通过2维平面的线性判别界为例说明判别函数的类别。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-1-2.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-1-2.png" alt="［左］：1个点的分类情况；［右］：2个点的分类情况" /></a><div class="caption">Figure 1:  ［左］：1个点的分类情况；［右］：2个点的分类情况 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-1-2.png">PNG</a>]</div></div></div>

<p>上图左可见，对于只有1个点的数据集，只有2种分类情况，$\mathcal H$只需2种假设就够了；上图右可见，对于2个点的数据集，有4种分类情况，$\mathcal H$只需4种假设就够了。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-3-4.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-3-4.png" alt="［左］：3个点的分类情况；［右］：4个点的部分分类情况" /></a><div class="caption">Figure 2:  ［左］：3个点的分类情况；［右］：4个点的部分分类情况 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-3-4.png">PNG</a>]</div></div></div>

<p>上图中，打叉表示线性不可分。上图左可见，对于有3个点的数据集，有6种分类情况，$\mathcal H$只需6种假设就够了；上图右可见，对于4个点的数据集，有14种分类情况（图中只画出了其中一半的情况），$\mathcal H$只需14种假设就够了。</p>

<p>$N$输入数据$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$所需判别界的类别数目称之为判别界的有效数目（effective number of lines）。通过分析可知，$\mbox{effective}(N)\leq 2^N$，用其代替$M$可得
\begin{equation}
P\left[\left\lvert E_{in}(g) - E_{out}(g)\right\rvert &gt; \epsilon\right]\leq 2\cdot\mbox{effective}(N)\cdot\exp\left(-2\epsilon^2N\right)。
\end{equation}</p>

<h2 id="section-1">成长函数</h2>

<p>将$h(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)=(h(\mathbf x_1), h(\mathbf x_2), \ldots, h(\mathbf x_N))\in\{\times, \circ\}^N$称为一个二分法（dichotomy）。这就将假设限定在了数据集$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$上。$\mathcal H(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)$表示$\mathcal H$在$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$上的所有二分法。</p>

<p>$\lvert\mathcal H(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)\rvert$的大小受数据$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$的影响，不同的$N$个点，得到的值可能不一样。将成长函数（growth function）定义为
\begin{equation}
m_{\mathcal H}(N) = \max_{\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N\in\mathcal X}\lvert\mathcal H(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)\rvert，
\end{equation}
成长函数消除数据集依赖，是$N$个点数据集二分法数目的最大值，最大值为$2^N$。</p>

<p>对2维平面的线性判别界，$m_{\mathcal H}(1)=2$、$m_{\mathcal H}(2)=4$、$m_{\mathcal H}(3)=8$、$m_{\mathcal H}(4)=14$。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-growth-function-1D-lines.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-growth-function-1D-lines.png" alt="［左］：1维空间正射线判别函数；［右］：1维空间正区间判别函数" /></a><div class="caption">Figure 3:  ［左］：1维空间正射线判别函数；［右］：1维空间正区间判别函数 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-growth-function-1D-lines.png">PNG</a>]</div></div></div>

<p>上图左，对1维空间的正射线判别函数，$\mathcal X = \mathbb R$，$h(x)=\mbox{sign}(x-a)$（$a$是分类阈值），$m_{\mathcal H}(N)=N+1$。</p>

<p>上图右，对1维空间的正区间判别函数，$\mathcal X = \mathbb R$，
\[
h(x)=\left\{
\begin{aligned}
&amp;+1 &amp;x\in[\ell, r)\\
&amp;-1 &amp;\mbox{otherwise}
\end{aligned}
\right. ，
\]
$m_{\mathcal H}(N)=\binom{N+1}{2}+1={1\over 2}N^2+{1\over 2}N + 1$。</p>

<h2 id="section-2">断点</h2>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-shattered.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-shattered.png" alt="假设集打碎输入数据" /></a><div class="caption">Figure 4:  假设集打碎输入数据 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-shattered.png">PNG</a>]</div></div></div>

<p>对于2维平面上的$N$个点，$\mathcal X\in \mathbb R^2$，若$\mathcal H$是凸包，那么如上图所示，$m_{\mathcal H}(N)=2^N$。</p>

<p>如果$N$个点的所有二分法都能被$\mathcal H$实现，就称这$N$个点被$\mathcal H$打碎（shatter）。也就是，若$m_{\mathcal H}(N)=2^N$，当且仅当$N$个点能被打碎。</p>

<p>如果$k$个点不能被$\mathcal H$打碎，就称$k$是$\mathcal H$的一个断点（break point）。显然，$m_{\mathcal H}(k)=2^k$。如果$k$是断电，那么$k,k+1,k+2,\ldots$都是断点，通常研究最小的断点$k$。</p>

<p>正射线和正区间判别函数的最小断点分别是$2$和$3$，2维感知器的最小断点是$4$，凸包没有断点。</p>

<h2 id="section-3">成长函数与断点</h2>

<p>$m_{\mathcal H}(N)=O\left(N^{k-1}\right)$。</p>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="lin_ml_tt_2014">[1]H.-T. Lin, “Lecture 5: Training versus Testing.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li></ol>

<h3 id="section-5">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：学习的可行性</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-feasibility-of-learning" />
      <pubdate>2014-12-14T06:19:24+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-feasibility-of-learning</guid>
      <content:encoded>&lt;![CDATA[<p>本节的主要内容来自Hsuan-Tien Lin的机器学习基石课程<a href="#lin_ml_fl_2014">[1]</a>。</p>

<p>Learning is PAC-possible, if enough statistical data and finite $\left\lvert\mathcal H\right\rvert$.</p>

<h2 id="section">基本定义</h2>

<ul>
  <li>未知的目标函数 $f:\mathcal X \rightarrow\mathcal Y$；</li>
  <li>$\mathcal X$的分布$P$；</li>
  <li>训练集 $\mathcal D:\left(\mathbf x_1,y_1\right),\ldots,\left(\mathbf x_N,y_N\right)$；</li>
  <li>学习算法 $\mathcal A$；</li>
  <li>假设集 $\mathcal H$。</li>
</ul>

<p>机器学习的任务就是找到$f$的近似$g$，使得$g\approx f$。利用学习算法$\mathcal A$，通过数据集$\mathcal D$，从$\mathcal H$中找到合适的$h$，当$g=h$有$g\approx f$。</p>

<h2 id="hoeffding">Hoeffding不等式</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-bin-and-sample.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-bin-and-sample.png" alt="估计罐中橙色弹珠的概率" /></a><div class="caption">Figure 1:  估计罐中橙色弹珠的概率 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-bin-and-sample.png">PNG</a>]</div></div></div>

<p>能用从罐中抽样出橙色弹珠的比率$\nu$，作为罐中橙色弹珠出现概率$\mu$的估计么？Hoeffding不等式给出了答案，
\begin{equation}
P\left[\lvert\nu-\mu\rvert&gt;\epsilon\right]\leq 2\exp\left(-2\epsilon^2N\right)，
\end{equation}
当$N$很大时，$\nu$和$\mu$可能很接近（PAC，Probably Approximately Correct）。一个大的$N$和松散的$\epsilon$约束，使得$\nu\approx\mu$。</p>

<blockquote>
  <h4 id="section-1">问题</h4>
  <hr />
  <p>设$\mu=0.4$，若从罐中抽$10$个弹珠得到$\nu\leq 0.1$。利用Hoeffding不等式估计发生这样情况的概率界。</p>

  <p>答案：$0.33$（该概率的精确值是$0.05$）</p>

  <p>这个问题等价于：已知一次伯努利实验成功的概率为$0.4$，求$10$重伯努利实验中，最多出现一次成功的概率。
\begin{equation*}
\begin{aligned}
P(最多一次成功) = &amp;P(10次都不成功) + P(仅有1次成功）\\
    = &amp; 0.6^{10}+  \binom{10}{1} \times 0.4^1 \times 0.6^9\\
    = &amp;0.0464 \approx 0.05
\end{aligned}
\end{equation*}</p>
</blockquote>

<h2 id="section-2">概率与机器学习</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-connection2learning.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-connection2learning.png" alt="从概率到机器学习" /></a><div class="caption">Figure 2:  从概率到机器学习 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-connection2learning.png">PNG</a>]</div></div></div>

<p>如上图所示，将罐中的弹珠当作$\mathcal X$。对某个特定的假设$h$，若$h(\mathbf x)\neq f(\mathbf x)$则将弹珠涂为橙色，若$h(\mathbf x)= f(\mathbf x)$则将弹珠涂为绿色。将机器学习的可行性用概率问题进行判断。</p>

<p>对特定的$h$，抽样出来$N$个数据的in-sample误差定义为
\begin{equation}
E_{in}\left(h\right) = {1\over N}\sum_{n=1}^N\left[\left[h\left(x_n\right)\neq y_n\right]\right]，
\end{equation}
$\mathcal X$中数据的out-sample误差定义为
\begin{equation}
E_{out}\left(h\right) = \varepsilon_{\mathbf x\sim P}\left[\left[h\left(\mathbf x\right)\neq f\left(\mathbf x\right)\right]\right]，
\end{equation}
于是得到类似的Hoeffding不等式
\begin{equation}
P\left[\left\lvert E_{in}\left(h\right)-E_{out}\left(h\right)\right\rvert&gt;\epsilon\right]\leq 2\exp\left(-2\epsilon^2N\right)。
\end{equation}</p>

<p>由上式可知，对所有$N$和$\epsilon$而言，在不需要知道$E_{out}\left(h\right)$、$f$和$P$的前提下，$E_{in}\left(h\right)=E_{out}\left(h\right)$近似可能正确。也就是说，如果$E_{in}\left(h\right)\approx E_{out}\left(h\right)$并且$E_{in}\left(h\right)$很小，可以得出$E_{out}\left(h\right)$也很小，进而可以得出对于同样分布$P$的数据$h\approx f$。</p>

<p>如果令$g=h$，上述情况是否表明学习是可行的了呢？事实上，上述情况只是验证了某个特定的$h$，机器学习是要从$\mathcal H$中找出满足条件的$h$作为$g$，还没有$h$选择的过程。</p>

<h2 id="section-3">从概率到机器学习</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-many-hypothesis.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-many-hypothesis.png" alt="多个假设" /></a><div class="caption">Figure 3:  多个假设 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-many-hypothesis.png">PNG</a>]</div></div></div>

<p>不好的数据集（BAD Data）是指，存在$h$使得该数据集上$E_{out}\left(h\right)$和$E_{in}\left(h\right)$差异很大。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-bad-data.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-bad-data.png" alt="不好的数据集" /></a><div class="caption">Figure 4:  不好的数据集 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-bad-data.png">PNG</a>]</div></div></div>

<p>上图中$\mathcal D_i$表示有$N$个数据点的数据集，<code>BAD</code>标注的是不好的数据集。每个$h_j$对应行上出现<code>BAD</code>的概率通过Hoeffding定理限定，对某个$h_j$，$E_{out}\left(h\right)$和$E_{in}\left(h\right)$差异很大的概率是受约束的。Hoeffding定理保证的是每行不会有太多的<code>BAD</code>。</p>

<p>如果某个数据集$\mathcal D_i$上，对至少一个$h_j$是不好的数据集，也就是上图中的列至少存在一个<code>BAD</code>，那么在该数据集上，不能通过算法$\mathcal A$自由的从假设$\mathcal H$中选择$h$，因为总存在$E_{out}\left(h\right)$和$E_{in}\left(h\right)$差异很大的情况。机器学习期望的是算法$\mathcal A$能在好的数据集（例如$\mathcal D_{1126}$）上自由的选择$h$。</p>

<p>根据上图可推算，选到不好数据集的概率
\begin{equation}
P_{\mathcal D}\left[\mbox{BAD } \mathcal D\right] \leq 2M\exp\left(-2\epsilon^2N\right)，
\end{equation}
由此可见，选到不好数据集的概率是受限的，也就是可能找到好数据集，使得可以利用它自由在假设$\mathcal H$中选择。</p>

<p>如果$\left\lvert\mathcal H\right\rvert=M$有限，并且$N$足够大，使得可以通过$\mathcal A$选择到$g$，选择$E_{in}\left(h_m\right)$最小的那个$h_m$作为$g$，使得$E_{out}\left(g\right)\approx E_{in}\left(g\right)$。如果$\mathcal A$找到一个$g$使得$E_{in}\left(g\right)\approx 0$，PAC保证了$E_{out}\left(g\right)\approx 0$，也就是说学习是可行的。</p>

<p>因此，学习的可行性通过以下两条保证：</p>

<ol>
  <li>可以通过$E_{in}\left(h\right)$估计$E_{out}\left(h\right)$；</li>
  <li>存在数据集$\mathcal D$，使得可以在$\mathcal H$中自由的选择$h$。</li>
</ol>

<p>满足这两条的前提条件是假设集$\mathcal H$中候选$h$的数目$M$有限且$\mathcal D$中数据点数量$N$足够大。</p>

<p>如果$M=\infty$，咋办？</p>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="lin_ml_fl_2014">[1]H.-T. Lin, “Lecture 4: Feasibility of Learning.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li></ol>

<h3 id="section-5">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：大数据上的机器学习</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-large-scale-machine-learning" />
      <pubdate>2014-12-10T19:51:50+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-large-scale-machine-learning</guid>
      <content:encoded>&lt;![CDATA[<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_lsml_2014">[1]</a>。</p>

<h2 id="section">需要大数据么？</h2>

<p>当机器学习面对大数据的时候，是否从大数据中抽取一个小的子集就可以了呢？这需要分析学习曲线，确定影响性能的关键问题是数据量、特征还是模型或其它问题。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-is-needed.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-is-needed.png" alt="学习曲线" /></a><div class="caption">Figure 1:  学习曲线 [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-is-needed.png">PNG</a>]</div></div></div>

<p>如果是上图左所示的High Variance情况，则采用大数据能提高模型效果。若从大数据中抽取$m=1000$个样本的训练，如上图右所示，这表明机器学习是High Bias，即使加入更多的数据对性能也没有大的提升，应先加入更多的新特征（若神经网络，则增加神经元），再考虑大数据上的训练是否有利。</p>

<p>如何减少学习时间提高学习效率，是大数据上的机器学习需要解决的重要问题。</p>

<h2 id="section-1">随机梯度下降法</h2>

<h3 id="section-2">随机梯度下降法</h3>

<p>对于梯度下降法，参数更新的方法是
\begin{equation}
\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^m\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}，
\end{equation}
这种方法叫做批量（batch）梯度下降法，参数更新需在整个训练集上计算一次，当$m$特别大的时候，速度就会很慢。随机梯度下降法（stochastic gradient descent）的更新方式是每次只用一个数据点更新参数。</p>

<blockquote>
  <h4 id="section-3">随机梯度下降法</h4>
  <hr />

  <ol>
    <li>数据集随机化；</li>
    <li>更新模型参数，  <br />
Repeat <sup id="fnref:sgd-cycle-times"><a href="#fn:sgd-cycle-times" class="footnote">1</a></sup> {  // 通常是$1\sim 10$轮迭。 <br />
 for $i := 1,\dots,m$ {
\begin{equation}
\theta_j := \theta_j - \alpha\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}~~(j=1,\ldots,n)
\end{equation}
 }  }。</li>
  </ol>

</blockquote>

<p>如下图所示，批量梯度下降法通常会向着极小值逼近，随机梯度下降法逼近道路稍显曲折，最总结果通常在极小值的某个区域内徘徊。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-illustration-gradient-descent.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-illustration-gradient-descent.png" alt="左：批量梯度下降法，右：随机梯度下降法" /></a><div class="caption">Figure 2:  左：批量梯度下降法，右：随机梯度下降法 [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-illustration-gradient-descent.png">PNG</a>]</div></div></div>

<h3 id="section-4">小批量梯度下降法</h3>

<p>随机梯度法每次更新参数只需要一个数据点，批量梯度法每次更新参数只需要整个训练集参数。小批量（mini-batch）梯度下降法间于二者之间，每次更新参数利用训练集的一个小子集的$b$个数据点（通常$b=2,\ldots,100$）。小批量梯度下降法的参数更新规则为
\begin{equation}
\theta_j := \theta_j - \frac{\alpha}{b}\sum_{i=k}^{k+b-1}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}，
\end{equation}
其中$k=1,b+1,2b+1,3b+1,\ldots$。</p>

<p>小批量梯度下降法可利用并行化，获得比随机梯度法更快的速度，但是又多了参数$b$需要调节。</p>

<h3 id="section-5">收敛性判断</h3>

<p>随机梯度下降法可利用代价函数曲线，判断迭代过程是否收敛。但是，随机梯度下降法不会像批量梯度下降法那样，在整个训练集上评估代价。</p>

<p>在利用$\left(\mathbf x^{(i)},y^{(i)}\right)$更新参数$\boldsymbol\theta_j$之前，计算该点的代价（误差）
\begin{equation}
\mbox{cost}\left(\boldsymbol\theta,\left(\mathbf x^{(i)},y^{(i)}\right)\right)= {1\over 2}\left(h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)-y^{(i)}\right)^2，
\end{equation}</p>

<p>可以通过代价函数的梯度检测，判断随机梯度法是否沿着梯度下降方向更新参数。</p>

<p>若是在参数更新之后再计算误差，不能真实反映迭代的误差。将最近多次（比如$1000$）迭代的误差平均，作为代价函数曲线上的一个点，下图就是随机梯度下降法的代价函数曲线。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-checking-for-convergence.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-checking-for-convergence.png" alt="代价函数曲线" /></a><div class="caption">Figure 3:  代价函数曲线 [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-checking-for-convergence.png">PNG</a>]</div></div></div>

<p>小的$\alpha$能否得到更好的结果呢？随机梯度下降法的性质表明其结果会在极小值附近区域震荡，很小的学习率$\alpha$可能得到的结果也只是好一点点而已。如上图左上所示，小的$\alpha$得到稍微光滑一点的曲线，但效果提升并不明显。</p>

<p>上图右下的代价函数曲线不降反升，是因为学习率$\alpha$过大，可以适当调小学习率。</p>

<p>选择最近多少个点平均作为代价函数曲线的点合适呢？</p>

<ul>
  <li>点的数目多，代价函数曲线更光滑，需要较长时间才展示参数更新结果，不能及时的反应参数更新的情况。上图右上所示，更多数目的点平均得到的曲线更光滑。</li>
  <li>点的数目少，代价函数曲线噪声更大。上图左下所示，过少数目的点导致曲线震荡厉害，看不到变化趋势；过多的点又导致曲线过于平坦，也看不到变化趋势。</li>
</ul>

<p>因此，选择点的数目需要综合考虑这些情况，便于观察判断迭代是否收敛。</p>

<p>为了随机梯度下降法能更好逼近极小值，可动态调整学习效率$\alpha=\frac{\mbox{constant1}}{\mbox{interationNumber + constant2}}$，学习过程中不断减小$\alpha$，越是靠近极小值的地方更新步长越短。但是，这又多出两个参数$\mbox{constant1}$和$\mbox{constant2}$需要调节了，该方法也不十分常用。</p>

<h2 id="section-6">在线学习</h2>

<p>在线学习通常不需要维护一个固定的训练集，思想上和随机梯度法类似，每次新数据来，学习更新模型，然后继续接收新数据，继续更新模型……在线学习适合用于数据集动态缓慢变化的情况，模型随可随数据变换动态演进。</p>

<p>对于购物网站来说，随着经济大环境的改变，用户对价格的敏感度也会变化，用户特性会随时变迁，在线学习及时通过新样本训练模型可适应这些变化。</p>

<p>预测CTR（click-through rate）是经典的在线学习例子。比如用户在网站搜索手机，返回用户最可能点击的10个结果。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-online-example.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-online-example.png" alt="预测CTR" /></a><div class="caption">Figure 4:  预测CTR [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-online-example.png">PNG</a>]</div></div></div>

<p>如何计算用户点击的概率呢？将搜索匹配的单词等作为特征向量，利用logistic回归可以估计用户点击概率。推荐系统的协同过滤算法学习到的特征向量，也可作为logistic的输入特征。</p>

<p>每次用户搜索可以得到对这10个搜索结果的反馈（是否点击了），从而得到10组数据，这些数据又可以用来训练模型。</p>

<h2 id="mapreduce">MapReduce</h2>

<p>MapReduce可将学习任务分配到多台机器上（或者一台机器的多个CPU核上），然后将这些机器的学习结果汇总得到整个学习结果。</p>

<blockquote>
  <h4 id="mapreduce-1">基于MapReduce的批量梯度学习算法</h4>
  <hr />
  <p>整个任务：$\theta_j := \theta_j - \alpha\frac{1}{400}\sum_{i=1}^{400}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$。</p>

  <p>分配任务：</p>

  <ul>
    <li>Machine 1: $temp_j^{(1)}=\sum_{i=1}^{100}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$；</li>
    <li>Machine 2: $temp_j^{(2)}=\sum_{i={101}}^{200}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$；</li>
    <li>Machine 3: $temp_j^{(3)}=\sum_{i={201}}^{300}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$；</li>
    <li>Machine 4: $temp_j^{(4)}=\sum_{i={301}}^{400}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$。</li>
  </ul>

  <p>任务合并：$\theta_j := \theta_j - \alpha\frac{1}{400}\left(temp_j^{(1)}+temp_j^{(2)}+temp_j^{(3)}+temp_j^{(4)}\right)$。</p>
</blockquote>

<p>随机梯度下降法每次只采用一个数据点，是一个串行过程，因此不适合用Mapreduce这样的并行化方法。</p>

<h2 id="section-7">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_lsml_2014">[1]A. Ng, “Large scale machine learning.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-8">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:sgd-cycle-times">
      <p>对于大数据，通常一轮迭代（每个点参与一次）也能得到较好结果，通常进行$1\sim 10$轮迭代（这个还依赖于训练集的大小）。 <a href="#fnref:sgd-cycle-times" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>计算广告学：广告基础</title>
      <link href="http://qianjiye.de/2014/12/computational-advertising-foundation" />
      <pubdate>2014-12-09T09:02:19+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/computational-advertising-foundation</guid>
      <content:encoded>&lt;![CDATA[<p>本文的内容来自于刘鹏的网络课程《计算广告学》<a href="#liu_cad_foundations_2014">[1]</a>。</p>

<h2 id="tips">tips</h2>

<p>广告和推荐系统很相似。对广告而言，在同样位置文字链的点击率远远高于图片；对推荐而言，图片的点击率远远高于文字链。</p>

<h2 id="section">广告目的</h2>

<p>广告（advertising）是由已确定的出资人通过各种媒介进行的有关产品（商品、服务和观点）的，通常是有偿的、有组织的、综合的、劝服性的非人员的信息传播活动<a href="#arens_ad_2013">[2]</a>。</p>

<p>广告的三主体是出资人（sponsor）即广告主（advertiser）、媒介（medium）、受众（audience）<sup id="fnref:search-001"><a href="#fn:search-001" class="footnote">1</a></sup>，这是计算广告学中的三个基本变量。广告是一个三方博弈问题。</p>

<p>广告的本质功能是借助某种有广泛受众的媒介力量，完成较低成本的用户接触（不是向用户卖东西哦）。</p>

<p>品牌广告（brand awareness）：创造独特良好的品牌或产品形象，目的在于提升较长时期内的离线转化率。</p>

<p>效果广告（direct response）：有短期内明确用户转化行为诉求的广告，用户转化行为有购买、注册、投票、捐款等。</p>

<h2 id="section-1">广告的有效性模型</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-09-computational-advertising-effect-model.png"><img src="/assets/images/2014-12-09-computational-advertising-effect-model.png" alt="广告的有效性模型" /></a><div class="caption">Figure 1:  广告的有效性模型 [<a href="/assets/images/2014-12-09-computational-advertising-effect-model.png">PNG</a>]</div></div></div>

<p>曝光阶段，广告位对广告的曝光率和点击率有决定性作用，这种资源优势不是通过算法改进可以获得的。</p>

<p>关注阶段，可以通过技术手段提高用户关注度。不要打断用户而言，比如ad系统通过上下文推荐；对揭示推荐原因而言，比如租车行的广告根据用户所在地理更换背景图片。</p>

<p>信息接受阶段，广告位影响着广告的认可度，比如大的品牌广告主要确保自己的广告投放到影响力大和没有负面影响的媒介，还要关注竞争对手的广告投放情况。</p>

<p>评价在线广告的两个基本指标：点击率和转化率。一般而言，越靠前的阶段对点击率影响越大，越靠后的阶段对转化率影响越大。</p>

<p>下图展示了一些广告策略的效果，＋表示正面作用，－表示负面作用。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-09-computational-advertising-improve-ad-performance.png"><img src="/assets/images/2014-12-09-computational-advertising-improve-ad-performance.png" alt="一些广告策略的效果" /></a><div class="caption">Figure 2:  一些广告策略的效果 [<a href="/assets/images/2014-12-09-computational-advertising-improve-ad-performance.png">PNG</a>]</div></div></div>

<h2 id="section-2">广告与营销的区别</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-09-computational-advertising-ad-vs-sale.png"><img src="/assets/images/2014-12-09-computational-advertising-ad-vs-sale.png" alt="广告与营销的区别" /></a><div class="caption">Figure 3:  广告与营销的区别 [<a href="/assets/images/2014-12-09-computational-advertising-ad-vs-sale.png">PNG</a>]</div></div></div>

<p>就效果广告（direct response）而言，从硬广到返利网，效果越来越好<sup id="fnref:problem-001"><a href="#fn:problem-001" class="footnote">2</a></sup>。当然，各种形式的广告之间有相互作用，配合使用可提升效果。</p>

<h2 id="section-3">参考文献</h2>

<ol class="bibliography"><li><span id="liu_cad_foundations_2014">[1]刘鹏, “广告的基本知识.” 云课堂, 2014.</span>

[<a href="http://study.163.com/c/ad">Online</a>]

</li>
<li><span id="arens_ad_2013">[2]威廉·阿伦斯, <i>当代广告学</i>. 人民邮电出版社, 2013.</span>

</li></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:search-001">
      <p>搜索有两个主体，用户和搜索引擎。 <a href="#fnref:search-001" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:problem-001">
      <p>如何理解把你的客户卖给你，把竞争对手的客户买给你？ <a href="#fnref:problem-001" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：推荐系统</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-recommender-systems" />
      <pubdate>2014-12-09T07:20:25+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-recommender-systems</guid>
      <content:encoded>&lt;![CDATA[<p>推荐系统首先通过分析用户的使用历史获得用户的兴趣偏向，然后使用得到的用户兴趣偏向获得用户潜在感兴趣的产品或服务。鉴于产生推荐的方式不同，推荐系统通常可以分为以下三类<a href="#wu_thesis_bju_2010">[1]</a>：基于内容的过滤（content-based filtering）、协同过滤（collaborative filtering）和CBF与CF的混合过滤（hybrid filtering）。</p>

<p>以电影的推荐系统为例，相关变量定义如下<a href="#ng_ml_rs_2014">[2]</a>：</p>

<ul>
  <li>$n_u$：用户数目；</li>
  <li>$n_m$：电影数目；</li>
  <li>$r(i, j)$：若用户$j$对电影$i$进行了评分则赋值为1；</li>
  <li>$y^{(i, j)}$：用户$j$对电影$i$的评分；</li>
  <li>$\boldsymbol\theta^{(j)}$：用户$j$的参数向量；</li>
  <li>$\mathbf x^{(i)}$：电影$i$的特征向量；</li>
  <li>$m^{(j)}$：用户$j$评价过的电影数目。</li>
</ul>

<h2 id="section">基于内容的过滤</h2>

<p>基于内容的过滤（CBF）方法根据抽取出的用户和产品特征获得推荐。这类方法利用用户和产品的特征计算他们之间的匹配度，最终把匹配得最好的数个产品推荐给相应的用户。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-recommender-systems-recommender-data.png"><img src="/assets/images/2014-12-08-machine-learning-recommender-systems-recommender-data.png" alt="用户对电影的评价" /></a><div class="caption">Figure 1:  用户对电影的评价 [<a href="/assets/images/2014-12-08-machine-learning-recommender-systems-recommender-data.png">PNG</a>]</div></div></div>

<p>上图展示了用户对电影的评分$0\sim 5$，用属于爱情片（romance）和动作片（action）的概率表示电影特征。用户评分<code>?</code>表示用户$j$未对电影$i$作出评价，也就是$r(i, j)=0$。</p>

<p>如何估计用户未评价电影的得分呢？这时一个线性回归问题。利用电影特征向量$\mathbf x^{(i)}$和参数$\boldsymbol\theta^{(j)}$，可估计用户$j$对电影$i$的评分
\begin{equation}
y^{(i, j)} = \left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)}。
\label{eq:user-rating}
\end{equation}</p>

<p>因此，基于内容的的推荐需要学习参数$\boldsymbol\theta^{(1)},\boldsymbol\theta^{(2)},\dots,\boldsymbol\theta^{(n_u)}$。假设已知$\mathbf x^{(1)}, \mathbf x^{(2)}, \ldots, \mathbf x^{(n_m)}$，学习算法采用代价函数
\begin{equation}
\begin{aligned}
J\left(\boldsymbol\theta^{(1)},\dots,\boldsymbol\theta^{(n_u)}\right) = &amp;{1\over 2}\sum_{j=1}^{n_u}\sum_{i:r(i, j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)^2 + \\
&amp;{\lambda\over 2}\sum_{j=1}^{n_u}\sum_{k=1}^n\left(\theta_k^{(j)}\right)^2，
\end{aligned}
\label{eq:cf-learn-user-parameters}
\end{equation}
由于电影评分的总数目是固定的，省去平均化过程对最小化代价函数没有影响，只保留$1\over 2$方便求导，梯度下降法更新参数的规则为
\begin{equation}
\begin{aligned}
\theta_k^{(j)}&amp;:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)x_k^{(i)} &amp; (k=0)\\
\theta_k^{(j)}&amp;:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)x_k^{(i)}+\lambda\theta_k^{(j)}\right)&amp;(k\neq 0)
\end{aligned}。
\end{equation}</p>

<p>CBF就是把某用户评价高的电影推荐给该用户。为了实现推荐，需要计算用户对所有电影的评分，计算复杂度高。</p>

<p>CBF方法具有两个主要的缺陷：</p>

<ol>
  <li>CBF需要预处理产品以得到代表它们的特征，但这种预处理在实际问题中往往非常困难；</li>
  <li>CBF推荐给某个用户的产品往往和此用户已经消费过的产品很相似，它们无法发现用户并不熟悉但具有潜在兴趣的产品种类。 </li>
</ol>

<h2 id="section-1">协同过滤</h2>

<p>协同过滤（CF）方法不需要事先获得产品或用户的特征，它们只依赖于用户过去的行为（如对产品的浏览、评价或购买等）。 通过用户过去的行为企业可以收集用户对产品的显式评分（如Netflix）或隐式评分（如Google新闻）。通常 CF方法首先分析已经收集到的用户-产品评分对中所呈现的用户与产品的相互作用，然后它们使用这些相互作用为用户产生个性化产品推荐。</p>

<p>CF通常分为基于产品的（item-based）推荐和基于用户的（user-based）推荐。基于用户的推荐假设如果两个用户过去对产品有相似的喜好，那么他们现在对产品仍有相似的喜好；基于产品的推荐假设如果某个用户过去喜欢某种产品，那么该用户现在仍喜欢与此产品相似的产品。 </p>

<p>在实际应用中，电影的特征向量往往也是未知的，需要通过学习得到。协同过滤不仅可以学习到用户对电影的评价，而且能学习到电影的特征。</p>

<p>电影特征向量学习与用户评价模型参数估计\eqref{eq:cf-learn-user-parameters}类似，假设已知$\boldsymbol\theta^{(1)},\boldsymbol\theta^{(2)},\dots,\boldsymbol\theta^{(n_u)}$，学习$\mathbf x^{(1)}, \mathbf x^{(2)}, \ldots, \mathbf x^{(n_m)}$采用的代价函数为
\begin{equation}
\begin{aligned}
J\left(\mathbf x^{(1)}, \ldots, \mathbf x^{(n_m)}\right) = &amp;{1\over 2}\sum_{i=1}^{n_m}\sum_{i: r(i, j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} -  y^{(i, j)}\right)^2 + \\
&amp;{\lambda\over 2}\sum_{i=1}^{n_m}\sum_{k=1}^n\left(x_k^{(i)}\right)^2
\end{aligned}。
\label{eq:cf-learn-item-features}
\end{equation}</p>

<p>根据\eqref{eq:cf-learn-user-parameters}和\eqref{eq:cf-learn-item-features}，同时学习$\mathbf x^{(1)}, \mathbf x^{(2)}, \ldots, \mathbf x^{(n_m)}$和$\boldsymbol\theta^{(1)},\boldsymbol\theta^{(2)},\dots,\boldsymbol\theta^{(n_u)}$可以采用代价函数
\begin{equation}
\begin{aligned}
J\left(\mathbf x^{(1)},\ldots,\mathbf x^{(n_m)},\boldsymbol\theta^{(1)},\dots,\boldsymbol\theta^{(n_u)}\right) = &amp;{1\over 2}\sum_{(i,j): r(i, j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)^2 + \\
&amp;{\lambda\over 2}\sum_{i=1}^{n_m}\sum_{k=1}^n\left(x_k^{(i)}\right)^2+{\lambda\over 2}\sum_{j=1}^{n_u}\sum_{k=1}^n\left(\theta_k^{(j)}\right)^2
\end{aligned}，
\label{eq:cf-learn-all-parameters}
\end{equation}
梯度下降法更新参数的规则为
\begin{equation}
\begin{aligned}
x_k^{(i)}&amp;:=x_k^{(i)}-\alpha\left(\sum_{j:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)\theta_k^{(j)}+\lambda x_k^{(i)}\right)\\
\theta_k^{(j)}&amp;:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)x_k^{(i)}+\lambda\theta_k^{(j)}\right)
\end{aligned}，
\label{eq:grd-x-theta}
\end{equation}
由于电影的特征$\mathbf x$也通过学习得到，不再需要额外增加$x_0^{(i)}=1$的项。</p>

<blockquote>
  <h4 id="section-2">协同过滤算法</h4>
  <hr />

  <ol>
    <li>用小的随机变量初始化$\mathbf x^{(1)},\ldots,\mathbf x^{(n_m)},\boldsymbol\theta^{(1)},\dots,\boldsymbol\theta^{(n_u)}$<sup id="fnref:how-item-feature-demension"><a href="#fn:how-item-feature-demension" class="footnote">1</a></sup>；</li>
    <li>最小化代价函数\eqref{eq:cf-learn-all-parameters}，若采用梯度下降法，采用\eqref{eq:grd-x-theta}更新参数；</li>
    <li>学习到参数后，利用\eqref{eq:user-rating}计算用户$j$对电影$i$的评分。</li>
  </ol>
</blockquote>

<p>协同过滤算法是一个不断进化的过程，$\mathbf x^{(i)}$和$\boldsymbol\theta^{(j)}$相互作用，$\mathbf x^{(i)}$推动$\boldsymbol\theta^{(j)}$更新，$\boldsymbol\theta^{(j)}$也推动$\mathbf x^{(i)}$更新。</p>

<p>当学习到电影的特征向量$\mathbf x^{(i)}$后，可以用$\left\lVert \mathbf x^{(i_1)}-\mathbf x^{(i_2)}\right\rVert$计算电影之间的相似度。通过电影的相似度，为用户推荐相关的电影，这就是基于物品的推荐方法。</p>

<p>CF方法存在的主要问题：</p>

<ol>
  <li>冷启动：对于一个新用户，由于缺乏其对产品的评分，CF无法为其提供可靠的 产品推荐；对于一种新的产品，CF无法确定该把它推荐给哪些用户。</li>
  <li>可扩展性：CF方法中可能涉及到数以百万计的用户为成千上万种产品提供的评分。传统的CF推荐算法通常需要计算每对用户或产品之间的相似度，然后把这些相似度存放至电脑的主存中以便高效地产生推荐。当用户或产品的数量较大时，计算复杂度很高。 </li>
</ol>

<h3 id="section-3">均值规范化</h3>

<p>针对新用户的冷启动，该用户$j$从未对任何电影做出评价，协同过滤算法会得到用户的参数向量$\boldsymbol\theta^{(j)}=\mathbf 0$，如果估计该用户对电影的评分，也将全为$0$，这显然不符合逻辑。因此，需要对数据进行适当的处理，避免这样的情况发生。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-recommender-systems-mean-normalization.png"><img src="/assets/images/2014-12-08-machine-learning-recommender-systems-mean-normalization.png" alt="均值规范化" /></a><div class="caption">Figure 2:  均值规范化 [<a href="/assets/images/2014-12-08-machine-learning-recommender-systems-mean-normalization.png">PNG</a>]</div></div></div>

<p>定义用户对所有电影评价的均值为$\boldsymbol\mu$，重新对用户对电影的评分规范化
\begin{equation}
 y^{(i,j)} := y^{(i,j)} - \mu_i。
\end{equation}
规范化评分后，公式\eqref{eq:user-rating}计算用户$j$对电影$i$的评分规则变为
\begin{equation}
y^{(i, j)} = \left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)}+\mu_i，
\end{equation}
即使参数向量$\boldsymbol\theta^{(j)}=\mathbf 0$，估计新用户对电影的评分将是所有用户的平均分，合情合理。</p>

<h3 id="section-4">思考问题</h3>

<ul>
  <li>如果系统已经有了部分标注的特征$\mathbf x$，如何融入到协同过滤算法中？</li>
  <li>如何利用协同过滤提高广告点击率？</li>
  <li>协同过滤的特征学习方法可以做传感器校准么？</li>
  <li>协同过滤和广联规则挖掘有何联系？</li>
  <li>协同过滤的特征学习可以解决盲源信号分离么？</li>
</ul>

<h2 id="section-5">混合过滤</h2>

<p>混合过滤(HF)组合CBF和CF，以期在克服它们各自缺点的同时，融合它们特有的优势。通常组合的方式包括以下三种：</p>

<ol>
  <li>加权（weighted）组合：首先分别独立应用CBF和CF获得对产品的预测评分，然后组合它们的预测评分以便获得混合过滤的预测评分，最后根据混合预测评分为用户产生推荐列表。</li>
  <li>混合（mixed）组合：首先分别独立应用CBF和CF产生各自的推荐列表，然后组合这两组推荐列表以便获得最终的推荐列表。</li>
  <li>序贯（sequential）组合：当可用评分较少时使用CBF方法获得用户的特征并进行推荐；而当可用评分积聚到一定程度时，使用CF方法代替原来的CBF方法获得最终的推荐列表。 </li>
</ol>

<h2 id="section-6">参考资料</h2>

<ol class="bibliography"><li><span id="wu_thesis_bju_2010">[1]吴金龙, “Netflix Prize 中的协同过滤算法,” PhD thesis, 北京大学, 2010.</span>

</li>
<li><span id="ng_ml_rs_2014">[2]A. Ng, “Recommender Systems.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-7">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:how-item-feature-demension">
      <p>如何确定电影的特征多少维合适呢？ <a href="#fnref:how-item-feature-demension" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：异常检测</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-anomaly-detection" />
      <pubdate>2014-12-08T10:29:01+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-anomaly-detection</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">简介</h2>

<p>异常检测的基本思想：若发生了小概率事件，就认为出现了异常。</p>

<p>常用的异常检测方法是利用高斯密度函数，计算数据出现的概率，如果发现了概率小于某个阈值的数据，就认为该数据是异常的。</p>

<p>异常检测也是一种模式二分类方法，但两类数据严重不平衡，异常数据要显著少于正常数据。异常检测通常只需要对正常数据进行建模。</p>

<h2 id="section-1">基于高斯（正态）分布的异常检测</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_ad_2014">[1]</a>。</p>

<p>根据异常检测的思想，若$\mathbf x$出现的概率$p(\mathbf x) &lt; \varepsilon$，则认为$\mathbf x$是异常点。因此，异常检测的重要内容是估计概率密度函数。</p>

<h3 id="section-2">一元高斯分布</h3>

<p>基于一元高斯分布的异常检测的前提条件是假设特征之间相互独立。</p>

<p>通常假设特征分量的数据集$X$满足均值为$\mu$，方差为$\sigma^2$的正态分布，
\begin{equation}
X\sim\mathcal{N}\left(\mu, \sigma^2\right)，
\end{equation}
因此有
\begin{equation}
p(x;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)，
\end{equation}
这需要估计均值$\mu$和方差$\sigma^2$，它们的极大似然估计为
\begin{equation}
\begin{aligned}
\mu = &amp; {1\over m}\sum_{i=1}^{m}x^{(i)}\\
\sigma^2 = &amp; {1\over m}\sum_{i=1}^{m}\left(x^{(i)}-\mu\right)^2
\end{aligned}。
\label{eq:likehood-mu-sigma}
\end{equation}</p>

<p>得到了概率密度函数，就容易利用概率判断异常。</p>

<h4 id="section-3">一、异常检测</h4>

<blockquote>
  <h4 id="section-4">异常检测算法</h4>
  <hr />

  <ol>
    <li>选择能指示异常的特征$\mathbf x_j$；</li>
    <li>利用公式\eqref{eq:likehood-mu-sigma}，估计每维特征的均值和方差$\mu_1,\ldots,\mu_n,\sigma_1^2,\ldots,\sigma_n^2$；</li>
    <li>计算$\mathbf x$的概率，
\begin{equation}
p(\mathbf x) = \prod_{j=1}^n p\left(x_j;\mu_j,\sigma_j^2\right)，
\end{equation}
通过特征分量概率密度函数乘积计算$\mathbf x$概率密度，需满足特征之间相互独立的假设；</li>
    <li>若$p(\mathbf x) &lt; \varepsilon$，则$\mathbf x$为异常点。</li>
  </ol>
</blockquote>

<p>异常检测的训练过程就是估计概率密度函数参数$\boldsymbol\mu$和$\boldsymbol\sigma^2$。通常情况，训练过程不需要异常数据。$60\%$的正常数据作为训练集，$20\%$的正常数据和$50\%$的异常数据作为交叉检验集，$20\%$的正常数据和$50\%$的异常数据作为测试集。</p>

<p>通过交叉检验集可确定判定异常的阈值$\varepsilon$，选择参数可利用<a href="/2014/11/machine-learning-advice-for-applying-machine-learning/#performance-evaluation">分类器性能评价指标</a>。</p>

<p>异常检测和监督学习存在不同的特点，应用在不同的场景：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">异常检测</th>
      <th style="text-align: left">监督学习</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">正样本（异常数据，$y=1$）少，通常$0\sim 20$个正样本，负样本（正常数据，$y=0$）多；</td>
      <td style="text-align: left">正样本和负样本都较多；</td>
    </tr>
    <tr>
      <td style="text-align: left">可能存多种不同类型的异常数据，难以通过正样本学习；</td>
      <td style="text-align: left">大量的正样本数据，能通过训练集了解正样本特点；</td>
    </tr>
    <tr>
      <td style="text-align: left">应用领域：欺诈检测、故障诊断、数据中心设备监控等</td>
      <td style="text-align: left">应用领域：垃圾邮件分类、天气预测、癌症分类等。</td>
    </tr>
  </tbody>
</table>

<h4 id="feature-transform">二、特征变换</h4>

<p>根据异常检测方法可知，运用异常检测有两个重要的前提条件：</p>

<ol>
  <li>特征满足高斯分布（特征之间的相关性下节考虑）；</li>
  <li>$p(\mathbf x)$对正常数据很大，但对异常数据很小。</li>
</ol>

<p>在实际应用中，原始特征可能并不满足这两个前提条件，需要将特征作一定变换或构造新的特征。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-nongaussain-features.png"><img src="/assets/images/2014-12-08-machine-learning-anomaly-detection-nongaussain-features.png" alt="原始特征通过变换满足高斯分布" /></a><div class="caption">Figure 1:  原始特征通过变换满足高斯分布 [<a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-nongaussain-features.png">PNG</a>]</div></div></div>

<p>上图展示了通过函数$\log x$变换原始特征以满足高斯分布。也可以通过构造新的特征，比如数据中心监控，利用特征$\mbox{CPU load}$和$\mbox{network traffic}$构造新的特征$\frac{\mbox{CPU load}}{\mbox{network traffic}}$<sup id="fnref:why-create-new-feature"><a href="#fn:why-create-new-feature" class="footnote">1</a></sup>，使其在发生异常的时数据会变得很大或者很小。</p>

<h3 id="multi-gaussian-anormaly-detection">多元高斯分布</h3>

<p>实际应用中，特征之间可能存在相关性，需要采用多元高斯分布概率密度函数进行异常检测。</p>

<p>多元高斯分布的概率密度函数定义为</p>

<p>\begin{equation}
p(\mathbf x; \boldsymbol\mu, \Sigma)=\frac{1}{(2\pi)^{n\over 2}\lvert\Sigma\rvert^{1\over 2}}\exp\left(-{1\over 2}(\mathbf x - \boldsymbol\mu)^T\Sigma^{-1}(\mathbf x - \boldsymbol\mu)\right)，
\label{eq:multi-gaussians-pdf}
\end{equation}</p>

<p>其均值向量和协方差矩阵的极大似然估计为</p>

<p>\begin{equation}
\begin{aligned}
\boldsymbol\mu = &amp; {1\over m}\sum_{i=1}^{m}\mathbf x^{(i)}\\
\Sigma = &amp; {1\over m}\sum_{i=1}^{m}\left(\mathbf x^{(i)}-\boldsymbol\mu\right)\left(\mathbf x^{(i)}-\boldsymbol\mu\right)^T
\end{aligned}。
\end{equation}</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-multi-gaussians.png"><img src="/assets/images/2014-12-08-machine-learning-anomaly-detection-multi-gaussians.png" alt="二元高斯分布" /></a><div class="caption">Figure 2:  二元高斯分布 [<a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-multi-gaussians.png">PNG</a>]</div></div></div>

<p>上图给出了不同参数的二元高斯密度函数图。图上排的协方差矩阵为对角阵，表示特征之间独立，可用一元高斯分布的方法进行异常检测；图下排的协方差矩阵是非对角阵，表示特征之间存在相关性，需借助多元高斯分布密度函数\eqref{eq:multi-gaussians-pdf}进行异常检测。</p>

<p>基于一元高斯分布和多元高斯分布的异常检测有不同的应用场景：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">一元高斯分布</th>
      <th style="text-align: left">多元高斯分布</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">根据先验知识<a href="#feature-transform">构造新特征</a>，手动处理相关性问题；</td>
      <td style="text-align: left">自动处理样本之间的相关性，计算$\Sigma$<sup id="fnref:multi-gaussian-feature-transform"><a href="#fn:multi-gaussian-feature-transform" class="footnote">2</a></sup>；</td>
    </tr>
    <tr>
      <td style="text-align: left">计算复杂度较低；</td>
      <td style="text-align: left">计算复杂度较高；</td>
    </tr>
    <tr>
      <td style="text-align: left">能处理样本数$m$很少的情况。</td>
      <td style="text-align: left">需要$m&gt;n$（一般$m&gt;10n$），否则$\Sigma$不可逆。</td>
    </tr>
  </tbody>
</table>

<p>若$\Sigma$不可逆，原因可能是不满足条件$m&gt;n$，或者存在冗余特征，也就是特征之间有相关性（比如$\mathbf x_1=k\mathbf x_2$或$\mathbf x_1=\mathbf x_2 ＋ \mathbf x_3$等）。</p>

<p>由此可见，特征之间是否具有相关性并非利用多元还是一元高斯分布进行异常检测的唯一条件，在必要的时候需要借助一元高斯分布对具有相关性特征的数据集进行异常检测。</p>

<p>具有相关性的特征数据，经过基于PCA的坐标变换（参考维数约减部分关于PCA的内容）消除相关性，也可以用一元高斯分布的方法处理。</p>

<h2 id="section-5">参考文献</h2>

<ol class="bibliography"><li><span id="ng_ml_ad_2014">[1]A. Ng, “Anomaly detection.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-6">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:why-create-new-feature">
      <p>如何判断构造的新特征有价值？哪些特征加入会有助于提高性能？ <a href="#fnref:why-create-new-feature" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:multi-gaussian-feature-transform">
      <p>利用多元高斯分布也要将每维特征变换为高斯分布么？ <a href="#fnref:multi-gaussian-feature-transform" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：维数约减</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-dimensionality-reduction" />
      <pubdate>2014-12-08T04:53:42+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-dimensionality-reduction</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">简介</h2>

<p>维数约减的作用通常是为了数据压缩和可视化。数据压缩不仅可以节省存储空间，而且可以加速机器学习算法。高维数据需要约减到3维或2维空间，以便观测其特性。 </p>

<h2 id="pca">主成分分析（PCA）</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_dr_2014">[1]</a>。</p>

<p>维数约减最常用的方法是主成分分析（PCA，Principal Component Analysis）。PCA可以理解为在高维空间中寻找一个低维的面，使得高维空间中的点到该面上的距离之和最小，这个距离也叫投影误差。</p>

<p>利用PCA将维数从$n$维约减到$k$维，需要寻找$n$维空间中的$k$个向量$\mathbf u^{(1)}, \mathbf u^{(2)},\ldots,\mathbf u^{(k)}\in\mathbb R^n$，使空间中的点到这$k$个向量确定的面的投影误差最小。事实上，$n$维空间中的这$k$个向量是样本协方差矩阵最大的$k$个特征值对应的特征向量。</p>

<blockquote>
  <h4 id="pca-1">PCA维数约减算法</h4>
  <hr />

  <ol>
    <li>数据作均值为$0$的规范化（mean normalization），确保每维均值为$0$，若取值范围差异过大，还需尺度规范化（feature scaling）：$x_j^{(i)}:=\frac{x_j^{(i)}-\mu_j}{ \sigma_j}$（$\mu_j$表示均值，$\sigma_j$表示标准差）；</li>
    <li>计算协方差矩阵（covariance matrix）：$\Sigma = \frac{1}{m}\sum_{i=1}^m\mathbf x^{(i)}\left(\mathbf x^{(i)}\right)^T$；</li>
    <li>利用特征向量将$n$维向量$\mathbf x$映射到$k$维向量$\mathbf z$：
\begin{equation}
\mathbf z^{(i)} = \mathbf U_{reduce}^T\mathbf x^{(i)}。
\label{eq:pca-mapping}
\end{equation}</li>
  </ol>

  <div class="highlight"><pre><code class="language-matlab"><span class="p">[</span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span><span class="p">]</span> <span class="p">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">Sigma</span><span class="p">);</span>
<span class="n">Ureduce</span> <span class="p">=</span> <span class="n">U</span><span class="p">(:,</span> <span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">);</span>
<span class="n">z</span> <span class="p">=</span> <span class="n">Ureduce</span>’ <span class="o">*</span> <span class="n">x</span><span class="p">;</span></code></pre></div>
  <p>在应用中，只需要在训练集上做PCA，交叉检验和测试集上可以直接应用训练集的均值$\boldsymbol\mu$、标准差$\mathbf s$和映射矩阵$U_{reduce}$计算约减后的向量。</p>
</blockquote>

<p>Matlab中<code>svd</code>和<code>eig</code>函数都可以得到相同的特征值和特征向量，但是<code>svd</code>更稳定。</p>

<p>从$k$维数据$\mathbf z$重构$n$维数据$\mathbf x$的方法为</p>

<p>\begin{equation}
\mathbf x_{approx}^{(i)} = \mathbf U_{reduce}\mathbf z^{(i)}。
\label{eq:pca-reconstruction}
\end{equation}</p>

<p>约减后的维数$k$（主成分个数）通过方差保留的比率确定，选择满足下列条件的最小$k$</p>

<p>\begin{equation*}
\frac{\frac{1}{m}\sum_{i=1}^m\left\lVert\mathbf x^{(i)}-\mathbf x_{approx}^{(i)}\right\rVert^2}{\frac{1}{m}\sum_{i=1}^m\left\lVert\mathbf x^{(i)}\right\rVert^2}\leq 0.01，
\end{equation*}</p>

<p>此时方差保存比率为$99\%$。但是该方法计算复杂，可以通过特征值更简单的计算，选择满足下列条件的最小$k$</p>

<p>\begin{equation}
\frac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}}\geq 0.99，
\end{equation}</p>

<p>$S_{ii}$是SVD得到的特征值。</p>

<blockquote>
  <h4 id="pca-2">谨慎使用PCA</h4>
  <hr />

  <ol>
    <li>PCA不是解决过拟合的好方法，正则化是更好的策略（PCA或多或少损失了有助于分类的信息）；</li>
    <li>不得滥用PCA，除非有证据表明PCA的价值，比如在有训练时间和存储空间的限制的时候。</li>
  </ol>

</blockquote>

<h3 id="pca-3">理解PCA</h3>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-mapping.svg"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-mapping.svg" alt="［左］规范化的数据；［中］PCA坐标变换；［右］PCA降维" /></a><div class="caption">Figure 1:  ［左］规范化的数据；［中］PCA坐标变换；［右］PCA降维 [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-mapping.svg">SVG</a>]</div></div></div>

<h4 id="pca-4">一、PCA是一种坐标变换方法</h4>

<p>如果PCA变换之后的维数$k = n$，也就是没有降维，没有任何信息损失，这相当于坐标变换。上图左，经过规范化处理后的数据；上图中，利用公式\eqref{eq:pca-mapping}的PCA坐标变换，$k=n$，大概相当于左边的数据顺时针旋转$45$度再绕$Y$轴镜像；上图右，红色的点是经过$k=1$的降维处理后，再利用公式\eqref{eq:pca-reconstruction}重构回的数据。</p>

<p>协方差矩阵的特征向量，相当于新坐标系的基，原始数据到基上的投影就是新坐标系中的坐标。从这个角度理解降维，就相当于新坐标系中，只用前$k$维的坐标表示一个点，上图右重构回来的数据就会只在新坐标系的某个坐标轴上。</p>

<p>经过基于PCA的坐标变换之后，消除了特征之间的相关性，协方差矩阵是对角阵。如果对于<a href="/2014/12/machine-learning-anomaly-detection/#multi-gaussian-anormaly-detection">基于多元高斯分布的异常检测</a>，经过基于PCA的坐标变换之后，用一维高斯分布的方法就可处理。</p>

<h4 id="pca-5">二、PCA是一种特征提取方法</h4>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-eigen-faces.png"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-eigen-faces.png" alt="特征脸" /></a><div class="caption">Figure 2:  特征脸 [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-eigen-faces.png">PNG</a>]</div></div></div>

<p>协方差矩阵的特征向量可以看作是特征空间，在这个空间中投影，可视为特征提取。上图展示了人脸数据集协方差矩阵的前$36$维特征向量，如果人脸在这个特种空间中投影，相当于利用这$36$张特征脸的线性组合来表示人脸。向左上角靠近的特征脸，表现的是人脸的主要信息；向右下角靠近的特征脸，表现的是人脸的细节信息<sup id="fnref:thinking-pca-for-classfication"><a href="#fn:thinking-pca-for-classfication" class="footnote">1</a></sup>。</p>

<p>用少量特征维表示人脸，可认为是人脸的一种稀疏表示。这是一种目的很明确的表示方法，将对象特征从主要到次要，根据需要依次表示出来。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-reconstruct-faces.png"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-reconstruct-faces.png" alt="［左］原图；［右］PCA降维后重构的人脸" /></a><div class="caption">Figure 3:  ［左］原图；［右］PCA降维后重构的人脸 [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-reconstruct-faces.png">PNG</a>]</div></div></div>

<h4 id="pca-6">三、其它角度理解PCA</h4>

<ul>
  <li>傅立叶变换、小波变换、PCA特征向量空间的变换、稀疏表示……</li>
  <li>特征学习：神经网络权值、PCA特征向量空间、深度学习……</li>
</ul>

<h2 id="kpca">KPCA</h2>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-kpca.png"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-kpca.png" alt="Kernel PCA" /></a><div class="caption">Figure 4:  Kernel PCA [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-kpca.png">PNG</a>]</div></div></div>

<p><a href="http://zhanxw.com/blog/2011/02/kernel-pca-原理和演示/">Kernel PCA 原理和演示</a></p>

<h2 id="section-1">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_dr_2014">[1]A. Ng, “Dimensionality Reduction.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-2">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:thinking-pca-for-classfication">
      <p>对于识别（分类）问题，采用主要特征（大特征值对应特征向量的投影）好呢还是次要特征？对于类间识别，比如人脸和猫脸分类，采用主要特征；对于同类的子类识别，比如区别张山李仕，更多靠的是细节信息，采用次要特征可能跟好。 <a href="#fnref:thinking-pca-for-classfication" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：聚类</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-clustering" />
      <pubdate>2014-12-08T02:38:59+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-clustering</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">聚类简介</h2>

<p>聚类是一种非监督学习方法。</p>

<h2 id="k-means">$k$-means聚类</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_c_2014">[1]</a>。</p>

<p>$k$-means算法主要包含两步：为样本分配类标签以及修改类中心。</p>

<blockquote>
  <h4 id="k-means-1">$k$-means算法</h4>
  <hr />
  <p>随机初始化$K$个类中心$\boldsymbol\mu_1,\boldsymbol\mu_2,\ldots,\boldsymbol\mu_K\in\mathbb R^n$。 <br />
重复 {</p>

  <ol>
    <li>for $i=1$ to $m$：将$\mathbf x^{(i)}$的类别标签$c^{(i)}$设为最靠近的类中心标签，$c^{(i)}=\arg\min_{k=1}^K\left\lVert\mathbf x^{(i)}-\boldsymbol\mu_k\right\rVert^2$；</li>
    <li>for $k=1$ to $K$：重新计算类中心$\boldsymbol\mu_k$。</li>
  </ol>

  <p>}</p>
</blockquote>

<p>$k$-means聚类的代价函数为</p>

<p>\begin{equation}
J\left(c^{(1)},\dots,c^{(m)},\boldsymbol\mu_1,\ldots,\boldsymbol\mu_K\right)=\frac{1}{m}\sum_{i=1}^m\left\lVert\mathbf x^{(i)}-\boldsymbol\mu_{c^{(i)}}\right\rVert^2，
\label{eq:cf-k-means}
\end{equation}</p>

<p>该代价函数通常也称为distortion function。</p>

<p>从代价函数可以看出，$k$-means算法的第1步是通过修改类标签$c^{(i)}$最小化代价函数，第2步是通过修改类中心$\boldsymbol\mu_k$最小化代价函数。</p>

<p>从$k$-means算法可知，初始化类中心$\boldsymbol\mu_k$和确定类别数$k$影响着算法的性能。</p>

<h3 id="boldsymbolmuk">初始化类中心$\boldsymbol\mu_k$</h3>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-k-means-local-minimum.png"><img src="/assets/images/2014-11-27-machine-learning-k-means-local-minimum.png" alt="不恰当的类中心初始化导致局部极值" /></a><div class="caption">Figure 1:  不恰当的类中心初始化导致局部极值 [<a href="/assets/images/2014-11-27-machine-learning-k-means-local-minimum.png">PNG</a>]</div></div></div>

<p>随机初始化类中心的方法通常是，随机从样本中选取$K$个点作为类中心。为了避免陷入局部极致，通常会进行多轮初始化，选择代价函数值最小的作为聚类结果。</p>

<blockquote>
  <h4 id="k-means-2">随机初始化选择$k$-means的类中心</h4>
  <hr />
  <p>For i = 1 to 100 {</p>

  <ol>
    <li>随机初始化类中心$\boldsymbol\mu_k$；</li>
    <li>$k$-means算法得到$c^{(1)},\dots,c^{(m)},\boldsymbol\mu_1,\ldots,\boldsymbol\mu_K$；</li>
    <li>计算代价函数\eqref{eq:cf-k-means}。</li>
  </ol>

  <p>}  <br />
选择代价函数值最小的聚类结果输出。</p>
</blockquote>

<p>当$K=2,\ldots,10$时，这种方法的代价函数变化明显，当$K$很大（$K&gt;100$）时，代价函数可能没有明显的变化。</p>

<h3 id="k">确定类别数$K$</h3>

<p>通过不停增大类别数$K$，选择代价函数曲线拐点对应的类别数，如下图左所示。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-k-means-elbow-method.png"><img src="/assets/images/2014-11-27-machine-learning-k-means-elbow-method.png" alt="确定类别数的elbow method" /></a><div class="caption">Figure 2:  确定类别数的elbow method [<a href="/assets/images/2014-11-27-machine-learning-k-means-elbow-method.png">PNG</a>]</div></div></div>

<p>有时，代价函数曲线不存在拐点，如上图右所示。还可以根据$k$-means应用的具体场景，选择聚类数目，比如要制作XS、S、M、L、XL几种规格的服装，当然用类别数$K=5$来划分人的身高体重。</p>

<h2 id="section-1">参考文献</h2>

<ol class="bibliography"><li><span id="ng_ml_c_2014">[1]A. Ng, “Clustering.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-2">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：支持向量机（SVM）</title>
      <link href="http://qianjiye.de/2014/11/machine-learning-support-vector-machines" />
      <pubdate>2014-11-27T08:05:56+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/11/machine-learning-support-vector-machines</guid>
      <content:encoded>&lt;![CDATA[<h2 id="logisticsvm">从Logistic回归到SVM</h2>

<p>本节通过Logistic回归的代价函数，演化到SVM的代价函数，然后通过代价函数最小化推导SVM的判别界<a href="#ng_ml_svm_2014">[1, P. 3—14]</a>。</p>

<p>Logistic回归的代价函数为</p>

<p>\begin{equation}
\begin{aligned}
J(\boldsymbol\theta)  = &amp;-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)\right)\right) \\
&amp; + \frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
\end{aligned}，
\label{eq:cf-logistic-regression-r}
\end{equation}</p>

<p>取出代价函数中的一项如下图，并绘制逼近Logistic代价函数的两个新的代价函数项$\mbox{cost}_1(\mathbf z)$和$\mbox{cost}_0(\mathbf z)$。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-logistic2svm.png"><img src="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-logistic2svm.png" alt="图解Logistic回归的代价函数" /></a><div class="caption">Figure 1:  图解Logistic回归的代价函数 [<a href="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-logistic2svm.png">PNG</a>]</div></div></div>

<p>将Logistic回归的代价函数提取$\lambda\over m$，令$C={1\over\lambda}$，并用新的代价函数项替代Logistic回归的代价函数项，可得SVM的代价函数</p>

<p>\begin{equation}
J(\boldsymbol\theta)  =  C\sum_{i=1}^{m}\left(y^{(i)}\mbox{cost}_1\left(\boldsymbol\theta ^T\mathbf x^{(i)}\right)+\left(1-y^{(i)}\right)\mbox{cost}_0\left(\boldsymbol\theta ^T\mathbf x^{(i)}\right)\right) + \frac{1}{2}\sum_{j=1}^n\theta_j^2 ，
\label{eq:cf-svm-r}
\end{equation}</p>

<p>新的代价函数不再以$0$作为分类边界，而是以$+1$和$-1$。若代价函数\eqref{eq:cf-svm-r}要得最小值，可得SVM的判别界</p>

<p>\begin{equation}
\begin{aligned}
&amp; \min_\boldsymbol\theta\frac{1}{2}\sum_{j=1}^{n}\theta_j^2 &amp; \\
&amp;
\begin{aligned}
\mbox{s.t.} &amp; ~~ \boldsymbol\theta^T\mathbf x^{(i)} \geq 1 &amp;\mbox{if} &amp; ~~ y^{(i)} = 1 \\
&amp; ~~ \boldsymbol\theta^T\mathbf x^{(i)} \leq -1 &amp; \mbox{if} &amp; ~~ y^{(i)} = 0
\end{aligned}
\end{aligned}。
\label{eq:svm-decision-boundary}
\end{equation}</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-svm-boundary.png"><img src="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-svm-boundary.png" alt="图解SVM的判别界" /></a><div class="caption">Figure 2:  图解SVM的判别界 [<a href="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-svm-boundary.png">PNG</a>]</div></div></div>

<p>根据向量间的夹角公式$\cos\theta = \frac{\boldsymbol\theta^T\mathbf x^{(i)}}{\left\lVert\boldsymbol\theta\right\rVert\left\lVert\mathbf x^{(i)}\right\rVert}$，则$p^{(i)}=\left\lVert\mathbf x^{(i)}\right\rVert\cos\theta$表示向量$\mathbf x^{(i)}$在向量$\boldsymbol\theta$上的投影，SVM的判别界\eqref{eq:svm-decision-boundary}可以改写为</p>

<p>\begin{equation*}
\begin{aligned}
&amp; \min_\boldsymbol\theta\frac{1}{2} \lVert\boldsymbol\theta\rVert^2 &amp; \\
&amp;
\begin{aligned}
\mbox{s.t.} &amp; ~~ p^{(i)}\lVert\boldsymbol\theta\rVert \geq 1 &amp;\mbox{if} &amp; ~~ y^{(i)} = 1 \\
&amp; ~~ p^{(i)}\lVert\boldsymbol\theta\rVert \leq -1 &amp; \mbox{if} &amp; ~~ y^{(i)} = 0
\end{aligned}
\end{aligned}。
\end{equation*}</p>

<p>$\boldsymbol\theta$是判别界的法线，$p^{(i)}$的值可正可负。要满足判别界的条件，$\left\vert p^{(i)}\right\vert$越大越好，这样$\lVert\boldsymbol\theta\rVert$就可以取到很小的值。因此，上图中右下比左下有更大的$\left\vert p^{(i)}\right\vert$，是更合适的SVM判别界。</p>

<h2 id="section">核函数</h2>

<p>SVM为了解决非线性可分问题，需要引入核函数（kernel）。作为SVM的核函数须满足Mercer定理。</p>

<blockquote>
  <h4 id="mercer-a-hrefjulysvm20142a">Mercer 定理<a href="#July_svm_2014">[2]</a></h4>
  <hr />
  <p>函数$\kappa$是 $\mathbb R^n \times \mathbb R^n \to \mathbb R$ 上的映射。如果$\kappa$是一个有效核函数（也称为Mercer核函数），那么当且仅当对于训练样例$\{\mathbf x_1,\mathbf x_2,\ldots,\mathbf x_n\}$，其相应的核函数矩阵是对称半正定的。</p>
</blockquote>

<p>通过特征与参考地标（landmark）$\mathbf l^{(i)}$之间的相似性，定义高斯核为<a href="#ng_ml_svm_2014">[1, P. 17—20]</a></p>

<p>\begin{equation}
\mathbf f_i = \mbox{similarity}\left(\mathbf x, \mathbf l^{(i)} \right)
= \exp\left(-\frac{\left\lVert\mathbf x - \mathbf l^{(i)}\right\rVert}{2\sigma^2} \right)。
\end{equation}</p>

<p>核函数的作用相当于特征变换，SVM引入了核函数的代价函数为</p>

<p>\begin{equation}
J(\boldsymbol\theta)  =  C\sum_{i=1}^{m}\left(y^{(i)}\mbox{cost}_1\left(\boldsymbol\theta ^T\mathbf f^{(i)}\right)+\left(1-y^{(i)}\right)\mbox{cost}_0\left(\boldsymbol\theta ^T\mathbf f^{(i)}\right)\right) + \frac{1}{2}\sum_{j=1}^n\theta_j^2。
\label{eq:cf-svm-kernel-r}
\end{equation}</p>

<p>在使用高斯核之前，需要对特征进行规范化，使其取值取值近似位于同一区间。SVM代价函数和核函数的参数对SVM分类有如下影响<a href="#ng_ml_svm_2014">[1, P. 25]</a>：</p>

<ol>
  <li>大的$C~\left(C={1\over\lambda}\right)$导致Low Bias和High Variance；</li>
  <li>小的$C~\left(C={1\over\lambda}\right)$导致High Bias和Low Variance；</li>
  <li>大的$\sigma^2$使得特征$\mathbf f_i$变化平缓，导致High Bias和Low Variance；</li>
  <li>小的$\sigma^2$使得特征$\mathbf f_i$变化较大，导致Low Bias和High Variance。 </li>
</ol>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-kernel-svm-performance.svg"><img src="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-kernel-svm-performance.svg" alt="高斯核的SVM分类效果" /></a><div class="caption">Figure 3:  高斯核的SVM分类效果 [<a href="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-kernel-svm-performance.svg">SVG</a>, <a href="/assets/images/2014-11-27-machine-learning-advice-for-applying-machine-learning-kernel-svm-performance.png">PNG</a>]</div></div></div>

<p>对于在线性可分的数据集上训练线性核的SVM，采用不同的$C$也会得到不同的分界面。比如，增大$C$可能得到更大的$\boldsymbol\theta$值，以增大在特定样本之间的分类间隔。</p>

<h2 id="smo">SMO算法</h2>

<h2 id="svm">使用SVM</h2>

<p>Logistic回归强调所有点尽可能地远离中间那条线，SVM更应该关心靠近中间分割线的点，让他们尽可能地远离中间线。SVM考虑局部（不关心已经确定远离的点），Logistic回归考虑全局（已经远离的点可能通过调整中间线使其能够更加远离）<a href="#JerryLead_svm1_2011">[3]</a>。</p>

<h3 id="logisticsvm-1">Logistic回归、SVM、神经网络</h3>

<p>如何在分类器Logistic回归、SVM和神经网络之间做出选择？</p>

<p>$n$为特征数目（$x\in \mathbb{R}^{n+1} $），$m$为训练集样本数目，分类器选择的方法如下<a href="#ng_ml_svm_2014">[1, P. 31]</a>：</p>

<ol>
  <li>若$n$很大（比如$n\geq m, n=10000,m=10,\ldots,1000$），采用Logistic回归或者无核函数（线性核函数）的SVM（此种情况，用Logistic回归难以训练好非线性分类器）；</li>
  <li>若$n$很小而$m$大小适中（比如$n=1,\ldots,1000,m=10,\ldots,10000$），采用高斯核的SVM；</li>
  <li>若$n$很小而$m$很大（比如$n=1,\ldots,1000,m=50000+$），先可以增加特征，然后采用Logistic回归或者无核函数（线性核函数）的SVM（此种情况，高斯核的SVM分类器训练会慢）；</li>
  <li>神经网络在以上大多数情况都工作较好，但是可能训练速度会很慢；</li>
  <li>神经网络是非凸优化，会陷入局部极值，SVM是凸优化，不用担心陷入局部极值。</li>
</ol>

<p>选择Logistic回归或者无核函数（线性核函数）的SVM，是因为Logistic回归和无核函数（线性核函数）的SVM相似。</p>

<p>核函数的Logistic回归训练较慢，核函数的SVM可以训练较快。</p>

<h2 id="section-1">应用案例</h2>

<h3 id="a-hrefngmlsvmex20144-p-1015a">垃圾邮件分类<a href="#ng_ml_svm_ex_2014">[4, P. 10—15]</a></h3>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-svm-email-processing.svg"><img src="/assets/images/2014-11-27-machine-learning-svm-email-processing.svg" alt="Email转换为特征向量" /></a><div class="caption">Figure 4:  Email转换为特征向量 [<a href="/assets/images/2014-11-27-machine-learning-svm-email-processing.svg">SVG</a>]</div></div></div>

<p>垃圾邮件分类首先需要将Email文本转换为特征向量。如上图所示，转换方法如下：</p>

<ol>
  <li>将Email文本转换为纯单词，比如：单词小写化，移除所有HTML标签，url链接均用单词<code>httpaddr</code>代替，提取词干（例如including、includes和included都用include代替）等；</li>
  <li>利用事先准备的词典，将单词用其在词典中的索引表示，实际应用中，词典通常有10000到50000个单词；</li>
  <li>将索引转换为$\{0, 1\}$特征向量，向量长度和词典中词汇数目一样，某个单词出现用$1$表示，否者用$0$表示。  </li>
</ol>

<h2 id="section-2">相关评论</h2>

<p>事实上，支持向量机是一个具有很好数学基础的分类方法，但它本质上也只不过是一个简单的两层方法：第一层可以看作是一些单元集合（一个支持向量就是一个单元），这些单元通过核函数能够度量输入向量和每个支持向量的相似度；第二层则把这些相似度做了简单的线性累加。支持向量机第一层的训练和最简单的无监督学习基本一致：利用支持向量来表示训练样本。一般来讲，通过调整核函数的平滑性（参数）能在线性分类和模板匹配之间做出平衡。从这个角度来讲，核函数只不过是一种模板匹配方法。<a href="#lecun_dl_vs_svm_2014">[5]</a></p>

<p>［@余凯_西二旗民工］很多有关SVM的教科书都有misleading: (1)KKT条件，support vectors，quadratic programing都是浮云；（2）kernel本身对理解学习问题有帮助，但实际工程上用处为0；（3）hinge loss只是众多可选项之一，logistic效果一点不差。［@老师木］做论文时迷信kernel，margin，认为这些机制和graphical model结合不就无敌了吗？等论文出来的结论是hinge loss对比无优越性。再翻vapnik的 统计学习的本质，原来他老人家也早做过对比试验，没发现svm相对于lr的优越性。看损失函数曲线，真看不出hinge loss比log loss好，只是hinge loss能得到稀疏解，看上去很美。当然理解这些优化理论本身会给人一些享受。数据线性可分的可能性随维度升高而变大，这是Thomas cover五六十年代得出的结论。要严格一点，数据线性可分和线性无关等价，张成维度高的线性空间所需的基多，其实就是VC维了。引入kernel就是引入非线性，使变换后的样例线性无关。Rbf核等价于无穷次多项式拟合，相对于有限的样例，没有不能分开的。<a href="#mu_svm_myth_2014">[6]</a></p>

<h2 id="section-3">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_svm_2014">[1]A. Ng, “Support Vector Machines.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li>
<li><span id="July_svm_2014">[2]July, “支持向量机通俗导论（理解SVM的三层境界）.” csdn, 2014.</span>

[<a href="http://blog.csdn.net/v_july_v/article/details/7624837/">Online</a>]

</li>
<li><span id="JerryLead_svm1_2011">[3]JerryLead, “支持向量机SVM（一）.” cnblogs, 2011.</span>

[<a href="http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982639.html">Online</a>]

</li>
<li><span id="ng_ml_svm_ex_2014">[4]A. Ng, “Programming Exercise 6: Support Vector Machines.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li>
<li><span id="lecun_dl_vs_svm_2014">[5]Y. LeCun, “深度学习与支持向量机有什么联系？.” 52cs, 2014.</span>

[<a href="http://www.52cs.org/?p=46">Online</a>]

</li>
<li><span id="mu_svm_myth_2014">[6]老师木, “SVM神话.” 52cs, 2014.</span>

[<a href="http://www.52cs.org/?p=359">Online</a>]

</li></ol>

<h3 id="section-4">脚注</h3>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：实战技能</title>
      <link href="http://qianjiye.de/2014/11/machine-learning-advice-for-applying-machine-learning" />
      <pubdate>2014-11-25T09:44:20+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/11/machine-learning-advice-for-applying-machine-learning</guid>
      <content:encoded>&lt;![CDATA[<p>对于分类器而言通常需要考虑如下问题：</p>

<ul>
  <li>如何评价分类器性能？</li>
  <li>数据需要如何预处理？</li>
  <li>如何设计代价函数？</li>
  <li>代价函数是凸的么？</li>
  <li>如何用最优化方法求解模型参数？</li>
  <li>如何调整参数，在Bias和Variance之间寻求平衡？</li>
  <li>如何解决多分类问题？</li>
  <li>如何处理线性不可分问题？</li>
</ul>

<p>对于样本动态变化的情况，还需要考虑如何在线学习和动态更新模型参数；对于大规模数据集，需要考虑如何选择合适的模型，如何降低复杂度。</p>

<h2 id="section">模型选择</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_aaml_2014">[1]</a>。</p>

<p>模型选择主要是通过评估模型效果，评价模型Bias和Variance的状况，选择合适的模型和估计相应的参数。</p>

<p>数据集一般划分为训练集、交叉验证集和测试集3部分，分别占的比例大概是60%、20%和20%<sup id="fnref:only-train-test"><a href="#fn:only-train-test" class="footnote">1</a></sup>。训练集用于估计模型参数，交叉验证集用于选择模型，测试集用于估计模型的泛化误差（generalization error）；选择在交叉验证集上误差小的模型，但是用测试集上误差作为模型的误差。测试集上的数据对参数估计和模型选择都是不可见的，因此才能“公平”的评价模型的性能。</p>

<p>$J_\mbox{train}(\boldsymbol\theta)$、$J_\mbox{cv}(\boldsymbol\theta)$、$J_\mbox{test}(\boldsymbol\theta)$分别表示模型在训练集、交叉验证集和测试集上的误差</p>

<p>\begin{equation}
J_{s}(\boldsymbol\theta) = \frac{1}{2m_{s}}\sum_{i=1}^{m_s}\left(h_\boldsymbol\theta\left(\mathbf x_s^{(i)}\right)-y_s^{(i)}\right)^2~~(s = \{\mbox{train},\mbox{cv},\mbox{test}\})。
\end{equation}</p>

<h3 id="bias-vs-variance">Bias vs. Variance</h3>

<p>简单来说，Bias和Variance评价模型的拟合程度，High Bias就是欠拟合（underfit），High Variance就是过拟合（overfit）。对于欠拟合，$J_\mbox{cv}(\boldsymbol\theta)\approx J_\mbox{train}(\boldsymbol\theta)$且都较大；对于过拟合，$J_\mbox{cv}(\boldsymbol\theta)\gg J_\mbox{train}(\boldsymbol\theta)$且$J_\mbox{train}(\boldsymbol\theta)$较小。</p>

<h3 id="section-1">模型选择与正则化——以多项式回归为例</h3>

<p>模型的复杂度和参数估计时采用的正则化参数$\lambda$对模型的Bias和Variance均有影响。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models.png" alt="多项式回归模型" /></a><div class="caption">Figure 1:  多项式回归模型 [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models.png">PNG</a>]</div></div></div>

<p>如果选用多项式回归模型，需要选择多项式的次数确定合适的模型。参数估计的时候，可以通过调节正则化系数，平衡Bias和Variance的关系。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-d-lambda.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-d-lambda.png" alt="多项式次数和正则化系数与误差的关系" /></a><div class="caption">Figure 2:  多项式次数和正则化系数与误差的关系 [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-d-lambda.png">PNG</a>]</div></div></div>

<p>随着多项式次数$d$的增加， 模型从High Bias变为了High Variance；随着正则化系数$\lambda$的增加， 模型从High Variance变为了High Bias。通过评估调整模型和正则化参数时的误差，确定模型的相关系数。</p>

<h3 id="section-2">学习曲线</h3>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-learning-curves.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-learning-curves.png" alt="High Bias和High Variance的学习曲线" /></a><div class="caption">Figure 3:  High Bias和High Variance的学习曲线 [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-learning-curves.png">PNG</a>]</div></div></div>

<p>学习曲线描绘了训练样本数目和误差之间的关系，展示了模型可能存在的问题。通过学习曲线，判断模型是否合适；如果不合适，模型是High Bias还是High Variance，从而有针对性地解决问题。</p>

<h3 id="section-3">提升模型性能的策略</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left">技术手段</th>
      <th style="text-align: left">处理问题</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">加入更多的训练样本</td>
      <td style="text-align: left">High Variance<sup id="fnref:Not-good-if-high-bias"><a href="#fn:Not-good-if-high-bias" class="footnote">2</a></sup></td>
    </tr>
    <tr>
      <td style="text-align: left">抽取特征子集</td>
      <td style="text-align: left">High Variance<sup id="fnref:Not-good-if-high-bias:1"><a href="#fn:Not-good-if-high-bias" class="footnote">2</a></sup></td>
    </tr>
    <tr>
      <td style="text-align: left">增加特征</td>
      <td style="text-align: left">High Bias</td>
    </tr>
    <tr>
      <td style="text-align: left">构造多项式特征</td>
      <td style="text-align: left">High Bias</td>
    </tr>
    <tr>
      <td style="text-align: left">增大$\lambda$</td>
      <td style="text-align: left">High Variance</td>
    </tr>
    <tr>
      <td style="text-align: left">减小$\lambda$</td>
      <td style="text-align: left">High Bias</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <h4 id="example">Example</h4>
  <hr />
  <p>Suppose you have a dataset with n = 10 features and m = 5000 examples. After training your logistic regression classifier with gradient descent, you find that it has underfit the training set and does not achieve the desired performance on the training or cross validation sets. Which of the following might be promising steps to take? Check all that apply.</p>

  <ul>
    <li>[A] Use an SVM with a Gaussian Kernel. (By using a Gaussian kernel, your model will have greater complexity and can avoid underfitting the data.)</li>
    <li>[B] Increase the regularization parameter $\lambda$.</li>
    <li>[C] Try using a neural network with a large number of hidden units. (A neural network with many hidden units is a more complex (higher variance) model than logistic regression, so it is less likely to underfit the data.)</li>
    <li>[D] Reduce the number of examples in the training set. (While you can improve accuracy on the training set by removing examples, doing so results in a worse model that will not generalize as well.)</li>
    <li>[E] Create / add new polynomial features.</li>
  </ul>

  <p>Answer: A C E</p>
</blockquote>

<h2 id="performance-evaluation">性能评估</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_mlsd_2014">[2]</a>。</p>

<p>如何和里评价机器学习算法，尤其是对于有偏的类别而言，单纯的正确率（Accuracy），
\begin{equation}
\mbox{Accuracy} = \frac{\mbox{true positives + true negatives}}{\mbox{total examples}}，
\end{equation}
难以合理评价分类器性能。</p>

<p>比如癌症检测，癌症的概率大概只有0.5左右，对于分类器，采用作弊的方法，即使全部输出非癌症的结果，也可以获得99.5％的正确率。因此需要合理的评估方法，通常采用的是准确率（Precision）和召回率（Recall）。</p>

<h3 id="precision--recall">Precision &amp; Recall</h3>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-precisionrecall.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-precisionrecall.png" alt="准确率和召回率" /></a><div class="caption">Figure 4:  准确率和召回率 [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-precisionrecall.png">PNG</a>, <a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-precisionrecall.svg">SVG</a>]</div></div></div>

<p>准确率刻画的是，被正确分类的样本在分类结果中占的比率，</p>

<p>\begin{equation}
\mbox{Precision} = \frac{\mbox{true positives}}{\mbox{true positives + false positives}}。
\end{equation}</p>

<ul>
  <li>true positives：真正正确分类的样本数；</li>
  <li>false positives：混入该类别的其它类别样本数。 </li>
</ul>

<p>召回率刻画的是，被正确分类的样本在输入样本中占的比率，</p>

<p>\begin{equation}
\mbox{Recall} = \frac{\mbox{true positives}}{\mbox{true positives + false negatives}}。
\end{equation}</p>

<ul>
  <li>false negatives：本该属于该类别却被分到其它类被的样本数。</li>
</ul>

<p>根据应用的具体需求，可以在准确率和召回率之间折中。若采用Logistic回归分类器，调高分类的阈值，可以提升该类别分类的准确率和降低召回率。</p>

<h3 id="ff1-score">$F$/$F_1$ Score</h3>

<p>采用准确率和召回率可以合理评估分类器性能，但是两个数值不如单数值的评估直接明了。$F$/$F_1$ Score是基于准确率和召回率的单数值评估指标，</p>

<p>\begin{equation}
F = 2 \times \frac{\mbox{Precision}\times\mbox{Recall}}{\mbox{Precision} + \mbox{Recall}}，
\end{equation}</p>

<p>数值越高表示效果越好。</p>

<h3 id="section-4">数据为王</h3>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-size-accuracy.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-size-accuracy.png" alt="数据集大小对准确率的影响" /></a><div class="caption">Figure 5:  数据集大小对准确率的影响 [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-polynomial-models-size-accuracy.png">PNG</a>]</div></div></div>

<p>通常而言，增加参数数目（比如：Logistic回归增加特征数目，神经网络增加隐藏层神经元）和训练样本数目，可以提升分类器的性能。增加参数数目可以获得Low Bias（$J_\mbox{train}(\theta)$小），增加样本数目可以获得Low Variance（$J_\mbox{test}(\theta)$小）。</p>

<blockquote>
  <p>“It’s not who has the best algorithm that wins. It’s who has the most data.”<a href="#ng_ml_mlsd_2014">[2, P. 16]</a></p>
</blockquote>

<p>在大规模数据上训练模型，取得良好效果的前提条件是：</p>

<ol>
  <li>模型具备足够多的参数，能够表示复杂的函数；</li>
  <li>特征$\mathbf x$包含了预测$y$的足够信息（例如：该领域的专家可以仅仅通过$x$的有把握地预测$y$）。</li>
</ol>

<p>Guo-Xun Yuan等撰文指出<a href="#yuan_ralll_2012">[3]</a>，对于大规模数据的应用而言，线性分类器可能获得和非线性分类器接近的性能，并且训练和测试的速度要快得多。</p>

<h2 id="section-5">获取更多的数据</h2>

<p>并非总是数据越多越好。在获取更多数据之前，先判断模型是否需要更多的数据。</p>

<p>针对Low Bias（或High Variance）的模型，获取更多的数据才能提高模型的性能。如果是High Bias（或Low Variance）的模型，先增加特征（神经网络增加神经元），使模型是Low Bias（或High Variance）的，然后更多的数据才有助于提升模型性能。获取更多数据的方法通常有人工合成、手动搜集标柱等<a href="#ng_ml_ocr_2014">[4]</a>。</p>

<p>针对OCR，可以将计算机字库中的标准字体叠加随机背景，然后进行形变，产生更多的样本集。一般而言，通过叠加高斯噪声增大样本集对提升性能帮助不大，除非需要解决的问题的就是高斯噪声下的OCR。</p>

<h2 id="section-6">提升关键步骤性能</h2>

<p>针对一个机器学习应用的流水线，找出影响性能的瓶颈，对症下药，才能更有效的改善性能<a href="#ng_ml_ocr_2014">[4]</a>。</p>

<div class="image_line" id="figure-6"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-segmentation.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-segmentation.png" alt="学习字符分割间隔的神奇方法" /></a><div class="caption">Figure 6:  学习字符分割间隔的神奇方法 [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-segmentation.png">PNG</a>]</div></div></div>

<p>对OCR问题而言，通常分为文字检测、字符分割、字符识别几个步骤。提升OCR性能，需要先定量分析究竟哪个步骤对性能的影响最大，然后有针对性的解决。</p>

<div class="image_line" id="figure-7"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-ceiling-analysis.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-ceiling-analysis.png" alt="Ceiling Analysis" /></a><div class="caption">Figure 7:  Ceiling Analysis [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-ceiling-analysis.png">PNG</a>]</div></div></div>

<p>上图给出了通过Ceiling Analysis分析出关键问题的示例，系统的总体精度是$72\%$。如果手动标注（检测定位）待识别的文字区域（也就是让文字都正确定位），那么系统的精度会提升到$89\%$；如果继续将所有的字符都正确分割出，精度会提升到$90\%$。从而可得出，字符检测可以提升$17\%$的精度，字符识别可提升$10\%$的精度，首先从这两个地方改善性能，字符分割对性能的提升只有$1\%$，可先不考虑改进。</p>

<div class="image_line" id="figure-8"><div class="image_card"><a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-face-recognition.png"><img src="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-face-recognition.png" alt="人脸识别" /></a><div class="caption">Figure 8:  人脸识别 [<a href="/assets/images/2014-11-25-machine-learning-advice-for-applying-machine-learning-face-recognition.png">PNG</a>]</div></div></div>

<p>上图给出了对人脸识别的Ceiling Analysis，可以看出预处理的背景移除对提升性能影响不大，仅仅为$0.1\%$，这个步骤其实可以去掉。人脸检测才是影响性能的关键。</p>

<h2 id="section-7">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_aaml_2014">[1]A. Ng, “Advice for applying machine learning.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li>
<li><span id="ng_ml_mlsd_2014">[2]A. Ng, “Machine Learning System Design.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li>
<li><span id="yuan_ralll_2012">[3]G.-X. Yuan, C.-H. Ho, and C.-J. Lin, “Recent Advances of Large-Scale Linear Classification,” <i>Proceedings of the IEEE</i>, vol. 100, no. 9, pp. 2584–2603, 2012.</span>

</li>
<li><span id="ng_ml_ocr_2014">[4]A. Ng, “Application example: Photo OCR.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-8">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:only-train-test">
      <p>对于不需要做模型选择的情况，只需要训练集和测试集，样本的比例通常是70%和30%。 <a href="#fnref:only-train-test" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:Not-good-if-high-bias">
      <p><a href="http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning.html">Not good if you have high bias</a> <a href="#fnref:Not-good-if-high-bias" class="reversefootnote">&#8617;</a> <a href="#fnref:Not-good-if-high-bias:1" class="reversefootnote">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
