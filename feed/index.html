<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2015-02-13T10:20:46+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>特征学习模型总结</title>
      <link href="http://qianjiye.de/2015/02/summary-of-extraction-models" />
      <pubdate>2015-02-13T17:48:53+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/summary-of-extraction-models</guid>
      <content:encoded>&lt;![CDATA[<p>特征学习／提取模型（extraction model）：除了得到最终的线性模型外，将特征变换$\Phi$作为隐含的学习变量。</p>

<p>特征学习模型是拥有众多成员的大家族：</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>隐藏变量</th>
      <th>线性模型</th>
      <th>extraction技术</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>神经网络／深度学习</td>
      <td>$w_{ij}^{(\ell)}$</td>
      <td>$w_{ij}^{(L)}$</td>
      <td>梯度下降法＋BP<br />自编码器（非监督学习）</td>
    </tr>
    <tr>
      <td>RBF网络</td>
      <td>中心$\boldsymbol\mu_m$</td>
      <td>$\beta_m$</td>
      <td>k均值聚类（非监督学习）</td>
    </tr>
    <tr>
      <td>矩阵分解<sup id="fnref:v-equals-w"><a href="#fn:v-equals-w" class="footnote">1</a></sup></td>
      <td>用户特征$\mathbf v_n$</td>
      <td>电影特征$\mathbf w_m$</td>
      <td>梯度下降法<br />交替最小二乘法</td>
    </tr>
    <tr>
      <td>Ada/Gradient Boosting</td>
      <td>假设$g_t$</td>
      <td>投票权重$\alpha_t$</td>
      <td>函数梯度下降法</td>
    </tr>
    <tr>
      <td>k最近邻算法</td>
      <td>邻居$\mathbf x_n$</td>
      <td>$y_n$</td>
      <td>lazy learning</td>
    </tr>
  </tbody>
</table>

<p>特征学习模型的优劣：</p>

<table>
  <thead>
    <tr>
      <th>优势</th>
      <th>坏处</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>容易：减轻了人工提取特征的负担</td>
      <td>困难：通常是非凸优化</td>
    </tr>
    <tr>
      <td>强大：如果有足够多的隐含变量</td>
      <td>过拟合：需要正则化或验证</td>
    </tr>
  </tbody>
</table>

<p>因此，使用特征学习模型要当心！</p>

<h2 id="section">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-1">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:v-equals-w">
      <p>$\mathbf v_n$和$\mathbf w_m$实际上是对称的（等价的）。 <a href="#fnref:v-equals-w" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>矩阵分解</title>
      <link href="http://qianjiye.de/2015/02/matrix-factorization" />
      <pubdate>2015-02-12T18:33:54+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/matrix-factorization</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">线性网络</h2>

<p>对于推荐系统（recommender system）数据集，用户对第$m$部电影的评分表示为
\[
\mathcal D_m=
\left\{\left(
\tilde x_n=(n), y_n=r_{nm}
\right)
\mbox{ user }n\mbox{ rated movie }m
\right\}，
\]
$\tilde x_n=(n)$表示抽象的（abstract）特征，代表用户编号（ID），不代表任何数值上的意义，这类的特征称为<strong>类别特征</strong>（categorical feature）。</p>

<p>常见的类别特征有ID、血型、程序语言……然而，许多机器学习算法都对数值特征友好，比如线性模型、扩展的（extended）线性模型（神经网络等）……决策树可以处理类别特征。若要将类别特征用于对数值特征友好的模型，需要将类别特征转换或编码（transform/encode）为数值特征。二值编码（binary vector encoding）是比较简单的征编码方式，对于血型有
\[
A=[1\;0\;0\;0]^\top,\quad
B=[0\;1\;0\;0]^\top,\quad
AB=[0\;0\;1\;0]^\top,\quad
O=[0\;0\;0\;1]^\top。
\]
编码之后第$m$部电影的的数据记为
\[
\mathcal D_m=
\left\{\left(
\tilde x_n=\mbox{BinaryVectorEncoding}(n), y_n=r_{nm}
\right)
\mbox{ user }n\mbox{ rated movie }m
\right\}，
\]
所有用户的数据可以统一记为
\[
\mathcal D=
\left\{\left(
\tilde x_n=\mbox{BinaryVectorEncoding}(n), 
y_n=\left[r_{n1}\;?\;?\;r_{n4}\;r_{n5}\;\ldots\;r_{nM}\right]^\top
\right)
\right\}，
\]
“$?$”表示用户没有对电影做出评价。若要学到每个用户的爱好，需要先学到每个用户的特征（年龄、电影类型的偏好等）。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-NN-for-features.png"><img src="/assets/images/2015-02-12-matrix-factorization-NN-for-features.png" alt="利用神经网络提取特征" /></a><div class="caption">图 1:  利用神经网络提取特征 [<a href="/assets/images/2015-02-12-matrix-factorization-NN-for-features.png">PNG</a>]</div></div></div>

<p>利用不含$x_0^{(\ell)}$神经元<sup id="fnref:why-no-1-neuron"><a href="#fn:why-no-1-neuron" class="footnote">1</a></sup>的$N-\tilde d-M$神经网络（自编码器）提取特征，如上图所示，$\mathbf x$是只有一个非0元的二值向量。中间的$\tanh$转换必要么？</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-linear-neuron-for-features.png"><img src="/assets/images/2015-02-12-matrix-factorization-linear-neuron-for-features.png" alt="采用线性神经元提取特征" /></a><div class="caption">图 2:  采用线性神经元提取特征 [<a href="/assets/images/2015-02-12-matrix-factorization-linear-neuron-for-features.png">PNG</a>]</div></div></div>

<p>对于$\mathbf x$，只会有一个非0分量进入$\tanh$层的神经元，即使不进行$\tanh$转换（采用线性模型，如上图所示）也能找到特征的恰当描述方式，这样的神经网络称为<strong>线性网络</strong>（linear network）。第一层用$N\times\tilde d$的矩阵$\mathbf V^\top$表示，第二层用$\tilde d\times M$的矩阵$\mathbf W$表示，线性网络可以表示为
\begin{equation}
h(\mathbf x)=\mathbf W^\top\mathbf V\mathbf x。
\end{equation}
对每个用户而言，由于$\mathbf x_n$只有一个元素为1，相当于抽取矩阵的一列
\begin{equation*}
h(\mathbf x_n)=\mathbf W^\top\mathbf v_n，
\end{equation*}
$\mathbf v_n$表示$\mathbf V$的第$n$列，相当于对第$n$个用户进行了特征转换。</p>

<p>对于推荐系统，线性网络学习$\mathbf V$和$\mathbf W$。</p>

<h2 id="section-1">矩阵分解</h2>

<p>令$\Phi(\mathbf x)=\mathbf V\mathbf x$，第$m$部电影的评分只是线性模型$h_m(\mathbf x)=\mathbf w_m^\top\Phi(\mathbf x)$。对于$\mathcal D_m$，期望有
\[
r_{nm}=y_n\approx\mathbf w_m^\top\mathbf v_n，
\]
需要最小化目标函数
\begin{equation}
E_{in}\left(\left\{\mathbf w_m\right\},\left\{\mathbf v_n\right\}\right)
={1\over \sum_{m=1}^M\lvert\mathcal D_m\rvert}\sum_{\mbox{user }n\mbox{ rated movie }m}
\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)^2，
\end{equation}
同时学到转换方式$\left\{\mathbf v_n\right\}$和线性模型$\left\{\mathbf w_m\right\}$。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-matrix-factorization.png"><img src="/assets/images/2015-02-12-matrix-factorization-matrix-factorization.png" alt="矩阵分解的形式" /></a><div class="caption">图 3:  矩阵分解的形式 [<a href="/assets/images/2015-02-12-matrix-factorization-matrix-factorization.png">PNG</a>]</div></div></div>

<p>当$r_{nm}=\mathbf w_m^\top\mathbf v_n=\mathbf v_n^\top\mathbf w_m$时，所有评价可记为矩阵形式$\mathbf R\approx\mathbf V^\top\mathbf W$，将含有缺失值的$\mathbf R$矩阵分解为两个矩阵的乘积，如上图所示，就得到了用户的特征以及特征的线性组合方式。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-recommender.png"><img src="/assets/images/2015-02-12-matrix-factorization-recommender.png" alt="推荐系统" /></a><div class="caption">图 4:  推荐系统 [<a href="/assets/images/2015-02-12-matrix-factorization-recommender.png">PNG</a>]</div></div></div>

<p>通过用户的评分$\mathbf R$，学到了$\mathbf v_n$表示用户的特征（喜好），也学到了$\mathbf w_m$表电影具备哪些元素，如上图所示。</p>

<p>类似的矩阵分解模型可以用于提取其它抽象特征。线性自编码器可看作一种特殊的矩阵分解方法：</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th><a href="/2015/02/deep-learning/#linear-autoencoder">线性自编码器</a> $\mathbf X\approx\mathbf W\left(\mathbf W^\top\mathbf X\right)$</th>
      <th>矩阵分解 $\mathbf R\approx \mathbf V^\top\mathbf W$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>motivation</td>
      <td>特殊的$d-\tilde d-d$的线性神经网络</td>
      <td>$N-\tilde d-M$的线性神经网络</td>
    </tr>
    <tr>
      <td>误差度量</td>
      <td>所有数据$x_{ni}$上的平方误差</td>
      <td>已知数据$r_{nm}$上的平方误差</td>
    </tr>
    <tr>
      <td>求解方法</td>
      <td>$\mathbf X^\top\mathbf X$特征向量上的全局最优解</td>
      <td>交替最小二乘法求取的局部最优解</td>
    </tr>
    <tr>
      <td>功能</td>
      <td>获取数据低维特征表示</td>
      <td>提取隐含特征</td>
    </tr>
  </tbody>
</table>

<h2 id="section-2">交替最小二乘法</h2>

<p>通过最优化
\[
\min_{\mathbf W,\mathbf V}E_{in}\left(\left\{\mathbf w_m\right\},\left\{\mathbf v_n\right\}\right)
\propto\sum_{m=1}^M\left(
\sum_{(\mathbf x_n,r_{nm})\in\mathcal D_m}
\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)^2
\right)，
\]
学到参数矩阵$\mathbf W,\mathbf V$。同时学习两组变量很困难，可以采取类似<a href="/2015/02/radial-basis-function-network/#k-means">k均值算法</a>的<strong>交替最小二乘法</strong>（alternating least squares algorithm）：</p>

<ul>
  <li>当固定$\mathbf v_n$时，相当于在第$m$部电影的数据$\mathcal D_m$上最小化$E_{in}$得到$\mathbf w_m$，通过对每部电影的线性回归（不含$w_0$）实现；</li>
  <li>由于用户特征向量和电影特征向量的对称性（二者地位一样），当固定$\mathbf w_m$时，相当于对每个用户的线性回归（不含$v_0$）。</li>
</ul>

<blockquote>
  <h4 id="section-3">交替最小二乘法</h4>
  <hr />
  <p>随机初始化$\tilde d$维向量$\{\mathbf w_m\}，\{\mathbf v_n\}$；</p>

  <p>交替最小化$E_{in}$直到收敛：</p>

  <ul>
    <li>最优化$\mathbf w_1,\mathbf w_2,\ldots,\mathbf w_M$：对电影$m$在数据集$\{(\mathbf v_n,r_{nm})\}$做线性回归；</li>
    <li>最优化$\mathbf v_1,\mathbf v_2,\ldots,\mathbf v_N$：对用户$n$在数据集$\{(\mathbf w_m,r_{nm})\}$做线性回归。</li>
  </ul>
</blockquote>

<p>每次交替最小化都会使$E_{in}$减小，收敛是有保障的。采用交替最小二乘法，类似于用户和电影之间的“探戈”（tango）。</p>

<h2 id="section-4">随机梯度下降法</h2>

<p>随机梯度下降法（SGD，stochastic gradient descent）容易实现，每轮迭代高效，容易扩展到平方误差之外的其它误差度量方式。</p>

<p>单个数据产生的误差为
\[
err(\mbox{user }n, \mbox{movie }m, \mbox{rating }r_{nm})
=\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)^2，
\]
那么可得偏微分
\[
\begin{aligned}
\nabla_{\mathbf v_n} &amp;err(\mbox{user }n, \mbox{movie }m, \mbox{rating }r_{nm})
=-2\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)\mathbf w_m\\
\nabla_{\mathbf w_m} &amp;err(\mbox{user }n, \mbox{movie }m, \mbox{rating }r_{nm})
=-2\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)\mathbf v_n。
\end{aligned}
\]
每次跟新量$\propto -(\mbox{residual})(\mbox{the other feature vector})$，余数（residual）为$r_{nm}-\mathbf w_m^T\mathbf v_n$，也就是用余数倍另一个量更新当前量。</p>

<blockquote>
  <h4 id="section-5">基于随机梯度下降法的矩阵分解</h4>
  <hr />
  <p>随机初始化$\tilde d$维向量$\{\mathbf w_m\}，\{\mathbf v_n\}$<sup id="fnref:all-zeros"><a href="#fn:all-zeros" class="footnote">2</a></sup>；</p>

  <p>对$t=0,1,\ldots,T$迭代：</p>

  <ol>
    <li>对所有已知的$r_{nm}$，随机抽取$(n,m)$；</li>
    <li>计算余数$\tilde r_{nm}=r_{nm}-\mathbf w_m^T\mathbf v_n$；</li>
    <li>随机梯度更新：
\[
\begin{aligned}
\mathbf v_n^{new}&amp;\leftarrow\mathbf v_n^{old}+\eta\tilde r_{nm}\mathbf w_m^{old}\\
\mathbf w_m^{new}&amp;\leftarrow\mathbf w_m^{old}+\eta\tilde r_{nm}\mathbf v_n^{old}。
\end{aligned}
\]</li>
  </ol>
</blockquote>

<p>随机梯度下降法在大规模矩阵分解中很常用。</p>

<blockquote>
  <h4 id="kddcup-2011-track-1-world-champion-solution-by-ntu">KDDCup 2011 Track 1: World Champion Solution by NTU</h4>
  <hr />
  <p><strong>问题</strong>：训练数据时间上要早于测试数据。也就是训练和测试数据分布不同，有偏采样（sampling bias）。</p>

  <p><strong>对策</strong>：强化时间晚的数据。SGD在最后$T’$轮迭代只选用感兴趣的$T’$个数据。</p>

  <p><strong>结果</strong>：consistent improvements of test performance。</p>
</blockquote>

<h2 id="section-6">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-7">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-no-1-neuron">
      <p>让网络看上去简单些而已，加入$x_0^{(\ell)}$可以得到一个稍微有些不同的模型。 <a href="#fnref:why-no-1-neuron" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:all-zeros">
      <p>若都初始化为0，$\{\mathbf w_m\}$和$\{\mathbf v_n\}$始终为0，$E_{in}$永远也不会减少。 <a href="#fnref:all-zeros" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>径向基函数网络</title>
      <link href="http://qianjiye.de/2015/02/radial-basis-function-network" />
      <pubdate>2015-02-11T23:59:57+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/radial-basis-function-network</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">径向基函数网络</h2>

<p><a href="/2015/01/kernel-svm/#mjx-eqn-eqrbf-svm">高斯核SVM</a>，可以实现无限维特征空间的最大边界分类器，它的实现方式是利用$\alpha_n$实现以支持向量$\mathbf x_n$为中心高斯函数的线性组合。</p>

<p>高斯核通常也称为径向基函数（RBF，radial basis function）。radial表示函数值只依赖于$\mathbf x$与“中心”$\mathbf x_n$之间的距离；basis function表示用来组合的系数$\alpha_n，y_n$。</p>

<p>令$g_n(\mathbf x)=y_n\exp\left(-\gamma\left\lVert\mathbf x-\mathbf x_n\right\rVert^2\right)$，它表示基于$\mathbf x$与$\mathbf x_n$之间距离权重的加权投票（$+1$或$-1$的票）。高斯核SVM可以表示为
\[
g_{SVM}(\mathbf x)=\mbox{sign}\left(\sum_{SV}\alpha_ng_n(\mathbf x)+b\right)，
\]
它是径向基假设的线性融合。</p>

<p><strong>径向基函数网络</strong>就是径向基假设的线性融合，它也是一种神经网络。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-NN-vs-RBFN.png"><img src="/assets/images/2015-02-11-radial-basis-function-network-NN-vs-RBFN.png" alt="神经网络与径向基函数网络" /></a><div class="caption">图 1:  神经网络与径向基函数网络 [<a href="/assets/images/2015-02-11-radial-basis-function-network-NN-vs-RBFN.png">PNG</a>]</div></div></div>

<p>神经网络与径向基函数网络如上图所示：</p>

<ul>
  <li>隐藏层：神经网络采用“内积＋$\tanh$”，径向基函数网络采用“距离＋高斯函数”；</li>
  <li>输出层都是同样的线性融合模型。</li>
</ul>

<p>径向基函数网络的假设为
\begin{equation}
h(\mathbf x)=\mbox{Output}\left(
\sum_{m=1}^{M}\beta_m\mbox{RBF}(\mathbf x,\boldsymbol\mu_m)+b
\right)，
\end{equation}
高斯函数只是一种径向基函数$\mbox{RBF}$，$\beta_m$是投票权值，$\mbox{Output}$形式由不同的回归或分类问题确定。$\boldsymbol\mu_m$和$\beta_m$（带符号）是两个关键参数。高斯核SVM是一种径向基函数网络：径向基函数$\mbox{RBF}$采用高斯函数；对二分类问题输出是$\pm 1$；$M=\#SV$；$\boldsymbol\mu_m$是支持向量$\mathbf x_m$；$\beta_m$是从对偶SVM推导的$\alpha_my_m$。</p>

<p>给定径向基函数$\mbox{RBF}$和输出，径向基函数网络需要学习的参数是$\mu_m$和$\beta_m$。</p>

<p>核和RBF是两种不同的相似度度量方法。核描述基于$\mathcal Z$空间内积的相似性，需要满足<a href="/2015/01/kernel-svm">Mercer条件</a>。RBF通过$\mathcal X$空间的距离度量相似性，这种相似性与距离是单调递减（monotonically non-increasing）关系。一般采用度量$\mathbf x$和$\mathbf x’$相似性的函数还可以是<sup id="fnref:edit-distance"><a href="#fn:edit-distance" class="footnote">1</a></sup>
\[
\mbox{Neuron}(\mathbf x,\mathbf x’)=\tanh\left(\gamma\mathbf x^\top\mathbf x’+1\right)，\quad\mbox{DNASim}(\mathbf x,\mathbf x’)=\mbox{EditDistance}(\mathbf x,\mathbf x’)。
\]
神经网络的神经元也是在比较输入向量与权值向量之间的相似性。</p>

<p>RBF网络展示了通过度量到中心的距离也是一种很好的特征转换。 相似性是一种很好的特征转换方法，相似性不一定与距离有关，也不一定与核有关。</p>

<h2 id="section-1">学习算法</h2>

<p>当$M=N$和$\boldsymbol\mu_m=\mathbf x_m$时，称为完全RBF网络。它的物理含义是每个点$\mathbf x_m$对周围的数据$\mathbf x$有权重$\beta_m$的影响，假设对二分类问题均匀影响（uniform influence）周围的数据，$\beta_m=1\cdot y_m$，那么
\begin{equation}
g_{uniform}(\mathbf x)=\mbox{sign}\left(\sum_{m=1}^Ny_m\exp\left(-\gamma\left\lVert\mathbf x-\mathbf x_m\right\rVert^2\right)\right)，
\end{equation}
这就是每个数据通过相似度对新数据的投票融合。这和<a href="/2015/01/image-classification-knn-based-introduction/#kNN">k最近邻算法</a>思想很相似。离$\mathbf x$最近的$\mathbf x_m$让$\exp\left(-\gamma\left\lVert\mathbf x-\mathbf x_m\right\rVert^2\right)$取得最大值。高斯函数衰减很快，最大的投票很可能会左右投票结果，不需要让所有数据投票，只用离$\mathbf x$最近数据投票，用选择法（selection）替代融合法（aggregation），
\begin{equation}
g_{nbor}=y_m\mbox{ such that }\mathbf x\mbox{ closest to }\mathbf x_m， 
\end{equation}
这就是最近邻算法。若让k个$\mathbf x_m$参与对$\mathbf x$投票就是k最近邻算法。</p>

<p>如果不直接用$y_m$作为$\beta_m$投票，而更进一步考虑对$\beta_m$进行优化，用完全RBF网络解决基于平方误差的回归问题，
\begin{equation}
h(\mathbf x)=\sum_{m=1}^{M}\beta_m\mbox{RBF}(\mathbf x,\mathbf x_m)。
\end{equation}
这是基于RBF特征转换的线性回归，
\[
\mathbf z_n=[\mbox{RBF}(\mathbf x_n,\mathbf x_1),\mbox{RBF}(\mathbf x_n,\mathbf x_2),\ldots,\mbox{RBF}(\mathbf x_n,\mathbf x_N)]，
\]
最优解为$\boldsymbol\beta=\left(\mathbf Z^\top\mathbf Z\right)^{-1}\mathbf Z^\top\mathbf y$（若$\mathbf Z^\top\mathbf Z$可逆），$\mathbf Z$是$N\times N$的对称方阵，那么就有
\begin{equation}
\boldsymbol\beta=\mathbf Z^{-1}\mathbf y。
\end{equation}
若每个$\mathbf x_n$都不一样，那么$\mathbf Z$总可逆。对于数据$\mathbf x_1$，
\[
g_{RBF}(\mathbf x_1)
=\boldsymbol\beta^\top\mathbf z_1
=\mathbf y^\top\mathbf Z^{-1}\cdot(\mbox{first column of }\mathbf Z)
=\mathbf y^\top\left[1,0,\ldots,0\right]^\top
=y_1，
\]
那么就有
\begin{equation}
g_{RBF}(\mathbf x_n)=y_n，
\end{equation}
对于回归问题$E_{in}(g_{RBF})=0$。在函数逼近（function approximation）领域这叫完美内插（exact interpolation）；对机器学习而言这是过拟合，需要正则化。</p>

<h2 id="section-2">正则化</h2>

<p>对正则化的完全RBF网络的脊回归可得
\begin{equation}
\boldsymbol\beta=\left(\mathbf Z^\top\mathbf Z+\lambda\mathbf I\right)^{-1}\mathbf Z^\top\mathbf y，
\end{equation}
其中$\mathbf Z$可以看作<a href="/2015/01/kernel-svm">高斯核矩阵</a>，$\mathbf K=\mathbf Z$，对比<a href="/2015/01/support-vector-regression/#mjx-eqn-eqanalytic-solution-ridge-regression">脊回归的核模型</a>，二则只相差矩阵$\mathbf Z^\top$，前者是有限$N$维转换的回归，后者是无限维转换的回归。</p>

<p>对于<a href="/2015/01/kernel-svm/#mjx-eqn-eqrbf-svm">SVM核模型</a>，只采用了支持向量作为参考进行距离度量。减少中心数量（也就减少了参与投票的权值），只使用部分代表点（prototype）作为中心，使$M\ll N$，也是一种有效的正则化方法。</p>

<p>如何找出这些有效的代表点呢？</p>

<h2 id="k-means">k均值聚类</h2>

<p>若$\mathbf x_1\approx\mathbf x_2$，不需要$\mbox{RBF}(\mathbf x,\mathbf x_1)$和$\mbox{RBF}(\mathbf x,\mathbf x_2)$都出现在RBF网络中，可以只用一个cluster$\boldsymbol\mu\approx\mathbf x_1\approx\mathbf x_2$替代两个点即可。</p>

<p>聚类是将数据$\{\mathbf x_n\}$分为不相交的集合（类）$S_1,S_2,\ldots,S_M$。当每个集合用$\boldsymbol\mu_m$作为代表时，若$\mathbf x_1$和$\mathbf x_2$都属于$S_m$，当且仅当$\boldsymbol\mu_m\approx\mathbf x_1\approx\mathbf x_2$。聚类的目标函数为
\begin{equation}
\min_{\{S_1,\ldots,S_M;\boldsymbol\mu_1,\ldots,\boldsymbol\mu_M\}}E_{in}(S_1,\ldots,S_M;\boldsymbol\mu_1,\ldots,\boldsymbol\mu_M)
={1\over N}\sum_{n=1}^{N}\sum_{m=1}^M[[\mathbf x_n\in S_m]]\lVert\mathbf x_n-\boldsymbol\mu_m\rVert^2。
\end{equation}
这是混合的组合数值优化问题，很难最优化，但是可以简化为分别交替最优化$S_m$和$\boldsymbol\mu_m$：</p>

<ol>
  <li>最优划分：固定$\boldsymbol\mu_1,\ldots,\boldsymbol\mu_M$；选择每个$\mathbf x_n$所属的唯一类别$S_m$，使$\lVert\mathbf x_n-\boldsymbol\mu_m\rVert$最小。</li>
  <li>最优计算：固定$S_1,\ldots,S_M$；对每个$\boldsymbol\mu_m$，由于
\[
\nabla_{\boldsymbol\mu_m}E_{in}
=-2\sum_{n=1}^N[[\mathbf x_n\in S_m]](\mathbf x_n-\boldsymbol\mu_m)
=-2\left(\left(\sum_{\mathbf x_n\in S_m}\mathbf x_n\right)-\left|S_m\right|\boldsymbol\mu_m\right)=0，
\]
可得最佳$\boldsymbol\mu_m$是属于$S_m$所有$\mathbf x_n$的均值。</li>
</ol>

<p>以上就是<a href="/2014/12/k-means">k均值算法</a>的关键步骤，$k=M$，重复以上2步直至收敛。通常随机选择k个$\mathbf x_n$作为$\boldsymbol\mu_k$的初始值。收敛是指$S_1,\ldots,S_k$不再改变。算法通过交替最小化使$E_{in}$减小，一定能收敛。</p>

<blockquote>
  <h4 id="krbf">基于k均值的RBF网络</h4>
  <hr />

  <ol>
    <li>利用k均值算法，$k=M$，得到$\{\boldsymbol\mu_m\}$；</li>
    <li>进行特征转换
\[
\Phi(\mathbf x)=\left[\mbox{RBF}(\mathbf x,\boldsymbol\mu_1),\mbox{RBF}(\mathbf x,\boldsymbol\mu_2),\ldots,\mbox{RBF}(\mathbf x,\boldsymbol\mu_M)\right]；
\]</li>
    <li>通过$\{(\Phi(\mathbf x_n),y_n)\}$上的线性模型得到参数$\boldsymbol\beta$；</li>
    <li>返回$g_{RBFNET}(\mathbf x)=\mbox{LinearHypothesis}(\boldsymbol\beta, \Phi(\mathbf x))$。</li>
  </ol>
</blockquote>

<p>上述算法采用非监督的k均值作为特征转换，如同自编码器。RBF网络需要确定的的参数是$M$和$\mbox{RBF}$函数，这些可通过验证方法确定。</p>

<p>虽然RBF网络和SVM的核模型与神经网络性能差不多，但在实际中并不常用。</p>

<h2 id="section-3">实战技能</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-k-means.png"><img src="/assets/images/2015-02-11-radial-basis-function-network-k-means.png" alt="k均值算法对参数敏感" /></a><div class="caption">图 2:  k均值算法对参数敏感 [<a href="/assets/images/2015-02-11-radial-basis-function-network-k-means.png">PNG</a>]</div></div></div>

<p>只要选择合适的$k$和恰当的初始化，k均值算法通常表现良好。k均值算法对参数敏感，选择不同的$k$和不同的初始化，结果差异大，如上图所示。对参数交替最优化不能保证得到全局最优。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-k-means-and-RBFN.jpg"><img src="/assets/images/2015-02-11-radial-basis-function-network-k-means-and-RBFN.jpg" alt="基于k均值的RBF网络" /></a><div class="caption">图 3:  基于k均值的RBF网络 [<a href="/assets/images/2015-02-11-radial-basis-function-network-k-means-and-RBFN.jpg">JPG</a>]</div></div></div>

<p>上图是利用了k均值的RBF网络，蓝色和红色表示两类的标签，阴影渐变区域表示k均值聚类的结果，黑色线条展示分类结果。上图左完全没办法分出两类，输出都是同一类的结果。如果k均值的效果较好，RBF网络效果也更好。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-full-RBFN.jpg"><img src="/assets/images/2015-02-11-radial-basis-function-network-full-RBFN.jpg" alt="完全RBF网络" /></a><div class="caption">图 4:  完全RBF网络 [<a href="/assets/images/2015-02-11-radial-basis-function-network-full-RBFN.jpg">JPG</a>]</div></div></div>

<p>上图左和右分别展示了两种完全RBF网络的效果，所有的数据都参与分类计算，由于计算量很大，在实际中很少使用。或者说这类算法还需要借助其它方式，克服计算复杂度。</p>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:edit-distance">
      <p>$\mbox{EditDistance}$表示一个字符串如何通过最小的修改变为另一个字符串。 <a href="#fnref:edit-distance" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>深度学习</title>
      <link href="http://qianjiye.de/2015/02/deep-learning" />
      <pubdate>2015-02-04T19:31:41+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/deep-learning</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">深度神经网络</h2>

<p>确定神经网络的结构是非常核心也是非常困难的问题。</p>

<p>需要多少神经元？网络多少层？神经元之间如何连接？……这些选择一方面凭主观意愿，另一方面通过验证的方法确定。</p>

<p>浅层（shallow）神经网络只有少量的隐层，深度（deep）神经网络有很多层，它们之间的对比如下：</p>

<table>
  <thead>
    <tr>
      <th>浅层神经网络</th>
      <th>深度神经网络</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>✅训练较高效</td>
      <td>❌训练极具挑战性</td>
    </tr>
    <tr>
      <td>✅结构简单</td>
      <td>❌结构复杂</td>
    </tr>
    <tr>
      <td>✅非常强大</td>
      <td>✅非常强大</td>
    </tr>
    <tr>
      <td> </td>
      <td>✅能提取有意义的特征</td>
    </tr>
  </tbody>
</table>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-04-deep-learning-meaningfulness-of-DL.png"><img src="/assets/images/2015-02-04-deep-learning-meaningfulness-of-DL.png" alt="深度学习提取有意义的特征" /></a><div class="caption">图 1:  深度学习提取有意义的特征 [<a href="/assets/images/2015-02-04-deep-learning-meaningfulness-of-DL.png">PNG</a>]</div></div></div>

<p>若只有一层，它需要完成的任务就很复杂。层数增多，每层或层与层之间功能简单，如上图所示，只需从输入中提取简单的笔画，若还有下一层，继续从简单笔画中找出更复杂的笔画。层与层之间，实现从简单到复杂的特征转换。若原始特征是raw feature（每个特征物理意义有限，比如图像的每个像素），最终需要完成复杂的分类动作，深度学习处理这样的问题更自然。</p>

<h4 id="section-1">一、深度学习的挑战与关键技术</h4>

<ul>
  <li>决定网络结构很困难。
    <ul>
      <li>验证能帮忙但并非易事；</li>
      <li>借助领域知识（domain knowledge），比如用于图像的convolutional NNet，像素物理位置有意义，相邻像素连接到下层同一神经元可描述更高阶的特征，相距太远的像素不连接在一起。</li>
    </ul>
  </li>
  <li>模型复杂度很高。
    <ul>
      <li>数据足够多时模型复杂度不是问题，但计算复杂度会更高；</li>
      <li>利用正则化（在某些神经元坏掉时，dropout能使网络很好工作；输入出问题时，denoising能使网络很好工作）。</li>
    </ul>
  </li>
  <li>最优化很困难。局部极小值比神经网络更容易出现。
    <ul>
      <li>精心初始化，避免陷入糟糕的局部极小值（利用pre-training）。</li>
    </ul>
  </li>
  <li>计算复杂度很高，尤其是面对大数据的时候。
    <ul>
      <li>利用新的硬件软件架构，比如mini-batch+GPU。</li>
    </ul>
  </li>
</ul>

<p>其中，正则化和初始化是尤为关键的两项技术。</p>

<blockquote>
  <h4 id="section-2">二、深度学习两步走策略</h4>
  <hr />

  <ol>
    <li>预训练：对$\ell=1,\dots,L$，假设$\mathbf w_*^{(1)},\ldots\mathbf w_*^{(\ell-1)}$已知，逐层训练权值$\left\{w_{ij}^{(\ell)}\right\}$。</li>
    <li>训练：利用BP算法在预训练的基础上调整（fine-tune）权值$\left\{w_{ij}^{(\ell)}\right\}$。</li>
  </ol>
</blockquote>

<h2 id="section-3">非线性自编码器：神经网络</h2>

<p>权值的作用是进行特征转换，将数据换成另一种表现形式，也就是编码（encoding）。在预训练深度神经网络时，并不清楚当前层的权重对以后层有何影响。因此，好的权值需要能保持信息（information-preserving），不同层的权值以不同的形式表示信息。保持信息的意思是数据经过编码之后能重建或精确解码（decode accurately）出原来的信息。预训练权值就是保持信息的编码。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-04-deep-learning-information-preserving-NN.png"><img src="/assets/images/2015-02-04-deep-learning-information-preserving-NN.png" alt="自编码器（保持信息的神经网络）" /></a><div class="caption">图 2:  自编码器（保持信息的神经网络） [<a href="/assets/images/2015-02-04-deep-learning-information-preserving-NN.png">PNG</a>]</div></div></div>

<p>上图的$d-\tilde d-d$结构的神经网络力求输出与输入一致，$g(\mathbf x) = \mathbf x$，这种保持信息的神经网络称为<strong>自编码器</strong>（autoencoder），它的目的是做函数到它本身的逼近（approximate identity function）。$w_{ij}^{(1)}$称为编码权值，$w_{ji}^{(2)}$称为解码权值。</p>

<p>自编码器的变换$g(\mathbf x) = \mathbf x$采用了数据集上的隐含结构（hidden structure），其价值在于：</p>

<ul>
  <li>对于监督学习：$\mathbf x$的隐含结构（权值）很好的保持了信息，可用作特征变换$\Phi(\mathbf x)$。——informative representation of data</li>
  <li>对于非监督学习：（1）密度估计（density estimation）：稠密的区域$g(\mathbf x)\approx\mathbf x$效果好<sup id="fnref:why-density-estimate"><a href="#fn:why-density-estimate" class="footnote">1</a></sup>，新的数据若表现好则位于稠密区域；（2）异常检测（outlier detection）：异常点的$g(\mathbf x)\ne\mathbf x$。——typical representation of data</li>
</ul>

<p>自编码器通过学习identity function得到了数据的表现形式。</p>

<p>基本的自编码器就是$d-\tilde d-d$结构的神经网络，误差函数为
$
\sum_{i=1}^d(g_i(\mathbf x)-x_i)^2。
$
这是浅层网络，可以容易利用BP算法训练。通常情况$\tilde d&lt;d$，这是数据的压缩表示。数据集是$\{(\mathbf x_1, \mathbf y_1=\mathbf x_1),(\mathbf x_2,\mathbf y_2=\mathbf x_2),\ldots,(\mathbf x_N, \mathbf y_N=\mathbf x_N)\}$，因此这也被视为非监督学习。有时会用约束条件$w_{ij}^{(1)}=w_{ji}^{(2)}$让网络更简单，也就是进行正则化，这也会让算法更复杂。</p>

<p>在深度学习中，采用基本的自编码器在数据集$\left\{\mathbf x_n^{(\ell-1)}\right\}$上训练（其中$\tilde d=d^{(\ell)}$），将自编码器权值$\left\{w_{ij}^{(1)}\right\}$作为深度神经网络预训练的权值$\left\{w_{ij}^{(\ell)}\right\}$。</p>

<p>许多成功的预训练技术，利用不同的网络结构或正则化机制等方法，实现了更精妙的自编码器。</p>

<h2 id="section-4">去噪自编码器：正则化</h2>

<p>复杂的神经网络模型复杂度高，需要利用正则化避免过拟合。通常采用的正则化技术包括：</p>

<ul>
  <li>选择简单的网络结构；</li>
  <li><a href="/2015/02/neural-network/#regularization-weighted-methods">weight-decay或weight-elimination正则化</a>；</li>
  <li><a href="/2015/02/neural-network/#regularization-early-stopping">尽早停止迭代</a>。</li>
</ul>

<p>深度学习和自编码器采用了不同的正则化方法。</p>

<p>噪声是导致过拟合的重要原因，<a href="/2015/01/hazard-of-overfitting/#overfitting-illustration">数据越少噪声越多时，越容易过拟合</a>。当模型和数据确定时，去噪是避免过拟合的正则化方法。最直接的去噪技术可以采用<a href="/2015/01/hazard-of-overfitting/#data-cleaning">数据清洗或者数据剪枝</a>。能否反其道而行之，加入噪声？✅</p>

<p>对于鲁棒的自编码器，不仅能对原始数据$\mathbf x$有$g(\mathbf x)\approx \mathbf x$，而且对噪声数据$\tilde{\mathbf x}$有$g(\tilde{\mathbf x})\approx \mathbf x$，这就是<strong>去噪自编码器</strong>（denoising autoencoder）的任务。在数据集$\{(\tilde{\mathbf x}_1, \mathbf y_1=\mathbf x_1),(\tilde{\mathbf x}_2,\mathbf y_2=\mathbf x_2),\ldots,(\tilde{\mathbf x}_N, \mathbf y_N=\mathbf x_N)\}$训练自编码器，其中$\tilde{\mathbf x}_n$是对${\mathbf x}_n$加入了人工噪声的数据。在图像处理领域，$g(\tilde{\mathbf x})$可以得到$\tilde{\mathbf x}$的去噪版本。</p>

<p>在有噪声的数据集上训练出正则化的$g$具备抗噪的能力，这种正则化方法在神经网络模型中非常实用<sup id="fnref:data-hinting"><a href="#fn:data-hinting" class="footnote">2</a></sup>。</p>

<h2 id="linear-autoencoder">线性自编码器／主成分分析</h2>

<p>神经网络是复杂的非线性自编码器，能否利用简单高效且不易过拟合的线性自编码器呢？✅</p>

<p>对于第$k$个元素的线性模型
\[
h_k(\mathbf x)=\sum_{j=0}^{\tilde d}w_{jk}^{(2)}\left(
\sum_{i=0}^{d}w_{ij}^{(1)}x_i
\right)，
\]
加入限制条件：</p>

<ul>
  <li>去除掉常数项$x_0$，使$i$和$k$取值范围相同；</li>
  <li>加入正则化约束$w_{ij}^{(1)}=w_{ji}^{(2)}=w_{ij}$，$\mathbf W=[w_{ij}]$是$d\times\tilde d$的权值矩阵；</li>
  <li>$\tilde d&lt;d$；</li>
</ul>

<p>可得
\[
h_k(\mathbf x)=\sum_{j=0}^{\tilde d}w_{kj}\left(
\sum_{i=1}^{d}w_{ij}x_i
\right)。
\]</p>

<p>因此，线性自编码器的假设（hypothesis）可以表示为
\begin{equation}
h(\mathbf x)=\mathbf W\mathbf W^\top\mathbf x。
\end{equation}
好的自编码器就是对$\mathbf W$做最优化
\[
\mathbf W=\arg\min_{\mathbf W} E_{in}(\mathbf h)=E_{in}(\mathbf W)=
{1\over N}\sum_{n=1}^N\left\lVert\mathbf x_n-\mathbf W\mathbf W^\top\mathbf x_n\right\rVert^2，
\]
这是$w_{ij}$的4次多项式，不易得到解析解。</p>

<p>$\mathbf W\mathbf W^\top$是半正定矩阵，进行特征值分解$\mathbf W\mathbf W^\top=\mathbf V\boldsymbol\Gamma\mathbf V^\top$：</p>

<ul>
  <li>$d\times d$的矩阵$\mathbf V$是正交的（orthogonal）$\mathbf V\mathbf V^\top=\mathbf V^\top\mathbf V=\mathbf I_d$；</li>
  <li>$d\times d$的对角（diagonal）矩阵$\boldsymbol\Gamma$非零对角线元素最多$\tilde d$个。</li>
</ul>

<p>由此可得$\mathbf W\mathbf W^\top\mathbf x_n=\mathbf V\boldsymbol\Gamma\mathbf V^\top\mathbf x_n$：</p>

<ul>
  <li>$\mathbf V^\top\mathbf x_n$表示对$\mathbf x_n$的坐标转换，几何上看是一种旋转或镜射（rotate or reflect），$\mathbf x_n$的长度不会改变；</li>
  <li>$\boldsymbol\Gamma(\cdots)$中$\boldsymbol\Gamma$对角线有$d-\tilde d$个0元素，其余的非0元素进行尺度缩放；</li>
  <li>$\mathbf V(\cdots)$表示还原到原始坐标系。</li>
</ul>

<p>由于$\mathbf x_n=\mathbf V\mathbf I\mathbf V^\top\mathbf x_n$，最优化问题可变为
\[
\min_{\mathbf V}\min_{\boldsymbol\Gamma}{1\over N}\sum_{n=1}^N\left\lVert\mathbf V\mathbf I\mathbf V^\top\mathbf x_n-\mathbf V\boldsymbol\Gamma\mathbf V^\top\mathbf x_n\right\rVert^2，
\]
可先对$\boldsymbol\Gamma$最优化再对$\mathbf V$最优化，并且$\mathbf V$不影响向量在变换过程中的长度，可省去$\mathbf V$。最优化的形式可记为$\min_{\boldsymbol\Gamma}\sum\lVert(\mathbf I-\boldsymbol\Gamma)(\cdots)\rVert^2$，这需要$\mathbf I-\boldsymbol\Gamma$的0元素越多越好，也就是$\boldsymbol\Gamma$的对角线1越多越好。由于$\boldsymbol\Gamma$的秩不超过$\tilde d$，$\boldsymbol\Gamma$的对角线最多$\tilde d$个1，$\boldsymbol\Gamma$的最佳形式为
\[
\boldsymbol\Gamma=
\left[
\begin{aligned}
\mathbf I_{\tilde d}&amp;\quad 0\\
0&amp;\quad 0
\end{aligned}
\right]。
\]
接下来对$\mathbf V$优化
\[
\min_{\mathbf V}
\sum_{n=1}^N
\left\lVert
\left[
\begin{aligned}
0&amp;\quad 0\\
0&amp;\quad \mathbf I_{d-\tilde d}
\end{aligned}
\right]
\mathbf V^\top\mathbf x_n
\right\rVert^2，
\]
上式的意思是保留$\mathbf V^\top\mathbf x_n$的$d-\tilde d$个维度实现最小化，这可以通过最大化实现
\[
\max_{\mathbf V}
\sum_{n=1}^N
\left\lVert
\left[
\begin{aligned}
\mathbf I_{\tilde d}&amp;\quad 0\\
0&amp;\quad 0
\end{aligned}
\right]
\mathbf V^\top\mathbf x_n
\right\rVert^2。
\]
当$\tilde d=1$时，只有$\mathbf V^\top$的第一行$\mathbf v^\top$参与优化，也就是
\[
\max_{\mathbf v}\sum_{n=1}^N\mathbf v^\top\mathbf x_n\mathbf x_n^\top\mathbf v\quad\mbox{ s.t. }\mathbf v^\top\mathbf v=1，
\]
最佳的$\mathbf v$满足$\sum_{n=1}^N\mathbf x_n\mathbf x_n^\top\mathbf v=\lambda\mathbf v$（$\lambda$是拉格朗日乘子）<sup id="fnref:get-optimal-v"><a href="#fn:get-optimal-v" class="footnote">3</a></sup>，此时最佳目标值为$\lambda$，这个最佳的$\mathbf v$是$\mathbf X^\top\mathbf X$的“最大”（topmost）特征向量。一般地，$\{\mathbf v_j\}_{j=1}^{\tilde d}$是$\mathbf X^\top\mathbf X$“最大”的$\tilde d$个特征向量。</p>

<p>最佳的$\{\mathbf w_j\}$就是$\mathbf X^\top\mathbf X$“最大”的特征向量。线性自编码器就是投影到最符合数据$\{\mathbf x_n\}$的正交模式（orthogonal pattern）$\mathbf w_j$。</p>

<p>线性编码器的目标是最大化$\sum(\mbox{maginitude after projection})^2$；主成分分析（PCA，principal component analysis）的目标是最大化$\sum(\mbox{variance after projection})$，变化量$\mbox{variance}$是相对于平均数差距的平方。线性编码器和主成分分析都是线性降维方法，主成分分析＝数据0均值化 ＋ 线性自编码器，在降维中应用更普遍。</p>

<blockquote>
  <h4 id="section-5">线性编码器／主成分分析</h4>
  <hr />

  <ol>
    <li>令$\bar{\mathbf x}={1\over N}\sum_{n=1}^N\mathbf x_n$，$\mathbf x_n\leftarrow\mathbf x_n-\bar{\mathbf x}$<sup id="fnref:zero-mean-vector"><a href="#fn:zero-mean-vector" class="footnote">4</a></sup>；</li>
    <li>计算$\mathbf X^\top\mathbf X$的最大$\tilde d$个特征向量$\mathbf w_1,\mathbf w_2,\ldots,\mathbf w_{\tilde d}$；</li>
    <li>返回转换后的特征$\Phi(\mathbf x)=\mathbf W(\mathbf x-\bar{\mathbf x})$。</li>
  </ol>
</blockquote>

<h2 id="section-6">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-7">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-density-estimate">
      <p>为啥稠密区域效果好？ <a href="#fnref:why-density-estimate" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:data-hinting">
      <p>可视为<a href="/2015/02/neural-network/#data-hinting">data hinting</a>的正则化技术。 <a href="#fnref:data-hinting" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:get-optimal-v">
      <p>利用拉格朗日乘子法求导可得。 <a href="#fnref:get-optimal-v" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:zero-mean-vector">
      <p>在0均值数据集基础上进行线性编码，自然实现了投影方向上变化最大。 <a href="#fnref:zero-mean-vector" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>神经网络</title>
      <link href="http://qianjiye.de/2015/02/neural-network" />
      <pubdate>2015-02-04T16:15:04+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/neural-network</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">感知器融合</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png" alt="感知器的线性融合" /></a><div class="caption">图 1:  感知器的线性融合 [<a href="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png">PNG</a>]</div></div></div>

<p>上图展示了感知器的线性融合结构，其中包含两层的权重$\mathbf w_t$和$\boldsymbol\alpha$，还包含两层的符号函数（sign function）$g_t$和$G$。这样的融合可以表示什么样的分类边界呢？</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-and-xor-operator.png"><img src="/assets/images/2015-02-04-neural-network-and-xor-operator.png" alt="AND和XOR运算" /></a><div class="caption">图 2:  AND和XOR运算 [<a href="/assets/images/2015-02-04-neural-network-and-xor-operator.png">PNG</a>]</div></div></div>

<p>单层感知器可以实现如上图所示的AND运算（+1表示TRUE，-1表示FALSE）
\[
G(\mathbf x)=\mbox{sign}(-1+g_1(\mathbf x)+g_2(\mathbf x))，
\]
也可实现OR和NOT运算。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-enough-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-enough-perceptrons.png" alt="足够多感知器的融合" /></a><div class="caption">图 3:  足够多感知器的融合 [<a href="/assets/images/2015-02-04-neural-network-enough-perceptrons.png">PNG</a>]</div></div></div>

<p>即使感知器的线性组合，分类能力也很强大，如上图所示。只要对足够多的感知器融合，可以在空间中切割出任意凸集（convex set），但$d_{VC}\rightarrow\infty$。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png" alt="两层感知器的线性融合实现XOR运算" /></a><div class="caption">图 4:  两层感知器的线性融合实现XOR运算 [<a href="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png">PNG</a>]</div></div></div>

<p>但是，单层感知器不能实现XOR运算，经过XOR运算的特征转换$\phi(\mathbf x)=(g_1(\mathbf x),g_2(\mathbf x))$后数据线性不可分。线性不可分数据继续特征转换，最终将XOR用AND和OR实现
\[
XOR(g_1,g_2)=OR(AND(-g_1,g_2),AND(g_1,-g_2))，
\]
并且可以用上图所示的两层级连结构表示<sup id="fnref:five-input-xor"><a href="#fn:five-input-xor" class="footnote">1</a></sup>。</p>

<p>由此可见，虽然感知器算法简单，经过线性融合，以及多层级连，可以得到功能强大的分类器。多层感知器就是基本的神经网络结构。</p>

<h2 id="section-1">神经网络</h2>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-simple-NN.png"><img src="/assets/images/2015-02-04-neural-network-simple-NN.png" alt="简单的神经网络模型" /></a><div class="caption">图 5:  简单的神经网络模型 [<a href="/assets/images/2015-02-04-neural-network-simple-NN.png">PNG</a>]</div></div></div>

<p>事实上，对最后一层OUTPUT神经元，除了用感知器外，可以采用其它的<a href="/2015/01/linear-models-for-classification/#linear-models">线性模型</a>。若要分类，OUTPUT采用线性分类模型；若要回归分析，OUTPUT采用线性回归（不做任何处理）；若要soft分类，OUTPUT采用logistic回归。</p>

<p>中间层神经元采用的转换函数（transformation function），除了使用阶梯（符号）函数，也可采用其它转换函数。若所有神经元都采用线性回归，整个网络都是线性运算，用一个线性模型就可以实现。因此，很少用线性回归作为转换函数。阶梯函数是离散的，难以通过最优化求解$\mathbf w$，也很少使用。通常使用的是S形的转换函数
\[
\tanh(s)={\exp(s)-\exp(-s)\over\exp(s)+\exp(-s)}=2\theta(2s)-1，
\]
可以通过<a href="/2015/01/logistic-regression/#mjx-eqn-eqsigmoid-function">logistic函数</a>得到。该函数是阶梯函数的近似，且容易优化，传说和生物神经元也相近。</p>

<div class="image_line" id="figure-6"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-common-NN.png"><img src="/assets/images/2015-02-04-neural-network-common-NN.png" alt="常用的神经网络模型" /></a><div class="caption">图 6:  常用的神经网络模型 [<a href="/assets/images/2015-02-04-neural-network-common-NN.png">PNG</a>]</div></div></div>

<p>常用的神经网络采用$\tanh$作为转换函数，输出采用线性回归，如上图所示。$d^{(0)},d^{(1)},\ldots,d^{(L)}$表示每层神经元数目（节点数目），每层的权值为
\[
w_{ij}^{(\ell)}:\left\{
\begin{aligned}
&amp;1\leq\ell\leq L&amp;\mbox{layers}&amp;\\
&amp;0\leq i\leq d^{(\ell-1)}&amp;\mbox{inputs}&amp;\\
&amp;1\leq j\leq d^{(\ell)}&amp;\mbox{outputs}&amp;，
\end{aligned}
\right.
\]
常数+1的神经元相当于偏移项，评分函数为
\begin{equation}
s_j^{(\ell)}=\sum_{i=0}^{d^{(\ell-1)}}w_{ij}^{(\ell)}x_i^{(\ell-1)}，
\end{equation}
转换后的特征为
\begin{equation}
x_j^{(\ell)}=\left\{
\begin{aligned}
&amp;\tanh\left(s_j^{(\ell)}\right)&amp;\mbox{if }\ell&lt;L\\
&amp;s_j^{(\ell)}&amp;\mbox{if }\ell=L
\end{aligned}
\right.
\label{eq:forward-x}
\end{equation}</p>

<p>神经网络将$\mathbf x$当作输入层$\mathbf x^{(0)}$，隐层计算变换后的特征$\mathbf x^{(\ell)}$，输出层计算预测结果$x_1^{(L)}$。</p>

<p>神经网络隐层相当于模式（特征）提取（pattern extraction），进行$\mathbf x^{(\ell)}$和权值向量的模式匹配（利用基于内积的余弦相似度），每个神经元提取一种特征，权值向量纪录了从数据中学到的模式。</p>

<h2 id="bp">BP算法</h2>

<p>如何通过最小化$E_{in}\left(\left\{w_{ij}^{(\ell)}\right\}\right)$学到权值$\left\{w_{ij}^{(\ell)}\right\}$？</p>

<p>如果只有一个隐层，神经网络相当于感知器的融合，可以通过GradientBoost方法一个接一个的确定隐层的神经元。如果有多个隐层，问题就变得复杂了。</p>

<p>每个数据的误差记为
\[
e_n=(y_n-\mbox{NNet}(\mathbf x_n))^2，
\]
若能计算$\partial e_n\over \partial w_{ij}^{(\ell)}$，就可以通过梯度下降法求解。对输出层
\[
e_n=\left(y_n-s_1^{(L)}\right)^2=\left(y_n-\sum_{i=0}^{d^{(L-1)}}w_{i1}^{(L)}x_i^{(L-1)}\right)^2，
\]
对输出层和其它层分别求偏微分
\[
\begin{aligned}
&amp;{\partial e_n\over\partial w_{i1}^{(L)}}
={\partial e_n\over\partial s_{1}^{(L)}}\cdot{\partial s_{1}^{(L)}\over\partial w_{i1}^{(L)}}
=-2\left(y_n-s_1^{(L)}\right)\cdot x_i^{(L-1)}，\\
&amp;{\partial e_n\over\partial w_{ij}^{(\ell)}}
={\partial e_n\over\partial s_{j}^{(\ell)}}\cdot{\partial s_{j}^{(\ell)}\over\partial w_{ij}^{(\ell)}}
=\delta_j^{(\ell)}x_i^{(\ell-1)}。
\end{aligned}
\]
对输出层，令
\begin{equation}
\delta_1^{(L)}=-2\left(y_n-s_1^{(L)}\right)。
\end{equation}
对其它层
\begin{equation}
\delta_j^{(\ell)}
={\partial e_n\over\partial s_{j}^{(\ell)}}
=\sum_{k=1}^{d^{(\ell+1)}}{\partial e_n\over\partial s_{k}^{(\ell+1)}}{\partial s_{k}^{(\ell+1)}\over\partial x_{j}^{(\ell)}}{\partial x_{j}^{(\ell)}\over\partial s_{j}^{(\ell)}}
=\sum_k\delta_k^{(\ell+1)}w_{jk}^{(\ell+1)}\tanh’\left(s_j^{(\ell)}\right)，
\label{eq:backpropagation-delta}
\end{equation}
也就是前一层的$\delta_j^{(\ell)}$，可以通过后一层$\delta_k^{(\ell+1)}$回推计算，<a href="http://www.wolframalpha.com/input/?i=d%2Fdx+tanh">其中</a>
\[
\tanh’(x)={2\over e^x + e^{-x}}。
\]</p>

<blockquote>
  <h4 id="bpbackpropagation">BP（backpropagation）算法</h4>
  <hr />
  <p>用小的随机值初始化所有的$w_{ij}^{(\ell)}$；</p>

  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>随机化：随机选取$n\in\{1,2,\ldots,N\}$；</li>
    <li>前向传播：从$\mathbf x^{(0)}=\mathbf x_n$开始，利用\eqref{eq:forward-x}计算所有$x_i^{(\ell)}$；</li>
    <li>误差回传：对$\mathbf x^{(0)}=\mathbf x_n$，利用\eqref{eq:backpropagation-delta}计算所有$\delta_j^{(\ell)}$；</li>
    <li>梯度下降：$w_{ij}^{(\ell)}\leftarrow w_{ij}^{(\ell)}-\eta x_i^{(\ell-1)}\delta_j^{(\ell)}$；</li>
  </ol>

  <p>返回$g_{\mbox{NNET}}(\mathbf x)=\left(\ldots\tanh\left(\sum_jw_{jk}^{(2)}\cdot\tanh\left(\sum_iw_{ij}^{(1)}x_i\right)\right)\right)$。</p>

  <p>在实际应用中，第1步至第3步可以先执行多次后，再用$x_i^{(\ell-1)}\delta_j^{(\ell)}$的平均值执行第4步的更新，这就是mini-batch的方法。</p>
</blockquote>

<p>神经网络通过最小化
\[
E_{in}(\mathbf w)={1\over N}\sum_{n=1}^Nerr\left(\left(\ldots\tanh\left(\sum_jw_{jk}^{(2)}\cdot\tanh\left(\sum_iw_{ij}^{(1)}x_i\right)\right)\right),y_n\right)
\]
计算权值。通常多隐层神经网络的误差函数是非凸的（non-convex），难以达到全局最小值（global minimum），梯度下降法通过BP算法也仅仅得到局部极小值（local minimum）。不同的初始化$w_{ij}^{(\ell)}$，会得到不同的局部极值：</p>

<ul>
  <li>BP算法对权重初始值敏感；</li>
  <li>若权值太大，会落到$\tanh$的saturate区域（梯度很小），每次按梯度更新很小；</li>
  <li>用小的随机值初始化权值$w_{ij}^{(\ell)}$。</li>
</ul>

<p>若初始化$w_{ij}^{(\ell)}＝0$，由于$x_0^{(\ell)}=1$，除了${\partial e_n\over \partial w_{01}^{(L)}}\neq 0$外，其它的导数都为0；若初始化$w_{ij}^{(\ell)}＝1$，那么$w_{ij}^{(1)}=w_{i(j+1)}^{(1)}$。因此，$w_{ij}^{(\ell)}$不能初始化为0和1。</p>

<p>虽然神经网络很难最优化，但在实际中很有用。</p>

<h2 id="regularization">正则化</h2>

<p>若用形如$\tanh$的转换函数，神经网络的$d_{VC}=O(VD)$，$V$为神经元数量，$D$为神经元之间的权值数量。当神经元数目足够时，可以做任意逼近，也更容易导致过拟合。为了避免过拟合，需要采取正则化方法。</p>

<h4 id="regularization-weighted-methods">一、weight-elimination正则化</h4>

<p>常用的方法是基于$L_2$的weight-decay正则化，$\Omega(\mathbf w)=\sum\left(w_{ij}^{(\ell)}\right)^2$。这种正则化对权值的压缩（shrink）力度和权值大小“成比例”，大的权值压缩厉害，小的权值压缩较小。</p>

<p>如果通过正则化使权值部分为0（稀疏），就能有效减小$d_{VC}$，常用的方法是$L_1$正则化，$\Omega(\mathbf w)=\sum\left\lvert w_{ij}^{(\ell)}\right\rvert$，但是不可微。采用weight-elimination正则化（放缩的$L_2$正则化），大的权值中等幅度的压缩（median shrink），小的权值也中等幅度的压缩，小的权值就会接近0，具有权值稀疏化的效果。weight-elimination正则化采用
\begin{equation}
\Omega(\mathbf w)=\sum{\left(w_{ij}^{(\ell)}\right)^2\over 1+\left(w_{ij}^{(\ell)}\right)^2}，
\end{equation}
那么
\[
{\partial\Omega(\mathbf w)\over \partial w_{ij}^{(\ell)}}
={2w_{ij}^{(\ell)}\over\left(1+\left(w_{ij}^{(\ell)}\right)^2\right)^2}。
\]</p>

<h4 id="regularization-early-stopping">二、尽早停止迭代</h4>

<div class="image_line" id="figure-7"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-early-stopping.png"><img src="/assets/images/2015-02-04-neural-network-early-stopping.png" alt="迭代次数对误差的影响" /></a><div class="caption">图 7:  迭代次数对误差的影响 [<a href="/assets/images/2015-02-04-neural-network-early-stopping.png">PNG</a>]</div></div></div>

<p>迭代的次数$t$越多，选择过的$\mathbf w$也就越多，有效的$d_{VC}$也越大。小的$t$使得$d_{VC}$也较小。尽早停止（early stopping）迭代，通过如上图右的最佳$t^*$，获得如上图左的最佳$d_{VC}^*$，克服过拟合。通过验证（validation）确定停止迭代的参数$t$。</p>

<p>所有和梯度有关的优化算法，都可利用尽早停止迭代的机制，实现某种正则化。</p>

<h2 id="section-2">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:five-input-xor">
      <p>如果用神经网络实现$XOR(x_1,\dots,x_5)$，采用结构为5-D-1，那么<a href="https://class.coursera.org/ntumltwo-001/forum/thread?thread_id=243">最小的D</a>是多少？ <a href="#fnref:five-input-xor" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（6）：融合模型总结</title>
      <link href="http://qianjiye.de/2015/02/summary-of-aggregation-models" />
      <pubdate>2015-02-04T13:39:58+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/summary-of-aggregation-models</guid>
      <content:encoded>&lt;![CDATA[<h4 id="section">一、分类器融合策略</h4>

<table>
  <thead>
    <tr>
      <th>融合类型</th>
      <th>混合（blending）</th>
      <th>学习（learning）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-equniform-blending-hypothesis">均匀</a>（uniform）</td>
      <td>voting／averaging</td>
      <td>Bagging</td>
    </tr>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-eqlinear-blending-hypothesis">非均匀</a>（non-uniform）</td>
      <td>linear</td>
      <td>AdaBoost</td>
    </tr>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-eqconditional-blending-hypothesis">有条件</a>（conditional）</td>
      <td>stacking</td>
      <td>Decision Tree</td>
    </tr>
  </tbody>
</table>

<p>对于非均匀和条件融合，$g_t$可以视为特征转换。</p>

<p>混合（blending）方法是选择了不同的$g_t$之后再融合，学习（learning）方法是在选择（学习）不同$g_t$的同时进行融合。</p>

<p>均匀融合性能比较稳定，不同$g_t$相互修正，类似正则化的中庸思想。非均匀和条件融合，学习之上的再学习过程，增加了复杂度，功能强大，存在更大的过拟合风险。</p>

<h4 id="section-1">二、基于学习机制的分类器融合方法对比</h4>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>获取不同$g_t$的方法</th>
      <th>融合策略</th>
      <th>优化算法</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Bagging</td>
      <td>bootstrapping</td>
      <td>uniform vote</td>
      <td> </td>
    </tr>
    <tr>
      <td>AdaBoost</td>
      <td>reweighting</td>
      <td>linear vote</td>
      <td>steepest search</td>
    </tr>
    <tr>
      <td>GradientBoost</td>
      <td>residual fitting</td>
      <td>linear vote</td>
      <td>steepest search</td>
    </tr>
    <tr>
      <td>Decision Tree</td>
      <td>data splitting</td>
      <td>conditional vote</td>
      <td>branching</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>random forest = randomized bagging + strong DTree;</li>
  <li>AdaBoost-DTree = AdaBoost + weak DTree;</li>
  <li>GBDT = GradientBoost + weak DTree.</li>
</ul>

<p>boosting系列的算法应用非常广泛。</p>

<h4 id="section-2">三、融合机制的双重性</h4>

<div class="image_line" id="aggregation-performance"><div class="image_card"><a href="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png"><img src="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png" alt="［左］：融合解决欠拟合；［右］：融合解决过拟合" /></a><div class="caption">图 1:  ［左］：融合解决欠拟合；［右］：融合解决过拟合 [<a href="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png">PNG</a>]</div></div></div>

<ol>
  <li>融合可以解决欠拟合问题。单一的$g_t$能力较弱，通过AdaBoost或GradientBoost的方法得到强大的$G(\mathbf x)$。融合相当于利用了特征转换的功能。</li>
  <li>融合可以解决过拟合问题。通过融合可以得到中庸（moderate）的$G(\mathbf x)$。融合相当于利用了正则化的功能，如上图右的large-margin效果。</li>
</ol>

<p>因此，合适的融合（aggregation or ensemble）机制可以提升分类器的性能。</p>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（5）：梯度提升决策树</title>
      <link href="http://qianjiye.de/2015/01/gradient-boosted-decision-tree" />
      <pubdate>2015-01-29T16:12:28+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/gradient-boosted-decision-tree</guid>
      <content:encoded>&lt;![CDATA[<h2 id="adaboost">AdaBoost决策树</h2>

<blockquote>
  <h4 id="adaboost-dtreemathcal-d">AdaBoost-DTree($\mathcal D$)</h4>
  <hr />
  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>更新数据的权重$\mathbf u^{(t)}$；</li>
    <li>通过决策树算法$\mbox{DTree}\left(\tilde{\mathcal D}, \mathbf u^{(t)}\right)$得到$g_t$；</li>
    <li>计算$g_t$的投票权重$\alpha_t$。</li>
  </ol>

  <p>返回$G=\mbox{LinearHypo}(\{\left(g_t,\alpha_t\right)\})$。</p>
</blockquote>

<p>由此可见，AdaBoost决策树需要加权决策树算法。对于有权重的算法，需要根据权重最小化$E_{in}$，通常有两种方法：</p>

<ul>
  <li>一种方法是通过算法加权，在计算$E_{in}$的地方嵌入权重计算，比如AdaBoost采用的最小化<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqweighted-Ein">加权误差</a>；</li>
  <li>另一种方法是将算法当成黑盒不变更，通过数据集加权，根据权重在bootstrap时“复制”数据，也就是加权的重采样。</li>
</ul>

<p>AdaBoost决策树通常采用后一种方法，AdaBoost＋sampling $\propto \mathbf u^{(t)}$＋$\mbox{DTree}(\tilde{\mathcal D}_t)$。</p>

<p>AdaBoost的<a href="/2015/01/adaptive-boosting/#AdaBoost-algorithm">$\alpha_t$通过错误率确定</a>。对于所有$\mathbf x_n$不同的完全成长决策树，$E_{in}(g_t)=0$，那么$E_{in}^{\mathbf u}(g_t)=0$，因此$\epsilon_t=0$并且$\alpha_t=\infty$。合适的方法是让决策树弱些，在部分数据集上训练剪枝的决策树。即使在$\tilde{\mathcal D}_t$上得到错误率为0的决策树$g_t$，回到$\mathcal D$上$\alpha_t$可能是大于、等于或小于0。剪枝可采用常规方法或只限制决策树高度，在数据重采样阶段已经包含了只抽取部分数据的功能。因此，AdaBoost决策树＝AdaBoost＋sampling $\propto \mathbf u^{(t)}$＋剪枝的$\mbox{DTree}(\tilde{\mathcal D}_t)$。</p>

<p>如果C&amp;RT的高度限制为不超过1，当用二分类的误差作为<a href="/2015/01/decision-tree/#mjx-eqn-eqdtree-decision-stump">不纯度</a>时，AdaBoost决策树就是<a href="/2015/01/adaptive-boosting/#AdaBoost-Stump">AdaBoost-Stump</a>，此时通常有$\epsilon_t\neq 0$，一般不再需要sampling。</p>

<h2 id="functional-gradient-steepest-descent">AdaBoost理论分析：最速函数梯度下降法</h2>

<p>AdaBoost的<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqadaboost-update-u">权重更新</a>可以合并为
\[
u_n^{(t+1)}=u_n^{(t)}\cdot\blacklozenge_t^{-y_ng_t(\mathbf x_n)}，
\]
由于$\blacklozenge_t=\exp(\alpha_t)$，因此
\[
u_n^{(t+1)}=u_n^{(t)}\cdot\exp\left(-y_n\alpha_tg_t\left(\mathbf x_n\right)\right)，
\]
那么
\begin{equation}
u_n^{(T+1)}=u_n^{(1)}\cdot\prod_{t=1}^T\exp\left(-y_n\alpha_tg_t\left(\mathbf x_n\right)\right)={1\over N}\exp\left(-y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)\right)。
\label{eq:un-t-plus-1}
\end{equation}
AdaBoost是<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqadaboost-Gx">分类器的线性组合</a>，$\sum_{t=1}^T\alpha_tg_t(\mathbf x)$是$\{g_t\}$在$\mathbf x$上的投票得分（voting score），也就是对AdaBoost，$u_n^{(T+1)}\propto \exp\left(-y_n\cdot\left(\mbox{voting score on }\mathbf x_n\right)\right)$。</p>

<p id="decrease-un">线性混合（linear blending），可以看作线性模型和以假设作为特征转换的结合
\[
G(\mathbf x_n)=\mbox{sign}\left(\overbrace{\sum_{t=1}^T\underbrace{\alpha_t}_{w_i}\underbrace{g_t(\mathbf x_n)}_{\phi_i(\mathbf x_n)}}^{\mbox{voting score}}\right)。
\]
对比<a href="/2015/01/linear-svm/#mjx-eqn-eqhard-margin-svm-origin-model">hard-margin的SVM</a>的边界${y_n\cdot\left(\mathbf w^T\phi(\mathbf x_n)+b\right)\over\lVert\mathbf w\rVert}$，投票得分可视为某种空间中非规范化的边界（距离）的度量，“$y_n$(voting score)=signed &amp; unnormalized margin”。期望$y_n$(voting score)是正的，且越大越好，那么$\exp(-y_n(\mbox{voting score}))$越小越好，$u_n^{(T+1)}$越小越好。AdaBoost的$\sum_{n=1}^Nu_n^{(t)}$随着$t$的增大越来越小，在最后一轮
\begin{equation}
\sum_{n=1}^Nu_n^{(T+1)}={1\over N}\sum_{n=1}^N\exp\left(-y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)\right)
\label{eq:sum-un-t-plus-1}
\end{equation}
达到最小，边界$y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)$最大化实现large margin的效果。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png"><img src="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png" alt="AdaBoost的误差界" /></a><div class="caption">图 1:  AdaBoost的误差界 [<a href="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png">PNG</a>]</div></div></div>

<p>令线性评分函数$s=\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)$，AdaBoost的指数误差度量（exponential error measure）$\widehat{err}_{ADA}(s,y)=\exp(-ys)$是0/1误差$\widehat{err}_{0/1}(s,y)=[[ys\leq 1]]$的上界<sup id="fnref:other-error-bounds"><a href="#fn:other-error-bounds" class="footnote">1</a></sup>，如上图右所示，通过0/1误差的凸上界（convex upper bound）$\widehat{err}_{ADA}$作为算法误差度量（algorithmic error measure），通过上界误差最小化使0/1误差最小化。</p>

<p>AdaBoost通过增加函数$h(\mathbf x)$的方式，使基于\eqref{eq:sum-un-t-plus-1}的误差$\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t+1)}$最小化，
\begin{equation}
\begin{aligned}
\min_h\quad\widehat E_{ADA}
&amp;\overset{[1]}{=}{1\over N}\sum_{n=1}^N\exp\left(-y_n\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n)\right)\right)\\
&amp;\overset{[2]}{=}\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta h(\mathbf x_n)\right)
\overset{\mbox{taylor}}{\approx}\sum_{n=1}^Nu_n^{(t)}\left(1-y_n\eta h(\mathbf x_n)\right)\\
&amp;=\sum_{n=1}^Nu_n^{(t)}+\eta\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)，
\end{aligned}
\label{eq:min-E-ADA}
\end{equation}</p>

<ul>
  <li>[1]：增加函数$h(\mathbf x)$，由\eqref{eq:sum-un-t-plus-1}可得$\sum_{\tau=1}^t\alpha_\tau g_\tau\left(\mathbf x_n\right)=\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\left(\mathbf x_n\right)+\eta h(\mathbf x_n)$；</li>
  <li>[2]：由\eqref{eq:un-t-plus-1}可得$u_n^{(t)}={1\over N}\exp\left(-y_n\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\left(\mathbf x_n\right)\right)$。</li>
</ul>

<p>公式\eqref{eq:min-E-ADA}形如<a href="/2015/01/logistic-regression/#mjx-eqn-eqtaylor-expansion-Ein">梯度下降法最小化$E_{in}$</a>
\[
\min_{\lVert\mathbf v\rVert=1}E_{in}(\mathbf w_t+\eta\mathbf v)
\approx \underbrace{E_{in}(\mathbf w_t)}_{\mbox{known}}
+\underbrace{\eta}_{\mbox{given positive}}\mathbf v^T\underbrace{\nabla E_{in}(\mathbf w_t)}_{\mbox{known}}，
\]
好的$h(\mathbf x)$能最小化$\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)$。对二分类，$y_n$和$h(\mathbf x_n)$都属于$\{-1,+1\}$，那么
\[
\begin{aligned}
\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)
&amp;=\sum_{n=1}^Nu_n^{(t)}
\left\{
\begin{aligned}
-1\quad\mbox{if }y_n=h(\mathbf x_n)\\
+1\quad\mbox{if }y_n\neq h(\mathbf x_n)
\end{aligned}
\right.\\
&amp;=-\sum_{n=1}^Nu_n^{(t)}+\sum_{n=1}^Nu_n^{(t)}
\left\{
\begin{aligned}
0\quad\mbox{if }y_n=h(\mathbf x_n)\\
2\quad\mbox{if }y_n\neq h(\mathbf x_n)
\end{aligned}
\right.\\
&amp;\overset{[1]}{=}-\sum_{n=1}^Nu_n^{(t)}+2E_{in}^{\mathbf u^{(t)}}(h)\cdot N，
\end{aligned}
\]</p>

<ul>
  <li>[1]：根据<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqweighted-Ein">AdaBoost的$E_{in}^\mathbf u$计算可得</a>。</li>
</ul>

<p>因此，也就是要使$E_{in}^{\mathbf u^{(t)}}(h)$变小，这就是AdaBoost中算法$\mathcal A$的任务，找出一个好的函数方向$h$。</p>

<p>AdaBoost通过近似最小化$\min_h\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta h(\mathbf x_n)\right)$，公式\eqref{eq:min-E-ADA}的$[2]$等式，找到新的分类器$g_t=h$之后，还需要找到最佳的$\eta$，
\[
\min_\eta\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta g_t(\mathbf x_n)\right)，
\]
$\eta$越大步越好。最佳的$\eta_t$会比固定的$\eta$在短期内下降更快（greedily faster），在最优化中通常称为<strong>最速（最陡）下降</strong>（steepest descent）。对于分类正确和错误两种情形，$u_n^{(t)}\exp\left(-y_n\eta g_t(\mathbf x_n)\right)$分别为$u_n^{(t)}\exp(-\eta)$和$u_n^{(t)}\exp(+\eta)$，那么有
\[
\widehat E_{ADA}=\left(\sum_{n=1}^Nu_n^{(t)}\right)\cdot
\left(
(1-\epsilon_t)\exp(-\eta)+\epsilon_t\exp(+\eta)
\right)，
\]
$\epsilon_t$表示<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqepsilon-t">错误率</a>。
通过${\partial\widehat E_{ADA}\over\partial\eta}=0$可得最速梯度步长$\eta_t=\ln\sqrt{1-\epsilon_t\over\epsilon_t}=\alpha_t$。当进行到$t+1$轮迭代时，误差为
\[
\widehat E_{ADA}^{(t+1)}=\widehat E_{ADA}^{(t)}\cdot\left(
(1-\epsilon_t)\exp(-\eta_t)+\epsilon_t\exp(+\eta_t)
\right)，
\]
将$\eta_t$和$\widehat E_{ADA}^{(1)}=\sum_{n=1}^Nu_n^{(1)}=1$带入可得
\[
\widehat E_{ADA}^{(t+1)}=\prod_{\tau=1}^{t}\left(2\sqrt{\epsilon_\tau(1-\epsilon_\tau)}\right)。
\]
由此可见，最糟糕的情况是当$\epsilon_t={1\over 2}$时（错误率$\epsilon_t$始终小于正确率$1-\epsilon_t$），$\widehat E_{ADA}^{(t+1)}$不减少，否则$\widehat E_{ADA}^{(t+1)}$随着迭代增加不断减少。</p>

<p>因此，AdaBoost是近似的函数梯度（functional gradient）最速下降法。</p>

<h2 id="section">任意误差函数的梯度提升</h2>

<p>AdaBoost可以表示为最优化的形式
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^N\exp\left(-y_n\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n)\right)\right)，
\end{equation}
每一轮找到$h$作为$g_t$，并决定该$g_t$要前进的距离$\eta_t$。利用更一般的误差函数，将AdaBoost推广到GradientBoost
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^Nerr\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n),y_n\right)。
\end{equation}
GradientBoost分为两步：（1）确定$h$；（2）确定$\eta$。由于要采用梯度下降法，需要平滑的误差函数$err$，$h$也不限于二分类，可以推广到实数输出。通过采用不同的误差函数$err$，GradientBoost可实现回归、soft分类等功能。</p>

<h2 id="section-1">梯度提升决策树</h2>

<p>对于回归问题，采用误差函数$err(s,y)=(s-y)^2$，令$s_n=\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)$可得
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^N\left(s_n+
\eta h(\mathbf x_n)-y_n\right)^2，
\label{eq:min-gradientboost-regression-Ein}
\end{equation}
内层最小化
\[
\begin{aligned}
\min_h\ldots
&amp;\overset{\mbox{taylor}}{\approx}\min_h\left({1\over N}\sum_{n=1}^N\underbrace{err(s_n,y_n)}_{\mbox{constant}}+{1\over N}\sum_{n=1}^N\eta h(\mathbf x_n)\left.{\partial err(s,y_n)\over\partial s}\right\rvert_{s=s_n}\right)\\
&amp;\overset{\quad\quad}{=}\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N2h(\mathbf x_n)(s_n-y_n)\right)。
\end{aligned}
\]
<del>如果对$h$无约束条件，那么$h(\mathbf x_n)=-\infty\cdot(s_n-y_n)$时取最小值。</del>事实上，只需要$h$的方向，$h$的大小（magnitude）通过步长$\eta$控制。利用拉格朗日乘子法的思想，避免求解复杂的约束优化问题，惩罚大的$h$
\[
\begin{aligned}
&amp;\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N\left(2h(\mathbf x_n)(s_n-y_n)+(h(\mathbf x_n))^2\right)\right)\\
\Longleftrightarrow&amp;\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N\left(\mbox{constant}+(h(\mathbf x_n)-(y_n-s_n))^2\right)\right)。
\end{aligned}
\]
去掉常数项，带惩罚的近似函数梯度是数据集$\{(\mathbf x_n,y_n-s_n)\}$上，基于平方误差的回归。$y_n-s_n$表示期望的值与目前能达到的值之间的差异，表示尚未达到的部分，称为余数（residual）。好的$h(\mathbf x_n)$需要弥补余数的差距。</p>

<p>［1/2］因此，GradientBoost的回归问题就是通过余数上的回归找到$g_t=h$。</p>

<p>当$g_t$确定后，继续\eqref{eq:min-gradientboost-regression-Ein}的外层最小化
\[
\min_\eta{1\over N}\sum_{n=1}^N(s_n+\eta g_t(\mathbf x_n)-y_n)^2\Leftrightarrow\min_\eta{1\over N}\sum_{n=1}^N((y_n-s_n)-\eta g_t(\mathbf x_n))^2，
\]
这是单变量的线性回归，非常容易求解，
\begin{equation}
\eta={\sum_{n=1}^Ng_t(\mathbf x_n)(y_n-s_n)\over\sum_{n=1}^Ng_t^2(\mathbf x_n)}。
\label{eq:gbdt-eta}
\end{equation}</p>

<p>［2/2］因此，GradientBoost的回归问题通过单变量回归求解最优作为步长$\alpha_t=\eta$。</p>

<blockquote>
  <h4 id="gbdtgradient-boosted-decision-tree">梯度提升决策树（GBDT，gradient boosted decision tree）</h4>
  <hr />
  <p>初始化$s_1=s_2=\ldots=s_N=0$；</p>

  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>利用$\mathcal A(\{(\mathbf x_n,y_n-s_n)\})$得到$g_t$，其中$\mathcal A$是基于平方误差的回归算法（例如C&amp;RT）；</li>
    <li>利用\eqref{eq:gbdt-eta}更新步长$\alpha_t=\mbox{OneVarLinearRegression}(\{(g_t(\mathbf x_n),y_n-s_n)\})$；</li>
    <li>更新$s_n\leftarrow s_n+\alpha_tg_t(\mathbf x_n)$；</li>
  </ol>

  <p>返回$G(\mathbf x)=\sum_{t=1}^T\alpha_tg_t(\mathbf x)$。</p>
</blockquote>

<p>GBDT就是AdaBoost决策树的回归版本。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:other-error-bounds">
      <p><a href="/2015/01/linear-models-for-classification/#error-bound">其它误差界</a>可参考线性分类模型的相关资料。 <a href="#fnref:other-error-bounds" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习三原则</title>
      <link href="http://qianjiye.de/2015/01/three-learning-principles" />
      <pubdate>2015-01-28T20:05:37+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/three-learning-principles</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">使用奥卡姆剃刀</h2>

<blockquote>
  <p>An explanation of the data should be made as simple as possible, but no simpler.         <br />
—Albert Einstein? (1879-1955)</p>

  <hr />

  <p>entia non sunt multiplicanda praeter necessitatem (entities must not be multiplied beyond necessity)       <br />
—William of Occam (1287-1347) </p>
</blockquote>

<p>奥卡姆剃刀（Occam’s rezor）：剃掉不必要的解释。对机器学习，适合数据的最简单模型也是最合理的模型。</p>

<ul>
  <li>简单的假设$h$：小的$\Omega(h)$，假设的参数少；</li>
  <li>简单的模型$\mathcal H$：小的$\Omega(\mathcal H)$，包含较少的假设，成长函数增长很慢。</li>
</ul>

<p>当$\Omega(\mathcal H)$小时，$\Omega(h)$也小。当假设集大小为$2^\ell$时，每个假设最多有$\ell$个参数<sup id="fnref:why-ell-parameters"><a href="#fn:why-ell-parameters" class="footnote">1</a></sup>。在实际应用中，通过正则化或从简单模型开始尝试，都可以得到简单的假设。</p>

<p>对于简单模型，$m_\mathcal H(N)$小，难以将数据拟合好（拟合好的概率为$m_{\mathcal H}(N)\over 2^N$<sup id="fnref:why-ration"><a href="#fn:why-ration" class="footnote">2</a></sup>）。对简单的模型，如果数据被分开，那么数据是规律的；对于复杂的模型，如果数据能分开，就不能判断数据是否有规律（复杂模型能把任何数据分开）。</p>

<p>在实际应用中，从简单的线性模型开始尝试，经常考量数据是否被模型过度表示（data over-modeled）。</p>

<h2 id="section-1">避免抽样偏差</h2>

<p>如果数据通过有偏抽样得到<a href="#Darrell_Huff_2002">[1]</a>，学习到的结果也是有偏的。</p>

<p>若从$P_1(\mathbf x,y)$的数据中学习，却在$P_2\neq P_1$的数据中测试，VC理论不适用。相当于学了数学却要参加英语考试。VC理论的前提是训练和测试数据都iid来自同一分布。</p>

<p>通过信用卡用户的信用记录，判断是否给新顾客信用卡。——由于没有未开通信用卡用户的信息，这两者分布可能很不一样……</p>

<p>在实际应用中，尽可能的了解测试环境，使训练环境和测试环境尽量一致。</p>

<h2 id="no-snooping">绝不偷看数据</h2>

<blockquote>
  <p>If you torture the data long enough, it will confess.</p>
</blockquote>

<p>使用数据的任何过程都相当于间接偷看了数据。为了让VC维可靠，选择$\Phi$时不应当<a href="/2015/01/nonlinear-transformation/#human-learning">偷看数据</a>。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png"><img src="/assets/images/2015-01-28-three-learning-principles-snoop-data.png" alt="简单的偷看也会导致结果偏差很大" /></a><div class="caption">图 1:  简单的偷看也会导致结果偏差很大 [<a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png">PNG</a>]</div></div></div>

<p>对使用同样数据集$\mathcal D$的论文，后来作者针对以前论文改进，阅读以前论文也就相当于偷看资料。若把这些论文看成一篇长长的论文，付出的模型复杂度为$d_{VC}(\cup_m\mathcal H_m)$，泛化能力差。</p>

<p>偷看数据很难避免，合理处理偷看数据：</p>

<p><img src="/assets/images/2015-01-28-three-learning-principles-deal-with-snooping.png" alt="合理处理偷看数据" /></p>

<p>“be blind”是指尽量避免用数据做决定，不要在看了数据之后再决定采用什么样的特征等操作。也就是避免human learning的复杂度进入。</p>

<h2 id="section-2">其它三原则</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-tools.png" alt="三大工具" /></a><div class="caption">图 2:  三大工具 [<a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png" alt="三大理论边界" /></a><div class="caption">图 3:  三大理论边界 [<a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png">PNG</a>]</div></div></div>

<h2 id="section-3">参考资料</h2>

<ol class="bibliography"><li><span id="Darrell_Huff_2002">[1]达莱尔·哈夫, <i>统计陷阱</i>. 上海: 上海财经大学出版社, 2002.</span>

</li></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-ell-parameters">
      <p>为什么最多$\ell$个参数？ <a href="#fnref:why-ell-parameters" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-ration">
      <p>这个比率什么意思？ <a href="#fnref:why-ration" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>验证</title>
      <link href="http://qianjiye.de/2015/01/validation" />
      <pubdate>2015-01-27T23:28:10+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/validation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">模型选择问题</h2>

<p>若有$M$个<a href="/assets/images/2015-01-27-validation-so-many-models.png">候选模型</a>$\mathcal H_1,\mathcal H_2,\ldots,\mathcal H_M$和相应的算法$\mathcal A_1,\mathcal A_2,\ldots,\mathcal A_M$，如何选择$\mathcal H_{m^*}$使得$g_{m^*}=\mathcal A_{m^*}(\mathcal D)$有低的$E_{out}(g_{m^*})$？</p>

<p>由于$P(\mathbf x)$和$P(y|\mathbf x)$未知，那么$E_{out}$未也知……</p>

<h4 id="section-1">一、利用数据可视化不可行</h4>

<p>只有一些数据集……基于视觉化的选择是“<a href="/2015/01/nonlinear-transformation/#human-learning">human learning</a>”，并且高维度的数据不能视觉化。</p>

<h4 id="ein">二、利用$E_{in}$很危险</h4>

<p>如果利用$E_{in}$选择，高维特征变换通常犹豫低维，非正则化方法通常优于正则化方法。若$\mathcal A_1$在$\mathcal H_1$最小化$E_{in}$，$\mathcal A_2$在$\mathcal H_2$最小化$E_{in}$，二者再择优$g_{m^*}$在$\mathcal H_1\cup\mathcal H_2$中得到最小的$E_{in}$，这样增加了额外的模型复杂度，VC维$d_{VC}(\mathcal H_1\cup\mathcal H_2)$变大了，泛化能力差。</p>

<h4 id="etest">三、利用$E_{test}$是作弊</h4>

<p>根据finite-bin Hoeffding可得
\[
E_{out}(g_{m^*})\leq E_{test}(g_{m^*})+O\left(\sqrt{\log M\over N_{test}}\right)，
\]
看上去很美，$\mathcal D_{test}$是没用于模型训来的干净数据，可是$\mathcal D_{test}$（相当于老师的考卷）从哪里来呢？</p>

<h4 id="einetesteval">四、$E_{in}$和$E_{test}$折中的合法作弊方案$E_{val}$</h4>

<ul>
  <li>$\mathcal D_{val}\subset\mathcal D$；</li>
  <li>可以获取的；</li>
  <li>若$\mathcal D_{val}$没用于$\mathcal A_m$，那么它是干净的，就像测试数据一样。</li>
</ul>

<h2 id="section-2">单一验证集</h2>

<p>数据$\mathcal D$的划分和相应关系如下：</p>

<p>\begin{align*}
E_{in}(h)\quad&amp;\quad&amp;\quad&amp;\quad &amp;E_{val}(h)\\
\uparrow\quad\quad&amp;\quad&amp;\quad&amp;\quad &amp;\uparrow\;\;\,\,\\
\quad\underbrace{\mathcal D}_{\mbox{size }N}\quad\,&amp;\rightarrow&amp;\underbrace{\mathcal D_{train}}_{\mbox{size }N-K}\quad\quad\,&amp;\cup&amp;\underbrace{\mathcal D_{val}}_{\mbox{size }K}\;\\
\downarrow\quad\quad&amp;\quad &amp;\downarrow\quad\quad\quad\;&amp;\quad&amp;\quad\\
g_m=\mathcal A_m(\mathcal D)&amp;\quad &amp;g_m^-=\mathcal A_m(\mathcal D_{trian})&amp;\quad&amp;\quad
\end{align*}</p>

<p>$\mathcal D_{val}\subset\mathcal D$称为<strong>验证集</strong>（validation set），用于模拟测试集。$\mathcal D_{val}$是随机从$\mathcal D$中抽取的$K$个样本，那么$\mathcal D_{val}\overset{iid}{\sim} P(\mathbf x,y)$，通过数据建立了$E_{val}$与$E_{out}$的联系。确保$\mathcal D_{val}$是干净的，$\mathcal A_m$只使用了$\mathcal D_{train}$进行模型选择（也就是训练得到模型参数，从$\mathcal H$中选出$h$）。</p>

<p>原来使用$\mathcal D$扮演两个角色，既要计算$E_{in}$进行模型选择，又要通过算法得到$g$，两个角色导致资料被污染。利用$D_{val}$，通过最佳$E_{val}$进行模型选择
\[
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{val}(\mathcal A_m(\mathcal D_{train})))，
\]
可得如下误差保证
\begin{equation}
E_{out}(g_m^-)\leq E_{val}(g_m^-)+O\left(\sqrt{\log M\over K}\right)，
\end{equation}
但是只用$N-K$个训练模型out-of-sample误差会偏大（也可从学习曲线看出，理论上若要成立，还需更严格的限制条件），
\[
E_{out}\left(\underbrace{g_{m^*}}_{\mathcal A_m^*(\mathcal D)}\right)\leq E_{out}\left(\underbrace{g_{m^*}^-}_{\mathcal A_m^*(\mathcal D_{train})}\right)，
\]
因此，
\[
E_{out}(g_{m^*})\leq E_{out}(g_{m^*}^-)\leq E_{val}(g_{m^*}^-)+O\left(\sqrt{\log M\over K}\right)。
\]</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-27-validation-model-selection.png"><img src="/assets/images/2015-01-27-validation-model-selection.png" alt="基于验证集的模型选择方案" /></a><div class="caption">图 1:  基于验证集的模型选择方案 [<a href="/assets/images/2015-01-27-validation-model-selection.png">PNG</a>]</div></div></div>

<p>模型选择整个方案如上图所示，得到$g_{m^*}^-$之后，再回到原来整个数据集上得到$g_{m^*}$效果会更好<sup id="fnref:is-it-necessary"><a href="#fn:is-it-necessary" class="footnote">1</a></sup>。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-27-validation-vlidation-example.png"><img src="/assets/images/2015-01-27-validation-vlidation-example.png" alt="模型选择的学习曲线" /></a><div class="caption">图 2:  模型选择的学习曲线 [<a href="/assets/images/2015-01-27-validation-vlidation-example.png">PNG</a>]</div></div></div>

<p>上图是在$\mathcal H_{\Phi_5}$和$\mathcal H_{\Phi_{10}}$中进行模型选择的学习曲线。$g_{m^*}$的效果要优于$g_{m^*}^-$。利用$E_{in}$总会选择到复杂的模型，利用$E_{out}$的作弊方案选择结果总最优。随着验证集不断增大，用于模型选择的训练集不断减小，所以$g_{m^*}^-$甚至会比$g_{\widehat m}$效果差，对很小的训练集，采用$E_{in}$还算不错的模型选择方案。</p>

<p>对大的验证集样本数$K$，有$E_{val}(g^-)\approx E_{out}(g^-)$，但$g_{m^*}^-$通常比$g_{m^*}$糟糕；对小的$K$，有$g_m^-\approx g_m$和$E_{out}(g)\approx E_{out}(g^-)$，但$E_{val}$和$E_{out}$差异较大；
\[
E_{out}(g)\underset{\mbox{small }K}{\approx}E_{out}(g^-)\underset{\mbox{large }K}{\approx}E_{val}(g^-)。
\]</p>

<p>从时间上看，由于部分数据当作了验证集，在训练集上选择每个模型的时间会缩短。</p>

<p>$K={N\over 5}$通常是不错的选择。</p>

<h2 id="section-3">留1交叉验证</h2>

<p>当在验证集的$K=1$的极端情况下，$g^-$和$g$就会非常接近，但$E_{out}$和$E_{val}$差异就很大。能否在$K=1$时找到方案，使得$E_{out}\approx E_{val}$？✅</p>

<p>当$K=1$时，验证集$\mathcal D_{val}^{(n)}=\{(\mathbf x_n,y_n)\}$，误差为$E_{val}^{(n)}(g_n^-)=err(g_n^-(\mathbf x_n),y_n)=e_n$，将留1交叉验证（leave-one-out cross validation）误差
\begin{equation}
E_{loocv}(\mathcal H,\mathcal A)={1\over N}\sum_{n=1}^Ne_n={1\over N}\sum_{n=1}^Nerr(g_n^-(\mathbf x_n),y_n)
\end{equation}
作为$E_{out}(g)$的近似，$E_{loocv}(\mathcal H,\mathcal A)\approx E_{out}(g)$，然后进行模型选择，
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{loocv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-example.png"><img src="/assets/images/2015-01-27-validation-loocv-example.png" alt="loocv选择常数模型而非线性模型" /></a><div class="caption">图 3:  loocv选择常数模型而非线性模型 [<a href="/assets/images/2015-01-27-validation-loocv-example.png">PNG</a>]</div></div></div>

<p>用$\underset{\mathcal D_n}{\varepsilon}$表示在训练集上的数学期望，那么有<sup id="fnref:how-expectation-do"><a href="#fn:how-expectation-do" class="footnote">2</a></sup>
\begin{aligned}
\underset{\mathcal D}{\varepsilon}E_{loocv}(\mathcal H,\mathcal A) = \underset{\mathcal D}{\varepsilon}{1\over N}\sum_{n=1}^Ne_n 
&amp;= {1\over N}\sum_{n=1}^N\underset{\mathcal D}{\varepsilon}e_n\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}\underset{(\mathbf x_n,y_n)}{\varepsilon}err(g_n^-(\mathbf x_n),y_n)\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}E_{out}(g_n^-)\\
&amp;={1\over N}\sum_{n=1}^N\overline{E_{out}}(N-1)\\
&amp;=\overline{E_{out}}(N-1)，
\end{aligned}
因此可得$E_{loocv}(\mathcal H,\mathcal A)$和$E_{out}(g^-)$联系紧密，通常称作$E_{out}(g)$几乎无偏的估计（almost unbiased estimate）。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-practice.jpg"><img src="/assets/images/2015-01-27-validation-loocv-practice.jpg" alt="loocv手写识别示例" /></a><div class="caption">图 4:  loocv手写识别示例 [<a href="/assets/images/2015-01-27-validation-loocv-practice.jpg">JPG</a>]</div></div></div>

<p>上图手写识别例子中，通过验证确定选择多少维多项式特征。若用$E_{in}$，特征维度越多越好；利用$E_{loocv}$（图中标注为$E_{cv}$），会选到较低纬度的特征。</p>

<h2 id="v-fold-cross-validation">V-fold交叉验证</h2>

<p>由于loocv需要训练$N$次，时间复杂度非常大，在实际中并不总是可行的。但也有特例，线性回归的的loocv容易计算。通过单点估计误差波动较大，结果不是很稳定，曲线上有些跳动的点。如何降低loocv的计算量？</p>

<p>将数据集$\mathcal D$随机分为$V$等份（loocv相当于将数据集分为$N$等份），$V-1$份用于训练模型，剩余的1份用于验证，这称为V-fold交叉验证，
\begin{equation}
E_{cv}(\mathcal H,\mathcal A)={1\over V}\sum_{v=1}^VE_{val}^{(v)}(g_v^-)，
\end{equation}
模型选择方式为
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{cv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<p>通常情况，$V=10$。</p>

<p>通常，V-fold交叉验证要优于单一验证集方法，计算量也更大，5-fold或10-fold通常都会工作得很好，实际中loocv并不常用。</p>

<h2 id="section-4">小结</h2>

<p>各种模型选择的关系：</p>

<ul>
  <li>模型训练（初赛）：从假设集中选择；</li>
  <li>验证方案（复赛）：从训练好的模型中选择；</li>
  <li>测试：衡量最终的表现（测试集只在此时才能使用1次）。</li>
</ul>

<p>由于资料污染，以及付出了模型复杂度代价等因素，通常验证的结果仍然会比最终测试结果乐观。因此，提交测试结果而非验证结果更客观。</p>

<h2 id="section-5">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-6">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-it-necessary">
      <p><a href="/2015/01/image-classification-knn-based-introduction/#is-validation-set-need">并不是所有的人都这样做</a>…… <a href="#fnref:is-it-necessary" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-expectation-do">
      <p>数学期望如何分离计算的？ <a href="#fnref:how-expectation-do" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>正则化</title>
      <link href="http://qianjiye.de/2015/01/regularization" />
      <pubdate>2015-01-26T17:50:30+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/regularization</guid>
      <content:encoded>&lt;![CDATA[<p>正则化来源于处理函数逼近（function approximation）中的病态问题（ill-posed problem）。克服过拟合的一个方法是从简单模型开始尝试；正则化是相反的思路，从复杂模型的假设集开始，通过正则化约束求解得到未过拟合的简单模型（复杂项的系数很小或接近0）。</p>

<p>正则化等价于结构风险最小化（SRM，structural risk minimuzation）<a href="#lihang_sml_2012">[1, P. 9]</a>，它是结构风险最小化策略的实现，通过在经验风险上加一个正则化项或惩罚项实现<a href="#lihang_sml_2012">[1, P. 13]</a>。正则化符合奥卡姆剃刀（Occam’s rezor）原理：在所有可能选择的模型中，能够很好解释已知数据并且十分简单才是最好的模型。<a href="http://ask.julyedu.com/question/150">从贝叶斯估计的角度看，正则化项对应于模型的先验概率</a>，可以假设复杂的模型有较大的先验概率，简单的模型有较小的先验概率<a href="#lihang_sml_2012">[1, P. 14]</a>。</p>

<p>本文的主要参考资料是机器学习基石<a href="#lin_ml_regularization_2014">[2]</a>。</p>

<h2 id="section">带约束回归</h2>

<p>对于$x\in\mathbb R$的Q阶多项式变换$\Phi_Q(x)=\left(1,x,x^2,\ldots,x^Q\right)$，为了方便用$\mathbf w$代替回归系数$\tilde{\mathbf w}$。10次和2次空间中回归问题的假设集$\mathcal H_{10}$和$\mathcal H_2$分别表示为
\[
\begin{aligned}
&amp;w_0+w_1x+w_2x^2+w_3x^3+\ldots,w_{10}x^{10}\\
&amp;w_0+w_1x+w_2x^2。
\end{aligned}
\]
若$w_3=w_4=\ldots=w_{10}=0$，则$\mathcal H_2=\mathcal H_{10}$，也就是$\mathcal H_2$的回归问题可以用带约束的$\mathcal H_{10}$实现
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }w_3=w_4=\ldots=w_{10}=0。
\]
正则化可以看作带约束的优化$E_{in}$。</p>

<p>稍微放松约束条件，任意8个系数为0，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H’_2$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}\left[\left[w_q\neq 0\right]\right]\leq 3。
\]
$\mathcal H’_2$比$\mathcal H_2$宽松，但比$\mathcal H_{10}$过拟合风险低，$\mathcal H_2\subset\mathcal H’_2\subset\mathcal H_{10}$。求解稀疏形式（含8个0系数）$\mathcal H’_2$中的假设非常困难，NP-hard。</p>

<p>进一步放松约束条件，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H(C)$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}w_q^2\leq C。
\]
$\mathcal H(C)$和$\mathcal H’_2$有交集（overlap），对$C\geq 0$存在嵌套结构
\[
\mathcal H(0)\subset\mathcal H(1.126)\subset\ldots\subset\mathcal H(1126)\subset\ldots\subset\mathcal H(\infty)=\mathcal H(10)。
\]
从正则化假设集$\mathcal H(C)$的到的最优解就是正则化假设$\mathbf w_{REG}$。</p>

<h2 id="section-1">拉格朗日乘子法</h2>

<p>根据上述推导，正则化回归问题的向量表示形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}\sum_{n=1}^N\left(\mathbf w^T\mathbf z_n-y_n\right)^2\qquad\mbox{s.t. }\sum_{q=0}^Qw_q^2\leq C，
\end{equation}
进一步记为矩阵形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}(\mathbf Z\mathbf w-\mathbf y)^T(\mathbf Z\mathbf w-\mathbf y)\qquad\mbox{s.t. }\mathbf w^T\mathbf w\leq C，
\label{eq:constrained-Ein-matrix}
\end{equation}
事实上$\mathbf w$位于半径为$\sqrt C$的球中。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-gradient-descent.png"><img src="/assets/images/2015-01-26-regularization-gradient-descent.png" alt="正则化约束的梯度下降法" /></a><div class="caption">图 1:  正则化约束的梯度下降法 [<a href="/assets/images/2015-01-26-regularization-gradient-descent.png">PNG</a>]</div></div></div>

<p>上图展示了正则化约束的梯度下降法，蓝色的椭圆曲线表示梯度相同的等高线，红色的圆形表示约束条件。没有正则化约束时，$\mathbf w$沿着$-\nabla E_{in}(\mathbf w)$方向达到最优解$\mathbf w_{lin}$，梯度方向指出了到达最优解的方式。有正则化约束时，大部分情况，最优解都在球面$\mathbf w^T\mathbf w=C$上。$-\nabla E_{in}(\mathbf w)$可以分解为绿色和红色$\mathbf w$（球切面的法向量）两个方向，如果已经在球面上，仍然继续沿着$\mathbf w$下降，会破坏约束条件。正则化梯度下降法，可看作在绿色箭头方向作用下接近最优解。达到最优解的条件是满足约束且不能继续下降，也就是$-\nabla E_{in}(\mathbf w)$平行于$\mathbf w$，那么有$-\nabla E_{in}(\mathbf w_{REG})\propto\mathbf w_{REG}$，此时绿色方向的分量为0，不再下降，优化过程结束。</p>

<p>利用拉格朗日乘子$\lambda&gt;0$，达到最优解的条件是
\begin{equation}
\nabla E_{in}(\mathbf w_{REG})+{2\lambda\over N}\mathbf w_{REG}=0。
\label{eq:nabla-E-w-reg}
\end{equation}
因为$\nabla E_{in}(\mathbf w_{REG})={2\over N}\left(\mathbf Z^T\mathbf Z\mathbf w_{REG}-\mathbf Z^T\mathbf y\right)$，所以可得最优解<sup id="fnref:why-regularize-all"><a href="#fn:why-regularize-all" class="footnote">1</a></sup>
\begin{equation}
\mathbf w_{REG}\leftarrow\left(\mathbf Z^T\mathbf Z+\lambda\mathbf I\right)^{-1}\mathbf Z^T\mathbf y。
\end{equation}
$\mathbf Z^T\mathbf Z$是半正定的，当$\lambda&gt;0$时，上述逆矩阵总存在。正则化的线性回归在统计学中称为<strong>脊回归</strong>（ridge regression）。</p>

<p>求解\eqref{eq:nabla-E-w-reg}等价于最小化增广误差（augmented error）
\begin{equation}
\mathbf w_{REG}\leftarrow \arg\min_{\mathbf w}E_{aug}(\mathbf w)\quad \lambda\geq 0，
\label{eq:Eaug-minimization}
\end{equation}
其中增广误差
\begin{equation}
E_{aug}(\mathbf w)=E_{in}(\mathbf w)+{\lambda\over N}\mathbf w^T\mathbf w，
\label{eq:E-aug}
\end{equation}
$\mathbf w^T\mathbf w$称为正则化项（regularizer）。带约束优化$E_{in}$，可通过无约束优化$E_{aug}(\mathbf w)$高效求解，每个$C$都有对应的$\lambda$，大的$\lambda$对应着小的$C$，也对应着短的$\mathbf w$。当$\lambda=1$或$C=\infty$或$C\geq\lVert\mathbf w_{LIN}\rVert^2$（相当于红色的圆已经把$\mathbf w_{LIN}$包含在内）时，相当于没有进行正则化。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-regularize-regression.png"><img src="/assets/images/2015-01-26-regularization-regularize-regression.png" alt="不同系数下正则化的效果" /></a><div class="caption">图 2:  不同系数下正则化的效果 [<a href="/assets/images/2015-01-26-regularization-regularize-regression.png">PNG</a>]</div></div></div>

<p>$\lambda$相当于对过拟合的惩罚因子，上图展示了不同$\lambda$惩罚下的效果。</p>

<p>${\lambda\over N}\mathbf w^T\mathbf w$称为权重衰减（weight-decay）正则化，可推广到“任意变换 ＋ 线性模型”。</p>

<h2 id="section-2">勒让德多项式</h2>

<p>当$x_n\in[-1,1]$和$Q$很大时，$x_n^q$会变得非常小，除精确度因素影响外，还需要很大的$w_q$才能体现$x_n^q$的影响，这就与正则化的目的有些“矛盾”，过度惩罚了高次项。对于$\mathcal Z$空间的特征
\[
\Phi(\mathbf x)=\left(1,x,x^2,\ldots,x^Q\right)，
\]
特征之间彼此非正交，对低次项容忍度较大，对高次项惩罚力度更大。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png"><img src="/assets/images/2015-01-26-regularization-legendre-polynomials.png" alt="勒让德多项式" /></a><div class="caption">图 3:  勒让德多项式 [<a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png">PNG</a>]</div></div></div>

<p>为改善这一问题，可以考虑在多项式空间找到一组正交的基函数（orthonormal basis function），也称为勒让德多项式（legendre polynomials），构造如上图所示的新多项式变换
\[
\Phi(\mathbf x)=\left(1,L_1(x),L_2(x),\ldots,L_Q(x)\right)。
\]</p>

<h2 id="vc">VC维分析</h2>

<p>带约束$E_{in}$优化\eqref{eq:constrained-Ein-matrix}的VC上界
\begin{equation}
E_{out}(\mathbf w)\leq E_{in}(\mathbf w)+\Omega(\mathcal H(C))，
\label{eq:vc-bound}
\end{equation}
采用与$C$等价的$\lambda$时，可以用优化\eqref{eq:Eaug-minimization}实现，在没有限定$\mathcal H(C)$的情况下，通过优化$E_{aug}$间接获得了VC维的保证。对比\eqref{eq:E-aug}和\eqref{eq:vc-bound}，$\mathbf w^T\mathbf w=\Omega(\mathbf w)$衡量了单一假设的复杂度，$\Omega(\mathcal H(C))$衡量了整个假设集的复杂度。如果${\lambda\over N}\Omega(\mathbf w)$能很好的表示$\Omega(\mathcal H(C))$，衡量$E_{out}$时，$E_{aug}$是比$E_{in}$更好中介。</p>

<p>对$\mathcal Z$空间的非正则化方法，$d_{VC}(\mathcal H)=\tilde d+1$。事实上，采用正则化考虑的假设集$\mathcal H(C)$要小于$\mathcal H$。采用了正则化后，有效（effective）VC维$d_{EFF}(\mathcal H,\mathcal A)\leq d_{VC}(\mathcal H)$，其中$\mathcal A$为正则化算法。因此，正则化方法具有更好的泛化性能。增大$\lambda$使$C$变小，从而使$\mathcal H(C)$变小，使得$d_{EFF}(\mathcal H,\mathcal A)$减小。</p>

<h2 id="section-3">正则化的推广</h2>

<p>除权重衰减（weight-decay）正则化外，还有很多其它的正则化方法。正则化的约束条件应当向着目标函数方向，选择正则化方法的思路包括：</p>

<ul>
  <li>目标相关（target-dependent）：利用目标的特性，比如已知目标函数的对称性，可采用对称正则化$\sum[[q\mbox{ is odd}]]w_q^2$；</li>
  <li>合理性（plausible）：使结果更加光滑和简单，比如要对随机或确定性噪声鲁棒，可采用稀疏的$L_1$正则化$\sum |w_q|$；</li>
  <li>友好（friendly）：易于优化，比如采用除权重衰减的$L_2$正则化$\sum w_q^2$。</li>
</ul>

<p>如果正则化选择不合适，还有$\lambda=0$这道防线，可以避免危害。以上正则化选择思路和<a href="/2014/12/machine-learning-noise-and-error/#error-measurement">误差度量</a>一致：用户相关（user-dependent）、合理性、友好。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png"><img src="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png" alt="［左］：L2正则化；［右］L1正则化" /></a><div class="caption">图 4:  ［左］：L2正则化；［右］L1正则化 [<a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png">PNG</a>]</div></div></div>

<p>$L_1$正则化在需要稀疏解时很有用。上图右是$L_1$正则化示意图，$L_1$正则化
\begin{equation}
\Omega(\mathbf w)=\sum_{q=0}^Q|w_q|=\lVert\mathbf w\rVert_1，
\end{equation}
虽然不可微分，但它是凸的，解是稀疏的（$\mathbf w$有很多0元素）。$-\nabla E_{in}$可分解到垂直于边界面的方向（边界面的法向量方向，如上图右红色箭头所示）和沿边界面的方向。当到达边界面后，如果继续沿着法向量方向下降，会破坏约束条件，沿着面的方向如果还能下降，则继续沿着面的方向下降，直到停在菱形球的顶点，或者直到$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$（沿边界面的方向分量为0）。边界面的法向量只和$\mathbf w$的符号有关，如果要$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$比较困难，通常会停在菱形球的顶点，该点在坐标轴上，必有元素为0。</p>

<h2 id="lambda">最优$\lambda$</h2>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png"><img src="/assets/images/2015-01-26-regularization-noise-and-lambda.png" alt="噪声对性能的影响" /></a><div class="caption">图 5:  噪声对性能的影响 [<a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png">PNG</a>]</div></div></div>

<p>上图表明，噪声等级越高，正则化的惩罚力度$\lambda$越大。实际上，噪声的等级不可预知，只有通过实验的方法选择最佳$\lambda$，也就是通过<a href="">验证</a>（validation）选择最佳$\lambda$。</p>

<h2 id="section-4">正则化实例</h2>

<p>本节内容源于机器学习<a href="#ng_ml_r_2014">[3]</a>网络课程，这里没有对增加的偏移项$x_0=1$的系数正则化，且$y\in\{0,1\}$。</p>

<h3 id="section-5">正则化线性回归</h3>

<h4 id="section-6">一、代价函数</h4>

<p>\begin{equation}
J(\boldsymbol\theta) = \frac{1}{2m}\left( \sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)^2 + \lambda\sum_{j=1}^n\theta_j^2 \right)
\label{eq:cf-linear-regression-r}
\end{equation}</p>

<h4 id="section-7">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<p>迭代过程可以化为如下形式：
\begin{equation*}
\theta_j := \theta_j\left(1 - \alpha\frac{\lambda}{m} \right) - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)};~~(j = 1, 2, \ldots, n)
\end{equation*}</p>

<p>通常$1 - \alpha\frac{\lambda}{m} &lt; 1$，与非正则化的梯度下降法比较，$\theta_j$减小更快。</p>

<h3 id="logistic">正则化Logistic回归</h3>

<h4 id="section-8">一、代价函数</h4>

<p>\begin{equation}
\begin{aligned}
J(\boldsymbol\theta)  = &amp;-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)\right)\right) \\
&amp; + \frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
\end{aligned}
\label{eq:cf-logistic-regression-r}
\end{equation}</p>

<h4 id="section-9">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<h3 id="matlab">Matlab实现</h3>

<p>第一步：实现Logistic函数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>g <span class="p">=</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span>z<span class="p">)</span><span class="w"></span>
<span class="n">g</span> <span class="p">=</span> <span class="mf">1.0</span> <span class="o">./</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="nb">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">));</span>
<span class="k">end</span></code></pre></div>

<p>第二步：实现代价函数（包含梯度计算）</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>[J, grad] <span class="p">=</span><span class="w"> </span><span class="nf">costFunctionReg</span><span class="p">(</span>theta, X, y, lambda<span class="p">)</span><span class="w"></span>
<span class="n">m</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">y</span><span class="p">);</span> <span class="c">% number of training examples</span>

<span class="n">h</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="n">J</span> <span class="p">=</span> <span class="o">-</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">+</span> <span class="c">...</span>
    <span class="n">lambda</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">sum</span><span class="p">(</span><span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">grad</span> <span class="p">=</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)])</span> <span class="o">/</span> <span class="n">m</span><span class="p">;</span>

<span class="k">end</span></code></pre></div>

<p>第三步：估计参数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="n">initial_theta</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">lambda</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">options</span> <span class="p">=</span> <span class="n">optimset</span><span class="p">(</span><span class="s">&#39;GradObj&#39;</span><span class="p">,</span> <span class="s">&#39;on&#39;</span><span class="p">,</span> <span class="s">&#39;MaxIter&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">);</span>
<span class="p">[</span><span class="n">theta</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">exit_flag</span><span class="p">]</span> <span class="p">=</span> <span class="c">...</span>
	<span class="n">fminunc</span><span class="p">(@(</span><span class="n">t</span><span class="p">)(</span><span class="n">costFunctionReg</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda</span><span class="p">)),</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">options</span><span class="p">);</span></code></pre></div>

<h2 id="section-10">参考资料</h2>

<ol class="bibliography"><li><span id="lihang_sml_2012">[1]李航, <i>统计学习方法</i>. 北京: 清华大学出版社, 2012.</span>

</li>
<li><span id="lin_ml_regularization_2014">[2]H.-T. Lin, “Lecture 14: Regularization.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li>
<li><span id="ng_ml_r_2014">[3]A. Ng, “Regularization: The problem of overfitting.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-11">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-regularize-all">
      <p>为什么正则化包括$x_0=1$的偏移项系数，两者有何区别？ <a href="#fnref:why-regularize-all" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
