<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2014-12-23T20:58:27+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>机器学习：不均衡数据问题</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-unbalanced-data-sets" />
      <pubdate>2014-12-23T22:15:19+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-unbalanced-data-sets</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">问题描述</h2>

<p>不均衡数据是指用于分类的正负样本数量差异很大。导致不均衡样本主要有两种情况：</p>

<ol>
  <li>数据本身的内在属性，比如：信用卡欺诈、异常检测、大众中癌症病人的筛查等；</li>
  <li>获取的数据不够，比如：车牌识别中的汉字。</li>
</ol>

<p>不均衡数据相关的另一个问题是小样本问题。</p>

<h2 id="section-1">处理内在不均衡</h2>

<p>内在不均衡就是指数据本身特性决定了它的不均衡性。即使获取更多的数据，仍然改变不了数据的不均衡属性。</p>

<h3 id="section-2">存在的问题</h3>

<p>这类问题主要考虑数据对机器学习的算法本身的影响。样本总数都是$N$，不同比率的正负样本对学习算法有何影响？对学习速度、学习效果有何影响？</p>

<h3 id="section-3">解决方案</h3>

<p>基本的方法是必须采用科学的<a href="/2014/11/machine-learning-advice-for-applying-machine-learning/#performance-evaluation">性能评价指标</a>，比如$F_1$ Scorce，避免大样本类淹没了小样本类。对小样本类别的分类性能也能进行有效的评估。</p>

<p><a href="/2014/12/machine-learning-anomaly-detection">异常检测</a>也是处理这类不均衡样本的方法，只对大样本类别进行建模，小样本类当作异常数据进行检测。</p>

<p>以下方法可行吗？</p>

<ol>
  <li>如果$1:1０$算是均匀的话，可以将多数类分割成为$1000$份。然后将每一份跟少数类的样本组合进行训练得到分类器。而后将这$1000$个分类器用assemble的方法组合位一个分类器。</li>
  <li>设计objective function的时候给不同misclassification的情况不同的relative weights。也就是说给从小数量的样本被分成大数量的样本更大的penalty。</li>
</ol>

<h2 id="section-4">处理外在不均衡</h2>

<p>外在不均衡就是指数据本身特性并不能表明它是不均衡的，是由于数据获取手段导致数据不均衡。只要获取的数据足够多，这种不均衡就能消除。</p>

<h3 id="section-5">存在的问题</h3>

<p>从机器学习的理论来说，如果样本数$N$不够，$E_{out}$和$E_{in}$差异很大，无法学习成功，导致Low Bias问题。</p>

<h3 id="section-6">解决方案</h3>

<p>克服外在的不均衡性，需要<a href="/2014/11/machine-learning-advice-for-applying-machine-learning/#get-more-data">获得更多的数据</a>：</p>

<ol>
  <li>人工合成（伪造）数据；</li>
  <li>采集更多的数据。</li>
</ol>

<p>由于条件或成本限制，无法采集到足够的数据，在这样的情况下可以考虑人工合成。人工合成数据的前提是了解数据，拥有足够的先验知识。在OCR中，比如车牌识别时，采集到的数据可能不够，特别是有时汉字样本很少。此时，可以通过字库和随机背景融合的方法（<a href="/2014/11/machine-learning-advice-for-applying-machine-learning/#get-more-data">通过叠加高斯噪声增大样本集对提升性能帮助不大</a>），生成大量的数据。</p>

<p>更多的时候，没有足够的先验知识预知数据特性，无法合理伪造，还得采集跟多的数据。机器学习本来就是探究数据特性的过程。</p>

<h2 id="section-7">其它建议</h2>

<p><a href="http://www.weibo.com/n/机器学习那些事儿">@机器学习那些事儿</a>发起过关于<a href="http://www.weibo.com/p/1001603785752793219283?sudaref=ml.memect.com">不均匀正负样本分布下的机器学习</a>的讨论，部分建议摘录如下：</p>

<ol>
  <li>上采样、下采样、代价敏感，没什么好办法。</li>
  <li>这个之前调研过，主要分重采样和欠采样！这种不平衡是因为比率的不平衡给一些学习方法带来问题。但是在某些领域，比如反欺诈和安全，不仅是比率极不平衡，而且是正样本样本绝对数很小。需要扩散正样本方法！</li>
  <li>Synthetic Minority Over-sampling Technique 我试过这个方法，解决部分问题，主要还是需要增加样本在特征空间的覆盖！ 工程上光靠算法也解决不了问题，有的还是需要加入下经验知识来做。</li>
  <li>用排序思想构造所谓的序对。</li>
  <li>如果1：1０算是均匀的话，可以将多数类分割成为1000份。然后将每一份跟少数类的样本组合进行训练得到分类器。而后将这1000个分类器用assemble的方法组合位一个分类器。记得读到的论文可行，但没有验证过。</li>
  <li>标准解决方法：设计objective function的时候给不同misclassification的情况不同的relative weights。也就是说给从小数量的样本被分成大数量的样本更大的penalty。</li>
  <li>训练数据与预测数据分布不一致，有专门研究的课题，sample selection bias，主要方法是各种reweighting。</li>
  <li>这个倒是可以参考positive only learning等半监督学习中如早期的spy算法等来构造合适的负例来解决正负例不平衡的问题。</li>
  <li>这个看起来像 one-class recommendation 问题，不知是否可以考虑转化成 learning to rank 问题，如果不是为了拟合一个分布的话。</li>
  <li>这在机器学习里面被称类别不平衡问题，可以参考Haibo, H. and E. A. Garcia (2009). “Learning from Imbalanced Data.” Knowledge and Data Engineering, IEEE Transactions on” 的survey.已有很多方法提出。</li>
  <li>个人觉得在类别不平衡条件下，Transductive SVM (TSVM)应该对于的active learning 来标注，可能结果更好。</li>
  <li>learning to rank对于训练数据量的要求较高，同时要确定用于learning to rank的pair，还是需要找到负例，从而将正例和负例形成偏序配对。所以learning to rank是一种方法，但个人认为这会将简单问题复杂化，且本质还是需要去找负例。</li>
</ol>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：泛化理论</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-theory-of-generalization" />
      <pubdate>2014-12-20T07:36:39+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-theory-of-generalization</guid>
      <content:encoded>&lt;![CDATA[<p>本节的主要内容来自Hsuan-Tien Lin的机器学习基石课程<a href="#lin_ml_tg_2014">[1]</a>。</p>

<h2 id="mmathcal-hn">最大可能的$m_{\mathcal H}(N)$</h2>

<p>如何通过断点$k$限定$m_{\mathcal H}(N)$的值？</p>

<p>由前文可得，正射线的断点是$2$，$m_{\mathcal H}(2)＝3$；正区间的断点是$3$，$m_{\mathcal H}(3)＝7$；2维感知器的断点是$4$，$m_{\mathcal H}(4)＝14$。</p>

<p>如果最小断点$k=2$，在$N=1,2,3,\ldots$的情况下，对任意的$\mathcal H$而言，可能得到的最大$m_{\mathcal H}(N)$是多少呢？</p>

<ul>
  <li>若$N=1$，只有1个点，永远不存在2个点能被打碎的情况，因此$m_{\mathcal H}(1)=2^1=2$；</li>
  <li>若$N=2$，由于最小断点$k=2$，不能打碎$2$个点，因此$m_{\mathcal H}(2)&lt;2^2=4$，最多为$3$；</li>
  <li>若$N=3$，$3$个点中任取$2$个点都不能被打碎时，最多可能的二分法有多少种？</li>
  <li>……</li>
</ul>

<p>当$N=3,k=2$时，如果$m_{\mathcal H}(3)＝3$，可以肯定从3个点中任意抽取2个都不会被打碎，因为打碎2个点至少要4种二分类方法，因此$m_{\mathcal H}(3)$最少为3，可以从$4$开始考察。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-19-machine-learning-theory-of-generalization-max-mH(N).png"><img src="/assets/images/2014-12-19-machine-learning-theory-of-generalization-max-mH(N).png" alt="4个二分类的情况" /></a><div class="caption">Figure 1:  4个二分类的情况 [<a href="/assets/images/2014-12-19-machine-learning-theory-of-generalization-max-mH(N).png">PNG</a>]</div></div></div>

<p>对于$4$个二分类的情况，如上图所示。上图左的二分类使得$\mathbf x_2$和$\mathbf x_3$被打碎了；上图右修改了最后一种分类方法，任意两个点都没有被打碎，因此$m_{\mathcal H}(3)$最少为4。</p>

<p>还需考察$m_{\mathcal H}(3)=5$的情况。结果表明，$m_{\mathcal H}(3)=5$时总会让其中的$2$个点被打碎。因此，若$N=3,k=2$，最多可能的二分法只有$4$种。</p>

<h2 id="section">上限函数</h2>

<p>期望对$m_{\mathcal H}(N)$进一步进行限定，
\[
m_{\mathcal H}(N)\leq\mbox{maximum possible }m_{\mathcal H}(N)\mbox{ given }k\leq\mbox{poly}(N)。
\]</p>

<p>当断点为$k$时，将最大可能的$m_{\mathcal H}(N)$定义为上限函数（bounding function）$B(N,k)$。该上限函数和假设集$\mathcal H$无关，不受感知器等特定分类器的约束，它的取值是所有$\mathcal H$中的最大值。</p>

<p>$m_{\mathcal H}(N)$受假设集（分类器）$\mathcal H$和样本点数目$N$的约束；$B(N,k)$受样本点数目$N$和断点$k$约束，而与假设集$\mathcal H$无关。但是，如果知道假设集$\mathcal H$的断点$k$，就可以用$B(N,k)$对$m_{\mathcal H}(N)$进一步约束，$m_{\mathcal H}(N)\leq B(N,k)$。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-19-machine-learning-theory-of-generalization-B(N,k).png"><img src="/assets/images/2014-12-19-machine-learning-theory-of-generalization-B(N,k).png" alt="上限函数计算表" /></a><div class="caption">Figure 2:  上限函数计算表 [<a href="/assets/images/2014-12-19-machine-learning-theory-of-generalization-B(N,k).png">PNG</a>]</div></div></div>

<p>当$N\leq k$时$B(N,k)$的计算公式容易推导，当$N&gt;k$时$B(N,k)$的计算比较复杂，
\begin{equation}
B(N,k)=
\left\{
\begin{aligned}
&amp; 2^N &amp; N&lt;k \\
&amp; 2^N-1 &amp; N=k \\
&amp; \sum_{i=1}^{k-1}\binom{N}{i} &amp; N&gt;k
\end{aligned}
\right. 。
\end{equation}</p>

<h2 id="vc">VC界</h2>
<p>通过
\[
P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E_{out}(h)\right\rvert&gt;\epsilon\right]\leq 2m_{\mathcal H}(N)\exp\left(-2\epsilon^2N\right)
\]
证明VC界（Vapnik-Chervonenkis bound）
\begin{equation}
P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E_{out}(h)\right\rvert&gt;\epsilon\right]\leq 4m_{\mathcal H}(2N)\exp\left(-{1\over 8}\epsilon^2N\right)
\label{eq:vc-bound}
\end{equation}
分三步，对应着3个常数的变化。</p>

<h4 id="eineout">第一步：用$E’_{in}$替换$E_{out}$</h4>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-19-machine-learning-theory-of-generalization-Eout_Ein.png"><img src="/assets/images/2014-12-19-machine-learning-theory-of-generalization-Eout_Ein.png" alt="替换掉out-sample误差" /></a><div class="caption">Figure 3:  替换掉out-sample误差 [<a href="/assets/images/2014-12-19-machine-learning-theory-of-generalization-Eout_Ein.png">PNG</a>]</div></div></div>

<p>另抽取$N$个点的数据集$\mathcal D’ $计算$E’_{in}$来估计$E_{out}$的值，$E’_{in}$和$E_{in}$的取值如上图，以$E_{out}$为中心分布。${1\over 2}P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E_{out}(h)\right\rvert&gt;\epsilon\right]$对应着上图粉色区域的面积（取$1\over 2$是忽略对称的左半区域），在满足该条件下，上图淡绿区域对应着$P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E’_{in}(h)\right\rvert&gt;\epsilon\right]$，于是显然有</p>

<p>\[
\begin{aligned}
{1\over 2}P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E_{out}(h)\right\rvert&gt;\epsilon\right] 
\leq &amp; P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E’_{in}(h)\right\rvert&gt;\epsilon\right]  \\
\leq &amp; P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E’_{in}(h)\right\rvert&gt;{\epsilon\over 2}\right] 。
\end{aligned}
\]</p>

<h4 id="section-1">第二步：利用成长函数约束二分类情况的数量</h4>

<p>上一步将问题转化为只考虑$N$个点数据集$\mathcal D $和$N$个点数据集$\mathcal D’ $的问题，最多有$m_{\mathcal H}(2N)$种二分类情况，可进一步得到坏事儿发生概率的上界</p>

<p>\[
\begin{aligned}
P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E_{out}(h)\right\rvert&gt;\epsilon\right] 
\leq &amp; 2P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E’_{in}(h)\right\rvert&gt;{\epsilon\over 2}\right]  \\
\leq &amp; 2m_{\mathcal H}(2N)P\left[\mbox{fixed } h\mbox{ s.t. }\left\lvert E_{in}(h)-E’_{in}(h)\right\rvert&gt;{\epsilon\over 2}\right] 。
\end{aligned}
\]</p>

<h4 id="hoeffding-without-replacement">第三步：利用Hoeffding without Replacement约束</h4>

<p>易知$\left\lvert E_{in}(h)-E’_{in}(h)\right\rvert&gt;{\epsilon\over 2}$和$\left\lvert E_{in}(h)-\frac{E_{in}(h)+E’_{in}(h)}{2}\right\rvert&gt;{\epsilon\over 4}$等价，$\frac{E_{in}(h)+E’_{in}(h)}{2}$可以认为是out-sample数据的误差估计，所以直接利用Hoeffding可得</p>

<p>\[
\begin{aligned}
P\left[\exists h\in\mathcal H\mbox{ s.t. }\left\lvert E_{in}(h)-E_{out}(h)\right\rvert&gt;\epsilon\right] \leq &amp; 2m_{\mathcal H}(2N)P\left[\mbox{fixed } h\mbox{ s.t. }\left\lvert E_{in}(h)-E’_{in}(h)\right\rvert&gt;{\epsilon\over 2}\right] \\
= &amp; 2m_{\mathcal H}(2N)P\left[\mbox{fixed } h\mbox{ s.t. }\left\lvert E_{in}(h)-\frac{E_{in}(h)+E’_{in}(h)}{2}\right\rvert&gt;{\epsilon\over 4}\right] \\
\leq &amp; 2m_{\mathcal H}(2N)\cdot 2\exp\left(-2\left(\epsilon\over 4\right)^2N\right)\\
= &amp; 4m_{\mathcal H}(2N)\exp\left(-{1\over 8}\epsilon^2N\right)。
\end{aligned}
\]</p>

<h2 id="section-2">参考资料</h2>

<ol class="bibliography"><li><span id="lin_ml_tg_2014">[1]H.-T. Lin, “Lecture 6: Theory of Generalization.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li></ol>

<h3 id="section-3">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：训练与测试</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-training-versus-testing" />
      <pubdate>2014-12-18T04:32:08+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-training-versus-testing</guid>
      <content:encoded>&lt;![CDATA[<p>本节的主要内容来自Hsuan-Tien Lin的机器学习基石课程<a href="#lin_ml_tt_2014">[1]</a>。</p>

<p>学习的两个核心问题：</p>

<ol>
  <li>能确保$E_{out}(g)$接近$E_{in}(g)$么？</li>
  <li>能够使$E_{in}(g)$足够小么？</li>
</ol>

<p>$\lvert\mathcal H\rvert=M$与上述两个问题有什么关系？</p>

<p>太小的$M$使坏事儿发生的概率小，$E_{out}(g)$接近$E_{in}(g)$接近的概率大，但是不一定能找到很小的$E_{in}(g)$；太大的$M$使坏事儿发生的概率增大了。</p>

<h2 id="m">M的起源</h2>

<p>坏事情（$\mathcal B$AD Event）$\mathcal B_m~\left(\left\lvert E_{in}(h_m) - E_{out}(h_m)\right\rvert &gt; \epsilon\right)$发生的概率为</p>

<p>\begin{equation*}
\begin{aligned}
P(\mbox{BAD}) &amp; = P(\mathcal B_1 \mbox{ or }\mathcal B_2 \mbox{ or }\ldots\mathcal B_M) \\
&amp;\leq P(\mathcal B_1) + P(\mathcal B_2) + \ldots + P(\mathcal B_M)\\
&amp;\leq 2M\exp\left(-2\epsilon^2N\right)
\end{aligned}。
\end{equation*}</p>

<p>事实上，过高的估计了坏事情发生的概率上界，因为$\mathcal B_m$之间可能有很大的相似区域重叠，比如感知器算法两次的判别界很接近。因此，可以期望得到比$M$小得多的值约束这个概率上界，也就是$\mathcal H$中的元素个数不会太多。</p>

<h2 id="section">有效判别界</h2>

<p>在$H$中，对相似的假设（判别函数）进行分组合并，有效减少假设的数目$M$。以下两图通过2维平面的线性判别界为例说明判别函数的类别。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-1-2.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-1-2.png" alt="［左］：1个点的分类情况；［右］：2个点的分类情况" /></a><div class="caption">Figure 1:  ［左］：1个点的分类情况；［右］：2个点的分类情况 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-1-2.png">PNG</a>]</div></div></div>

<p>上图左可见，对于只有1个点的数据集，只有2种分类情况，$\mathcal H$只需2种假设就够了；上图右可见，对于2个点的数据集，有4种分类情况，$\mathcal H$只需4种假设就够了。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-3-4.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-3-4.png" alt="［左］：3个点的分类情况；［右］：4个点的部分分类情况" /></a><div class="caption">Figure 2:  ［左］：3个点的分类情况；［右］：4个点的部分分类情况 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-lines-3-4.png">PNG</a>]</div></div></div>

<p>上图中，打叉表示线性不可分。上图左可见，对于有3个点的数据集，有6种分类情况，$\mathcal H$只需6种假设就够了；上图右可见，对于4个点的数据集，有14种分类情况（图中只画出了其中一半的情况），$\mathcal H$只需14种假设就够了。</p>

<p>$N$输入数据$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$所需判别界的类别数目称之为判别界的有效数目（effective number of lines）。通过分析可知，$\mbox{effective}(N)\leq 2^N$，用其代替$M$可得
\begin{equation}
P\left[\left\lvert E_{in}(g) - E_{out}(g)\right\rvert &gt; \epsilon\right]\leq 2\cdot\mbox{effective}(N)\cdot\exp\left(-2\epsilon^2N\right)。
\end{equation}</p>

<h2 id="section-1">成长函数</h2>

<p>将$h(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)=(h(\mathbf x_1), h(\mathbf x_2), \ldots, h(\mathbf x_N))\in\{\times, \circ\}^N$称为一个二分法（dichotomy）。这就将假设限定在了数据集$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$上。$\mathcal H(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)$表示$\mathcal H$在$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$上的所有二分法。</p>

<p>$\lvert\mathcal H(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)\rvert$的大小受数据$\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N$的影响，不同的$N$个点，得到的值可能不一样。将成长函数（growth function）定义为
\begin{equation}
m_{\mathcal H}(N) = \max_{\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N\in\mathcal X}\lvert\mathcal H(\mathbf x_1, \mathbf x_2, \ldots, \mathbf x_N)\rvert，
\end{equation}
成长函数消除数据集依赖，是$N$个点数据集二分法数目的最大值，最大值为$2^N$。</p>

<p>对2维平面的线性判别界，$m_{\mathcal H}(1)=2$、$m_{\mathcal H}(2)=4$、$m_{\mathcal H}(3)=8$、$m_{\mathcal H}(4)=14$。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-growth-function-1D-lines.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-growth-function-1D-lines.png" alt="［左］：1维空间正射线判别函数；［右］：1维空间正区间判别函数" /></a><div class="caption">Figure 3:  ［左］：1维空间正射线判别函数；［右］：1维空间正区间判别函数 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-growth-function-1D-lines.png">PNG</a>]</div></div></div>

<p>上图左，对1维空间的正射线判别函数，$\mathcal X = \mathbb R$，$h(x)=\mbox{sign}(x-a)$（$a$是分类阈值），$m_{\mathcal H}(N)=N+1$。</p>

<p>上图右，对1维空间的正区间判别函数，$\mathcal X = \mathbb R$，
\[
h(x)=\left\{
\begin{aligned}
&amp;+1 &amp;x\in[\ell, r)\\
&amp;-1 &amp;\mbox{otherwise}
\end{aligned}
\right. ，
\]
$m_{\mathcal H}(N)=\binom{N+1}{2}+1={1\over 2}N^2+{1\over 2}N + 1$。</p>

<h2 id="section-2">断点</h2>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-shattered.png"><img src="/assets/images/2014-12-17-machine-learning-training-versus-testing-shattered.png" alt="假设集打碎输入数据" /></a><div class="caption">Figure 4:  假设集打碎输入数据 [<a href="/assets/images/2014-12-17-machine-learning-training-versus-testing-shattered.png">PNG</a>]</div></div></div>

<p>对于2维平面上的$N$个点，$\mathcal X\in \mathbb R^2$，若$\mathcal H$是凸包，那么如上图所示，$m_{\mathcal H}(N)=2^N$。</p>

<p>如果$N$个点的所有二分法都能被$\mathcal H$实现，就称这$N$个点被$\mathcal H$打碎（shatter）。也就是，若$m_{\mathcal H}(N)=2^N$，当且仅当$N$个点能被打碎。</p>

<p>如果不存在$k$个点能够被$\mathcal H$打碎，就称$k$是$\mathcal H$的一个断点（break point），也就是对任意$k$个点$m_{\mathcal H}(k) &lt; 2^k$<sup id="fnref:break-point-explain"><a href="#fn:break-point-explain" class="footnote">1</a></sup>。如果$k$是断点，那么$k,k+1,k+2,\ldots$都是断点，通常研究最小的断点$k$。</p>

<h2 id="section-3">成长函数与断点</h2>

<p>$m_{\mathcal H}(N)=O\left(N^{k-1}\right)$。</p>

<p>正射线和正区间判别函数的最小断点分别是$2$和$3$，2维感知器的最小断点是$4$，凸包没有断点<sup id="fnref:break-point-example"><a href="#fn:break-point-example" class="footnote">2</a></sup>。</p>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="lin_ml_tt_2014">[1]H.-T. Lin, “Lecture 5: Training versus Testing.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li></ol>

<h3 id="section-5">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:break-point-explain">
      <p>若数据集有$N$个点，断点是$k$（$N\geq k$），那么从$N$个点中任意抽取$k$个点，这$k$个点都不能被打碎。也就是说$N$个点的数据集中，不存在$k$个点的子集满足$m_{\mathcal H}(k)=2^k$。 <a href="#fnref:break-point-explain" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:break-point-example">
      <p>对于正射线当$m_{\mathcal H}(N)=N+1=2^N$时，有$N=1$，故断点为$1+1=2$，其它情况计算类似…… <a href="#fnref:break-point-example" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：学习的可行性</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-feasibility-of-learning" />
      <pubdate>2014-12-14T06:19:24+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-feasibility-of-learning</guid>
      <content:encoded>&lt;![CDATA[<p>本节的主要内容来自Hsuan-Tien Lin的机器学习基石课程<a href="#lin_ml_fl_2014">[1]</a>。</p>

<p>Learning is PAC-possible, if enough statistical data and finite $\left\lvert\mathcal H\right\rvert$.</p>

<h2 id="section">基本定义</h2>

<ul>
  <li>未知的目标函数 $f:\mathcal X \rightarrow\mathcal Y$；</li>
  <li>$\mathcal X$的分布$P$；</li>
  <li>训练集 $\mathcal D:\left(\mathbf x_1,y_1\right),\ldots,\left(\mathbf x_N,y_N\right)$；</li>
  <li>学习算法 $\mathcal A$；</li>
  <li>假设集 $\mathcal H$。</li>
</ul>

<p>机器学习的任务就是找到$f$的近似$g$，使得$g\approx f$。利用学习算法$\mathcal A$，通过数据集$\mathcal D$，从$\mathcal H$中找到合适的$h$，当$g=h$有$g\approx f$。</p>

<h2 id="hoeffding">Hoeffding不等式</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-bin-and-sample.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-bin-and-sample.png" alt="估计罐中橙色弹珠的概率" /></a><div class="caption">Figure 1:  估计罐中橙色弹珠的概率 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-bin-and-sample.png">PNG</a>]</div></div></div>

<p>能用从罐中抽样出橙色弹珠的比率$\nu$，作为罐中橙色弹珠出现概率$\mu$的估计么？Hoeffding不等式给出了答案，
\begin{equation}
P\left[\lvert\nu-\mu\rvert&gt;\epsilon\right]\leq 2\exp\left(-2\epsilon^2N\right)，
\end{equation}
当$N$很大时，$\nu$和$\mu$可能很接近（PAC，Probably Approximately Correct）。一个大的$N$和松散的$\epsilon$约束，使得$\nu\approx\mu$。</p>

<blockquote>
  <h4 id="section-1">问题</h4>
  <hr />
  <p>设$\mu=0.4$，若从罐中抽$10$个弹珠得到$\nu\leq 0.1$。利用Hoeffding不等式估计发生这样情况的概率界。</p>

  <p>答案：$0.33$（该概率的精确值是$0.05$）</p>

  <p>这个问题等价于：已知一次伯努利实验成功的概率为$0.4$，求$10$重伯努利实验中，最多出现一次成功的概率。
\begin{equation*}
\begin{aligned}
P(最多一次成功) = &amp;P(10次都不成功) + P(仅有1次成功）\\
    = &amp; 0.6^{10}+  \binom{10}{1} \times 0.4^1 \times 0.6^9\\
    = &amp;0.0464 \approx 0.05
\end{aligned}
\end{equation*}</p>
</blockquote>

<h2 id="section-2">概率与机器学习</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-connection2learning.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-connection2learning.png" alt="从概率到机器学习" /></a><div class="caption">Figure 2:  从概率到机器学习 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-connection2learning.png">PNG</a>]</div></div></div>

<p>如上图所示，将罐中的弹珠当作$\mathcal X$。对某个特定的假设$h$，若$h(\mathbf x)\neq f(\mathbf x)$则将弹珠涂为橙色，若$h(\mathbf x)= f(\mathbf x)$则将弹珠涂为绿色。将机器学习的可行性用概率问题进行判断。</p>

<p>对特定的$h$，抽样出来$N$个数据的in-sample误差定义为
\begin{equation}
E_{in}\left(h\right) = {1\over N}\sum_{n=1}^N\left[\left[h\left(x_n\right)\neq y_n\right]\right]，
\end{equation}
$\mathcal X$中数据的out-sample误差定义为
\begin{equation}
E_{out}\left(h\right) = \varepsilon_{\mathbf x\sim P}\left[\left[h\left(\mathbf x\right)\neq f\left(\mathbf x\right)\right]\right]，
\end{equation}
于是得到类似的Hoeffding不等式
\begin{equation}
P\left[\left\lvert E_{in}\left(h\right)-E_{out}\left(h\right)\right\rvert&gt;\epsilon\right]\leq 2\exp\left(-2\epsilon^2N\right)。
\end{equation}</p>

<p>由上式可知，对所有$N$和$\epsilon$而言，在不需要知道$E_{out}\left(h\right)$、$f$和$P$的前提下，$E_{in}\left(h\right)=E_{out}\left(h\right)$近似可能正确。也就是说，如果$E_{in}\left(h\right)\approx E_{out}\left(h\right)$并且$E_{in}\left(h\right)$很小，可以得出$E_{out}\left(h\right)$也很小，进而可以得出对于同样分布$P$的数据$h\approx f$。</p>

<p>如果令$g=h$，上述情况是否表明学习是可行的了呢？事实上，上述情况只是验证了某个特定的$h$，机器学习是要从$\mathcal H$中找出满足条件的$h$作为$g$，还没有$h$选择的过程。</p>

<h2 id="section-3">从概率到机器学习</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-many-hypothesis.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-many-hypothesis.png" alt="多个假设" /></a><div class="caption">Figure 3:  多个假设 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-probability-many-hypothesis.png">PNG</a>]</div></div></div>

<p>不好的数据集（BAD Data）是指，存在$h$使得该数据集上$E_{out}\left(h\right)$和$E_{in}\left(h\right)$差异很大。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-bad-data.png"><img src="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-bad-data.png" alt="不好的数据集" /></a><div class="caption">Figure 4:  不好的数据集 [<a href="/assets/images/2014-12-13-machine-learning-feasibility-of-learning-bad-data.png">PNG</a>]</div></div></div>

<p>上图中$\mathcal D_i$表示有$N$个数据点的数据集，<code>BAD</code>标注的是不好的数据集。每个$h_j$对应行上出现<code>BAD</code>的概率通过Hoeffding定理限定，对某个$h_j$，$E_{out}\left(h\right)$和$E_{in}\left(h\right)$差异很大的概率是受约束的。Hoeffding定理保证的是每行不会有太多的<code>BAD</code>。</p>

<p>如果某个数据集$\mathcal D_i$上，对至少一个$h_j$是不好的数据集，也就是上图中的列至少存在一个<code>BAD</code>，那么在该数据集上，不能通过算法$\mathcal A$自由的从假设$\mathcal H$中选择$h$，因为总存在$E_{out}\left(h\right)$和$E_{in}\left(h\right)$差异很大的情况。机器学习期望的是算法$\mathcal A$能在好的数据集（例如$\mathcal D_{1126}$）上自由的选择$h$。</p>

<p>根据上图可推算，选到不好数据集的概率
\begin{equation}
P_{\mathcal D}\left[\mbox{BAD } \mathcal D\right] \leq 2M\exp\left(-2\epsilon^2N\right)，
\end{equation}
由此可见，选到不好数据集的概率是受限的，也就是可能找到好数据集，使得可以利用它自由在假设$\mathcal H$中选择。</p>

<p>如果$\left\lvert\mathcal H\right\rvert=M$有限，并且$N$足够大，使得可以通过$\mathcal A$选择到$g$，选择$E_{in}\left(h_m\right)$最小的那个$h_m$作为$g$，使得$E_{out}\left(g\right)\approx E_{in}\left(g\right)$。如果$\mathcal A$找到一个$g$使得$E_{in}\left(g\right)\approx 0$，PAC保证了$E_{out}\left(g\right)\approx 0$，也就是说学习是可行的。</p>

<p>因此，学习的可行性通过以下两条保证：</p>

<ol>
  <li>可以通过$E_{in}\left(h\right)$估计$E_{out}\left(h\right)$；</li>
  <li>存在数据集$\mathcal D$，使得可以在$\mathcal H$中自由的选择$h$。</li>
</ol>

<p>满足这两条的前提条件是假设集$\mathcal H$中候选$h$的数目$M$有限且$\mathcal D$中数据点数量$N$足够大。</p>

<p>如果$M=\infty$，咋办？</p>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="lin_ml_fl_2014">[1]H.-T. Lin, “Lecture 4: Feasibility of Learning.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li></ol>

<h3 id="section-5">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：大数据上的机器学习</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-large-scale-machine-learning" />
      <pubdate>2014-12-10T19:51:50+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-large-scale-machine-learning</guid>
      <content:encoded>&lt;![CDATA[<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_lsml_2014">[1]</a>。</p>

<h2 id="section">需要大数据么？</h2>

<p>当机器学习面对大数据的时候，是否从大数据中抽取一个小的子集就可以了呢？这需要分析学习曲线，确定影响性能的关键问题是数据量、特征还是模型或其它问题。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-is-needed.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-is-needed.png" alt="学习曲线" /></a><div class="caption">Figure 1:  学习曲线 [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-is-needed.png">PNG</a>]</div></div></div>

<p>如果是上图左所示的High Variance情况，则采用大数据能提高模型效果。若从大数据中抽取$m=1000$个样本的训练，如上图右所示，这表明机器学习是High Bias，即使加入更多的数据对性能也没有大的提升，应先加入更多的新特征（若神经网络，则增加神经元），再考虑大数据上的训练是否有利。</p>

<p>如何减少学习时间提高学习效率，是大数据上的机器学习需要解决的重要问题。</p>

<h2 id="section-1">随机梯度下降法</h2>

<h3 id="section-2">随机梯度下降法</h3>

<p>对于梯度下降法，参数更新的方法是
\begin{equation}
\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^m\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}，
\end{equation}
这种方法叫做批量（batch）梯度下降法，参数更新需在整个训练集上计算一次，当$m$特别大的时候，速度就会很慢。随机梯度下降法（stochastic gradient descent）的更新方式是每次只用一个数据点更新参数。</p>

<blockquote>
  <h4 id="section-3">随机梯度下降法</h4>
  <hr />

  <ol>
    <li>数据集随机化；</li>
    <li>更新模型参数，  <br />
Repeat <sup id="fnref:sgd-cycle-times"><a href="#fn:sgd-cycle-times" class="footnote">1</a></sup> {  // 通常是$1\sim 10$轮迭。 <br />
 for $i := 1,\dots,m$ {
\begin{equation}
\theta_j := \theta_j - \alpha\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}~~(j=1,\ldots,n)
\end{equation}
 }  }。</li>
  </ol>

</blockquote>

<p>如下图所示，批量梯度下降法通常会向着极小值逼近，随机梯度下降法逼近道路稍显曲折，最总结果通常在极小值的某个区域内徘徊。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-illustration-gradient-descent.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-illustration-gradient-descent.png" alt="左：批量梯度下降法，右：随机梯度下降法" /></a><div class="caption">Figure 2:  左：批量梯度下降法，右：随机梯度下降法 [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-illustration-gradient-descent.png">PNG</a>]</div></div></div>

<h3 id="section-4">小批量梯度下降法</h3>

<p>随机梯度法每次更新参数只需要一个数据点，批量梯度法每次更新参数只需要整个训练集参数。小批量（mini-batch）梯度下降法间于二者之间，每次更新参数利用训练集的一个小子集的$b$个数据点（通常$b=2,\ldots,100$）。小批量梯度下降法的参数更新规则为
\begin{equation}
\theta_j := \theta_j - \frac{\alpha}{b}\sum_{i=k}^{k+b-1}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}，
\end{equation}
其中$k=1,b+1,2b+1,3b+1,\ldots$。</p>

<p>小批量梯度下降法可利用并行化，获得比随机梯度法更快的速度，但是又多了参数$b$需要调节。</p>

<h3 id="section-5">收敛性判断</h3>

<p>随机梯度下降法可利用代价函数曲线，判断迭代过程是否收敛。但是，随机梯度下降法不会像批量梯度下降法那样，在整个训练集上评估代价。</p>

<p>在利用$\left(\mathbf x^{(i)},y^{(i)}\right)$更新参数$\boldsymbol\theta_j$之前，计算该点的代价（误差）
\begin{equation}
\mbox{cost}\left(\boldsymbol\theta,\left(\mathbf x^{(i)},y^{(i)}\right)\right)= {1\over 2}\left(h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)-y^{(i)}\right)^2，
\end{equation}</p>

<p>可以通过代价函数的梯度检测，判断随机梯度法是否沿着梯度下降方向更新参数。</p>

<p>若是在参数更新之后再计算误差，不能真实反映迭代的误差。将最近多次（比如$1000$）迭代的误差平均，作为代价函数曲线上的一个点，下图就是随机梯度下降法的代价函数曲线。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-checking-for-convergence.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-checking-for-convergence.png" alt="代价函数曲线" /></a><div class="caption">Figure 3:  代价函数曲线 [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-checking-for-convergence.png">PNG</a>]</div></div></div>

<p>小的$\alpha$能否得到更好的结果呢？随机梯度下降法的性质表明其结果会在极小值附近区域震荡，很小的学习率$\alpha$可能得到的结果也只是好一点点而已。如上图左上所示，小的$\alpha$得到稍微光滑一点的曲线，但效果提升并不明显。</p>

<p>上图右下的代价函数曲线不降反升，是因为学习率$\alpha$过大，可以适当调小学习率。</p>

<p>选择最近多少个点平均作为代价函数曲线的点合适呢？</p>

<ul>
  <li>点的数目多，代价函数曲线更光滑，需要较长时间才展示参数更新结果，不能及时的反应参数更新的情况。上图右上所示，更多数目的点平均得到的曲线更光滑。</li>
  <li>点的数目少，代价函数曲线噪声更大。上图左下所示，过少数目的点导致曲线震荡厉害，看不到变化趋势；过多的点又导致曲线过于平坦，也看不到变化趋势。</li>
</ul>

<p>因此，选择点的数目需要综合考虑这些情况，便于观察判断迭代是否收敛。</p>

<p>为了随机梯度下降法能更好逼近极小值，可动态调整学习效率$\alpha=\frac{\mbox{constant1}}{\mbox{interationNumber + constant2}}$，学习过程中不断减小$\alpha$，越是靠近极小值的地方更新步长越短。但是，这又多出两个参数$\mbox{constant1}$和$\mbox{constant2}$需要调节了，该方法也不十分常用。</p>

<h2 id="section-6">在线学习</h2>

<p>在线学习通常不需要维护一个固定的训练集，思想上和随机梯度法类似，每次新数据来，学习更新模型，然后继续接收新数据，继续更新模型……在线学习适合用于数据集动态缓慢变化的情况，模型随可随数据变换动态演进。</p>

<p>对于购物网站来说，随着经济大环境的改变，用户对价格的敏感度也会变化，用户特性会随时变迁，在线学习及时通过新样本训练模型可适应这些变化。</p>

<p>预测CTR（click-through rate）是经典的在线学习例子。比如用户在网站搜索手机，返回用户最可能点击的10个结果。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-online-example.png"><img src="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-online-example.png" alt="预测CTR" /></a><div class="caption">Figure 4:  预测CTR [<a href="/assets/images/2014-12-10-machine-learning-large-scale-machine-learning-online-example.png">PNG</a>]</div></div></div>

<p>如何计算用户点击的概率呢？将搜索匹配的单词等作为特征向量，利用logistic回归可以估计用户点击概率。推荐系统的协同过滤算法学习到的特征向量，也可作为logistic的输入特征。</p>

<p>每次用户搜索可以得到对这10个搜索结果的反馈（是否点击了），从而得到10组数据，这些数据又可以用来训练模型。</p>

<h2 id="mapreduce">MapReduce</h2>

<p>MapReduce可将学习任务分配到多台机器上（或者一台机器的多个CPU核上），然后将这些机器的学习结果汇总得到整个学习结果。</p>

<blockquote>
  <h4 id="mapreduce-1">基于MapReduce的批量梯度学习算法</h4>
  <hr />
  <p>整个任务：$\theta_j := \theta_j - \alpha\frac{1}{400}\sum_{i=1}^{400}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$。</p>

  <p>分配任务：</p>

  <ul>
    <li>Machine 1: $temp_j^{(1)}=\sum_{i=1}^{100}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$；</li>
    <li>Machine 2: $temp_j^{(2)}=\sum_{i={101}}^{200}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$；</li>
    <li>Machine 3: $temp_j^{(3)}=\sum_{i={201}}^{300}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$；</li>
    <li>Machine 4: $temp_j^{(4)}=\sum_{i={301}}^{400}\left(h_\boldsymbol\theta\left(\mathbf x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}$。</li>
  </ul>

  <p>任务合并：$\theta_j := \theta_j - \alpha\frac{1}{400}\left(temp_j^{(1)}+temp_j^{(2)}+temp_j^{(3)}+temp_j^{(4)}\right)$。</p>
</blockquote>

<p>随机梯度下降法每次只采用一个数据点，是一个串行过程，因此不适合用Mapreduce这样的并行化方法。</p>

<h2 id="section-7">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_lsml_2014">[1]A. Ng, “Large scale machine learning.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-8">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:sgd-cycle-times">
      <p>对于大数据，通常一轮迭代（每个点参与一次）也能得到较好结果，通常进行$1\sim 10$轮迭代（这个还依赖于训练集的大小）。 <a href="#fnref:sgd-cycle-times" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>计算广告学：广告基础</title>
      <link href="http://qianjiye.de/2014/12/computational-advertising-foundation" />
      <pubdate>2014-12-09T09:02:19+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/computational-advertising-foundation</guid>
      <content:encoded>&lt;![CDATA[<p>本文的内容来自于刘鹏的网络课程《计算广告学》<a href="#liu_cad_foundations_2014">[1]</a>。</p>

<h2 id="tips">tips</h2>

<p>广告和推荐系统很相似。对广告而言，在同样位置文字链的点击率远远高于图片；对推荐而言，图片的点击率远远高于文字链。</p>

<h2 id="section">广告目的</h2>

<p>广告（advertising）是由已确定的出资人通过各种媒介进行的有关产品（商品、服务和观点）的，通常是有偿的、有组织的、综合的、劝服性的非人员的信息传播活动<a href="#arens_ad_2013">[2]</a>。</p>

<p>广告的三主体是出资人（sponsor）即广告主（advertiser）、媒介（medium）、受众（audience）<sup id="fnref:search-001"><a href="#fn:search-001" class="footnote">1</a></sup>，这是计算广告学中的三个基本变量。广告是一个三方博弈问题。</p>

<p>广告的本质功能是借助某种有广泛受众的媒介力量，完成较低成本的用户接触（不是向用户卖东西哦）。</p>

<p>品牌广告（brand awareness）：创造独特良好的品牌或产品形象，目的在于提升较长时期内的离线转化率。</p>

<p>效果广告（direct response）：有短期内明确用户转化行为诉求的广告，用户转化行为有购买、注册、投票、捐款等。</p>

<h2 id="section-1">广告的有效性模型</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-09-computational-advertising-effect-model.png"><img src="/assets/images/2014-12-09-computational-advertising-effect-model.png" alt="广告的有效性模型" /></a><div class="caption">Figure 1:  广告的有效性模型 [<a href="/assets/images/2014-12-09-computational-advertising-effect-model.png">PNG</a>]</div></div></div>

<p>曝光阶段，广告位对广告的曝光率和点击率有决定性作用，这种资源优势不是通过算法改进可以获得的。</p>

<p>关注阶段，可以通过技术手段提高用户关注度。不要打断用户而言，比如ad系统通过上下文推荐；对揭示推荐原因而言，比如租车行的广告根据用户所在地理更换背景图片。</p>

<p>信息接受阶段，广告位影响着广告的认可度，比如大的品牌广告主要确保自己的广告投放到影响力大和没有负面影响的媒介，还要关注竞争对手的广告投放情况。</p>

<p>评价在线广告的两个基本指标：点击率和转化率。一般而言，越靠前的阶段对点击率影响越大，越靠后的阶段对转化率影响越大。</p>

<p>下图展示了一些广告策略的效果，＋表示正面作用，－表示负面作用。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-09-computational-advertising-improve-ad-performance.png"><img src="/assets/images/2014-12-09-computational-advertising-improve-ad-performance.png" alt="一些广告策略的效果" /></a><div class="caption">Figure 2:  一些广告策略的效果 [<a href="/assets/images/2014-12-09-computational-advertising-improve-ad-performance.png">PNG</a>]</div></div></div>

<h2 id="section-2">广告与营销的区别</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-09-computational-advertising-ad-vs-sale.png"><img src="/assets/images/2014-12-09-computational-advertising-ad-vs-sale.png" alt="广告与营销的区别" /></a><div class="caption">Figure 3:  广告与营销的区别 [<a href="/assets/images/2014-12-09-computational-advertising-ad-vs-sale.png">PNG</a>]</div></div></div>

<p>就效果广告（direct response）而言，从硬广到返利网，效果越来越好<sup id="fnref:problem-001"><a href="#fn:problem-001" class="footnote">2</a></sup>。当然，各种形式的广告之间有相互作用，配合使用可提升效果。</p>

<h2 id="section-3">参考文献</h2>

<ol class="bibliography"><li><span id="liu_cad_foundations_2014">[1]刘鹏, “广告的基本知识.” 云课堂, 2014.</span>

[<a href="http://study.163.com/c/ad">Online</a>]

</li>
<li><span id="arens_ad_2013">[2]威廉·阿伦斯, <i>当代广告学</i>. 人民邮电出版社, 2013.</span>

</li></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:search-001">
      <p>搜索有两个主体，用户和搜索引擎。 <a href="#fnref:search-001" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:problem-001">
      <p>如何理解把你的客户卖给你，把竞争对手的客户买给你？ <a href="#fnref:problem-001" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：推荐系统</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-recommender-systems" />
      <pubdate>2014-12-09T07:20:25+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-recommender-systems</guid>
      <content:encoded>&lt;![CDATA[<p>推荐系统首先通过分析用户的使用历史获得用户的兴趣偏向，然后使用得到的用户兴趣偏向获得用户潜在感兴趣的产品或服务。鉴于产生推荐的方式不同，推荐系统通常可以分为以下三类<a href="#wu_thesis_bju_2010">[1]</a>：基于内容的过滤（content-based filtering）、协同过滤（collaborative filtering）和CBF与CF的混合过滤（hybrid filtering）。</p>

<p>以电影的推荐系统为例，相关变量定义如下<a href="#ng_ml_rs_2014">[2]</a>：</p>

<ul>
  <li>$n_u$：用户数目；</li>
  <li>$n_m$：电影数目；</li>
  <li>$r(i, j)$：若用户$j$对电影$i$进行了评分则赋值为1；</li>
  <li>$y^{(i, j)}$：用户$j$对电影$i$的评分；</li>
  <li>$\boldsymbol\theta^{(j)}$：用户$j$的参数向量；</li>
  <li>$\mathbf x^{(i)}$：电影$i$的特征向量；</li>
  <li>$m^{(j)}$：用户$j$评价过的电影数目。</li>
</ul>

<h2 id="section">基于内容的过滤</h2>

<p>基于内容的过滤（CBF）方法根据抽取出的用户和产品特征获得推荐。这类方法利用用户和产品的特征计算他们之间的匹配度，最终把匹配得最好的数个产品推荐给相应的用户。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-recommender-systems-recommender-data.png"><img src="/assets/images/2014-12-08-machine-learning-recommender-systems-recommender-data.png" alt="用户对电影的评价" /></a><div class="caption">Figure 1:  用户对电影的评价 [<a href="/assets/images/2014-12-08-machine-learning-recommender-systems-recommender-data.png">PNG</a>]</div></div></div>

<p>上图展示了用户对电影的评分$0\sim 5$，用属于爱情片（romance）和动作片（action）的概率表示电影特征。用户评分<code>?</code>表示用户$j$未对电影$i$作出评价，也就是$r(i, j)=0$。</p>

<p>如何估计用户未评价电影的得分呢？这时一个线性回归问题。利用电影特征向量$\mathbf x^{(i)}$和参数$\boldsymbol\theta^{(j)}$，可估计用户$j$对电影$i$的评分
\begin{equation}
y^{(i, j)} = \left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)}。
\label{eq:user-rating}
\end{equation}</p>

<p>因此，基于内容的的推荐需要学习参数$\boldsymbol\theta^{(1)},\boldsymbol\theta^{(2)},\dots,\boldsymbol\theta^{(n_u)}$。假设已知$\mathbf x^{(1)}, \mathbf x^{(2)}, \ldots, \mathbf x^{(n_m)}$，学习算法采用代价函数
\begin{equation}
\begin{aligned}
J\left(\boldsymbol\theta^{(1)},\dots,\boldsymbol\theta^{(n_u)}\right) = &amp;{1\over 2}\sum_{j=1}^{n_u}\sum_{i:r(i, j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)^2 + \\
&amp;{\lambda\over 2}\sum_{j=1}^{n_u}\sum_{k=1}^n\left(\theta_k^{(j)}\right)^2，
\end{aligned}
\label{eq:cf-learn-user-parameters}
\end{equation}
由于电影评分的总数目是固定的，省去平均化过程对最小化代价函数没有影响，只保留$1\over 2$方便求导，梯度下降法更新参数的规则为
\begin{equation}
\begin{aligned}
\theta_k^{(j)}&amp;:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)x_k^{(i)} &amp; (k=0)\\
\theta_k^{(j)}&amp;:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)x_k^{(i)}+\lambda\theta_k^{(j)}\right)&amp;(k\neq 0)
\end{aligned}。
\end{equation}</p>

<p>CBF就是把某用户评价高的电影推荐给该用户。为了实现推荐，需要计算用户对所有电影的评分，计算复杂度高。</p>

<p>CBF方法具有两个主要的缺陷：</p>

<ol>
  <li>CBF需要预处理产品以得到代表它们的特征，但这种预处理在实际问题中往往非常困难；</li>
  <li>CBF推荐给某个用户的产品往往和此用户已经消费过的产品很相似，它们无法发现用户并不熟悉但具有潜在兴趣的产品种类。 </li>
</ol>

<h2 id="section-1">协同过滤</h2>

<p>协同过滤（CF）方法不需要事先获得产品或用户的特征，它们只依赖于用户过去的行为（如对产品的浏览、评价或购买等）。 通过用户过去的行为企业可以收集用户对产品的显式评分（如Netflix）或隐式评分（如Google新闻）。通常 CF方法首先分析已经收集到的用户-产品评分对中所呈现的用户与产品的相互作用，然后它们使用这些相互作用为用户产生个性化产品推荐。</p>

<p>CF通常分为基于产品的（item-based）推荐和基于用户的（user-based）推荐。基于用户的推荐假设如果两个用户过去对产品有相似的喜好，那么他们现在对产品仍有相似的喜好；基于产品的推荐假设如果某个用户过去喜欢某种产品，那么该用户现在仍喜欢与此产品相似的产品。 </p>

<p>在实际应用中，电影的特征向量往往也是未知的，需要通过学习得到。协同过滤不仅可以学习到用户对电影的评价，而且能学习到电影的特征。</p>

<p>电影特征向量学习与用户评价模型参数估计\eqref{eq:cf-learn-user-parameters}类似，假设已知$\boldsymbol\theta^{(1)},\boldsymbol\theta^{(2)},\dots,\boldsymbol\theta^{(n_u)}$，学习$\mathbf x^{(1)}, \mathbf x^{(2)}, \ldots, \mathbf x^{(n_m)}$采用的代价函数为
\begin{equation}
\begin{aligned}
J\left(\mathbf x^{(1)}, \ldots, \mathbf x^{(n_m)}\right) = &amp;{1\over 2}\sum_{i=1}^{n_m}\sum_{i: r(i, j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} -  y^{(i, j)}\right)^2 + \\
&amp;{\lambda\over 2}\sum_{i=1}^{n_m}\sum_{k=1}^n\left(x_k^{(i)}\right)^2
\end{aligned}。
\label{eq:cf-learn-item-features}
\end{equation}</p>

<p>根据\eqref{eq:cf-learn-user-parameters}和\eqref{eq:cf-learn-item-features}，同时学习$\mathbf x^{(1)}, \mathbf x^{(2)}, \ldots, \mathbf x^{(n_m)}$和$\boldsymbol\theta^{(1)},\boldsymbol\theta^{(2)},\dots,\boldsymbol\theta^{(n_u)}$可以采用代价函数
\begin{equation}
\begin{aligned}
J\left(\mathbf x^{(1)},\ldots,\mathbf x^{(n_m)},\boldsymbol\theta^{(1)},\dots,\boldsymbol\theta^{(n_u)}\right) = &amp;{1\over 2}\sum_{(i,j): r(i, j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)^2 + \\
&amp;{\lambda\over 2}\sum_{i=1}^{n_m}\sum_{k=1}^n\left(x_k^{(i)}\right)^2+{\lambda\over 2}\sum_{j=1}^{n_u}\sum_{k=1}^n\left(\theta_k^{(j)}\right)^2
\end{aligned}，
\label{eq:cf-learn-all-parameters}
\end{equation}
梯度下降法更新参数的规则为
\begin{equation}
\begin{aligned}
x_k^{(i)}&amp;:=x_k^{(i)}-\alpha\left(\sum_{j:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)\theta_k^{(j)}+\lambda x_k^{(i)}\right)\\
\theta_k^{(j)}&amp;:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}\left(\left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)} - y^{(i, j)}\right)x_k^{(i)}+\lambda\theta_k^{(j)}\right)
\end{aligned}，
\label{eq:grd-x-theta}
\end{equation}
由于电影的特征$\mathbf x$也通过学习得到，不再需要额外增加$x_0^{(i)}=1$的项。</p>

<blockquote>
  <h4 id="section-2">协同过滤算法</h4>
  <hr />

  <ol>
    <li>用小的随机变量初始化$\mathbf x^{(1)},\ldots,\mathbf x^{(n_m)},\boldsymbol\theta^{(1)},\dots,\boldsymbol\theta^{(n_u)}$<sup id="fnref:how-item-feature-demension"><a href="#fn:how-item-feature-demension" class="footnote">1</a></sup>；</li>
    <li>最小化代价函数\eqref{eq:cf-learn-all-parameters}，若采用梯度下降法，采用\eqref{eq:grd-x-theta}更新参数；</li>
    <li>学习到参数后，利用\eqref{eq:user-rating}计算用户$j$对电影$i$的评分。</li>
  </ol>
</blockquote>

<p>协同过滤算法是一个不断进化的过程，$\mathbf x^{(i)}$和$\boldsymbol\theta^{(j)}$相互作用，$\mathbf x^{(i)}$推动$\boldsymbol\theta^{(j)}$更新，$\boldsymbol\theta^{(j)}$也推动$\mathbf x^{(i)}$更新。</p>

<p>当学习到电影的特征向量$\mathbf x^{(i)}$后，可以用$\left\lVert \mathbf x^{(i_1)}-\mathbf x^{(i_2)}\right\rVert$计算电影之间的相似度。通过电影的相似度，为用户推荐相关的电影，这就是基于物品的推荐方法。</p>

<p>CF方法存在的主要问题：</p>

<ol>
  <li>冷启动：对于一个新用户，由于缺乏其对产品的评分，CF无法为其提供可靠的 产品推荐；对于一种新的产品，CF无法确定该把它推荐给哪些用户。</li>
  <li>可扩展性：CF方法中可能涉及到数以百万计的用户为成千上万种产品提供的评分。传统的CF推荐算法通常需要计算每对用户或产品之间的相似度，然后把这些相似度存放至电脑的主存中以便高效地产生推荐。当用户或产品的数量较大时，计算复杂度很高。 </li>
</ol>

<h3 id="section-3">均值规范化</h3>

<p>针对新用户的冷启动，该用户$j$从未对任何电影做出评价，协同过滤算法会得到用户的参数向量$\boldsymbol\theta^{(j)}=\mathbf 0$，如果估计该用户对电影的评分，也将全为$0$，这显然不符合逻辑。因此，需要对数据进行适当的处理，避免这样的情况发生。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-recommender-systems-mean-normalization.png"><img src="/assets/images/2014-12-08-machine-learning-recommender-systems-mean-normalization.png" alt="均值规范化" /></a><div class="caption">Figure 2:  均值规范化 [<a href="/assets/images/2014-12-08-machine-learning-recommender-systems-mean-normalization.png">PNG</a>]</div></div></div>

<p>定义用户对所有电影评价的均值为$\boldsymbol\mu$，重新对用户对电影的评分规范化
\begin{equation}
 y^{(i,j)} := y^{(i,j)} - \mu_i。
\end{equation}
规范化评分后，公式\eqref{eq:user-rating}计算用户$j$对电影$i$的评分规则变为
\begin{equation}
y^{(i, j)} = \left(\boldsymbol\theta^{(j)}\right)^T\mathbf x^{(i)}+\mu_i，
\end{equation}
即使参数向量$\boldsymbol\theta^{(j)}=\mathbf 0$，估计新用户对电影的评分将是所有用户的平均分，合情合理。</p>

<h3 id="section-4">思考问题</h3>

<ul>
  <li>如果系统已经有了部分标注的特征$\mathbf x$，如何融入到协同过滤算法中？</li>
  <li>如何利用协同过滤提高广告点击率？</li>
  <li>协同过滤的特征学习方法可以做传感器校准么？</li>
  <li>协同过滤和广联规则挖掘有何联系？</li>
  <li>协同过滤的特征学习可以解决盲源信号分离么？</li>
</ul>

<h2 id="section-5">混合过滤</h2>

<p>混合过滤(HF)组合CBF和CF，以期在克服它们各自缺点的同时，融合它们特有的优势。通常组合的方式包括以下三种：</p>

<ol>
  <li>加权（weighted）组合：首先分别独立应用CBF和CF获得对产品的预测评分，然后组合它们的预测评分以便获得混合过滤的预测评分，最后根据混合预测评分为用户产生推荐列表。</li>
  <li>混合（mixed）组合：首先分别独立应用CBF和CF产生各自的推荐列表，然后组合这两组推荐列表以便获得最终的推荐列表。</li>
  <li>序贯（sequential）组合：当可用评分较少时使用CBF方法获得用户的特征并进行推荐；而当可用评分积聚到一定程度时，使用CF方法代替原来的CBF方法获得最终的推荐列表。 </li>
</ol>

<h2 id="section-6">参考资料</h2>

<ol class="bibliography"><li><span id="wu_thesis_bju_2010">[1]吴金龙, “Netflix Prize 中的协同过滤算法,” PhD thesis, 北京大学, 2010.</span>

</li>
<li><span id="ng_ml_rs_2014">[2]A. Ng, “Recommender Systems.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-7">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:how-item-feature-demension">
      <p>如何确定电影的特征多少维合适呢？ <a href="#fnref:how-item-feature-demension" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：异常检测</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-anomaly-detection" />
      <pubdate>2014-12-08T10:29:01+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-anomaly-detection</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">简介</h2>

<p>异常检测的基本思想：若发生了小概率事件，就认为出现了异常。</p>

<p>常用的异常检测方法是利用高斯密度函数，计算数据出现的概率，如果发现了概率小于某个阈值的数据，就认为该数据是异常的。</p>

<p>异常检测也是一种模式二分类方法，但两类数据严重不平衡，异常数据要显著少于正常数据。异常检测通常只需要对正常数据进行建模。</p>

<h2 id="section-1">基于高斯（正态）分布的异常检测</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_ad_2014">[1]</a>。</p>

<p>根据异常检测的思想，若$\mathbf x$出现的概率$p(\mathbf x) &lt; \varepsilon$，则认为$\mathbf x$是异常点。因此，异常检测的重要内容是估计概率密度函数。</p>

<h3 id="section-2">一元高斯分布</h3>

<p>基于一元高斯分布的异常检测的前提条件是假设特征之间相互独立。</p>

<p>通常假设特征分量的数据集$X$满足均值为$\mu$，方差为$\sigma^2$的正态分布，
\begin{equation}
X\sim\mathcal{N}\left(\mu, \sigma^2\right)，
\end{equation}
因此有
\begin{equation}
p(x;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)，
\end{equation}
这需要估计均值$\mu$和方差$\sigma^2$，它们的极大似然估计为
\begin{equation}
\begin{aligned}
\mu = &amp; {1\over m}\sum_{i=1}^{m}x^{(i)}\\
\sigma^2 = &amp; {1\over m}\sum_{i=1}^{m}\left(x^{(i)}-\mu\right)^2
\end{aligned}。
\label{eq:likehood-mu-sigma}
\end{equation}</p>

<p>得到了概率密度函数，就容易利用概率判断异常。</p>

<h4 id="section-3">一、异常检测</h4>

<blockquote>
  <h4 id="section-4">异常检测算法</h4>
  <hr />

  <ol>
    <li>选择能指示异常的特征$\mathbf x_j$；</li>
    <li>利用公式\eqref{eq:likehood-mu-sigma}，估计每维特征的均值和方差$\mu_1,\ldots,\mu_n,\sigma_1^2,\ldots,\sigma_n^2$；</li>
    <li>计算$\mathbf x$的概率，
\begin{equation}
p(\mathbf x) = \prod_{j=1}^n p\left(x_j;\mu_j,\sigma_j^2\right)，
\end{equation}
通过特征分量概率密度函数乘积计算$\mathbf x$概率密度，需满足特征之间相互独立的假设；</li>
    <li>若$p(\mathbf x) &lt; \varepsilon$，则$\mathbf x$为异常点。</li>
  </ol>
</blockquote>

<p>异常检测的训练过程就是估计概率密度函数参数$\boldsymbol\mu$和$\boldsymbol\sigma^2$。通常情况，训练过程不需要异常数据。$60\%$的正常数据作为训练集，$20\%$的正常数据和$50\%$的异常数据作为交叉检验集，$20\%$的正常数据和$50\%$的异常数据作为测试集。</p>

<p>通过交叉检验集可确定判定异常的阈值$\varepsilon$，选择参数可利用<a href="/2014/11/machine-learning-advice-for-applying-machine-learning/#performance-evaluation">分类器性能评价指标</a>。</p>

<p>异常检测和监督学习存在不同的特点，应用在不同的场景：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">异常检测</th>
      <th style="text-align: left">监督学习</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">正样本（异常数据，$y=1$）少，通常$0\sim 20$个正样本，负样本（正常数据，$y=0$）多；</td>
      <td style="text-align: left">正样本和负样本都较多；</td>
    </tr>
    <tr>
      <td style="text-align: left">可能存多种不同类型的异常数据，难以通过正样本学习；</td>
      <td style="text-align: left">大量的正样本数据，能通过训练集了解正样本特点；</td>
    </tr>
    <tr>
      <td style="text-align: left">应用领域：欺诈检测、故障诊断、数据中心设备监控等</td>
      <td style="text-align: left">应用领域：垃圾邮件分类、天气预测、癌症分类等。</td>
    </tr>
  </tbody>
</table>

<h4 id="feature-transform">二、特征变换</h4>

<p>根据异常检测方法可知，运用异常检测有两个重要的前提条件：</p>

<ol>
  <li>特征满足高斯分布（特征之间的相关性下节考虑）；</li>
  <li>$p(\mathbf x)$对正常数据很大，但对异常数据很小。</li>
</ol>

<p>在实际应用中，原始特征可能并不满足这两个前提条件，需要将特征作一定变换或构造新的特征。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-nongaussain-features.png"><img src="/assets/images/2014-12-08-machine-learning-anomaly-detection-nongaussain-features.png" alt="原始特征通过变换满足高斯分布" /></a><div class="caption">Figure 1:  原始特征通过变换满足高斯分布 [<a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-nongaussain-features.png">PNG</a>]</div></div></div>

<p>上图展示了通过函数$\log x$变换原始特征以满足高斯分布。也可以通过构造新的特征，比如数据中心监控，利用特征$\mbox{CPU load}$和$\mbox{network traffic}$构造新的特征$\frac{\mbox{CPU load}}{\mbox{network traffic}}$<sup id="fnref:why-create-new-feature"><a href="#fn:why-create-new-feature" class="footnote">1</a></sup>，使其在发生异常的时数据会变得很大或者很小。</p>

<h3 id="multi-gaussian-anormaly-detection">多元高斯分布</h3>

<p>实际应用中，特征之间可能存在相关性，需要采用多元高斯分布概率密度函数进行异常检测。</p>

<p>多元高斯分布的概率密度函数定义为</p>

<p>\begin{equation}
p(\mathbf x; \boldsymbol\mu, \Sigma)=\frac{1}{(2\pi)^{n\over 2}\lvert\Sigma\rvert^{1\over 2}}\exp\left(-{1\over 2}(\mathbf x - \boldsymbol\mu)^T\Sigma^{-1}(\mathbf x - \boldsymbol\mu)\right)，
\label{eq:multi-gaussians-pdf}
\end{equation}</p>

<p>其均值向量和协方差矩阵的极大似然估计为</p>

<p>\begin{equation}
\begin{aligned}
\boldsymbol\mu = &amp; {1\over m}\sum_{i=1}^{m}\mathbf x^{(i)}\\
\Sigma = &amp; {1\over m}\sum_{i=1}^{m}\left(\mathbf x^{(i)}-\boldsymbol\mu\right)\left(\mathbf x^{(i)}-\boldsymbol\mu\right)^T
\end{aligned}。
\end{equation}</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-multi-gaussians.png"><img src="/assets/images/2014-12-08-machine-learning-anomaly-detection-multi-gaussians.png" alt="二元高斯分布" /></a><div class="caption">Figure 2:  二元高斯分布 [<a href="/assets/images/2014-12-08-machine-learning-anomaly-detection-multi-gaussians.png">PNG</a>]</div></div></div>

<p>上图给出了不同参数的二元高斯密度函数图。图上排的协方差矩阵为对角阵，表示特征之间独立，可用一元高斯分布的方法进行异常检测；图下排的协方差矩阵是非对角阵，表示特征之间存在相关性，需借助多元高斯分布密度函数\eqref{eq:multi-gaussians-pdf}进行异常检测。</p>

<p>基于一元高斯分布和多元高斯分布的异常检测有不同的应用场景：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">一元高斯分布</th>
      <th style="text-align: left">多元高斯分布</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">根据先验知识<a href="#feature-transform">构造新特征</a>，手动处理相关性问题；</td>
      <td style="text-align: left">自动处理样本之间的相关性，计算$\Sigma$<sup id="fnref:multi-gaussian-feature-transform"><a href="#fn:multi-gaussian-feature-transform" class="footnote">2</a></sup>；</td>
    </tr>
    <tr>
      <td style="text-align: left">计算复杂度较低；</td>
      <td style="text-align: left">计算复杂度较高；</td>
    </tr>
    <tr>
      <td style="text-align: left">能处理样本数$m$很少的情况。</td>
      <td style="text-align: left">需要$m&gt;n$（一般$m&gt;10n$），否则$\Sigma$不可逆。</td>
    </tr>
  </tbody>
</table>

<p>若$\Sigma$不可逆，原因可能是不满足条件$m&gt;n$，或者存在冗余特征，也就是特征之间有相关性（比如$\mathbf x_1=k\mathbf x_2$或$\mathbf x_1=\mathbf x_2 ＋ \mathbf x_3$等）。</p>

<p>由此可见，特征之间是否具有相关性并非利用多元还是一元高斯分布进行异常检测的唯一条件，在必要的时候需要借助一元高斯分布对具有相关性特征的数据集进行异常检测。</p>

<p>具有相关性的特征数据，经过基于PCA的坐标变换（参考维数约减部分关于PCA的内容）消除相关性，也可以用一元高斯分布的方法处理。</p>

<h2 id="section-5">参考文献</h2>

<ol class="bibliography"><li><span id="ng_ml_ad_2014">[1]A. Ng, “Anomaly detection.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-6">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:why-create-new-feature">
      <p>如何判断构造的新特征有价值？哪些特征加入会有助于提高性能？ <a href="#fnref:why-create-new-feature" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:multi-gaussian-feature-transform">
      <p>利用多元高斯分布也要将每维特征变换为高斯分布么？ <a href="#fnref:multi-gaussian-feature-transform" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：维数约减</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-dimensionality-reduction" />
      <pubdate>2014-12-08T04:53:42+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-dimensionality-reduction</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">简介</h2>

<p>维数约减的作用通常是为了数据压缩和可视化。数据压缩不仅可以节省存储空间，而且可以加速机器学习算法。高维数据需要约减到3维或2维空间，以便观测其特性。 </p>

<h2 id="pca">主成分分析（PCA）</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_dr_2014">[1]</a>。</p>

<p>维数约减最常用的方法是主成分分析（PCA，Principal Component Analysis）。PCA可以理解为在高维空间中寻找一个低维的面，使得高维空间中的点到该面上的距离之和最小，这个距离也叫投影误差。</p>

<p>利用PCA将维数从$n$维约减到$k$维，需要寻找$n$维空间中的$k$个向量$\mathbf u^{(1)}, \mathbf u^{(2)},\ldots,\mathbf u^{(k)}\in\mathbb R^n$，使空间中的点到这$k$个向量确定的面的投影误差最小。事实上，$n$维空间中的这$k$个向量是样本协方差矩阵最大的$k$个特征值对应的特征向量。</p>

<blockquote>
  <h4 id="pca-1">PCA维数约减算法</h4>
  <hr />

  <ol>
    <li>数据作均值为$0$的规范化（mean normalization），确保每维均值为$0$，若取值范围差异过大，还需尺度规范化（feature scaling）：$x_j^{(i)}:=\frac{x_j^{(i)}-\mu_j}{ \sigma_j}$（$\mu_j$表示均值，$\sigma_j$表示标准差）；</li>
    <li>计算协方差矩阵（covariance matrix）：$\Sigma = \frac{1}{m}\sum_{i=1}^m\mathbf x^{(i)}\left(\mathbf x^{(i)}\right)^T$；</li>
    <li>利用特征向量将$n$维向量$\mathbf x$映射到$k$维向量$\mathbf z$：
\begin{equation}
\mathbf z^{(i)} = \mathbf U_{reduce}^T\mathbf x^{(i)}。
\label{eq:pca-mapping}
\end{equation}</li>
  </ol>

  <div class="highlight"><pre><code class="language-matlab"><span class="p">[</span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span><span class="p">]</span> <span class="p">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">Sigma</span><span class="p">);</span>
<span class="n">Ureduce</span> <span class="p">=</span> <span class="n">U</span><span class="p">(:,</span> <span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">);</span>
<span class="n">z</span> <span class="p">=</span> <span class="n">Ureduce</span>’ <span class="o">*</span> <span class="n">x</span><span class="p">;</span></code></pre></div>
  <p>在应用中，只需要在训练集上做PCA，交叉检验和测试集上可以直接应用训练集的均值$\boldsymbol\mu$、标准差$\mathbf s$和映射矩阵$U_{reduce}$计算约减后的向量。</p>
</blockquote>

<p>Matlab中<code>svd</code>和<code>eig</code>函数都可以得到相同的特征值和特征向量，但是<code>svd</code>更稳定。</p>

<p>从$k$维数据$\mathbf z$重构$n$维数据$\mathbf x$的方法为</p>

<p>\begin{equation}
\mathbf x_{approx}^{(i)} = \mathbf U_{reduce}\mathbf z^{(i)}。
\label{eq:pca-reconstruction}
\end{equation}</p>

<p>约减后的维数$k$（主成分个数）通过方差保留的比率确定，选择满足下列条件的最小$k$</p>

<p>\begin{equation*}
\frac{\frac{1}{m}\sum_{i=1}^m\left\lVert\mathbf x^{(i)}-\mathbf x_{approx}^{(i)}\right\rVert^2}{\frac{1}{m}\sum_{i=1}^m\left\lVert\mathbf x^{(i)}\right\rVert^2}\leq 0.01，
\end{equation*}</p>

<p>此时方差保存比率为$99\%$。但是该方法计算复杂，可以通过特征值更简单的计算，选择满足下列条件的最小$k$</p>

<p>\begin{equation}
\frac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}}\geq 0.99，
\end{equation}</p>

<p>$S_{ii}$是SVD得到的特征值。</p>

<blockquote>
  <h4 id="pca-2">谨慎使用PCA</h4>
  <hr />

  <ol>
    <li>PCA不是解决过拟合的好方法，正则化是更好的策略（PCA或多或少损失了有助于分类的信息）；</li>
    <li>不得滥用PCA，除非有证据表明PCA的价值，比如在有训练时间和存储空间的限制的时候。</li>
  </ol>

</blockquote>

<h3 id="pca-3">理解PCA</h3>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-mapping.svg"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-mapping.svg" alt="［左］规范化的数据；［中］PCA坐标变换；［右］PCA降维" /></a><div class="caption">Figure 1:  ［左］规范化的数据；［中］PCA坐标变换；［右］PCA降维 [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-mapping.svg">SVG</a>]</div></div></div>

<h4 id="pca-4">一、PCA是一种坐标变换方法</h4>

<p>如果PCA变换之后的维数$k = n$，也就是没有降维，没有任何信息损失，这相当于坐标变换。上图左，经过规范化处理后的数据；上图中，利用公式\eqref{eq:pca-mapping}的PCA坐标变换，$k=n$，大概相当于左边的数据顺时针旋转$45$度再绕$Y$轴镜像；上图右，红色的点是经过$k=1$的降维处理后，再利用公式\eqref{eq:pca-reconstruction}重构回的数据。</p>

<p>协方差矩阵的特征向量，相当于新坐标系的基，原始数据到基上的投影就是新坐标系中的坐标。从这个角度理解降维，就相当于新坐标系中，只用前$k$维的坐标表示一个点，上图右重构回来的数据就会只在新坐标系的某个坐标轴上。</p>

<p>经过基于PCA的坐标变换之后，消除了特征之间的相关性，协方差矩阵是对角阵。如果对于<a href="/2014/12/machine-learning-anomaly-detection/#multi-gaussian-anormaly-detection">基于多元高斯分布的异常检测</a>，经过基于PCA的坐标变换之后，用一维高斯分布的方法就可处理。</p>

<h4 id="pca-5">二、PCA是一种特征提取方法</h4>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-eigen-faces.png"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-eigen-faces.png" alt="特征脸" /></a><div class="caption">Figure 2:  特征脸 [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-eigen-faces.png">PNG</a>]</div></div></div>

<p>协方差矩阵的特征向量可以看作是特征空间，在这个空间中投影，可视为特征提取。上图展示了人脸数据集协方差矩阵的前$36$维特征向量，如果人脸在这个特种空间中投影，相当于利用这$36$张特征脸的线性组合来表示人脸。向左上角靠近的特征脸，表现的是人脸的主要信息；向右下角靠近的特征脸，表现的是人脸的细节信息<sup id="fnref:thinking-pca-for-classfication"><a href="#fn:thinking-pca-for-classfication" class="footnote">1</a></sup>。</p>

<p>用少量特征维表示人脸，可认为是人脸的一种稀疏表示。这是一种目的很明确的表示方法，将对象特征从主要到次要，根据需要依次表示出来。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-reconstruct-faces.png"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-reconstruct-faces.png" alt="［左］原图；［右］PCA降维后重构的人脸" /></a><div class="caption">Figure 3:  ［左］原图；［右］PCA降维后重构的人脸 [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-pca-reconstruct-faces.png">PNG</a>]</div></div></div>

<h4 id="pca-6">三、其它角度理解PCA</h4>

<ul>
  <li>傅立叶变换、小波变换、PCA特征向量空间的变换、稀疏表示……</li>
  <li>特征学习：神经网络权值、PCA特征向量空间、深度学习……</li>
</ul>

<h2 id="kpca">KPCA</h2>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-kpca.png"><img src="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-kpca.png" alt="Kernel PCA" /></a><div class="caption">Figure 4:  Kernel PCA [<a href="/assets/images/2014-12-07-machine-learning-dimensionality-reduction-kpca.png">PNG</a>]</div></div></div>

<p><a href="http://zhanxw.com/blog/2011/02/kernel-pca-原理和演示/">Kernel PCA 原理和演示</a></p>

<h2 id="section-1">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_dr_2014">[1]A. Ng, “Dimensionality Reduction.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-2">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:thinking-pca-for-classfication">
      <p>对于识别（分类）问题，采用主要特征（大特征值对应特征向量的投影）好呢还是次要特征？对于类间识别，比如人脸和猫脸分类，采用主要特征；对于同类的子类识别，比如区别张山李仕，更多靠的是细节信息，采用次要特征可能跟好。 <a href="#fnref:thinking-pca-for-classfication" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习：聚类</title>
      <link href="http://qianjiye.de/2014/12/machine-learning-clustering" />
      <pubdate>2014-12-08T02:38:59+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/12/machine-learning-clustering</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">聚类简介</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-12-07-machine-learning-clustering-plot_cluster_comparison_1.png"><img src="/assets/images/2014-12-07-machine-learning-clustering-plot_cluster_comparison_1.png" alt="几种聚类方法的比较" /></a><div class="caption">Figure 1:  几种聚类方法的比较 [<a href="/assets/images/2014-12-07-machine-learning-clustering-plot_cluster_comparison_1.png">PNG</a>]</div></div></div>

<p>聚类是一种非监督学习方法。上图是scikit-learn中几种聚类方法的比较<a href="#scikit-learn">[1]</a>。</p>

<h2 id="k-means">$k$-means聚类</h2>

<p>本节的主要内容来自Andrew NG的机器学习课程<a href="#ng_ml_c_2014">[2]</a>。</p>

<p>$k$-means算法主要包含两步：为样本分配类标签以及修改类中心。</p>

<blockquote>
  <h4 id="k-means-1">$k$-means算法</h4>
  <hr />
  <p>随机初始化$K$个类中心$\boldsymbol\mu_1,\boldsymbol\mu_2,\ldots,\boldsymbol\mu_K\in\mathbb R^n$。 <br />
重复 {</p>

  <ol>
    <li>for $i=1$ to $m$：将$\mathbf x^{(i)}$的类别标签$c^{(i)}$设为最靠近的类中心标签，$c^{(i)}=\arg\min_{k=1}^K\left\lVert\mathbf x^{(i)}-\boldsymbol\mu_k\right\rVert^2$；</li>
    <li>for $k=1$ to $K$：重新计算类中心$\boldsymbol\mu_k$。</li>
  </ol>

  <p>}</p>
</blockquote>

<p>$k$-means聚类的代价函数为</p>

<p>\begin{equation}
J\left(c^{(1)},\dots,c^{(m)},\boldsymbol\mu_1,\ldots,\boldsymbol\mu_K\right)=\frac{1}{m}\sum_{i=1}^m\left\lVert\mathbf x^{(i)}-\boldsymbol\mu_{c^{(i)}}\right\rVert^2，
\label{eq:cf-k-means}
\end{equation}</p>

<p>该代价函数通常也称为distortion function。</p>

<p>从代价函数可以看出，$k$-means算法的第1步是通过修改类标签$c^{(i)}$最小化代价函数，第2步是通过修改类中心$\boldsymbol\mu_k$最小化代价函数。</p>

<p>从$k$-means算法可知，初始化类中心$\boldsymbol\mu_k$和确定类别数$k$影响着算法的性能。</p>

<h3 id="boldsymbolmuk">初始化类中心$\boldsymbol\mu_k$</h3>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-k-means-local-minimum.png"><img src="/assets/images/2014-11-27-machine-learning-k-means-local-minimum.png" alt="不恰当的类中心初始化导致局部极值" /></a><div class="caption">Figure 2:  不恰当的类中心初始化导致局部极值 [<a href="/assets/images/2014-11-27-machine-learning-k-means-local-minimum.png">PNG</a>]</div></div></div>

<p>随机初始化类中心的方法通常是，随机从样本中选取$K$个点作为类中心。为了避免陷入局部极致，通常会进行多轮初始化，选择代价函数值最小的作为聚类结果。</p>

<blockquote>
  <h4 id="k-means-2">随机初始化选择$k$-means的类中心</h4>
  <hr />
  <p>For i = 1 to 100 {</p>

  <ol>
    <li>随机初始化类中心$\boldsymbol\mu_k$；</li>
    <li>$k$-means算法得到$c^{(1)},\dots,c^{(m)},\boldsymbol\mu_1,\ldots,\boldsymbol\mu_K$；</li>
    <li>计算代价函数\eqref{eq:cf-k-means}。</li>
  </ol>

  <p>}  <br />
选择代价函数值最小的聚类结果输出。</p>
</blockquote>

<p>当$K=2,\ldots,10$时，这种方法的代价函数变化明显，当$K$很大（$K&gt;100$）时，代价函数可能没有明显的变化。</p>

<h3 id="k">确定类别数$K$</h3>

<p>通过不停增大类别数$K$，选择代价函数曲线拐点对应的类别数，如下图左所示。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2014-11-27-machine-learning-k-means-elbow-method.png"><img src="/assets/images/2014-11-27-machine-learning-k-means-elbow-method.png" alt="确定类别数的elbow method" /></a><div class="caption">Figure 3:  确定类别数的elbow method [<a href="/assets/images/2014-11-27-machine-learning-k-means-elbow-method.png">PNG</a>]</div></div></div>

<p>有时，代价函数曲线不存在拐点，如上图右所示。还可以根据$k$-means应用的具体场景，选择聚类数目，比如要制作XS、S、M、L、XL几种规格的服装，当然用类别数$K=5$来划分人的身高体重。</p>

<h2 id="section-1">参考文献</h2>

<ol class="bibliography"><li><span id="scikit-learn">[1]F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine Learning in Python,” <i>Journal of Machine Learning Research</i>, vol. 12, pp. 2825–2830, 2011.</span>

</li>
<li><span id="ng_ml_c_2014">[2]A. Ng, “Clustering.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-2">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
