<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2015-03-05T14:45:26+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>图像分类（3）：最优化</title>
      <link href="http://qianjiye.de/2015/02/image-classification-optimization" />
      <pubdate>2015-02-13T22:53:50+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/image-classification-optimization</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">理解损失函数</h2>

<p>图像分类的两个关键步骤包括：（1）通过<strong>评分函数</strong>将图像映射到类别评分；（2）通过<strong>损失函数</strong>度量评分。多分类支持向量机采用的是线性评分函数$f\left(\mathbf x_i,\mathbf W\right)=\mathbf W\mathbf x_i$，需要最小化的损失函数为
\[
L={1\over N}\sum_i\sum_{j\neq y_i}
\max\left(
0, f\left(\mathbf x_i,\mathbf W\right)_j-f\left(\mathbf x_i,\mathbf W\right)_{y_i}+1
\right)
+\alpha R(\mathbf W)。
\]</p>

<p>图像分类的第三个关键步骤：（3）通过最优化求解最小化损失函数的参数$\mathbf W$。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-13-image-classification-optimization-loss-function-landscape.jpg"><img src="/assets/images/2015-02-13-image-classification-optimization-loss-function-landscape.jpg" alt="损失函数图" /></a><div class="caption">图 1:  损失函数图 [<a href="/assets/images/2015-02-13-image-classification-optimization-loss-function-landscape.jpg">JPG</a>]</div></div></div>

<p>将$\mathbf W$视为空间中的一个点，损失函数（不含正则化项）可以用上图表示。$\mathbf W$、$\mathbf W_1$和$\mathbf W_2$是随机产生的矩阵。上图左表示损失函数$L(\mathbf W+a\mathbf W_1)$，横轴为$a$，纵轴为$L$；上图中和右表示损失函数$L(\mathbf W+a\mathbf W_1+b\mathbf W_2)$，横轴和纵轴分别为$a$和$b$，越红损失$L$越大，越蓝损失$L$越小。上图左和中，只计算一张图片的损失；上图右的碗状图是100张图片损失的平均值，相当于100张上图中的平均图。</p>

<p>每张图$i$的损失为（不含正则化项）
\[
L_i=\sum_{j\neq y_i}\max\left(
0, \mathbf w_j^\top\mathbf x_i-\mathbf w_{y_i}^\top\mathbf x_i+1
\right)，
\]
它是分段线性（piecewise-linear）函数。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-13-image-classification-optimization-1d-loss.png"><img src="/assets/images/2015-02-13-image-classification-optimization-1d-loss.png" alt="1维损失函数" /></a><div class="caption">图 2:  1维损失函数 [<a href="/assets/images/2015-02-13-image-classification-optimization-1d-loss.png">PNG</a>]</div></div></div>

<p>三张图片$\mathbf x_0$、$\mathbf x_1$和$\mathbf x_2$分别属于类0、1和2，它们的损失计算如下
\[
\begin{aligned}
L_0 &amp;= \max\left(0, \mathbf w_1^\top\mathbf x_0-\mathbf w_{0}^\top\mathbf x_0+1\right)+
\max\left(0, \mathbf w_2^\top\mathbf x_0-\mathbf w_{0}^\top\mathbf x_0+1\right)\\
L_1 &amp;= \max\left(0, \mathbf w_0^\top\mathbf x_1-\mathbf w_{1}^\top\mathbf x_1+1\right)+
\max\left(0, \mathbf w_2^\top\mathbf x_1-\mathbf w_{1}^\top\mathbf x_1+1\right)\\
L_2 &amp;= \max\left(0, \mathbf w_0^\top\mathbf x_2-\mathbf w_{2}^\top\mathbf x_2+1\right)+
\max\left(0, \mathbf w_1^\top\mathbf x_2-\mathbf w_{2}^\top\mathbf x_2+1\right)\\
L &amp;= {1\over 3}\left(L_0+L_1+L_2\right)，
\end{aligned}
\]
如上图所示，横轴表示权值，纵轴表示损失。</p>

<p>多分类SVM的代价函数是凸函数的一个范例，当采用神经网络的评分函数$f$时，代价函数就是非凸的。损失函数不可微分（non-differentiable），因此梯度未定义，通常使用次梯度（subgradient）代替梯度。本文不区分梯度和次梯度。</p>

<p>损失函数可以评估任意权值$\mathbf W$，最优化的目标是找出最小化损失函数的权值$\mathbf W$。神经网络的优化不能方便地使用凸函数的优化工具。</p>

<h2 id="section-1">随机方法</h2>

<h3 id="section-2">随机搜索</h3>

<p>比较糟糕的优化策略是随机搜索（random search）。由于验证参数$\mathbf W$比较简单，随机搜索通过尝试不同的随机权值$\mathbf W$，从中选择最优的。</p>

<div class="highlight"><pre><code class="language-python"><span class="n">bestloss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">&quot;inf&quot;</span><span class="p">)</span> <span class="c"># Python assigns the highest possible float value</span>
<span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3073</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.0001</span> <span class="c"># generate random parameters</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="c"># get the loss over the entire training set</span>
  <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">bestloss</span><span class="p">:</span> <span class="c"># keep track of the best solution</span>
    <span class="n">bestloss</span> <span class="o">=</span> <span class="n">loss</span>
    <span class="n">bestW</span> <span class="o">=</span> <span class="n">W</span>
  <span class="k">print</span> <span class="s">&#39;in attempt </span><span class="si">%d</span><span class="s"> the loss was </span><span class="si">%f</span><span class="s">, best </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">bestloss</span><span class="p">)</span></code></pre></div>

<p>在CIFAR-10数据集上，经过1000次尝试，随机搜索可以做到约15.5%的精度，优于随机猜想的10%。找到最优的$\mathbf W$很困难甚至不可行，但是找到更好一些的$\mathbf W$就不难么困难了。基于这个思路，优化算法可以从随机的$\mathbf W$开始，不断更新权值，使得每次更新都提升一点性能。随机搜索如同徒步者带上眼罩向山脚走。针对CIFAR-10数据集，这山有30730维，山上的每一点都相当于特定的损失值。</p>

<h3 id="section-3">随机局部搜索</h3>

<p>从随机初始化的$\mathbf W$开始，若增加扰动$\delta\mathbf W$，损失在$\mathbf W+\delta\mathbf W$比在$\mathbf W$时更低，那么更新$\mathbf W\leftarrow\mathbf W+\delta\mathbf W$。</p>

<div class="highlight"><pre><code class="language-python"><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3073</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span> <span class="c"># generate random starting W</span>
<span class="n">bestloss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">&quot;inf&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.0001</span>
  <span class="n">Wtry</span> <span class="o">=</span> <span class="n">W</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3073</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_size</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">Xtr_cols</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Wtry</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">bestloss</span><span class="p">:</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">Wtry</span>
    <span class="n">bestloss</span> <span class="o">=</span> <span class="n">loss</span>
  <span class="k">print</span> <span class="s">&#39;iter </span><span class="si">%d</span><span class="s"> loss is </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">bestloss</span><span class="p">)</span></code></pre></div>

<p>在CIFAR-10数据集上，经过1000次尝试，精度提高到了21.4%。但这仍然是低效耗时的算法。</p>

<h2 id="section-4">梯度下降法</h2>

<p>随机搜索对寻找最佳的权值改变方向没有帮助。沿着最佳的方向改变权值，在数学上可以保证损失最速下降（steepest descend）。这个方向和梯度（gradient）相关。</p>

<p>一维函数的斜率（slope）是函数值在某点的瞬时（instantaneous）变化率。梯度是斜率在多维空间函数的推广，它是每维斜率构成的向量，通常也称为导数（derivative）。一维函数的导数为
\[
{df(x)\over dx}=\lim_{h\rightarrow 0}{f(x+h)-f(x)\over h}，
\]
将其推广到多变量函数时称为偏导数（partial derivative）。梯度就是每一维偏导数组成的向量，有两种计算方法：</p>

<ul>
  <li>数值梯度（numerical gradient）：近似计算，较慢，但容易；</li>
  <li>解析梯度（analytic gradient）：计算快，但是容易出错（error-prone）。</li>
</ul>

<h3 id="section-5">数值梯度</h3>

<p>梯度的数值计算方法如下：</p>

<div class="highlight"><pre><code class="language-python"><span class="k">def</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">  a naive implementation of numerical gradient of f at x </span>
<span class="sd">  - f should be a function that takes a single argument</span>
<span class="sd">  - x is the point (numpy array) to evaluate the gradient at</span>
<span class="sd">  &quot;&quot;&quot;</span> 

  <span class="n">fx</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c"># evaluate function value at original point</span>
  <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">h</span> <span class="o">=</span> <span class="mf">0.00001</span>

  <span class="c"># iterate over all indexes in x</span>
  <span class="n">it</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nditer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;multi_index&#39;</span><span class="p">],</span> <span class="n">op_flags</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;readwrite&#39;</span><span class="p">])</span>
  <span class="k">while</span> <span class="ow">not</span> <span class="n">it</span><span class="o">.</span><span class="n">finished</span><span class="p">:</span>

    <span class="c"># evaluate function at x+h</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">it</span><span class="o">.</span><span class="n">multi_index</span>
    <span class="n">old_value</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
    <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_value</span> <span class="o">+</span> <span class="n">h</span> <span class="c"># increment by h</span>
    <span class="n">fxh</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c"># evalute f(x + h)</span>
    <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_value</span> <span class="c"># restore to previous value (very important!)</span>

    <span class="c"># compute the partial derivative</span>
    <span class="n">grad</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fxh</span> <span class="o">-</span> <span class="n">fx</span><span class="p">)</span> <span class="o">/</span> <span class="n">h</span> <span class="c"># the slope</span>
    <span class="n">it</span><span class="o">.</span><span class="n">iternext</span><span class="p">()</span> <span class="c"># step to next dimension</span>

  <span class="k">return</span> <span class="n">grad</span></code></pre></div>
<p>上述代码计算损失函数在$\mathbf x$每个维度的偏导数。在实际应用中通常使用中心差分公式（centered difference formula）
\[
{df(x)\over dx}=\lim_{h\rightarrow 0}{f(x+h)-f(x-h)\over 2h}。
\]</p>

<p>梯度只表明了最快增长的方向，还需要在这个方向前进的步长（也就是学习率）。步长是神经网络需要设定的重要超参数。</p>

<div class="highlight"><pre><code class="language-python"><span class="c"># to use the generic code above we want a function that takes a single argument</span>
<span class="c"># (the weights in our case) so we close over X_train and Y_train</span>
<span class="k">def</span> <span class="nf">CIFAR10_loss_fun</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">L</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3073</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span> <span class="c"># random weight vector</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">eval_numerical_gradient</span><span class="p">(</span><span class="n">CIFAR10_loss_fun</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="c"># get the gradient</span>

<span class="n">loss_original</span> <span class="o">=</span> <span class="n">CIFAR10_loss_fun</span><span class="p">(</span><span class="n">W</span><span class="p">)</span> <span class="c"># the original loss</span>
<span class="k">print</span> <span class="s">&#39;original loss: </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">loss_original</span><span class="p">,</span> <span class="p">)</span>

<span class="c"># lets see the effect of multiple step sizes</span>
<span class="k">for</span> <span class="n">step_size_log</span> <span class="ow">in</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">9</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
  <span class="n">step_size</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">step_size_log</span>
  <span class="n">W_new</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">df</span> <span class="c"># new position in the weight space</span>
  <span class="n">loss_new</span> <span class="o">=</span> <span class="n">CIFAR10_loss_fun</span><span class="p">(</span><span class="n">W_new</span><span class="p">)</span>
  <span class="k">print</span> <span class="s">&#39;for step size </span><span class="si">%f</span><span class="s"> new loss: </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">step_size</span><span class="p">,</span> <span class="n">loss_new</span><span class="p">)</span>

<span class="c"># prints:</span>
<span class="c"># original loss: 2.200718</span>
<span class="c"># for step size 1.000000e-10 new loss: 2.200652</span>
<span class="c"># for step size 1.000000e-09 new loss: 2.200057</span>
<span class="c"># for step size 1.000000e-08 new loss: 2.194116</span>
<span class="c"># for step size 1.000000e-07 new loss: 2.135493</span>
<span class="c"># for step size 1.000000e-06 new loss: 1.647802</span>
<span class="c"># for step size 1.000000e-05 new loss: 2.844355</span>
<span class="c"># for step size 1.000000e-04 new loss: 25.558142</span>
<span class="c"># for step size 1.000000e-03 new loss: 254.086573</span>
<span class="c"># for step size 1.000000e-02 new loss: 2539.370888</span>
<span class="c"># for step size 1.000000e-01 new loss: 25392.214036</span></code></pre></div>
<p>上述代码中，<code>step_size</code>表示步长（学习率），步长小损失函数减小慢，但步长太大损失函数不降反增。当损失函数有30730个参数时，每次更新参数需要计算30731次损失函数，计算复杂度非常高。</p>

<h3 id="section-6">解析梯度</h3>

<p>数值梯度虽简单但耗时，解析梯度计算高效但易错。在实际应用中，采用解析梯度时，通过比较它与数值梯度确定梯度计算是否正确，这称为<strong>梯度校验</strong>（gradient check）。</p>

<p>对每个数据，多分类SVM的损失函数为</p>

<p>\[
L_i=\sum_{j\neq y_i}\max\left(
0, \mathbf w_j^\top\mathbf x_i-\mathbf w_{y_i}^\top\mathbf x_i+\Delta
\right)，
\]</p>

<p>对$\mathbf w_{y_i}$求偏导（梯度）</p>

<p>\[
\nabla_{\mathbf w_{y_i}}L_i=
-\left(\sum_{j\neq y_i}\left[\left[\mathbf w_j^\top\mathbf x_i-\mathbf w_{y_i}^\top\mathbf x_i+\Delta&gt;0
\right]\right]\right)\mathbf x_i，
\]</p>

<p>对$\mathbf w_{j}$求偏导（梯度）</p>

<p>\[
\nabla_{\mathbf w_{j}}L_i=
\left[\left[\mathbf w_j^\top\mathbf x_i-\mathbf w_{y_i}^\top\mathbf x_i+\Delta&gt;0
\right]\right]\mathbf x_i。
\]</p>

<p>利用梯度更新参数的方法称为<strong>梯度下降法</strong>（gradient descent），通常的形式：</p>

<div class="highlight"><pre><code class="language-python"><span class="c"># Vanilla Gradient Descent</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
  <span class="n">weights_grad</span> <span class="o">=</span> <span class="n">evaluate_gradient</span><span class="p">(</span><span class="n">loss_fun</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
  <span class="n">weights</span> <span class="o">+=</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">weights_grad</span> <span class="c"># perform parameter update</span></code></pre></div>

<p>梯度下降法是到目前为止最常用的优化神经网络损失函数的方法。</p>

<p>对大数据集上的应用，在整个数据集上计算损失函数的梯度非常耗时，通常从中抽取从中抽取一部分数据计算梯度，这称为mini-batch梯度下降法，例如采用256个样本计算梯度：</p>

<div class="highlight"><pre><code class="language-python"><span class="c"># Vanilla Minibatch Gradient Descent</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
  <span class="n">data_batch</span> <span class="o">=</span> <span class="n">sample_training_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span> <span class="c"># sample 256 examples</span>
  <span class="n">weights_grad</span> <span class="o">=</span> <span class="n">evaluate_gradient</span><span class="p">(</span><span class="n">loss_fun</span><span class="p">,</span> <span class="n">data_batch</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
  <span class="n">weights</span> <span class="o">+=</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">weights_grad</span> <span class="c"># perform parameter update</span></code></pre></div>

<p>在实际中，采用mini-batch的方法能提高参数更新频率，更快收敛。若mini-batch梯度下降法只采用一个样本，称为随机梯度下降法（SGD，stochastic gradient descent）或在线（on-line）梯度下降法。但这不太常用，在实际中由于向量化代码的优化，计算100个样本的梯度比1个样本的梯度计算100次高效。虽然人们使用SGD这个称谓，实际通常指的是mini-batch的梯度下降法（MGD／BGD，minbatch/batch gradient descent）。min-batch的样本数量虽是超参数，但很少采用验证法确定，通常根据内存大小来决定，或者直接设定为100左右的值。</p>

<h2 id="bp">BP梯度</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-13-image-classification-optimization-circuit2.png"><img src="/assets/images/2015-02-13-image-classification-optimization-circuit2.png" alt="BP梯度计算" /></a><div class="caption">图 3:  BP梯度计算 [<a href="/assets/images/2015-02-13-image-classification-optimization-circuit2.png">PNG</a>]</div></div></div>

<p>对函数$f(x,y,z)=(x+y)z$，令$q=x+y$，那么根据链式法则（chain rule）有${\partial f\over \partial x}={\partial f\over \partial q}{\partial q\over \partial x}$。梯度${\partial f\over \partial x}$从右到左反向计算如上图“电路”所示，通过相邻节点的局部梯度链式相乘得到，每个节点用门（gate）表示。当${\partial f\over \partial q}=-4$和${\partial q\over \partial x}=1$时，${\partial f\over \partial x}=-4\times 1 = -4$。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-13-image-classification-optimization-circuit3.png"><img src="/assets/images/2015-02-13-image-classification-optimization-circuit3.png" alt="BP梯度计算" /></a><div class="caption">图 4:  BP梯度计算 [<a href="/assets/images/2015-02-13-image-classification-optimization-circuit3.png">PNG</a>]</div></div></div>

<p>当
$
f(\mathbf w,\mathbf x)={1\over 1 + e^{-\left(w_0x_0+w_1x_1+w_2\right)}}
$
时，链式计算如上如所示。链式法则的依据是复合函数的求导法则。门可以是任何可导函数（differentiable function），通常选择导数容易计算的函数作为门，如sigmoid函数$\sigma(x)={1\over 1 + e^{-x}}$。将${df\over dx}$简记为<code>dx</code>，${d\sigma(x)\over dx}=(1-\sigma(x))\sigma(x)$，上图的计算过程简化如下：</p>

<div class="highlight"><pre><code class="language-python"><span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="c"># assume some random weights and data</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>

<span class="c"># forward pass</span>
<span class="n">dot</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">f</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dot</span><span class="p">))</span> <span class="c"># sigmoid function</span>

<span class="c"># backward pass through the neuron (backpropagation)</span>
<span class="n">ddot</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">*</span> <span class="n">f</span> <span class="c"># gradient on dot variable, using the sigmoid gradient derivation</span>
<span class="n">dx</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">ddot</span><span class="p">,</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">ddot</span><span class="p">]</span> <span class="c"># backprop into x</span>
<span class="n">dw</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">ddot</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">ddot</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">ddot</span><span class="p">]</span> <span class="c"># backprop into w</span>
<span class="c"># we&#39;re done! we have the gradients on the inputs to the circuit</span></code></pre></div>

<p>对于复杂的函数，一次求导很复杂，如果采用链式法则，可以降低计算复杂度。对函数
\[
f(x,y)={x+\sigma(y)\over\sigma(x)+(x+y)^2}，
\]
前向计算如下：</p>

<div class="highlight"><pre><code class="language-python"><span class="n">x</span> <span class="o">=</span> <span class="mi">3</span> <span class="c"># example values</span>
<span class="n">y</span> <span class="o">=</span> <span class="o">-</span><span class="mi">4</span>

<span class="c"># forward pass</span>
<span class="n">sigy</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="p">))</span> <span class="c"># sigmoid in numerator   #(1)</span>
<span class="n">num</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">sigy</span> <span class="c"># numerator                               #(2)</span>
<span class="n">sigx</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span> <span class="c"># sigmoid in denominator #(3)</span>
<span class="n">xpy</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>                                              <span class="c">#(4)</span>
<span class="n">xpysqr</span> <span class="o">=</span> <span class="n">xpy</span><span class="o">**</span><span class="mi">2</span>                                          <span class="c">#(5)</span>
<span class="n">den</span> <span class="o">=</span> <span class="n">sigx</span> <span class="o">+</span> <span class="n">xpysqr</span> <span class="c"># denominator                        #(6)</span>
<span class="n">invden</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">den</span>                                       <span class="c">#(7)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">num</span> <span class="o">*</span> <span class="n">invden</span> <span class="c"># done!                                 #(8)</span></code></pre></div>

<p>反向梯度计算如下：</p>

<div class="highlight"><pre><code class="language-python"><span class="c"># backprop f = num * invden</span>
<span class="n">dnum</span> <span class="o">=</span> <span class="n">invden</span> <span class="c"># gradient on numerator                             #(8)</span>
<span class="n">dinvden</span> <span class="o">=</span> <span class="n">num</span>                                                     <span class="c">#(8)</span>
<span class="c"># backprop invden = 1.0 / den </span>
<span class="n">dden</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">den</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">dinvden</span>                                <span class="c">#(7)</span>
<span class="c"># backprop den = sigx + xpysqr</span>
<span class="n">dsigx</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dden</span>                                                <span class="c">#(6)</span>
<span class="n">dxpysqr</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dden</span>                                              <span class="c">#(6)</span>
<span class="c"># backprop xpysqr = xpy**2</span>
<span class="n">dxpy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">xpy</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpysqr</span>                                        <span class="c">#(5)</span>
<span class="c"># backprop xpy = x + y</span>
<span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpy</span>                                                   <span class="c">#(4)</span>
<span class="n">dy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dxpy</span>                                                   <span class="c">#(4)</span>
<span class="c"># backprop sigx = 1.0 / (1 + math.exp(-x))</span>
<span class="n">dx</span> <span class="o">+=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigx</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigx</span><span class="p">)</span> <span class="o">*</span> <span class="n">dsigx</span> <span class="c"># Notice += !! See notes below  #(3)</span>
<span class="c"># backprop num = x + sigy</span>
<span class="n">dx</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dnum</span>                                                  <span class="c">#(2)</span>
<span class="n">dsigy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dnum</span>                                                <span class="c">#(2)</span>
<span class="c"># backprop sigy = 1.0 / (1 + math.exp(-y))</span>
<span class="n">dy</span> <span class="o">+=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigy</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigy</span><span class="p">)</span> <span class="o">*</span> <span class="n">dsigy</span>                                 <span class="c">#(1)</span>
<span class="c"># done! phew</span></code></pre></div>

<h4 id="section-7">注意事项：</h4>

<ol>
  <li>将前向计算结果缓存起来，供后向计算使用，如<code>xpy</code>；</li>
  <li>当变量的导数分成几部分计算时，结果要加起来，采用<code>+=</code>。</li>
</ol>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-02-13-image-classification-optimization-circuit4.png"><img src="/assets/images/2015-02-13-image-classification-optimization-circuit4.png" alt="BP梯度计算" /></a><div class="caption">图 5:  BP梯度计算 [<a href="/assets/images/2015-02-13-image-classification-optimization-circuit4.png">PNG</a>]</div></div></div>

<p>神经网络中常使用的三种门是$+,\times,\max$，计算法则如上图。</p>

<p>对于线性分类器$\mathbf w^\top\mathbf x_i$，采用乘法门，输入数据的大小会影响权值梯度。输入数据对梯度影响很大，因此数据预处理能极大影响梯度。如果输入数据增大1000倍，权值的梯度也会增大1000倍，此时可以降低学习率补偿数据的影响。</p>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>特征学习模型总结</title>
      <link href="http://qianjiye.de/2015/02/summary-of-extraction-models" />
      <pubdate>2015-02-13T17:48:53+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/summary-of-extraction-models</guid>
      <content:encoded>&lt;![CDATA[<p>特征学习／提取模型（extraction model）：除了得到最终的线性模型外，将特征变换$\Phi$作为隐含的学习变量。</p>

<p>特征学习模型是拥有众多成员的大家族：</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>隐藏变量</th>
      <th>线性模型</th>
      <th>extraction技术</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>神经网络／深度学习</td>
      <td>$w_{ij}^{(\ell)}$</td>
      <td>$w_{ij}^{(L)}$</td>
      <td>梯度下降法＋BP<br />自编码器（非监督学习）</td>
    </tr>
    <tr>
      <td>RBF网络</td>
      <td>中心$\boldsymbol\mu_m$</td>
      <td>$\beta_m$</td>
      <td>k均值聚类（非监督学习）</td>
    </tr>
    <tr>
      <td>矩阵分解<sup id="fnref:v-equals-w"><a href="#fn:v-equals-w" class="footnote">1</a></sup></td>
      <td>用户特征$\mathbf v_n$</td>
      <td>电影特征$\mathbf w_m$</td>
      <td>梯度下降法<br />交替最小二乘法</td>
    </tr>
    <tr>
      <td>Ada/Gradient Boosting</td>
      <td>假设$g_t$</td>
      <td>投票权重$\alpha_t$</td>
      <td>函数梯度下降法</td>
    </tr>
    <tr>
      <td>k最近邻算法</td>
      <td>邻居$\mathbf x_n$</td>
      <td>$y_n$</td>
      <td>lazy learning</td>
    </tr>
  </tbody>
</table>

<p>特征学习模型的优劣：</p>

<table>
  <thead>
    <tr>
      <th>优势</th>
      <th>坏处</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>容易：减轻了人工提取特征的负担</td>
      <td>困难：通常是非凸优化</td>
    </tr>
    <tr>
      <td>强大：如果有足够多的隐含变量</td>
      <td>过拟合：需要正则化或验证</td>
    </tr>
  </tbody>
</table>

<p>因此，使用特征学习模型要当心！</p>

<h2 id="section">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-1">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:v-equals-w">
      <p>$\mathbf v_n$和$\mathbf w_m$实际上是对称的（等价的）。 <a href="#fnref:v-equals-w" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>矩阵分解</title>
      <link href="http://qianjiye.de/2015/02/matrix-factorization" />
      <pubdate>2015-02-12T18:33:54+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/matrix-factorization</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">线性网络</h2>

<p>对于推荐系统（recommender system）数据集，用户对第$m$部电影的评分表示为
\[
\mathcal D_m=
\left\{\left(
\tilde x_n=(n), y_n=r_{nm}
\right)
\mbox{ user }n\mbox{ rated movie }m
\right\}，
\]
$\tilde x_n=(n)$表示抽象的（abstract）特征，代表用户编号（ID），不代表任何数值上的意义，这类的特征称为<strong>类别特征</strong>（categorical feature）。</p>

<p>常见的类别特征有ID、血型、程序语言……然而，许多机器学习算法都对数值特征友好，比如线性模型、扩展的（extended）线性模型（神经网络等）……决策树可以处理类别特征。若要将类别特征用于对数值特征友好的模型，需要将类别特征转换或编码（transform/encode）为数值特征。二值编码（binary vector encoding）是比较简单的征编码方式，对于血型有
\[
A=[1\;0\;0\;0]^\top,\quad
B=[0\;1\;0\;0]^\top,\quad
AB=[0\;0\;1\;0]^\top,\quad
O=[0\;0\;0\;1]^\top。
\]
编码之后第$m$部电影的的数据记为
\[
\mathcal D_m=
\left\{\left(
\tilde x_n=\mbox{BinaryVectorEncoding}(n), y_n=r_{nm}
\right)
\mbox{ user }n\mbox{ rated movie }m
\right\}，
\]
所有用户的数据可以统一记为
\[
\mathcal D=
\left\{\left(
\tilde x_n=\mbox{BinaryVectorEncoding}(n), 
y_n=\left[r_{n1}\;?\;?\;r_{n4}\;r_{n5}\;\ldots\;r_{nM}\right]^\top
\right)
\right\}，
\]
“$?$”表示用户没有对电影做出评价。若要学到每个用户的爱好，需要先学到每个用户的特征（年龄、电影类型的偏好等）。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-NN-for-features.png"><img src="/assets/images/2015-02-12-matrix-factorization-NN-for-features.png" alt="利用神经网络提取特征" /></a><div class="caption">图 1:  利用神经网络提取特征 [<a href="/assets/images/2015-02-12-matrix-factorization-NN-for-features.png">PNG</a>]</div></div></div>

<p>利用不含$x_0^{(\ell)}$神经元<sup id="fnref:why-no-1-neuron"><a href="#fn:why-no-1-neuron" class="footnote">1</a></sup>的$N-\tilde d-M$神经网络（自编码器）提取特征，如上图所示，$\mathbf x$是只有一个非0元的二值向量。中间的$\tanh$转换必要么？</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-linear-neuron-for-features.png"><img src="/assets/images/2015-02-12-matrix-factorization-linear-neuron-for-features.png" alt="采用线性神经元提取特征" /></a><div class="caption">图 2:  采用线性神经元提取特征 [<a href="/assets/images/2015-02-12-matrix-factorization-linear-neuron-for-features.png">PNG</a>]</div></div></div>

<p>对于$\mathbf x$，只会有一个非0分量进入$\tanh$层的神经元，即使不进行$\tanh$转换（采用线性模型，如上图所示）也能找到特征的恰当描述方式，这样的神经网络称为<strong>线性网络</strong>（linear network）。第一层用$N\times\tilde d$的矩阵$\mathbf V^\top$表示，第二层用$\tilde d\times M$的矩阵$\mathbf W$表示，线性网络可以表示为
\begin{equation}
h(\mathbf x)=\mathbf W^\top\mathbf V\mathbf x。
\end{equation}
对每个用户而言，由于$\mathbf x_n$只有一个元素为1，相当于抽取矩阵的一列
\begin{equation*}
h(\mathbf x_n)=\mathbf W^\top\mathbf v_n，
\end{equation*}
$\mathbf v_n$表示$\mathbf V$的第$n$列，相当于对第$n$个用户进行了特征转换。</p>

<p>对于推荐系统，线性网络学习$\mathbf V$和$\mathbf W$。</p>

<h2 id="section-1">矩阵分解</h2>

<p>令$\Phi(\mathbf x)=\mathbf V\mathbf x$，第$m$部电影的评分只是线性模型$h_m(\mathbf x)=\mathbf w_m^\top\Phi(\mathbf x)$。对于$\mathcal D_m$，期望有
\[
r_{nm}=y_n\approx\mathbf w_m^\top\mathbf v_n，
\]
需要最小化目标函数
\begin{equation}
E_{in}\left(\left\{\mathbf w_m\right\},\left\{\mathbf v_n\right\}\right)
={1\over \sum_{m=1}^M\lvert\mathcal D_m\rvert}\sum_{\mbox{user }n\mbox{ rated movie }m}
\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)^2，
\end{equation}
同时学到转换方式$\left\{\mathbf v_n\right\}$和线性模型$\left\{\mathbf w_m\right\}$。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-matrix-factorization.png"><img src="/assets/images/2015-02-12-matrix-factorization-matrix-factorization.png" alt="矩阵分解的形式" /></a><div class="caption">图 3:  矩阵分解的形式 [<a href="/assets/images/2015-02-12-matrix-factorization-matrix-factorization.png">PNG</a>]</div></div></div>

<p>当$r_{nm}=\mathbf w_m^\top\mathbf v_n=\mathbf v_n^\top\mathbf w_m$时，所有评价可记为矩阵形式$\mathbf R\approx\mathbf V^\top\mathbf W$，将含有缺失值的$\mathbf R$矩阵分解为两个矩阵的乘积，如上图所示，就得到了用户的特征以及特征的线性组合方式。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-12-matrix-factorization-recommender.png"><img src="/assets/images/2015-02-12-matrix-factorization-recommender.png" alt="推荐系统" /></a><div class="caption">图 4:  推荐系统 [<a href="/assets/images/2015-02-12-matrix-factorization-recommender.png">PNG</a>]</div></div></div>

<p>通过用户的评分$\mathbf R$，学到了$\mathbf v_n$表示用户的特征（喜好），也学到了$\mathbf w_m$表电影具备哪些元素，如上图所示。当有新用户$N+1$时，$\mathbf v_{N+1}$初始化为$\mathbf v_{N+1}={1\over N}\sum_{n=1}^N\mathbf v_n$，新用户$N+1$的评分$r_{(N+1)m}$最高的电影是有最高平均评分的电影。</p>

<p>类似的矩阵分解模型可以用于提取其它抽象特征。线性自编码器可看作一种特殊的矩阵分解方法：</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th><a href="/2015/02/deep-learning/#linear-autoencoder">线性自编码器</a> $\mathbf X\approx\mathbf W\left(\mathbf W^\top\mathbf X\right)$</th>
      <th>矩阵分解 $\mathbf R\approx \mathbf V^\top\mathbf W$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>motivation</td>
      <td>特殊的$d-\tilde d-d$的线性神经网络</td>
      <td>$N-\tilde d-M$的线性神经网络</td>
    </tr>
    <tr>
      <td>误差度量</td>
      <td>所有数据$x_{ni}$上的平方误差</td>
      <td>已知数据$r_{nm}$上的平方误差</td>
    </tr>
    <tr>
      <td>求解方法</td>
      <td>$\mathbf X^\top\mathbf X$特征向量上的全局最优解</td>
      <td>交替最小二乘法求取的局部最优解</td>
    </tr>
    <tr>
      <td>功能</td>
      <td>获取数据低维特征表示</td>
      <td>提取隐含特征</td>
    </tr>
  </tbody>
</table>

<h2 id="section-2">交替最小二乘法</h2>

<p>通过最优化
\[
\min_{\mathbf W,\mathbf V}E_{in}\left(\left\{\mathbf w_m\right\},\left\{\mathbf v_n\right\}\right)
\propto\sum_{m=1}^M\left(
\sum_{(\mathbf x_n,r_{nm})\in\mathcal D_m}
\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)^2
\right)，
\]
学到参数矩阵$\mathbf W,\mathbf V$。同时学习两组变量很困难，可以采取类似<a href="/2015/02/radial-basis-function-network/#k-means">k均值算法</a>的<strong>交替最小二乘法</strong>（alternating least squares algorithm）：</p>

<ul>
  <li>当固定$\mathbf v_n$时，相当于在第$m$部电影的数据$\mathcal D_m$上最小化$E_{in}$得到$\mathbf w_m$，通过对每部电影的线性回归（不含$w_0$）实现；</li>
  <li>由于用户特征向量和电影特征向量的对称性（二者地位一样），当固定$\mathbf w_m$时，相当于对每个用户的线性回归（不含$v_0$）。</li>
</ul>

<blockquote>
  <h4 id="section-3">交替最小二乘法</h4>
  <hr />
  <p>随机初始化$\tilde d$维向量$\{\mathbf w_m\}，\{\mathbf v_n\}$；</p>

  <p>交替最小化$E_{in}$直到收敛：</p>

  <ul>
    <li>最优化$\mathbf w_1,\mathbf w_2,\ldots,\mathbf w_M$：对电影$m$在数据集$\{(\mathbf v_n,r_{nm})\}$做线性回归；</li>
    <li>最优化$\mathbf v_1,\mathbf v_2,\ldots,\mathbf v_N$：对用户$n$在数据集$\{(\mathbf w_m,r_{nm})\}$做线性回归。</li>
  </ul>
</blockquote>

<p>每次交替最小化都会使$E_{in}$减小，收敛是有保障的。采用交替最小二乘法，类似于用户和电影之间的“探戈”（tango）。</p>

<h2 id="section-4">随机梯度下降法</h2>

<p>随机梯度下降法（SGD，stochastic gradient descent）容易实现，每轮迭代高效，容易扩展到平方误差之外的其它误差度量方式。</p>

<p>单个数据产生的误差为
\[
err(\mbox{user }n, \mbox{movie }m, \mbox{rating }r_{nm})
=\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)^2，
\]
那么可得偏微分
\[
\begin{aligned}
\nabla_{\mathbf v_n} &amp;err(\mbox{user }n, \mbox{movie }m, \mbox{rating }r_{nm})
=-2\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)\mathbf w_m\\
\nabla_{\mathbf w_m} &amp;err(\mbox{user }n, \mbox{movie }m, \mbox{rating }r_{nm})
=-2\left(r_{nm}-\mathbf w_m^\top\mathbf v_n\right)\mathbf v_n。
\end{aligned}
\]
每次跟新量$\propto -(\mbox{residual})(\mbox{the other feature vector})$，余数（residual）为$r_{nm}-\mathbf w_m^T\mathbf v_n$，也就是用余数倍另一个量更新当前量。</p>

<blockquote>
  <h4 id="section-5">基于随机梯度下降法的矩阵分解</h4>
  <hr />
  <p>随机初始化$\tilde d$维向量$\{\mathbf w_m\}，\{\mathbf v_n\}$<sup id="fnref:all-zeros"><a href="#fn:all-zeros" class="footnote">2</a></sup>；</p>

  <p>对$t=0,1,\ldots,T$迭代：</p>

  <ol>
    <li>对所有已知的$r_{nm}$，随机抽取$(n,m)$；</li>
    <li>计算余数$\tilde r_{nm}=r_{nm}-\mathbf w_m^T\mathbf v_n$；</li>
    <li>随机梯度更新：
\[
\begin{aligned}
\mathbf v_n^{new}&amp;\leftarrow\mathbf v_n^{old}+\eta\tilde r_{nm}\mathbf w_m^{old}\\
\mathbf w_m^{new}&amp;\leftarrow\mathbf w_m^{old}+\eta\tilde r_{nm}\mathbf v_n^{old}。
\end{aligned}
\]</li>
  </ol>
</blockquote>

<p>随机梯度下降法在大规模矩阵分解中很常用。</p>

<blockquote>
  <h4 id="kddcup-2011-track-1-world-champion-solution-by-ntu">KDDCup 2011 Track 1: World Champion Solution by NTU</h4>
  <hr />
  <p><strong>问题</strong>：训练数据时间上要早于测试数据。也就是训练和测试数据分布不同，有偏采样（sampling bias）。</p>

  <p><strong>对策</strong>：强化时间晚的数据。SGD在最后$T’$轮迭代只选用感兴趣的$T’$个数据。</p>

  <p><strong>结果</strong>：consistent improvements of test performance。</p>
</blockquote>

<h2 id="section-6">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-7">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-no-1-neuron">
      <p>让网络看上去简单些而已，加入$x_0^{(\ell)}$可以得到一个稍微有些不同的模型。 <a href="#fnref:why-no-1-neuron" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:all-zeros">
      <p>若都初始化为0，$\{\mathbf w_m\}$和$\{\mathbf v_n\}$始终为0，$E_{in}$永远也不会减少。 <a href="#fnref:all-zeros" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>径向基函数网络</title>
      <link href="http://qianjiye.de/2015/02/radial-basis-function-network" />
      <pubdate>2015-02-11T23:59:57+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/radial-basis-function-network</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">径向基函数网络</h2>

<p><a href="/2015/01/kernel-svm/#mjx-eqn-eqrbf-svm">高斯核SVM</a>，可以实现无限维特征空间的最大边界分类器，它的实现方式是利用$\alpha_n$实现以支持向量$\mathbf x_n$为中心高斯函数的线性组合。</p>

<p>高斯核通常也称为径向基函数（RBF，radial basis function）。radial表示函数值只依赖于$\mathbf x$与“中心”$\mathbf x_n$之间的距离；basis function表示用来组合的系数$\alpha_n，y_n$。</p>

<p>令$g_n(\mathbf x)=y_n\exp\left(-\gamma\left\lVert\mathbf x-\mathbf x_n\right\rVert^2\right)$，它表示基于$\mathbf x$与$\mathbf x_n$之间距离权重的加权投票（$+1$或$-1$的票）。高斯核SVM可以表示为
\[
g_{SVM}(\mathbf x)=\mbox{sign}\left(\sum_{SV}\alpha_ng_n(\mathbf x)+b\right)，
\]
它是径向基假设的线性融合。</p>

<p><strong>径向基函数网络</strong>就是径向基假设的线性融合，它也是一种神经网络。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-NN-vs-RBFN.png"><img src="/assets/images/2015-02-11-radial-basis-function-network-NN-vs-RBFN.png" alt="神经网络与径向基函数网络" /></a><div class="caption">图 1:  神经网络与径向基函数网络 [<a href="/assets/images/2015-02-11-radial-basis-function-network-NN-vs-RBFN.png">PNG</a>]</div></div></div>

<p>神经网络与径向基函数网络如上图所示：</p>

<ul>
  <li>隐藏层：神经网络采用“内积＋$\tanh$”，径向基函数网络采用“距离＋高斯函数”；</li>
  <li>输出层都是同样的线性融合模型。</li>
</ul>

<p>径向基函数网络的假设为
\begin{equation}
h(\mathbf x)=\mbox{Output}\left(
\sum_{m=1}^{M}\beta_m\mbox{RBF}(\mathbf x,\boldsymbol\mu_m)+b
\right)，
\end{equation}
高斯函数只是一种径向基函数$\mbox{RBF}$，$\beta_m$是投票权值，$\mbox{Output}$形式由不同的回归或分类问题确定。$\boldsymbol\mu_m$和$\beta_m$（带符号）是两个关键参数。高斯核SVM是一种径向基函数网络：径向基函数$\mbox{RBF}$采用高斯函数；对二分类问题输出是$\pm 1$；$M=\#SV$；$\boldsymbol\mu_m$是支持向量$\mathbf x_m$；$\beta_m$是从对偶SVM推导的$\alpha_my_m$。</p>

<p>给定径向基函数$\mbox{RBF}$和输出，径向基函数网络需要学习的参数是$\mu_m$和$\beta_m$。</p>

<p>核和RBF是两种不同的相似度度量方法。核描述基于$\mathcal Z$空间内积的相似性，需要满足<a href="/2015/01/kernel-svm">Mercer条件</a>。RBF通过$\mathcal X$空间的距离度量相似性，这种相似性与距离是单调递减（monotonically non-increasing）关系。一般采用度量$\mathbf x$和$\mathbf x’$相似性的函数还可以是<sup id="fnref:edit-distance"><a href="#fn:edit-distance" class="footnote">1</a></sup>
\[
\mbox{Neuron}(\mathbf x,\mathbf x’)=\tanh\left(\gamma\mathbf x^\top\mathbf x’+1\right)，\quad\mbox{DNASim}(\mathbf x,\mathbf x’)=\mbox{EditDistance}(\mathbf x,\mathbf x’)。
\]
神经网络的神经元也是在比较输入向量与权值向量之间的相似性。</p>

<p>RBF网络展示了通过度量到中心的距离也是一种很好的特征转换。 相似性是一种很好的特征转换方法，相似性不一定与距离有关，也不一定与核有关。</p>

<h2 id="section-1">学习算法</h2>

<p>当$M=N$和$\boldsymbol\mu_m=\mathbf x_m$时，称为完全RBF网络。它的物理含义是每个点$\mathbf x_m$对周围的数据$\mathbf x$有权重$\beta_m$的影响，假设对二分类问题均匀影响（uniform influence）周围的数据，$\beta_m=1\cdot y_m$，那么
\begin{equation}
g_{uniform}(\mathbf x)=\mbox{sign}\left(\sum_{m=1}^Ny_m\exp\left(-\gamma\left\lVert\mathbf x-\mathbf x_m\right\rVert^2\right)\right)，
\end{equation}
这就是每个数据通过相似度对新数据的投票融合。这和<a href="/2015/01/image-classification-knn-based-introduction/#kNN">k最近邻算法</a>思想很相似。离$\mathbf x$最近的$\mathbf x_m$让$\exp\left(-\gamma\left\lVert\mathbf x-\mathbf x_m\right\rVert^2\right)$取得最大值。高斯函数衰减很快，最大的投票很可能会左右投票结果，不需要让所有数据投票，只用离$\mathbf x$最近数据投票，用选择法（selection）替代融合法（aggregation），
\begin{equation}
g_{nbor}=y_m\mbox{ such that }\mathbf x\mbox{ closest to }\mathbf x_m， 
\end{equation}
这就是最近邻算法。若让k个$\mathbf x_m$参与对$\mathbf x$投票就是k最近邻算法。</p>

<p>如果不直接用$y_m$作为$\beta_m$投票，而更进一步考虑对$\beta_m$进行优化，用完全RBF网络解决基于平方误差的回归问题，
\begin{equation}
h(\mathbf x)=\sum_{m=1}^{M}\beta_m\mbox{RBF}(\mathbf x,\mathbf x_m)。
\end{equation}
这是基于RBF特征转换的线性回归，
\[
\mathbf z_n=[\mbox{RBF}(\mathbf x_n,\mathbf x_1),\mbox{RBF}(\mathbf x_n,\mathbf x_2),\ldots,\mbox{RBF}(\mathbf x_n,\mathbf x_N)]，
\]
最优解为$\boldsymbol\beta=\left(\mathbf Z^\top\mathbf Z\right)^{-1}\mathbf Z^\top\mathbf y$（若$\mathbf Z^\top\mathbf Z$可逆），$\mathbf Z$是$N\times N$的对称方阵，那么就有
\begin{equation}
\boldsymbol\beta=\mathbf Z^{-1}\mathbf y。
\end{equation}
若每个$\mathbf x_n$都不一样，那么$\mathbf Z$总可逆。对于数据$\mathbf x_1$，
\[
g_{RBF}(\mathbf x_1)
=\boldsymbol\beta^\top\mathbf z_1
=\mathbf y^\top\mathbf Z^{-1}\cdot(\mbox{first column of }\mathbf Z)
=\mathbf y^\top\left[1,0,\ldots,0\right]^\top
=y_1，
\]
那么就有
\begin{equation}
g_{RBF}(\mathbf x_n)=y_n，
\end{equation}
对于回归问题$E_{in}(g_{RBF})=0$。在函数逼近（function approximation）领域这叫完美内插（exact interpolation）；对机器学习而言这是过拟合，需要正则化。</p>

<h2 id="section-2">正则化</h2>

<p>对正则化的完全RBF网络的脊回归可得
\begin{equation}
\boldsymbol\beta=\left(\mathbf Z^\top\mathbf Z+\lambda\mathbf I\right)^{-1}\mathbf Z^\top\mathbf y，
\end{equation}
其中$\mathbf Z$可以看作<a href="/2015/01/kernel-svm">高斯核矩阵</a>，$\mathbf K=\mathbf Z$，对比<a href="/2015/01/support-vector-regression/#mjx-eqn-eqanalytic-solution-ridge-regression">脊回归的核模型</a>，二则只相差矩阵$\mathbf Z^\top$，前者是有限$N$维转换的回归，后者是无限维转换的回归。</p>

<p>对于<a href="/2015/01/kernel-svm/#mjx-eqn-eqrbf-svm">SVM核模型</a>，只采用了支持向量作为参考进行距离度量。减少中心数量（也就减少了参与投票的权值），只使用部分代表点（prototype）作为中心，使$M\ll N$，也是一种有效的正则化方法。</p>

<p>如何找出这些有效的代表点呢？</p>

<h2 id="k-means">k均值聚类</h2>

<p>若$\mathbf x_1\approx\mathbf x_2$，不需要$\mbox{RBF}(\mathbf x,\mathbf x_1)$和$\mbox{RBF}(\mathbf x,\mathbf x_2)$都出现在RBF网络中，可以只用一个cluster$\boldsymbol\mu\approx\mathbf x_1\approx\mathbf x_2$替代两个点即可。</p>

<p>聚类是将数据$\{\mathbf x_n\}$分为不相交的集合（类）$S_1,S_2,\ldots,S_M$。当每个集合用$\boldsymbol\mu_m$作为代表时，若$\mathbf x_1$和$\mathbf x_2$都属于$S_m$，当且仅当$\boldsymbol\mu_m\approx\mathbf x_1\approx\mathbf x_2$。聚类的目标函数为
\begin{equation}
\min_{\{S_1,\ldots,S_M;\boldsymbol\mu_1,\ldots,\boldsymbol\mu_M\}}E_{in}(S_1,\ldots,S_M;\boldsymbol\mu_1,\ldots,\boldsymbol\mu_M)
={1\over N}\sum_{n=1}^{N}\sum_{m=1}^M[[\mathbf x_n\in S_m]]\lVert\mathbf x_n-\boldsymbol\mu_m\rVert^2。
\end{equation}
这是混合的组合数值优化问题，很难最优化，但是可以简化为分别交替最优化$S_m$和$\boldsymbol\mu_m$：</p>

<ol>
  <li>最优划分：固定$\boldsymbol\mu_1,\ldots,\boldsymbol\mu_M$；选择每个$\mathbf x_n$所属的唯一类别$S_m$，使$\lVert\mathbf x_n-\boldsymbol\mu_m\rVert$最小。</li>
  <li>最优计算：固定$S_1,\ldots,S_M$；对每个$\boldsymbol\mu_m$，由于
\[
\nabla_{\boldsymbol\mu_m}E_{in}
=-2\sum_{n=1}^N[[\mathbf x_n\in S_m]](\mathbf x_n-\boldsymbol\mu_m)
=-2\left(\left(\sum_{\mathbf x_n\in S_m}\mathbf x_n\right)-\left|S_m\right|\boldsymbol\mu_m\right)=0，
\]
可得最佳$\boldsymbol\mu_m$是属于$S_m$所有$\mathbf x_n$的均值。</li>
</ol>

<p>以上就是<a href="/2014/12/k-means">k均值算法</a>的关键步骤，$k=M$，重复以上2步直至收敛。通常随机选择k个$\mathbf x_n$作为$\boldsymbol\mu_k$的初始值。收敛是指$S_1,\ldots,S_k$不再改变。算法通过交替最小化使$E_{in}$减小，一定能收敛。</p>

<blockquote>
  <h4 id="krbf">基于k均值的RBF网络</h4>
  <hr />

  <ol>
    <li>利用k均值算法，$k=M$，得到$\{\boldsymbol\mu_m\}$；</li>
    <li>进行特征转换
\[
\Phi(\mathbf x)=\left[\mbox{RBF}(\mathbf x,\boldsymbol\mu_1),\mbox{RBF}(\mathbf x,\boldsymbol\mu_2),\ldots,\mbox{RBF}(\mathbf x,\boldsymbol\mu_M)\right]；
\]</li>
    <li>通过$\{(\Phi(\mathbf x_n),y_n)\}$上的线性模型得到参数$\boldsymbol\beta$；</li>
    <li>返回$g_{RBFNET}(\mathbf x)=\mbox{LinearHypothesis}(\boldsymbol\beta, \Phi(\mathbf x))$。</li>
  </ol>
</blockquote>

<p>上述算法采用非监督的k均值作为特征转换，如同自编码器。RBF网络需要确定的的参数是$M$和$\mbox{RBF}$函数，这些可通过验证方法确定。</p>

<p>虽然RBF网络和SVM的核模型与神经网络性能差不多，但在实际中并不常用。</p>

<h2 id="section-3">实战技能</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-k-means.png"><img src="/assets/images/2015-02-11-radial-basis-function-network-k-means.png" alt="k均值算法对参数敏感" /></a><div class="caption">图 2:  k均值算法对参数敏感 [<a href="/assets/images/2015-02-11-radial-basis-function-network-k-means.png">PNG</a>]</div></div></div>

<p>只要选择合适的$k$和恰当的初始化，k均值算法通常表现良好。k均值算法对参数敏感，选择不同的$k$和不同的初始化，结果差异大，如上图所示。对参数交替最优化不能保证得到全局最优。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-k-means-and-RBFN.jpg"><img src="/assets/images/2015-02-11-radial-basis-function-network-k-means-and-RBFN.jpg" alt="基于k均值的RBF网络" /></a><div class="caption">图 3:  基于k均值的RBF网络 [<a href="/assets/images/2015-02-11-radial-basis-function-network-k-means-and-RBFN.jpg">JPG</a>]</div></div></div>

<p>上图是利用了k均值的RBF网络，蓝色和红色表示两类的标签，阴影渐变区域表示k均值聚类的结果，黑色线条展示分类结果。上图左完全没办法分出两类，输出都是同一类的结果。如果k均值的效果较好，RBF网络效果也更好。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-11-radial-basis-function-network-full-RBFN.jpg"><img src="/assets/images/2015-02-11-radial-basis-function-network-full-RBFN.jpg" alt="完全RBF网络" /></a><div class="caption">图 4:  完全RBF网络 [<a href="/assets/images/2015-02-11-radial-basis-function-network-full-RBFN.jpg">JPG</a>]</div></div></div>

<p>上图左和右分别展示了两种完全RBF网络的效果，所有的数据都参与分类计算，由于计算量很大，在实际中很少使用。或者说这类算法还需要借助其它方式，克服计算复杂度。</p>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:edit-distance">
      <p>$\mbox{EditDistance}$表示一个字符串如何通过最小的修改变为另一个字符串。 <a href="#fnref:edit-distance" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>深度学习</title>
      <link href="http://qianjiye.de/2015/02/deep-learning" />
      <pubdate>2015-02-04T19:31:41+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/deep-learning</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">深度神经网络</h2>

<p>确定神经网络的结构是非常核心也是非常困难的问题。</p>

<p>需要多少神经元？网络多少层？神经元之间如何连接？……这些选择一方面凭主观意愿，另一方面通过验证的方法确定。</p>

<p>浅层（shallow）神经网络只有少量的隐层，深度（deep）神经网络有很多层，它们之间的对比如下：</p>

<table>
  <thead>
    <tr>
      <th>浅层神经网络</th>
      <th>深度神经网络</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>✅训练较高效</td>
      <td>❌训练极具挑战性</td>
    </tr>
    <tr>
      <td>✅结构简单</td>
      <td>❌结构复杂</td>
    </tr>
    <tr>
      <td>✅非常强大</td>
      <td>✅非常强大</td>
    </tr>
    <tr>
      <td> </td>
      <td>✅能提取有意义的特征</td>
    </tr>
  </tbody>
</table>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-04-deep-learning-meaningfulness-of-DL.png"><img src="/assets/images/2015-02-04-deep-learning-meaningfulness-of-DL.png" alt="深度学习提取有意义的特征" /></a><div class="caption">图 1:  深度学习提取有意义的特征 [<a href="/assets/images/2015-02-04-deep-learning-meaningfulness-of-DL.png">PNG</a>]</div></div></div>

<p>若只有一层，它需要完成的任务就很复杂。层数增多，每层或层与层之间功能简单，如上图所示，只需从输入中提取简单的笔画，若还有下一层，继续从简单笔画中找出更复杂的笔画。层与层之间，实现从简单到复杂的特征转换。若原始特征是raw feature（每个特征物理意义有限，比如图像的每个像素），最终需要完成复杂的分类动作，深度学习处理这样的问题更自然。</p>

<h4 id="section-1">一、深度学习的挑战与关键技术</h4>

<ul>
  <li>决定网络结构很困难。
    <ul>
      <li>验证能帮忙但并非易事；</li>
      <li>借助领域知识（domain knowledge），比如用于图像的convolutional NNet，像素物理位置有意义，相邻像素连接到下层同一神经元可描述更高阶的特征，相距太远的像素不连接在一起。</li>
    </ul>
  </li>
  <li>模型复杂度很高。
    <ul>
      <li>数据足够多时模型复杂度不是问题，但计算复杂度会更高；</li>
      <li>利用正则化（在某些神经元坏掉时，dropout能使网络很好工作；输入出问题时，denoising能使网络很好工作）。</li>
    </ul>
  </li>
  <li>最优化很困难。局部极小值比神经网络更容易出现。
    <ul>
      <li>精心初始化，避免陷入糟糕的局部极小值（利用pre-training）。</li>
    </ul>
  </li>
  <li>计算复杂度很高，尤其是面对大数据的时候。
    <ul>
      <li>利用新的硬件软件架构，比如mini-batch+GPU。</li>
    </ul>
  </li>
</ul>

<p>其中，正则化和初始化是尤为关键的两项技术。</p>

<blockquote>
  <h4 id="section-2">二、深度学习两步走策略</h4>
  <hr />

  <ol>
    <li>预训练：对$\ell=1,\dots,L$，假设$\mathbf w_*^{(1)},\ldots\mathbf w_*^{(\ell-1)}$已知，逐层训练权值$\left\{w_{ij}^{(\ell)}\right\}$。</li>
    <li>训练：利用BP算法在预训练的基础上调整（fine-tune）权值$\left\{w_{ij}^{(\ell)}\right\}$。</li>
  </ol>
</blockquote>

<h2 id="section-3">非线性自编码器：神经网络</h2>

<p>权值的作用是进行特征转换，将数据换成另一种表现形式，也就是编码（encoding）。在预训练深度神经网络时，并不清楚当前层的权重对以后层有何影响。因此，好的权值需要能保持信息（information-preserving），不同层的权值以不同的形式表示信息。保持信息的意思是数据经过编码之后能重建或精确解码（decode accurately）出原来的信息。预训练权值就是保持信息的编码。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-04-deep-learning-information-preserving-NN.png"><img src="/assets/images/2015-02-04-deep-learning-information-preserving-NN.png" alt="自编码器（保持信息的神经网络）" /></a><div class="caption">图 2:  自编码器（保持信息的神经网络） [<a href="/assets/images/2015-02-04-deep-learning-information-preserving-NN.png">PNG</a>]</div></div></div>

<p>上图的$d-\tilde d-d$结构的神经网络力求输出与输入一致，$g(\mathbf x) = \mathbf x$，这种保持信息的神经网络称为<strong>自编码器</strong>（autoencoder），它的目的是做函数到它本身的逼近（approximate identity function）。$w_{ij}^{(1)}$称为编码权值，$w_{ji}^{(2)}$称为解码权值。</p>

<p>自编码器的变换$g(\mathbf x) = \mathbf x$采用了数据集上的隐含结构（hidden structure），其价值在于：</p>

<ul>
  <li>对于监督学习：$\mathbf x$的隐含结构（权值）很好的保持了信息，可用作特征变换$\Phi(\mathbf x)$。——informative representation of data</li>
  <li>对于非监督学习：（1）密度估计（density estimation）：稠密的区域$g(\mathbf x)\approx\mathbf x$效果好<sup id="fnref:why-density-estimate"><a href="#fn:why-density-estimate" class="footnote">1</a></sup>，新的数据若表现好则位于稠密区域；（2）异常检测（outlier detection）：异常点的$g(\mathbf x)\ne\mathbf x$。——typical representation of data</li>
</ul>

<p>自编码器通过学习identity function得到了数据的表现形式。</p>

<p>基本的自编码器就是$d-\tilde d-d$结构的神经网络，误差函数为
$
\sum_{i=1}^d(g_i(\mathbf x)-x_i)^2。
$
这是浅层网络，可以容易利用BP算法训练。通常情况$\tilde d&lt;d$，这是数据的压缩表示。数据集是$\{(\mathbf x_1, \mathbf y_1=\mathbf x_1),(\mathbf x_2,\mathbf y_2=\mathbf x_2),\ldots,(\mathbf x_N, \mathbf y_N=\mathbf x_N)\}$，因此这也被视为非监督学习。有时会用约束条件$w_{ij}^{(1)}=w_{ji}^{(2)}$让网络更简单，也就是进行正则化，这也会让算法更复杂。</p>

<p>在深度学习中，采用基本的自编码器在数据集$\left\{\mathbf x_n^{(\ell-1)}\right\}$上训练（其中$\tilde d=d^{(\ell)}$），将自编码器权值$\left\{w_{ij}^{(1)}\right\}$作为深度神经网络预训练的权值$\left\{w_{ij}^{(\ell)}\right\}$。</p>

<p>许多成功的预训练技术，利用不同的网络结构或正则化机制等方法，实现了更精妙的自编码器。</p>

<h2 id="section-4">去噪自编码器：正则化</h2>

<p>复杂的神经网络模型复杂度高，需要利用正则化避免过拟合。通常采用的正则化技术包括：</p>

<ul>
  <li>选择简单的网络结构；</li>
  <li><a href="/2015/02/neural-network/#regularization-weighted-methods">weight-decay或weight-elimination正则化</a>；</li>
  <li><a href="/2015/02/neural-network/#regularization-early-stopping">尽早停止迭代</a>。</li>
</ul>

<p>深度学习和自编码器采用了不同的正则化方法。</p>

<p>噪声是导致过拟合的重要原因，<a href="/2015/01/hazard-of-overfitting/#overfitting-illustration">数据越少噪声越多时，越容易过拟合</a>。当模型和数据确定时，去噪是避免过拟合的正则化方法。最直接的去噪技术可以采用<a href="/2015/01/hazard-of-overfitting/#data-cleaning">数据清洗或者数据剪枝</a>。能否反其道而行之，加入噪声？✅</p>

<p>对于鲁棒的自编码器，不仅能对原始数据$\mathbf x$有$g(\mathbf x)\approx \mathbf x$，而且对噪声数据$\tilde{\mathbf x}$有$g(\tilde{\mathbf x})\approx \mathbf x$，这就是<strong>去噪自编码器</strong>（denoising autoencoder）的任务。在数据集$\{(\tilde{\mathbf x}_1, \mathbf y_1=\mathbf x_1),(\tilde{\mathbf x}_2,\mathbf y_2=\mathbf x_2),\ldots,(\tilde{\mathbf x}_N, \mathbf y_N=\mathbf x_N)\}$训练自编码器，其中$\tilde{\mathbf x}_n$是对${\mathbf x}_n$加入了人工噪声的数据。在图像处理领域，$g(\tilde{\mathbf x})$可以得到$\tilde{\mathbf x}$的去噪版本。</p>

<p>在有噪声的数据集上训练出正则化的$g$具备抗噪的能力，这种正则化方法在神经网络模型中非常实用<sup id="fnref:data-hinting"><a href="#fn:data-hinting" class="footnote">2</a></sup>。</p>

<h2 id="linear-autoencoder">线性自编码器／主成分分析</h2>

<p>神经网络是复杂的非线性自编码器，能否利用简单高效且不易过拟合的线性自编码器呢？✅</p>

<p>对于第$k$个元素的线性模型
\[
h_k(\mathbf x)=\sum_{j=0}^{\tilde d}w_{jk}^{(2)}\left(
\sum_{i=0}^{d}w_{ij}^{(1)}x_i
\right)，
\]
加入限制条件：</p>

<ul>
  <li>去除掉常数项$x_0$，使$i$和$k$取值范围相同；</li>
  <li>加入正则化约束$w_{ij}^{(1)}=w_{ji}^{(2)}=w_{ij}$，$\mathbf W=[w_{ij}]$是$d\times\tilde d$的权值矩阵；</li>
  <li>$\tilde d&lt;d$；</li>
</ul>

<p>可得
\[
h_k(\mathbf x)=\sum_{j=0}^{\tilde d}w_{kj}\left(
\sum_{i=1}^{d}w_{ij}x_i
\right)。
\]</p>

<p>因此，线性自编码器的假设（hypothesis）可以表示为
\begin{equation}
h(\mathbf x)=\mathbf W\mathbf W^\top\mathbf x。
\end{equation}
好的自编码器就是对$\mathbf W$做最优化
\[
\mathbf W=\arg\min_{\mathbf W} E_{in}(\mathbf h)=E_{in}(\mathbf W)=
{1\over N}\sum_{n=1}^N\left\lVert\mathbf x_n-\mathbf W\mathbf W^\top\mathbf x_n\right\rVert^2，
\]
这是$w_{ij}$的4次多项式，不易得到解析解。</p>

<p>$\mathbf W\mathbf W^\top$是半正定矩阵，进行特征值分解$\mathbf W\mathbf W^\top=\mathbf V\boldsymbol\Gamma\mathbf V^\top$：</p>

<ul>
  <li>$d\times d$的矩阵$\mathbf V$是正交的（orthogonal）$\mathbf V\mathbf V^\top=\mathbf V^\top\mathbf V=\mathbf I_d$；</li>
  <li>$d\times d$的对角（diagonal）矩阵$\boldsymbol\Gamma$非零对角线元素最多$\tilde d$个。</li>
</ul>

<p>由此可得$\mathbf W\mathbf W^\top\mathbf x_n=\mathbf V\boldsymbol\Gamma\mathbf V^\top\mathbf x_n$：</p>

<ul>
  <li>$\mathbf V^\top\mathbf x_n$表示对$\mathbf x_n$的坐标转换，几何上看是一种旋转或镜射（rotate or reflect），$\mathbf x_n$的长度不会改变；</li>
  <li>$\boldsymbol\Gamma(\cdots)$中$\boldsymbol\Gamma$对角线有$d-\tilde d$个0元素，其余的非0元素进行尺度缩放；</li>
  <li>$\mathbf V(\cdots)$表示还原到原始坐标系。</li>
</ul>

<p>由于$\mathbf x_n=\mathbf V\mathbf I\mathbf V^\top\mathbf x_n$，最优化问题可变为
\[
\min_{\mathbf V}\min_{\boldsymbol\Gamma}{1\over N}\sum_{n=1}^N\left\lVert\mathbf V\mathbf I\mathbf V^\top\mathbf x_n-\mathbf V\boldsymbol\Gamma\mathbf V^\top\mathbf x_n\right\rVert^2，
\]
可先对$\boldsymbol\Gamma$最优化再对$\mathbf V$最优化，并且$\mathbf V$不影响向量在变换过程中的长度，可省去$\mathbf V$。最优化的形式可记为$\min_{\boldsymbol\Gamma}\sum\lVert(\mathbf I-\boldsymbol\Gamma)(\cdots)\rVert^2$，这需要$\mathbf I-\boldsymbol\Gamma$的0元素越多越好，也就是$\boldsymbol\Gamma$的对角线1越多越好。由于$\boldsymbol\Gamma$的秩不超过$\tilde d$，$\boldsymbol\Gamma$的对角线最多$\tilde d$个1，$\boldsymbol\Gamma$的最佳形式为
\[
\boldsymbol\Gamma=
\left[
\begin{aligned}
\mathbf I_{\tilde d}&amp;\quad 0\\
0&amp;\quad 0
\end{aligned}
\right]。
\]
接下来对$\mathbf V$优化
\[
\min_{\mathbf V}
\sum_{n=1}^N
\left\lVert
\left[
\begin{aligned}
0&amp;\quad 0\\
0&amp;\quad \mathbf I_{d-\tilde d}
\end{aligned}
\right]
\mathbf V^\top\mathbf x_n
\right\rVert^2，
\]
上式的意思是保留$\mathbf V^\top\mathbf x_n$的$d-\tilde d$个维度实现最小化，这可以通过最大化实现
\[
\max_{\mathbf V}
\sum_{n=1}^N
\left\lVert
\left[
\begin{aligned}
\mathbf I_{\tilde d}&amp;\quad 0\\
0&amp;\quad 0
\end{aligned}
\right]
\mathbf V^\top\mathbf x_n
\right\rVert^2。
\]
当$\tilde d=1$时，只有$\mathbf V^\top$的第一行$\mathbf v^\top$参与优化，也就是
\[
\max_{\mathbf v}\sum_{n=1}^N\mathbf v^\top\mathbf x_n\mathbf x_n^\top\mathbf v\quad\mbox{ s.t. }\mathbf v^\top\mathbf v=1，
\]
最佳的$\mathbf v$满足$\sum_{n=1}^N\mathbf x_n\mathbf x_n^\top\mathbf v=\lambda\mathbf v$（$\lambda$是拉格朗日乘子）<sup id="fnref:get-optimal-v"><a href="#fn:get-optimal-v" class="footnote">3</a></sup>，此时最佳目标值为$\lambda$，这个最佳的$\mathbf v$是$\mathbf X^\top\mathbf X$的“最大”（topmost）特征向量。一般地，$\{\mathbf v_j\}_{j=1}^{\tilde d}$是$\mathbf X^\top\mathbf X$“最大”的$\tilde d$个特征向量。</p>

<p>最佳的$\{\mathbf w_j\}$就是$\mathbf X^\top\mathbf X$“最大”的特征向量。线性自编码器就是投影到最符合数据$\{\mathbf x_n\}$的正交模式（orthogonal pattern）$\mathbf w_j$。</p>

<p>线性编码器的目标是最大化$\sum(\mbox{maginitude after projection})^2$；主成分分析（PCA，principal component analysis）的目标是最大化$\sum(\mbox{variance after projection})$，变化量$\mbox{variance}$是相对于平均数差距的平方。线性编码器和主成分分析都是线性降维方法，主成分分析＝数据0均值化 ＋ 线性自编码器，在降维中应用更普遍。</p>

<blockquote>
  <h4 id="section-5">线性编码器／主成分分析</h4>
  <hr />

  <ol>
    <li>令$\bar{\mathbf x}={1\over N}\sum_{n=1}^N\mathbf x_n$，$\mathbf x_n\leftarrow\mathbf x_n-\bar{\mathbf x}$<sup id="fnref:zero-mean-vector"><a href="#fn:zero-mean-vector" class="footnote">4</a></sup>；</li>
    <li>计算$\mathbf X^\top\mathbf X$的最大$\tilde d$个特征向量$\mathbf w_1,\mathbf w_2,\ldots,\mathbf w_{\tilde d}$；</li>
    <li>返回转换后的特征$\Phi(\mathbf x)=\mathbf W(\mathbf x-\bar{\mathbf x})$。</li>
  </ol>
</blockquote>

<h2 id="section-6">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-7">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-density-estimate">
      <p>为啥稠密区域效果好？ <a href="#fnref:why-density-estimate" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:data-hinting">
      <p>可视为<a href="/2015/02/neural-network/#data-hinting">data hinting</a>的正则化技术。 <a href="#fnref:data-hinting" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:get-optimal-v">
      <p>利用拉格朗日乘子法求导可得。 <a href="#fnref:get-optimal-v" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:zero-mean-vector">
      <p>在0均值数据集基础上进行线性编码，自然实现了投影方向上变化最大。 <a href="#fnref:zero-mean-vector" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>神经网络</title>
      <link href="http://qianjiye.de/2015/02/neural-network" />
      <pubdate>2015-02-04T16:15:04+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/neural-network</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">感知器融合</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png" alt="感知器的线性融合" /></a><div class="caption">图 1:  感知器的线性融合 [<a href="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png">PNG</a>]</div></div></div>

<p>上图展示了感知器的线性融合结构，其中包含两层的权重$\mathbf w_t$和$\boldsymbol\alpha$，还包含两层的符号函数（sign function）$g_t$和$G$。这样的融合可以表示什么样的分类边界呢？</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-and-xor-operator.png"><img src="/assets/images/2015-02-04-neural-network-and-xor-operator.png" alt="AND和XOR运算" /></a><div class="caption">图 2:  AND和XOR运算 [<a href="/assets/images/2015-02-04-neural-network-and-xor-operator.png">PNG</a>]</div></div></div>

<p>单层感知器可以实现如上图所示的AND运算（+1表示TRUE，-1表示FALSE）
\[
G(\mathbf x)=\mbox{sign}(-1+g_1(\mathbf x)+g_2(\mathbf x))，
\]
也可实现OR和NOT运算。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-enough-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-enough-perceptrons.png" alt="足够多感知器的融合" /></a><div class="caption">图 3:  足够多感知器的融合 [<a href="/assets/images/2015-02-04-neural-network-enough-perceptrons.png">PNG</a>]</div></div></div>

<p>即使感知器的线性组合，分类能力也很强大，如上图所示。只要对足够多的感知器融合，可以在空间中切割出任意凸集（convex set），但$d_{VC}\rightarrow\infty$。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png" alt="两层感知器的线性融合实现XOR运算" /></a><div class="caption">图 4:  两层感知器的线性融合实现XOR运算 [<a href="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png">PNG</a>]</div></div></div>

<p>但是，单层感知器不能实现XOR运算，经过XOR运算的特征转换$\phi(\mathbf x)=(g_1(\mathbf x),g_2(\mathbf x))$后数据线性不可分。线性不可分数据继续特征转换，最终将XOR用AND和OR实现
\[
XOR(g_1,g_2)=OR(AND(-g_1,g_2),AND(g_1,-g_2))，
\]
并且可以用上图所示的两层级连结构表示<sup id="fnref:five-input-xor"><a href="#fn:five-input-xor" class="footnote">1</a></sup>。</p>

<p>由此可见，虽然感知器算法简单，经过线性融合，以及多层级连，可以得到功能强大的分类器。多层感知器就是基本的神经网络结构。</p>

<h2 id="section-1">神经网络</h2>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-simple-NN.png"><img src="/assets/images/2015-02-04-neural-network-simple-NN.png" alt="简单的神经网络模型" /></a><div class="caption">图 5:  简单的神经网络模型 [<a href="/assets/images/2015-02-04-neural-network-simple-NN.png">PNG</a>]</div></div></div>

<p>事实上，对最后一层OUTPUT神经元，除了用感知器外，可以采用其它的<a href="/2015/01/linear-models-for-classification/#linear-models">线性模型</a>。若要分类，OUTPUT采用线性分类模型；若要回归分析，OUTPUT采用线性回归（不做任何处理）；若要soft分类，OUTPUT采用logistic回归。</p>

<p>中间层神经元采用的转换函数（transformation function），除了使用阶梯（符号）函数，也可采用其它转换函数。若所有神经元都采用线性回归，整个网络都是线性运算，用一个线性模型就可以实现。因此，很少用线性回归作为转换函数。阶梯函数是离散的，难以通过最优化求解$\mathbf w$，也很少使用。通常使用的是S形的转换函数
\[
\tanh(s)={\exp(s)-\exp(-s)\over\exp(s)+\exp(-s)}=2\theta(2s)-1，
\]
可以通过<a href="/2015/01/logistic-regression/#mjx-eqn-eqsigmoid-function">logistic函数</a>得到。该函数是阶梯函数的近似，且容易优化，传说和生物神经元也相近。</p>

<div class="image_line" id="figure-6"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-common-NN.png"><img src="/assets/images/2015-02-04-neural-network-common-NN.png" alt="常用的神经网络模型" /></a><div class="caption">图 6:  常用的神经网络模型 [<a href="/assets/images/2015-02-04-neural-network-common-NN.png">PNG</a>]</div></div></div>

<p>常用的神经网络采用$\tanh$作为转换函数，输出采用线性回归，如上图所示。$d^{(0)},d^{(1)},\ldots,d^{(L)}$表示每层神经元数目（节点数目），每层的权值为
\[
w_{ij}^{(\ell)}:\left\{
\begin{aligned}
&amp;1\leq\ell\leq L&amp;\mbox{layers}&amp;\\
&amp;0\leq i\leq d^{(\ell-1)}&amp;\mbox{inputs}&amp;\\
&amp;1\leq j\leq d^{(\ell)}&amp;\mbox{outputs}&amp;，
\end{aligned}
\right.
\]
常数+1的神经元相当于偏移项，评分函数为
\begin{equation}
s_j^{(\ell)}=\sum_{i=0}^{d^{(\ell-1)}}w_{ij}^{(\ell)}x_i^{(\ell-1)}，
\end{equation}
转换后的特征为
\begin{equation}
x_j^{(\ell)}=\left\{
\begin{aligned}
&amp;\tanh\left(s_j^{(\ell)}\right)&amp;\mbox{if }\ell&lt;L\\
&amp;s_j^{(\ell)}&amp;\mbox{if }\ell=L
\end{aligned}
\right.
\label{eq:forward-x}
\end{equation}</p>

<p>神经网络将$\mathbf x$当作输入层$\mathbf x^{(0)}$，隐层计算变换后的特征$\mathbf x^{(\ell)}$，输出层计算预测结果$x_1^{(L)}$。</p>

<p>神经网络隐层相当于模式（特征）提取（pattern extraction），进行$\mathbf x^{(\ell)}$和权值向量的模式匹配（利用基于内积的余弦相似度），每个神经元提取一种特征，权值向量纪录了从数据中学到的模式。</p>

<h2 id="bp">BP算法</h2>

<p>如何通过最小化$E_{in}\left(\left\{w_{ij}^{(\ell)}\right\}\right)$学到权值$\left\{w_{ij}^{(\ell)}\right\}$？</p>

<p>如果只有一个隐层，神经网络相当于感知器的融合，可以通过GradientBoost方法一个接一个的确定隐层的神经元。如果有多个隐层，问题就变得复杂了。</p>

<p>每个数据的误差记为
\[
e_n=(y_n-\mbox{NNet}(\mathbf x_n))^2，
\]
若能计算$\partial e_n\over \partial w_{ij}^{(\ell)}$，就可以通过梯度下降法求解。对输出层
\[
e_n=\left(y_n-s_1^{(L)}\right)^2=\left(y_n-\sum_{i=0}^{d^{(L-1)}}w_{i1}^{(L)}x_i^{(L-1)}\right)^2，
\]
对输出层和其它层分别求偏微分
\[
\begin{aligned}
&amp;{\partial e_n\over\partial w_{i1}^{(L)}}
={\partial e_n\over\partial s_{1}^{(L)}}\cdot{\partial s_{1}^{(L)}\over\partial w_{i1}^{(L)}}
=-2\left(y_n-s_1^{(L)}\right)\cdot x_i^{(L-1)}，\\
&amp;{\partial e_n\over\partial w_{ij}^{(\ell)}}
={\partial e_n\over\partial s_{j}^{(\ell)}}\cdot{\partial s_{j}^{(\ell)}\over\partial w_{ij}^{(\ell)}}
=x_i^{(\ell-1)}\delta_j^{(\ell)}。
\end{aligned}
\]
对输出层，令<sup id="fnref:tanh_output"><a href="#fn:tanh_output" class="footnote">2</a></sup>
\begin{equation}
\delta_1^{(L)}=-2\left(y_n-s_1^{(L)}\right)。
\label{eq:backpropagation-delta-L}
\end{equation}
对其它层
\begin{equation}
\delta_j^{(\ell)}
={\partial e_n\over\partial s_{j}^{(\ell)}}
=\sum_{k=1}^{d^{(\ell+1)}}{\partial e_n\over\partial s_{k}^{(\ell+1)}}{\partial s_{k}^{(\ell+1)}\over\partial x_{j}^{(\ell)}}{\partial x_{j}^{(\ell)}\over\partial s_{j}^{(\ell)}}
=\tanh’\left(s_j^{(\ell)}\right)\sum_{k=1}^{d^{(\ell+1)}}\delta_k^{(\ell+1)}w_{jk}^{(\ell+1)}，
\label{eq:backpropagation-delta2}
\end{equation}
也就是前一层的$\delta_j^{(\ell)}$，可以通过后一层$\delta_k^{(\ell+1)}$回推计算，<a href="http://www.wolframalpha.com/input/?i=d%2Fdx+tanh">其中</a>
\[
\tanh’(s)=1-\tanh^2(s)=\left({2\over \exp(s) + \exp(-s)}\right)^2，
\]
那么
\begin{equation}
\delta_j^{(\ell)}
=\left(1-\left(x_j^{(\ell)}\right)^2\right)\sum_{k=1}^{d^{(\ell+1)}}\delta_k^{(\ell+1)}w_{jk}^{(\ell+1)},\quad(j\geq 1)。
\label{eq:backpropagation-delta}
\end{equation}</p>

<blockquote>
  <h4 id="bpbackpropagation">BP（backpropagation）算法</h4>
  <hr />
  <p>用小的随机值初始化所有的$w_{ij}^{(\ell)}$；</p>

  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>随机化：随机选取$n\in\{1,2,\ldots,N\}$；</li>
    <li>前向传播：从$\mathbf x^{(0)}=\mathbf x_n$开始，利用\eqref{eq:forward-x}计算所有$x_i^{(\ell)}$；</li>
    <li>误差回传：对$\mathbf x^{(0)}=\mathbf x_n$，利用\eqref{eq:backpropagation-delta-L}和\eqref{eq:backpropagation-delta}计算所有$\delta_j^{(\ell)}$；</li>
    <li>梯度下降：$w_{ij}^{(\ell)}\leftarrow w_{ij}^{(\ell)}-\eta x_i^{(\ell-1)}\delta_j^{(\ell)}$；</li>
  </ol>

  <p>返回$g_{\mbox{NNET}}(\mathbf x)=\left(\ldots\tanh\left(\sum_jw_{jk}^{(2)}\cdot\tanh\left(\sum_iw_{ij}^{(1)}x_i\right)\right)\right)$。</p>

  <p>在实际应用中，第1步至第3步可以先执行多次后，再用$x_i^{(\ell-1)}\delta_j^{(\ell)}$的平均值执行第4步的更新，这就是mini-batch的方法。</p>
</blockquote>

<p>神经网络通过最小化
\[
E_{in}(\mathbf w)={1\over N}\sum_{n=1}^Nerr\left(\left(\ldots\tanh\left(\sum_jw_{jk}^{(2)}\cdot\tanh\left(\sum_iw_{ij}^{(1)}x_i\right)\right)\right),y_n\right)
\]
计算权值。通常多隐层神经网络的误差函数是非凸的（non-convex），难以达到全局最小值（global minimum），梯度下降法通过BP算法也仅仅得到局部极小值（local minimum）。不同的初始化$w_{ij}^{(\ell)}$，会得到不同的局部极值：</p>

<ul>
  <li>BP算法对权重初始值敏感；</li>
  <li>若权值太大，会落到$\tanh$的saturate区域（梯度很小），每次按梯度更新很小；</li>
  <li>用小的随机值初始化权值$w_{ij}^{(\ell)}$。</li>
</ul>

<p>若初始化$w_{ij}^{(\ell)}＝0$，由于$x_0^{(\ell)}=1$，除了${\partial e_n\over \partial w_{01}^{(L)}}\neq 0$外，其它的导数都为0；若初始化$w_{ij}^{(\ell)}＝1$，那么$w_{ij}^{(1)}=w_{i(j+1)}^{(1)}$。因此，$w_{ij}^{(\ell)}$不能初始化为0和1。</p>

<p>虽然神经网络很难最优化，但在实际中很有用。</p>

<h2 id="regularization">正则化</h2>

<p>若用形如$\tanh$的转换函数，神经网络的$d_{VC}=O(VD)$，$V$为神经元数量，$D$为神经元之间的权值数量。当神经元数目足够时，可以做任意逼近，也更容易导致过拟合。为了避免过拟合，需要采取正则化方法。</p>

<h4 id="regularization-weighted-methods">一、weight-elimination正则化</h4>

<p>常用的方法是基于$L_2$的weight-decay正则化，$\Omega(\mathbf w)=\sum\left(w_{ij}^{(\ell)}\right)^2$。这种正则化对权值的压缩（shrink）力度和权值大小“成比例”，大的权值压缩厉害，小的权值压缩较小。</p>

<p>如果通过正则化使权值部分为0（稀疏），就能有效减小$d_{VC}$，常用的方法是$L_1$正则化，$\Omega(\mathbf w)=\sum\left\lvert w_{ij}^{(\ell)}\right\rvert$，但是不可微。采用weight-elimination正则化（放缩的$L_2$正则化），大的权值中等幅度的压缩（median shrink），小的权值也中等幅度的压缩，小的权值就会接近0，具有权值稀疏化的效果。weight-elimination正则化采用
\begin{equation}
\Omega(\mathbf w)=\sum{\left(w_{ij}^{(\ell)}\right)^2\over 1+\left(w_{ij}^{(\ell)}\right)^2}，
\end{equation}
那么
\[
{\partial\Omega(\mathbf w)\over \partial w_{ij}^{(\ell)}}
={2w_{ij}^{(\ell)}\over\left(1+\left(w_{ij}^{(\ell)}\right)^2\right)^2}。
\]</p>

<h4 id="regularization-early-stopping">二、尽早停止迭代</h4>

<div class="image_line" id="figure-7"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-early-stopping.png"><img src="/assets/images/2015-02-04-neural-network-early-stopping.png" alt="迭代次数对误差的影响" /></a><div class="caption">图 7:  迭代次数对误差的影响 [<a href="/assets/images/2015-02-04-neural-network-early-stopping.png">PNG</a>]</div></div></div>

<p>迭代的次数$t$越多，选择过的$\mathbf w$也就越多，有效的$d_{VC}$也越大。小的$t$使得$d_{VC}$也较小。尽早停止（early stopping）迭代，通过如上图右的最佳$t^*$，获得如上图左的最佳$d_{VC}^*$，克服过拟合。通过验证（validation）确定停止迭代的参数$t$。</p>

<p>所有和梯度有关的优化算法，都可利用尽早停止迭代的机制，实现某种正则化。</p>

<h2 id="section-2">程序示例</h2>

<div class="highlight"><pre><code class="language-R">nnet_train <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>X<span class="p">,</span> Y<span class="p">,</span> struct<span class="p">,</span> r<span class="p">,</span> eta<span class="p">,</span> TT<span class="p">)</span> <span class="p">{</span>
  <span class="c1"># X -- a matrix with each feature row </span>
  <span class="c1"># Y -- a matrix </span>
  <span class="c1"># struct -- a vector with neuron number of each layer, including the input layer</span>
  <span class="c1"># r -- initialization range</span>
  <span class="c1"># eta -- learning rate</span>
  <span class="c1"># TT -- iteration times</span>
  
  X <span class="o">&lt;-</span> <span class="kp">cbind</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> X<span class="p">)</span>
  num_data <span class="o">&lt;-</span> <span class="kp">nrow</span><span class="p">(</span>X<span class="p">)</span>
  num_layer <span class="o">&lt;-</span> <span class="kp">length</span><span class="p">(</span>struct<span class="p">)</span> 
  nnetwork <span class="o">&lt;-</span> Xs <span class="o">&lt;-</span> Deltas <span class="o">&lt;-</span> <span class="kt">list</span><span class="p">()</span>
  
  <span class="c1"># initialization</span>
  <span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span> <span class="o">:</span> <span class="p">(</span>num_layer <span class="o">-</span> <span class="m">1</span><span class="p">))</span> <span class="p">{</span>
    nnetwork<span class="p">[[</span>i<span class="p">]]</span> <span class="o">&lt;-</span> <span class="kt">matrix</span><span class="p">(</span>runif<span class="p">((</span>struct<span class="p">[</span>i<span class="p">]</span> <span class="o">+</span> <span class="m">1</span><span class="p">)</span> <span class="o">*</span> struct<span class="p">[</span>i <span class="o">+</span> <span class="m">1</span><span class="p">],</span> <span class="o">-</span>r<span class="p">,</span> r<span class="p">),</span>
                            struct<span class="p">[</span>i<span class="p">]</span> <span class="o">+</span> <span class="m">1</span><span class="p">,</span> struct<span class="p">[</span>i <span class="o">+</span> <span class="m">1</span><span class="p">])</span>
  <span class="p">}</span>
  
  <span class="kr">for</span> <span class="p">(</span>t <span class="kr">in</span> <span class="m">1</span> <span class="o">:</span> TT<span class="p">)</span> <span class="p">{</span>
    n <span class="o">&lt;-</span> <span class="kp">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span>num_data<span class="p">,</span> <span class="m">1</span><span class="p">)</span>
    
    <span class="c1"># forward</span>
    Xs<span class="p">[[</span><span class="m">1</span><span class="p">]]</span> <span class="o">&lt;-</span> <span class="kp">t</span><span class="p">(</span>X<span class="p">[</span>n<span class="p">,,</span>drop <span class="o">=</span> <span class="bp">F</span><span class="p">])</span>
    <span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> <span class="m">2</span> <span class="o">:</span> num_layer<span class="p">)</span> <span class="p">{</span>
      xx <span class="o">&lt;-</span> <span class="kp">tanh</span><span class="p">(</span><span class="kp">t</span><span class="p">(</span><span class="kp">t</span><span class="p">(</span>Xs<span class="p">[[</span>i <span class="o">-</span> <span class="m">1</span><span class="p">]])</span> <span class="o">%*%</span> nnetwork<span class="p">[[</span>i <span class="o">-</span> <span class="m">1</span><span class="p">]]))</span>
      <span class="kp">ifelse</span><span class="p">(</span>i <span class="o">!=</span> num_layer<span class="p">,</span> Xs<span class="p">[[</span>i<span class="p">]]</span> <span class="o">&lt;-</span> <span class="kp">rbind</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> xx<span class="p">),</span> Xs<span class="p">[[</span>i<span class="p">]]</span> <span class="o">&lt;-</span> xx<span class="p">)</span>
    <span class="p">}</span>
    
    <span class="c1"># backward</span>
    <span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> num_layer <span class="o">:</span> <span class="m">2</span><span class="p">)</span> <span class="p">{</span>
      <span class="kp">ifelse</span><span class="p">(</span>i <span class="o">==</span> num_layer<span class="p">,</span>
             Deltas<span class="p">[[</span>i<span class="p">]]</span> <span class="o">&lt;-</span> 
               <span class="m">-2</span> <span class="o">*</span> <span class="p">(</span><span class="kp">t</span><span class="p">(</span>Y<span class="p">[</span>n<span class="p">,,</span>drop<span class="o">=</span><span class="bp">F</span><span class="p">])</span> <span class="o">-</span> Xs<span class="p">[[</span>i<span class="p">]])</span> <span class="o">*</span> <span class="p">(</span><span class="m">1</span> <span class="o">-</span> Xs<span class="p">[[</span>i<span class="p">]]</span> <span class="o">^</span> <span class="m">2</span><span class="p">),</span>
             Deltas<span class="p">[[</span>i<span class="p">]]</span> <span class="o">&lt;-</span> 
               <span class="p">((</span>nnetwork<span class="p">[[</span>i<span class="p">]]</span> <span class="o">%*%</span> Deltas<span class="p">[[</span>i <span class="o">+</span> <span class="m">1</span><span class="p">]])</span> <span class="o">*</span>
                  <span class="p">(</span><span class="m">1</span> <span class="o">-</span> Xs<span class="p">[[</span>i<span class="p">]]</span> <span class="o">^</span> <span class="m">2</span><span class="p">))[</span><span class="m">2</span><span class="o">:</span><span class="kp">nrow</span><span class="p">(</span>nnetwork<span class="p">[[</span>i<span class="p">]]),,</span>drop<span class="o">=</span><span class="bp">F</span><span class="p">])</span>
    <span class="p">}</span>
    
    <span class="c1"># update weight</span>
    <span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span> <span class="o">:</span> <span class="p">(</span>num_layer <span class="o">-</span> <span class="m">1</span><span class="p">))</span> <span class="p">{</span>
      nnetwork<span class="p">[[</span>i<span class="p">]]</span> <span class="o">&lt;-</span> nnetwork<span class="p">[[</span>i<span class="p">]]</span> <span class="o">-</span> eta <span class="o">*</span> Xs<span class="p">[[</span>i<span class="p">]]</span> <span class="o">%*%</span> <span class="kp">t</span><span class="p">(</span>Deltas<span class="p">[[</span>i <span class="o">+</span> <span class="m">1</span><span class="p">]])</span>
    <span class="p">}</span>
    
  <span class="p">}</span>
  <span class="kr">return</span><span class="p">(</span>nnetwork<span class="p">)</span>
<span class="p">}</span></code></pre></div>

<h2 id="section-3">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:five-input-xor">
      <p>如果用神经网络实现$XOR(x_1,\dots,x_5)$，采用结构为5-D-1，那么<a href="https://class.coursera.org/ntumltwo-001/forum/thread?thread_id=243">最小的D</a>是多少？ <a href="#fnref:five-input-xor" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:tanh_output">
      <p>对于二分类问题的神经网络，输出为$\{-1,+1\}$，输出层的神经元也要采用$\tanh$，此时$e_n=\left(y_n-\tanh\left(s_1^{(L)}\right)\right)^2$，那么$\delta_1^{(L)}=-2\left(y_n-x_1^{(L)}\right)\left(1-\left(x_1^{(L)}\right)^2\right)$。 <a href="#fnref:tanh_output" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（6）：融合模型总结</title>
      <link href="http://qianjiye.de/2015/02/summary-of-aggregation-models" />
      <pubdate>2015-02-04T13:39:58+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/summary-of-aggregation-models</guid>
      <content:encoded>&lt;![CDATA[<h4 id="section">一、分类器融合策略</h4>

<table>
  <thead>
    <tr>
      <th>融合类型</th>
      <th>混合（blending）</th>
      <th>学习（learning）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-equniform-blending-hypothesis">均匀</a>（uniform）</td>
      <td>voting／averaging</td>
      <td>Bagging</td>
    </tr>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-eqlinear-blending-hypothesis">非均匀</a>（non-uniform）</td>
      <td>linear</td>
      <td>AdaBoost</td>
    </tr>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-eqconditional-blending-hypothesis">有条件</a>（conditional）</td>
      <td>stacking</td>
      <td>Decision Tree</td>
    </tr>
  </tbody>
</table>

<p>对于非均匀和条件融合，$g_t$可以视为特征转换。</p>

<p>混合（blending）方法是选择了不同的$g_t$之后再融合，学习（learning）方法是在选择（学习）不同$g_t$的同时进行融合。</p>

<p>均匀融合性能比较稳定，不同$g_t$相互修正，类似正则化的中庸思想。非均匀和条件融合，学习之上的再学习过程，增加了复杂度，功能强大，存在更大的过拟合风险。</p>

<h4 id="section-1">二、基于学习机制的分类器融合方法对比</h4>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>获取不同$g_t$的方法</th>
      <th>融合策略</th>
      <th>优化算法</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Bagging</td>
      <td>bootstrapping</td>
      <td>uniform vote</td>
      <td> </td>
    </tr>
    <tr>
      <td>AdaBoost</td>
      <td>reweighting</td>
      <td>linear vote</td>
      <td>steepest search</td>
    </tr>
    <tr>
      <td>GradientBoost</td>
      <td>residual fitting</td>
      <td>linear vote</td>
      <td>steepest search</td>
    </tr>
    <tr>
      <td>Decision Tree</td>
      <td>data splitting</td>
      <td>conditional vote</td>
      <td>branching</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>random forest = randomized bagging + strong DTree;</li>
  <li>AdaBoost-DTree = AdaBoost + weak DTree;</li>
  <li>GBDT = GradientBoost + weak DTree.</li>
</ul>

<p>boosting系列的算法应用非常广泛。</p>

<h4 id="section-2">三、融合机制的双重性</h4>

<div class="image_line" id="aggregation-performance"><div class="image_card"><a href="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png"><img src="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png" alt="［左］：融合解决欠拟合；［右］：融合解决过拟合" /></a><div class="caption">图 1:  ［左］：融合解决欠拟合；［右］：融合解决过拟合 [<a href="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png">PNG</a>]</div></div></div>

<ol>
  <li>融合可以解决欠拟合问题。单一的$g_t$能力较弱，通过AdaBoost或GradientBoost的方法得到强大的$G(\mathbf x)$。融合相当于利用了特征转换的功能。</li>
  <li>融合可以解决过拟合问题。通过融合可以得到中庸（moderate）的$G(\mathbf x)$。融合相当于利用了正则化的功能，如上图右的large-margin效果。</li>
</ol>

<p>因此，合适的融合（aggregation or ensemble）机制可以提升分类器的性能。</p>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（5）：梯度提升决策树</title>
      <link href="http://qianjiye.de/2015/01/gradient-boosted-decision-tree" />
      <pubdate>2015-01-29T16:12:28+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/gradient-boosted-decision-tree</guid>
      <content:encoded>&lt;![CDATA[<h2 id="adaboost">AdaBoost决策树</h2>

<blockquote>
  <h4 id="adaboost-dtreemathcal-d">AdaBoost-DTree($\mathcal D$)</h4>
  <hr />
  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>更新数据的权重$\mathbf u^{(t)}$；</li>
    <li>通过决策树算法$\mbox{DTree}\left(\tilde{\mathcal D}, \mathbf u^{(t)}\right)$得到$g_t$；</li>
    <li>计算$g_t$的投票权重$\alpha_t$。</li>
  </ol>

  <p>返回$G=\mbox{LinearHypo}(\{\left(g_t,\alpha_t\right)\})$。</p>
</blockquote>

<p>由此可见，AdaBoost决策树需要加权决策树算法。对于有权重的算法，需要根据权重最小化$E_{in}$，通常有两种方法：</p>

<ul>
  <li>一种方法是通过算法加权，在计算$E_{in}$的地方嵌入权重计算，比如AdaBoost采用的最小化<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqweighted-Ein">加权误差</a>；</li>
  <li>另一种方法是将算法当成黑盒不变更，通过数据集加权，根据权重在bootstrap时“复制”数据，也就是加权的重采样。</li>
</ul>

<p>AdaBoost决策树通常采用后一种方法，AdaBoost＋sampling $\propto \mathbf u^{(t)}$＋$\mbox{DTree}(\tilde{\mathcal D}_t)$。</p>

<p>AdaBoost的<a href="/2015/01/adaptive-boosting/#AdaBoost-algorithm">$\alpha_t$通过错误率确定</a>。对于所有$\mathbf x_n$不同的完全成长决策树，$E_{in}(g_t)=0$，那么$E_{in}^{\mathbf u}(g_t)=0$，因此$\epsilon_t=0$并且$\alpha_t=\infty$。合适的方法是让决策树弱些，在部分数据集上训练剪枝的决策树。即使在$\tilde{\mathcal D}_t$上得到错误率为0的决策树$g_t$，回到$\mathcal D$上$\alpha_t$可能是大于、等于或小于0。剪枝可采用常规方法或只限制决策树高度，在数据重采样阶段已经包含了只抽取部分数据的功能。因此，AdaBoost决策树＝AdaBoost＋sampling $\propto \mathbf u^{(t)}$＋剪枝的$\mbox{DTree}(\tilde{\mathcal D}_t)$。</p>

<p>如果C&amp;RT的高度限制为不超过1，当用二分类的误差作为<a href="/2015/01/decision-tree/#mjx-eqn-eqdtree-decision-stump">不纯度</a>时，AdaBoost决策树就是<a href="/2015/01/adaptive-boosting/#AdaBoost-Stump">AdaBoost-Stump</a>，此时通常有$\epsilon_t\neq 0$，一般不再需要sampling。</p>

<h2 id="functional-gradient-steepest-descent">AdaBoost理论分析：最速函数梯度下降法</h2>

<p>AdaBoost的<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqadaboost-update-u">权重更新</a>可以合并为
\[
u_n^{(t+1)}=u_n^{(t)}\cdot\blacklozenge_t^{-y_ng_t(\mathbf x_n)}，
\]
由于$\blacklozenge_t=\exp(\alpha_t)$，因此
\[
u_n^{(t+1)}=u_n^{(t)}\cdot\exp\left(-y_n\alpha_tg_t\left(\mathbf x_n\right)\right)，
\]
那么
\begin{equation}
u_n^{(T+1)}=u_n^{(1)}\cdot\prod_{t=1}^T\exp\left(-y_n\alpha_tg_t\left(\mathbf x_n\right)\right)={1\over N}\exp\left(-y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)\right)。
\label{eq:un-t-plus-1}
\end{equation}
AdaBoost是<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqadaboost-Gx">分类器的线性组合</a>，$\sum_{t=1}^T\alpha_tg_t(\mathbf x)$是$\{g_t\}$在$\mathbf x$上的投票得分（voting score），也就是对AdaBoost，$u_n^{(T+1)}\propto \exp\left(-y_n\cdot\left(\mbox{voting score on }\mathbf x_n\right)\right)$。</p>

<p id="decrease-un">线性混合（linear blending），可以看作线性模型和以假设作为特征转换的结合
\[
G(\mathbf x_n)=\mbox{sign}\left(\overbrace{\sum_{t=1}^T\underbrace{\alpha_t}_{w_i}\underbrace{g_t(\mathbf x_n)}_{\phi_i(\mathbf x_n)}}^{\mbox{voting score}}\right)。
\]
对比<a href="/2015/01/linear-svm/#mjx-eqn-eqhard-margin-svm-origin-model">hard-margin的SVM</a>的边界${y_n\cdot\left(\mathbf w^T\phi(\mathbf x_n)+b\right)\over\lVert\mathbf w\rVert}$，投票得分可视为某种空间中非规范化的边界（距离）的度量，“$y_n$(voting score)=signed &amp; unnormalized margin”。期望$y_n$(voting score)是正的，且越大越好，那么$\exp(-y_n(\mbox{voting score}))$越小越好，$u_n^{(T+1)}$越小越好。AdaBoost的$\sum_{n=1}^Nu_n^{(t)}$随着$t$的增大越来越小，在最后一轮
\begin{equation}
\sum_{n=1}^Nu_n^{(T+1)}={1\over N}\sum_{n=1}^N\exp\left(-y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)\right)
\label{eq:sum-un-t-plus-1}
\end{equation}
达到最小，边界$y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)$最大化实现large margin的效果。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png"><img src="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png" alt="AdaBoost的误差界" /></a><div class="caption">图 1:  AdaBoost的误差界 [<a href="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png">PNG</a>]</div></div></div>

<p>令线性评分函数$s=\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)$，AdaBoost的指数误差度量（exponential error measure）$\widehat{err}_{ADA}(s,y)=\exp(-ys)$是0/1误差$\widehat{err}_{0/1}(s,y)=[[ys\leq 1]]$的上界<sup id="fnref:other-error-bounds"><a href="#fn:other-error-bounds" class="footnote">1</a></sup>，如上图右所示，通过0/1误差的凸上界（convex upper bound）$\widehat{err}_{ADA}$作为算法误差度量（algorithmic error measure），通过上界误差最小化使0/1误差最小化。</p>

<p>AdaBoost通过增加函数$h(\mathbf x)$的方式，使基于\eqref{eq:sum-un-t-plus-1}的误差$\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t+1)}$最小化，
\begin{equation}
\begin{aligned}
\min_h\quad\widehat E_{ADA}
&amp;\overset{[1]}{=}{1\over N}\sum_{n=1}^N\exp\left(-y_n\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n)\right)\right)\\
&amp;\overset{[2]}{=}\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta h(\mathbf x_n)\right)
\overset{\mbox{taylor}}{\approx}\sum_{n=1}^Nu_n^{(t)}\left(1-y_n\eta h(\mathbf x_n)\right)\\
&amp;=\sum_{n=1}^Nu_n^{(t)}+\eta\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)，
\end{aligned}
\label{eq:min-E-ADA}
\end{equation}</p>

<ul>
  <li>[1]：增加函数$h(\mathbf x)$，由\eqref{eq:sum-un-t-plus-1}可得$\sum_{\tau=1}^t\alpha_\tau g_\tau\left(\mathbf x_n\right)=\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\left(\mathbf x_n\right)+\eta h(\mathbf x_n)$；</li>
  <li>[2]：由\eqref{eq:un-t-plus-1}可得$u_n^{(t)}={1\over N}\exp\left(-y_n\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\left(\mathbf x_n\right)\right)$。</li>
</ul>

<p>公式\eqref{eq:min-E-ADA}形如<a href="/2015/01/logistic-regression/#mjx-eqn-eqtaylor-expansion-Ein">梯度下降法最小化$E_{in}$</a>
\[
\min_{\lVert\mathbf v\rVert=1}E_{in}(\mathbf w_t+\eta\mathbf v)
\approx \underbrace{E_{in}(\mathbf w_t)}_{\mbox{known}}
+\underbrace{\eta}_{\mbox{given positive}}\mathbf v^T\underbrace{\nabla E_{in}(\mathbf w_t)}_{\mbox{known}}，
\]
好的$h(\mathbf x)$能最小化$\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)$。对二分类，$y_n$和$h(\mathbf x_n)$都属于$\{-1,+1\}$，那么
\[
\begin{aligned}
\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)
&amp;=\sum_{n=1}^Nu_n^{(t)}
\left\{
\begin{aligned}
-1\quad\mbox{if }y_n=h(\mathbf x_n)\\
+1\quad\mbox{if }y_n\neq h(\mathbf x_n)
\end{aligned}
\right.\\
&amp;=-\sum_{n=1}^Nu_n^{(t)}+\sum_{n=1}^Nu_n^{(t)}
\left\{
\begin{aligned}
0\quad\mbox{if }y_n=h(\mathbf x_n)\\
2\quad\mbox{if }y_n\neq h(\mathbf x_n)
\end{aligned}
\right.\\
&amp;\overset{[1]}{=}-\sum_{n=1}^Nu_n^{(t)}+2E_{in}^{\mathbf u^{(t)}}(h)\cdot N，
\end{aligned}
\]</p>

<ul>
  <li>[1]：根据<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqweighted-Ein">AdaBoost的$E_{in}^\mathbf u$计算可得</a>。</li>
</ul>

<p>因此，也就是要使$E_{in}^{\mathbf u^{(t)}}(h)$变小，这就是AdaBoost中算法$\mathcal A$的任务，找出一个好的函数方向$h$。</p>

<p>AdaBoost通过近似最小化$\min_h\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta h(\mathbf x_n)\right)$，公式\eqref{eq:min-E-ADA}的$[2]$等式，找到新的分类器$g_t=h$之后，还需要找到最佳的$\eta$，
\[
\min_\eta\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta g_t(\mathbf x_n)\right)，
\]
$\eta$越大步越好。最佳的$\eta_t$会比固定的$\eta$在短期内下降更快（greedily faster），在最优化中通常称为<strong>最速（最陡）下降</strong>（steepest descent）。对于分类正确和错误两种情形，$u_n^{(t)}\exp\left(-y_n\eta g_t(\mathbf x_n)\right)$分别为$u_n^{(t)}\exp(-\eta)$和$u_n^{(t)}\exp(+\eta)$，那么有
\[
\widehat E_{ADA}=\left(\sum_{n=1}^Nu_n^{(t)}\right)\cdot
\left(
(1-\epsilon_t)\exp(-\eta)+\epsilon_t\exp(+\eta)
\right)，
\]
$\epsilon_t$表示<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqepsilon-t">错误率</a>。
通过${\partial\widehat E_{ADA}\over\partial\eta}=0$可得最速梯度步长$\eta_t=\ln\sqrt{1-\epsilon_t\over\epsilon_t}=\alpha_t$。当进行到$t+1$轮迭代时，误差为
\[
\widehat E_{ADA}^{(t+1)}=\widehat E_{ADA}^{(t)}\cdot\left(
(1-\epsilon_t)\exp(-\eta_t)+\epsilon_t\exp(+\eta_t)
\right)，
\]
将$\eta_t$和$\widehat E_{ADA}^{(1)}=\sum_{n=1}^Nu_n^{(1)}=1$带入可得
\[
\widehat E_{ADA}^{(t+1)}=\prod_{\tau=1}^{t}\left(2\sqrt{\epsilon_\tau(1-\epsilon_\tau)}\right)。
\]
由此可见，最糟糕的情况是当$\epsilon_t={1\over 2}$时（错误率$\epsilon_t$始终小于正确率$1-\epsilon_t$），$\widehat E_{ADA}^{(t+1)}$不减少，否则$\widehat E_{ADA}^{(t+1)}$随着迭代增加不断减少。</p>

<p>因此，AdaBoost是近似的函数梯度（functional gradient）最速下降法。</p>

<h2 id="section">任意误差函数的梯度提升</h2>

<p>AdaBoost可以表示为最优化的形式
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^N\exp\left(-y_n\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n)\right)\right)，
\end{equation}
每一轮找到$h$作为$g_t$，并决定该$g_t$要前进的距离$\eta_t$。利用更一般的误差函数，将AdaBoost推广到GradientBoost
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^Nerr\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n),y_n\right)。
\end{equation}
GradientBoost分为两步：（1）确定$h$；（2）确定$\eta$。由于要采用梯度下降法，需要平滑的误差函数$err$，$h$也不限于二分类，可以推广到实数输出。通过采用不同的误差函数$err$，GradientBoost可实现回归、soft分类等功能。</p>

<h2 id="section-1">梯度提升决策树</h2>

<p>对于回归问题，采用误差函数$err(s,y)=(s-y)^2$，令$s_n=\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)$可得
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^N\left(s_n+
\eta h(\mathbf x_n)-y_n\right)^2，
\label{eq:min-gradientboost-regression-Ein}
\end{equation}
内层最小化
\[
\begin{aligned}
\min_h\ldots
&amp;\overset{\mbox{taylor}}{\approx}\min_h\left({1\over N}\sum_{n=1}^N\underbrace{err(s_n,y_n)}_{\mbox{constant}}+{1\over N}\sum_{n=1}^N\eta h(\mathbf x_n)\left.{\partial err(s,y_n)\over\partial s}\right\rvert_{s=s_n}\right)\\
&amp;\overset{\quad\quad}{=}\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N2h(\mathbf x_n)(s_n-y_n)\right)。
\end{aligned}
\]
<del>如果对$h$无约束条件，那么$h(\mathbf x_n)=-\infty\cdot(s_n-y_n)$时取最小值。</del>事实上，只需要$h$的方向，$h$的大小（magnitude）通过步长$\eta$控制。利用拉格朗日乘子法的思想，避免求解复杂的约束优化问题，惩罚大的$h$
\[
\begin{aligned}
&amp;\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N\left(2h(\mathbf x_n)(s_n-y_n)+(h(\mathbf x_n))^2\right)\right)\\
\Longleftrightarrow&amp;\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N\left(\mbox{constant}+(h(\mathbf x_n)-(y_n-s_n))^2\right)\right)。
\end{aligned}
\]
去掉常数项，带惩罚的近似函数梯度是数据集$\{(\mathbf x_n,y_n-s_n)\}$上，基于平方误差的回归。$y_n-s_n$表示期望的值与目前能达到的值之间的差异，表示尚未达到的部分，称为余数（residual）。好的$h(\mathbf x_n)$需要弥补余数的差距。</p>

<p>［1/2］因此，GradientBoost的回归问题就是通过余数上的回归找到$g_t=h$。</p>

<p>当$g_t$确定后，继续\eqref{eq:min-gradientboost-regression-Ein}的外层最小化
\[
\min_\eta{1\over N}\sum_{n=1}^N(s_n+\eta g_t(\mathbf x_n)-y_n)^2\Leftrightarrow\min_\eta{1\over N}\sum_{n=1}^N((y_n-s_n)-\eta g_t(\mathbf x_n))^2，
\]
这是单变量的线性回归，非常容易求解，
\begin{equation}
\eta={\sum_{n=1}^Ng_t(\mathbf x_n)(y_n-s_n)\over\sum_{n=1}^Ng_t^2(\mathbf x_n)}。
\label{eq:gbdt-eta}
\end{equation}</p>

<p>［2/2］因此，GradientBoost的回归问题通过单变量回归求解最优作为步长$\alpha_t=\eta$。</p>

<blockquote>
  <h4 id="gbdtgradient-boosted-decision-tree">梯度提升决策树（GBDT，gradient boosted decision tree）</h4>
  <hr />
  <p>初始化$s_1=s_2=\ldots=s_N=0$；</p>

  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>利用$\mathcal A(\{(\mathbf x_n,y_n-s_n)\})$得到$g_t$，其中$\mathcal A$是基于平方误差的回归算法（例如C&amp;RT）；</li>
    <li>利用\eqref{eq:gbdt-eta}更新步长$\alpha_t=\mbox{OneVarLinearRegression}(\{(g_t(\mathbf x_n),y_n-s_n)\})$；</li>
    <li>更新$s_n\leftarrow s_n+\alpha_tg_t(\mathbf x_n)$；</li>
  </ol>

  <p>返回$G(\mathbf x)=\sum_{t=1}^T\alpha_tg_t(\mathbf x)$。</p>
</blockquote>

<p>GBDT就是AdaBoost决策树的回归版本。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:other-error-bounds">
      <p><a href="/2015/01/linear-models-for-classification/#error-bound">其它误差界</a>可参考线性分类模型的相关资料。 <a href="#fnref:other-error-bounds" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习三原则</title>
      <link href="http://qianjiye.de/2015/01/three-learning-principles" />
      <pubdate>2015-01-28T20:05:37+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/three-learning-principles</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">使用奥卡姆剃刀</h2>

<blockquote>
  <p>An explanation of the data should be made as simple as possible, but no simpler.         <br />
—Albert Einstein? (1879-1955)</p>

  <hr />

  <p>entia non sunt multiplicanda praeter necessitatem (entities must not be multiplied beyond necessity)       <br />
—William of Occam (1287-1347) </p>
</blockquote>

<p>奥卡姆剃刀（Occam’s rezor）：剃掉不必要的解释。对机器学习，适合数据的最简单模型也是最合理的模型。</p>

<ul>
  <li>简单的假设$h$：小的$\Omega(h)$，假设的参数少；</li>
  <li>简单的模型$\mathcal H$：小的$\Omega(\mathcal H)$，包含较少的假设，成长函数增长很慢。</li>
</ul>

<p>当$\Omega(\mathcal H)$小时，$\Omega(h)$也小。当假设集大小为$2^\ell$时，每个假设最多有$\ell$个参数<sup id="fnref:why-ell-parameters"><a href="#fn:why-ell-parameters" class="footnote">1</a></sup>。在实际应用中，通过正则化或从简单模型开始尝试，都可以得到简单的假设。</p>

<p>对于简单模型，$m_\mathcal H(N)$小，难以将数据拟合好（拟合好的概率为$m_{\mathcal H}(N)\over 2^N$<sup id="fnref:why-ration"><a href="#fn:why-ration" class="footnote">2</a></sup>）。对简单的模型，如果数据被分开，那么数据是规律的；对于复杂的模型，如果数据能分开，就不能判断数据是否有规律（复杂模型能把任何数据分开）。</p>

<p>在实际应用中，从简单的线性模型开始尝试，经常考量数据是否被模型过度表示（data over-modeled）。</p>

<h2 id="section-1">避免抽样偏差</h2>

<p>如果数据通过有偏抽样得到<a href="#Darrell_Huff_2002">[1]</a>，学习到的结果也是有偏的。</p>

<p>若从$P_1(\mathbf x,y)$的数据中学习，却在$P_2\neq P_1$的数据中测试，VC理论不适用。相当于学了数学却要参加英语考试。VC理论的前提是训练和测试数据都iid来自同一分布。</p>

<p>通过信用卡用户的信用记录，判断是否给新顾客信用卡。——由于没有未开通信用卡用户的信息，这两者分布可能很不一样……</p>

<p>在实际应用中，尽可能的了解测试环境，使训练环境和测试环境尽量一致。</p>

<h2 id="no-snooping">绝不偷看数据</h2>

<blockquote>
  <p>If you torture the data long enough, it will confess.</p>
</blockquote>

<p>使用数据的任何过程都相当于间接偷看了数据。为了让VC维可靠，选择$\Phi$时不应当<a href="/2015/01/nonlinear-transformation/#human-learning">偷看数据</a>。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png"><img src="/assets/images/2015-01-28-three-learning-principles-snoop-data.png" alt="简单的偷看也会导致结果偏差很大" /></a><div class="caption">图 1:  简单的偷看也会导致结果偏差很大 [<a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png">PNG</a>]</div></div></div>

<p>对使用同样数据集$\mathcal D$的论文，后来作者针对以前论文改进，阅读以前论文也就相当于偷看资料。若把这些论文看成一篇长长的论文，付出的模型复杂度为$d_{VC}(\cup_m\mathcal H_m)$，泛化能力差。</p>

<p>偷看数据很难避免，合理处理偷看数据：</p>

<p><img src="/assets/images/2015-01-28-three-learning-principles-deal-with-snooping.png" alt="合理处理偷看数据" /></p>

<p>“be blind”是指尽量避免用数据做决定，不要在看了数据之后再决定采用什么样的特征等操作。也就是避免human learning的复杂度进入。</p>

<h2 id="section-2">其它三原则</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-tools.png" alt="三大工具" /></a><div class="caption">图 2:  三大工具 [<a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png" alt="三大理论边界" /></a><div class="caption">图 3:  三大理论边界 [<a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png">PNG</a>]</div></div></div>

<h2 id="section-3">参考资料</h2>

<ol class="bibliography"><li><span id="Darrell_Huff_2002">[1]达莱尔·哈夫, <i>统计陷阱</i>. 上海: 上海财经大学出版社, 2002.</span>

</li></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-ell-parameters">
      <p>为什么最多$\ell$个参数？ <a href="#fnref:why-ell-parameters" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-ration">
      <p>这个比率什么意思？ <a href="#fnref:why-ration" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>验证</title>
      <link href="http://qianjiye.de/2015/01/validation" />
      <pubdate>2015-01-27T23:28:10+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/validation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">模型选择问题</h2>

<p>若有$M$个<a href="/assets/images/2015-01-27-validation-so-many-models.png">候选模型</a>$\mathcal H_1,\mathcal H_2,\ldots,\mathcal H_M$和相应的算法$\mathcal A_1,\mathcal A_2,\ldots,\mathcal A_M$，如何选择$\mathcal H_{m^*}$使得$g_{m^*}=\mathcal A_{m^*}(\mathcal D)$有低的$E_{out}(g_{m^*})$？</p>

<p>由于$P(\mathbf x)$和$P(y|\mathbf x)$未知，那么$E_{out}$未也知……</p>

<h4 id="section-1">一、利用数据可视化不可行</h4>

<p>只有一些数据集……基于视觉化的选择是“<a href="/2015/01/nonlinear-transformation/#human-learning">human learning</a>”，并且高维度的数据不能视觉化。</p>

<h4 id="ein">二、利用$E_{in}$很危险</h4>

<p>如果利用$E_{in}$选择，高维特征变换通常犹豫低维，非正则化方法通常优于正则化方法。若$\mathcal A_1$在$\mathcal H_1$最小化$E_{in}$，$\mathcal A_2$在$\mathcal H_2$最小化$E_{in}$，二者再择优$g_{m^*}$在$\mathcal H_1\cup\mathcal H_2$中得到最小的$E_{in}$，这样增加了额外的模型复杂度，VC维$d_{VC}(\mathcal H_1\cup\mathcal H_2)$变大了，泛化能力差。</p>

<h4 id="etest">三、利用$E_{test}$是作弊</h4>

<p>根据finite-bin Hoeffding可得
\[
E_{out}(g_{m^*})\leq E_{test}(g_{m^*})+O\left(\sqrt{\log M\over N_{test}}\right)，
\]
看上去很美，$\mathcal D_{test}$是没用于模型训来的干净数据，可是$\mathcal D_{test}$（相当于老师的考卷）从哪里来呢？</p>

<h4 id="einetesteval">四、$E_{in}$和$E_{test}$折中的合法作弊方案$E_{val}$</h4>

<ul>
  <li>$\mathcal D_{val}\subset\mathcal D$；</li>
  <li>可以获取的；</li>
  <li>若$\mathcal D_{val}$没用于$\mathcal A_m$，那么它是干净的，就像测试数据一样。</li>
</ul>

<h2 id="section-2">单一验证集</h2>

<p>数据$\mathcal D$的划分和相应关系如下：</p>

<p>\begin{align*}
E_{in}(h)\quad&amp;\quad&amp;\quad&amp;\quad &amp;E_{val}(h)\\
\uparrow\quad\quad&amp;\quad&amp;\quad&amp;\quad &amp;\uparrow\;\;\,\,\\
\quad\underbrace{\mathcal D}_{\mbox{size }N}\quad\,&amp;\rightarrow&amp;\underbrace{\mathcal D_{train}}_{\mbox{size }N-K}\quad\quad\,&amp;\cup&amp;\underbrace{\mathcal D_{val}}_{\mbox{size }K}\;\\
\downarrow\quad\quad&amp;\quad &amp;\downarrow\quad\quad\quad\;&amp;\quad&amp;\quad\\
g_m=\mathcal A_m(\mathcal D)&amp;\quad &amp;g_m^-=\mathcal A_m(\mathcal D_{trian})&amp;\quad&amp;\quad
\end{align*}</p>

<p>$\mathcal D_{val}\subset\mathcal D$称为<strong>验证集</strong>（validation set），用于模拟测试集。$\mathcal D_{val}$是随机从$\mathcal D$中抽取的$K$个样本，那么$\mathcal D_{val}\overset{iid}{\sim} P(\mathbf x,y)$，通过数据建立了$E_{val}$与$E_{out}$的联系。确保$\mathcal D_{val}$是干净的，$\mathcal A_m$只使用了$\mathcal D_{train}$进行模型选择（也就是训练得到模型参数，从$\mathcal H$中选出$h$）。</p>

<p>原来使用$\mathcal D$扮演两个角色，既要计算$E_{in}$进行模型选择，又要通过算法得到$g$，两个角色导致资料被污染。利用$D_{val}$，通过最佳$E_{val}$进行模型选择
\[
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{val}(\mathcal A_m(\mathcal D_{train})))，
\]
可得如下误差保证
\begin{equation}
E_{out}(g_m^-)\leq E_{val}(g_m^-)+O\left(\sqrt{\log M\over K}\right)，
\end{equation}
但是只用$N-K$个训练模型out-of-sample误差会偏大（也可从学习曲线看出，理论上若要成立，还需更严格的限制条件），
\[
E_{out}\left(\underbrace{g_{m^*}}_{\mathcal A_m^*(\mathcal D)}\right)\leq E_{out}\left(\underbrace{g_{m^*}^-}_{\mathcal A_m^*(\mathcal D_{train})}\right)，
\]
因此，
\[
E_{out}(g_{m^*})\leq E_{out}(g_{m^*}^-)\leq E_{val}(g_{m^*}^-)+O\left(\sqrt{\log M\over K}\right)。
\]</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-27-validation-model-selection.png"><img src="/assets/images/2015-01-27-validation-model-selection.png" alt="基于验证集的模型选择方案" /></a><div class="caption">图 1:  基于验证集的模型选择方案 [<a href="/assets/images/2015-01-27-validation-model-selection.png">PNG</a>]</div></div></div>

<p>模型选择整个方案如上图所示，得到$g_{m^*}^-$之后，再回到原来整个数据集上得到$g_{m^*}$效果会更好<sup id="fnref:is-it-necessary"><a href="#fn:is-it-necessary" class="footnote">1</a></sup>。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-27-validation-vlidation-example.png"><img src="/assets/images/2015-01-27-validation-vlidation-example.png" alt="模型选择的学习曲线" /></a><div class="caption">图 2:  模型选择的学习曲线 [<a href="/assets/images/2015-01-27-validation-vlidation-example.png">PNG</a>]</div></div></div>

<p>上图是在$\mathcal H_{\Phi_5}$和$\mathcal H_{\Phi_{10}}$中进行模型选择的学习曲线。$g_{m^*}$的效果要优于$g_{m^*}^-$。利用$E_{in}$总会选择到复杂的模型，利用$E_{out}$的作弊方案选择结果总最优。随着验证集不断增大，用于模型选择的训练集不断减小，所以$g_{m^*}^-$甚至会比$g_{\widehat m}$效果差，对很小的训练集，采用$E_{in}$还算不错的模型选择方案。</p>

<p>对大的验证集样本数$K$，有$E_{val}(g^-)\approx E_{out}(g^-)$，但$g_{m^*}^-$通常比$g_{m^*}$糟糕；对小的$K$，有$g_m^-\approx g_m$和$E_{out}(g)\approx E_{out}(g^-)$，但$E_{val}$和$E_{out}$差异较大；
\[
E_{out}(g)\underset{\mbox{small }K}{\approx}E_{out}(g^-)\underset{\mbox{large }K}{\approx}E_{val}(g^-)。
\]</p>

<p>从时间上看，由于部分数据当作了验证集，在训练集上选择每个模型的时间会缩短。</p>

<p>$K={N\over 5}$通常是不错的选择。</p>

<h2 id="section-3">留1交叉验证</h2>

<p>当在验证集的$K=1$的极端情况下，$g^-$和$g$就会非常接近，但$E_{out}$和$E_{val}$差异就很大。能否在$K=1$时找到方案，使得$E_{out}\approx E_{val}$？✅</p>

<p>当$K=1$时，验证集$\mathcal D_{val}^{(n)}=\{(\mathbf x_n,y_n)\}$，误差为$E_{val}^{(n)}(g_n^-)=err(g_n^-(\mathbf x_n),y_n)=e_n$，将留1交叉验证（leave-one-out cross validation）误差
\begin{equation}
E_{loocv}(\mathcal H,\mathcal A)={1\over N}\sum_{n=1}^Ne_n={1\over N}\sum_{n=1}^Nerr(g_n^-(\mathbf x_n),y_n)
\end{equation}
作为$E_{out}(g)$的近似，$E_{loocv}(\mathcal H,\mathcal A)\approx E_{out}(g)$，然后进行模型选择，
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{loocv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-example.png"><img src="/assets/images/2015-01-27-validation-loocv-example.png" alt="loocv选择常数模型而非线性模型" /></a><div class="caption">图 3:  loocv选择常数模型而非线性模型 [<a href="/assets/images/2015-01-27-validation-loocv-example.png">PNG</a>]</div></div></div>

<p>用$\underset{\mathcal D_n}{\varepsilon}$表示在训练集上的数学期望，那么有<sup id="fnref:how-expectation-do"><a href="#fn:how-expectation-do" class="footnote">2</a></sup>
\begin{aligned}
\underset{\mathcal D}{\varepsilon}E_{loocv}(\mathcal H,\mathcal A) = \underset{\mathcal D}{\varepsilon}{1\over N}\sum_{n=1}^Ne_n 
&amp;= {1\over N}\sum_{n=1}^N\underset{\mathcal D}{\varepsilon}e_n\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}\underset{(\mathbf x_n,y_n)}{\varepsilon}err(g_n^-(\mathbf x_n),y_n)\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}E_{out}(g_n^-)\\
&amp;={1\over N}\sum_{n=1}^N\overline{E_{out}}(N-1)\\
&amp;=\overline{E_{out}}(N-1)，
\end{aligned}
因此可得$E_{loocv}(\mathcal H,\mathcal A)$和$E_{out}(g^-)$联系紧密，通常称作$E_{out}(g)$几乎无偏的估计（almost unbiased estimate）。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-practice.jpg"><img src="/assets/images/2015-01-27-validation-loocv-practice.jpg" alt="loocv手写识别示例" /></a><div class="caption">图 4:  loocv手写识别示例 [<a href="/assets/images/2015-01-27-validation-loocv-practice.jpg">JPG</a>]</div></div></div>

<p>上图手写识别例子中，通过验证确定选择多少维多项式特征。若用$E_{in}$，特征维度越多越好；利用$E_{loocv}$（图中标注为$E_{cv}$），会选到较低纬度的特征。</p>

<h2 id="v-fold-cross-validation">V-fold交叉验证</h2>

<p>由于loocv需要训练$N$次，时间复杂度非常大，在实际中并不总是可行的。但也有特例，线性回归的的loocv容易计算。通过单点估计误差波动较大，结果不是很稳定，曲线上有些跳动的点。如何降低loocv的计算量？</p>

<p>将数据集$\mathcal D$随机分为$V$等份（loocv相当于将数据集分为$N$等份），$V-1$份用于训练模型，剩余的1份用于验证，这称为V-fold交叉验证，
\begin{equation}
E_{cv}(\mathcal H,\mathcal A)={1\over V}\sum_{v=1}^VE_{val}^{(v)}(g_v^-)，
\end{equation}
模型选择方式为
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{cv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<p>通常情况，$V=10$。</p>

<p>通常，V-fold交叉验证要优于单一验证集方法，计算量也更大，5-fold或10-fold通常都会工作得很好，实际中loocv并不常用。</p>

<h2 id="section-4">小结</h2>

<p>各种模型选择的关系：</p>

<ul>
  <li>模型训练（初赛）：从假设集中选择；</li>
  <li>验证方案（复赛）：从训练好的模型中选择；</li>
  <li>测试：衡量最终的表现（测试集只在此时才能使用1次）。</li>
</ul>

<p>由于资料污染，以及付出了模型复杂度代价等因素，通常验证的结果仍然会比最终测试结果乐观。因此，提交测试结果而非验证结果更客观。</p>

<h2 id="section-5">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-6">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-it-necessary">
      <p><a href="/2015/01/image-classification-knn-based-introduction/#is-validation-set-need">并不是所有的人都这样做</a>…… <a href="#fnref:is-it-necessary" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-expectation-do">
      <p>数学期望如何分离计算的？ <a href="#fnref:how-expectation-do" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
