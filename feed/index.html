<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2015-02-04T17:27:25+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>神经网络</title>
      <link href="http://qianjiye.de/2015/02/neural-network" />
      <pubdate>2015-02-04T16:15:04+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/neural-network</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">感知器融合</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png" alt="感知器的线性融合" /></a><div class="caption">图 1:  感知器的线性融合 [<a href="/assets/images/2015-02-04-neural-network-aggregation-of-perceptrons.png">PNG</a>]</div></div></div>

<p>上图展示了感知器的线性融合结构，其中包含两层的权重$\mathbf w_t$和$\boldsymbol\alpha$，还包含两层的符号函数（sign function）$g_t$和$G$。这样的融合可以表示什么样的分类边界呢？</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-and-xor-operator.png"><img src="/assets/images/2015-02-04-neural-network-and-xor-operator.png" alt="AND和XOR运算" /></a><div class="caption">图 2:  AND和XOR运算 [<a href="/assets/images/2015-02-04-neural-network-and-xor-operator.png">PNG</a>]</div></div></div>

<p>单层感知器可以实现如上图所示的AND运算（+1表示TRUE，-1表示FALSE）
\[
G(\mathbf x)=\mbox{sign}(-1+g_1(\mathbf x)+g_2(\mathbf x))，
\]
也可实现OR和NOT运算。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-enough-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-enough-perceptrons.png" alt="足够多感知器的融合" /></a><div class="caption">图 3:  足够多感知器的融合 [<a href="/assets/images/2015-02-04-neural-network-enough-perceptrons.png">PNG</a>]</div></div></div>

<p>即使感知器的线性组合，分类能力也很强大，如上图所示。只要对足够多的感知器融合，可以在空间中切割出任意凸集（convex set），但$d_{VC}\rightarrow\infty$。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png"><img src="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png" alt="两层感知器的线性融合实现XOR运算" /></a><div class="caption">图 4:  两层感知器的线性融合实现XOR运算 [<a href="/assets/images/2015-02-04-neural-network-xor-multi-layer-perceptrons.png">PNG</a>]</div></div></div>

<p>但是，单层感知器不能实现XOR运算，经过XOR运算的特征转换$\phi(\mathbf x)=(g_1(\mathbf x),g_2(\mathbf x))$后数据线性不可分。线性不可分数据继续特征转换，最终将XOR用AND和OR实现
\[
XOR(g_1,g_2)=OR(AND(-g_1,g_2),AND(g_1,-g_2))，
\]
并且可以用上图所示的两层级连结构表示。</p>

<p>由此可见，虽然感知器算法简单，经过线性融合，以及多层级连，可以得到功能强大的分类器。多层感知器就是基本的神经网络结构。</p>

<h2 id="section-1">神经网络</h2>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-simple-NN.png"><img src="/assets/images/2015-02-04-neural-network-simple-NN.png" alt="简单的神经网络模型" /></a><div class="caption">图 5:  简单的神经网络模型 [<a href="/assets/images/2015-02-04-neural-network-simple-NN.png">PNG</a>]</div></div></div>

<p>事实上，对最后一层OUTPUT神经元，除了用感知器外，可以采用其它的<a href="/2015/01/linear-models-for-classification/#linear-models">线性模型</a>。若要分类，OUTPUT采用线性分类模型；若要回归分析，OUTPUT采用线性回归（不做任何处理）；若要soft分类，OUTPUT采用logistic回归。</p>

<p>中间层神经元采用的转换函数（transformation function），除了使用阶梯（符号）函数，也可采用其它转换函数。若所有神经元都采用线性回归，整个网络都是线性运算，用一个线性模型就可以实现。因此，很少用线性回归作为转换函数。阶梯函数是离散的，难以通过最优化求解$\mathbf w$，也很少使用。通常使用的是S形的转换函数
\[
\tanh(s)={\exp(s)-\exp(-s)\over\exp(s)+\exp(-s)}=2\theta(2s)-1，
\]
可以通过<a href="/2015/01/logistic-regression/#mjx-eqn-eqsigmoid-function">logistic函数</a>得到。该函数是阶梯函数的近似，且容易优化，传说和生物神经元也相近。</p>

<div class="image_line" id="figure-6"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-common-NN.png"><img src="/assets/images/2015-02-04-neural-network-common-NN.png" alt="常用的神经网络模型" /></a><div class="caption">图 6:  常用的神经网络模型 [<a href="/assets/images/2015-02-04-neural-network-common-NN.png">PNG</a>]</div></div></div>

<p>常用的神经网络采用$\tanh$作为转换函数，输出采用线性回归，如上图所示。$d^{(0)},d^{(1)},\ldots,d^{(L)}$表示每层神经元数目（节点数目），每层的权值为
\[
w_{ij}^{(\ell)}:\left\{
\begin{aligned}
&amp;1\leq\ell\leq L&amp;\mbox{layers}&amp;\\
&amp;0\leq i\leq d^{(\ell-1)}&amp;\mbox{inputs}&amp;\\
&amp;1\leq j\leq d^{(\ell)}&amp;\mbox{outputs}&amp;，
\end{aligned}
\right.
\]
常数+1的神经元相当于偏移项，评分函数为
\begin{equation}
s_j^{(\ell)}=\sum_{i=0}^{d^{(\ell-1)}}w_{ij}^{(\ell)}x_i^{(\ell-1)}，
\end{equation}
转换后的特征为
\begin{equation}
x_j^{(\ell)}=\left\{
\begin{aligned}
&amp;\tanh\left(s_j^{(\ell)}\right)&amp;\mbox{if }\ell&lt;L\\
&amp;s_j^{(\ell)}&amp;\mbox{if }\ell=L
\end{aligned}
\right.
\label{eq:forward-x}
\end{equation}</p>

<p>神经网络将$\mathbf x$当作输入层$\mathbf x^{(0)}$，隐层计算变换后的特征$\mathbf x^{(\ell)}$，输出层计算预测结果$x_1^{(L)}$。</p>

<p>神经网络隐层相当于模式（特征）提取（pattern extraction），进行$\mathbf x^{(\ell)}$和权值向量的模式匹配（利用基于内积的余弦相似度），每个神经元提取一种特征，权值向量纪录了从数据中学到的模式。</p>

<h2 id="bp">BP算法</h2>

<p>如何通过最小化$E_{in}\left(\left\{w_{ij}^{(\ell)}\right\}\right)$学到权值$\left\{w_{ij}^{(\ell)}\right\}$？</p>

<p>如果只有一个隐层，神经网络相当于感知器的融合，可以通过GradientBoost方法一个接一个的确定隐层的神经元。如果有多个隐层，问题就变得复杂了。</p>

<p>每个数据的误差记为
\[
e_n=(y_n-\mbox{NNet}(\mathbf x_n))^2，
\]
若能计算$\partial e_n\over \partial w_{ij}^{(\ell)}$，就可以通过梯度下降法求解。对输出层
\[
e_n=\left(y_n-s_1^{(L)}\right)^2=\left(y_n-\sum_{i=0}^{d^{(L-1)}}w_{i1}^{(L)}x_i^{(L-1)}\right)^2，
\]
对输出层和其它层分别求偏微分
\[
\begin{aligned}
&amp;{\partial e_n\over\partial w_{i1}^{(L)}}
={\partial e_n\over\partial s_{1}^{(L)}}\cdot{\partial s_{1}^{(L)}\over\partial w_{i1}^{(L)}}
=2\left(y_n-s_1^{(L)}\right)\cdot x_i^{(L-1)}，\\
&amp;{\partial e_n\over\partial w_{ij}^{(\ell)}}
={\partial e_n\over\partial s_{j}^{(\ell)}}\cdot{\partial s_{j}^{(\ell)}\over\partial w_{ij}^{(\ell)}}
=\delta_j^{(\ell)}x_i^{(\ell-1)}。
\end{aligned}
\]
对输出层，令
\begin{equation}
\delta_1^{(L)}=2\left(y_n-s_1^{(L)}\right)。
\end{equation}
对其它层
\begin{equation}
\delta_j^{(\ell)}
={\partial e_n\over\partial s_{j}^{(\ell)}}
=\sum_{k=1}^{d^{(\ell+1)}}{\partial e_n\over\partial s_{k}^{(\ell+1)}}{\partial s_{k}^{(\ell+1)}\over\partial x_{j}^{(\ell)}}{\partial x_{j}^{(\ell)}\over\partial s_{j}^{(\ell)}}
=\sum_k\delta_k^{(\ell+1)}w_{jk}^{(\ell)}\tanh’\left(s_j^{(\ell)}\right)，
\label{eq:backpropagation-delta}
\end{equation}
也就是前一层的$\delta_j^{(\ell)}$，可以通过后一层$\delta_k^{(\ell+1)}$回推计算。</p>

<blockquote>
  <h4 id="bpbackpropagation">BP（backpropagation）算法</h4>
  <hr />
  <p>用小的随机值初始化所有的$w_{ij}^{(\ell)}$；</p>

  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>随机化：随机选取$n\in\{1,2,\ldots,N\}$；</li>
    <li>前向传播：从$\mathbf x^{(0)}=\mathbf x_n$开始，利用\eqref{eq:forward-x}计算所有$x_i^{(\ell)}$；</li>
    <li>误差回传：对$\mathbf x^{(0)}=\mathbf x_n$，利用\eqref{eq:backpropagation-delta}计算所有$\delta_j^{(\ell)}$；</li>
    <li>梯度下降：$w_{ij}^{(\ell)}\leftarrow w_{ij}^{(\ell)}-\eta x_i^{(\ell-1)}\delta_j^{(\ell)}$；</li>
  </ol>

  <p>返回$g_{\mbox{NNET}}(\mathbf x)=\left(\ldots\tanh\left(\sum_jw_{jk}^{(2)}\cdot\tanh\left(\sum_iw_{ij}^{(1)}x_i\right)\right)\right)$。</p>

  <p>在实际应用中，第1步至第3步可以先执行多次后，再用$x_i^{(\ell-1)}\delta_j^{(\ell)}$的平均值执行第4步的更新，这就是mini-batch的方法。</p>
</blockquote>

<p>神经网络通过最小化
\[
E_{in}(\mathbf w)={1\over N}\sum_{n=1}^Nerr\left(\left(\ldots\tanh\left(\sum_jw_{jk}^{(2)}\cdot\tanh\left(\sum_iw_{ij}^{(1)}x_i\right)\right)\right),y_n\right)
\]
计算权值。通常多隐层神经网络的误差函数是非凸的（non-convex），难以达到全局最小值（global minimum），梯度下降法通过BP算法也仅仅得到局部极小值（local minimum）。不同的初始化$w_{ij}^{(\ell)}$，会得到不同的局部极值：</p>

<ul>
  <li>BP算法对权重初始值敏感；</li>
  <li>若权值太大，会落到$\tanh$的saturate区域（梯度很小），每次按梯度更新很小；</li>
  <li>用小的随机值初始化权值$w_{ij}^{(\ell)}$。</li>
</ul>

<p>虽然神经网络很难最优化，但在实际中很有用。</p>

<h2 id="section-2">正则化</h2>

<p>若用形如$\tanh$的转换函数，神经网络的$d_{VC}=O(VD)$，$V$为神经元数量，$D$为神经元之间的权值数量。当神经元数目足够时，可以做任意逼近，也更容易导致过拟合。为了避免过拟合，需要采取正则化方法。</p>

<h4 id="weight-elimination">一、weight-elimination正则化</h4>

<p>常用的方法是基于$L_2$的weight-decay正则化，$\Omega(\mathbf w)=\sum\left(w_{ij}^{(\ell)}\right)^2$。这种正则化对权值的压缩（shrink）力度和权值大小“成比例”，大的权值压缩厉害，小的权值压缩较小。</p>

<p>如果通过正则化使权值部分为0（稀疏），就能有效减小$d_{VC}$，常用的方法是$L_1$正则化，$\Omega(\mathbf w)=\sum\left\lvert w_{ij}^{(\ell)}\right\rvert$，但是不可微。采用weight-elimination正则化（放缩的$L_2$正则化），大的权值中等幅度的压缩（median shrink），小的权值也中等幅度的压缩，小的权值就会接近0，具有权值稀疏化的效果。weight-elimination正则化采用
\begin{equation}
\Omega(\mathbf w)=\sum{\left(w_{ij}^{(\ell)}\right)^2\over 1+\left(w_{ij}^{(\ell)}\right)^2}。
\end{equation}</p>

<h4 id="section-3">二、尽早停止迭代</h4>

<div class="image_line" id="figure-7"><div class="image_card"><a href="/assets/images/2015-02-04-neural-network-early-stopping.png"><img src="/assets/images/2015-02-04-neural-network-early-stopping.png" alt="迭代次数对误差的影响" /></a><div class="caption">图 7:  迭代次数对误差的影响 [<a href="/assets/images/2015-02-04-neural-network-early-stopping.png">PNG</a>]</div></div></div>

<p>迭代的次数$t$越多，选择过的$\mathbf w$也就越多，有效的$d_{VC}$也越大。小的$t$使得$d_{VC}$也较小。尽早停止（early stopping）迭代，通过如上图右的最佳$t^*$，获得如上图左的最佳$d_{VC}^*$，克服过拟合。通过验证（validation）确定停止迭代的参数$t$。</p>

<p>所有和梯度有关的优化算法，都可利用尽早停止迭代的机制，实现某种正则化。</p>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（6）：融合模型总结</title>
      <link href="http://qianjiye.de/2015/02/summary-of-aggregation-models" />
      <pubdate>2015-02-04T13:39:58+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/02/summary-of-aggregation-models</guid>
      <content:encoded>&lt;![CDATA[<h4 id="section">一、分类器融合策略</h4>

<table>
  <thead>
    <tr>
      <th>融合类型</th>
      <th>混合（blending）</th>
      <th>学习（learning）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-equniform-blending-hypothesis">均匀</a>（uniform）</td>
      <td>voting／averaging</td>
      <td>Bagging</td>
    </tr>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-eqlinear-blending-hypothesis">非均匀</a>（non-uniform）</td>
      <td>linear</td>
      <td>AdaBoost</td>
    </tr>
    <tr>
      <td><a href="/2015/01/blending-and-bagging/#mjx-eqn-eqconditional-blending-hypothesis">有条件</a>（conditional）</td>
      <td>stacking</td>
      <td>Decision Tree</td>
    </tr>
  </tbody>
</table>

<p>对于非均匀和条件融合，$g_t$可以视为特征转换。</p>

<p>混合（blending）方法是选择了不同的$g_t$之后再融合，学习（learning）方法是在选择（学习）不同$g_t$的同时进行融合。</p>

<p>均匀融合性能比较稳定，不同$g_t$相互修正，类似正则化的中庸思想。非均匀和条件融合，学习之上的再学习过程，增加了复杂度，功能强大，存在更大的过拟合风险。</p>

<h4 id="section-1">二、基于学习机制的分类器融合方法对比</h4>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>获取不同$g_t$的方法</th>
      <th>融合策略</th>
      <th>优化算法</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Bagging</td>
      <td>bootstrapping</td>
      <td>uniform vote</td>
      <td> </td>
    </tr>
    <tr>
      <td>AdaBoost</td>
      <td>reweighting</td>
      <td>linear vote</td>
      <td>steepest search</td>
    </tr>
    <tr>
      <td>GradientBoost</td>
      <td>residual fitting</td>
      <td>linear vote</td>
      <td>steepest search</td>
    </tr>
    <tr>
      <td>Decision Tree</td>
      <td>data splitting</td>
      <td>conditional vote</td>
      <td>branching</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>random forest = randomized bagging + strong DTree;</li>
  <li>AdaBoost-DTree = AdaBoost + weak DTree;</li>
  <li>GBDT = GradientBoost + weak DTree.</li>
</ul>

<p>boosting系列的算法应用非常广泛。</p>

<h4 id="section-2">三、融合机制的双重性</h4>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png"><img src="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png" alt="［左］：融合解决欠拟合；［右］：融合解决过拟合" /></a><div class="caption">图 1:  ［左］：融合解决欠拟合；［右］：融合解决过拟合 [<a href="/assets/images/2015-02-04-summary-of-aggregation-models-under-and-over-fitting.png">PNG</a>]</div></div></div>

<ol>
  <li>融合可以解决欠拟合问题。单一的$g_t$能力较弱，通过AdaBoost或GradientBoost的方法得到强大的$G(\mathbf x)$。融合相当于利用了特征转换的功能。</li>
  <li>融合可以解决过拟合问题。通过融合可以得到中庸（moderate）的$G(\mathbf x)$。融合相当于利用了正则化的功能，如上图右的large-margin效果。</li>
</ol>

<p>因此，合适的融合（aggregation or ensemble）机制可以提升分类器的性能。</p>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（5）：梯度提升决策树</title>
      <link href="http://qianjiye.de/2015/01/gradient-boosted-decision-tree" />
      <pubdate>2015-01-29T16:12:28+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/gradient-boosted-decision-tree</guid>
      <content:encoded>&lt;![CDATA[<h2 id="adaboost">AdaBoost决策树</h2>

<blockquote>
  <h4 id="adaboost-dtreemathcal-d">AdaBoost-DTree($\mathcal D$)</h4>
  <hr />
  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>更新数据的权重$\mathbf u^{(t)}$；</li>
    <li>通过决策树算法$\mbox{DTree}\left(\tilde{\mathcal D}, \mathbf u^{(t)}\right)$得到$g_t$；</li>
    <li>计算$g_t$的投票权重$\alpha_t$。</li>
  </ol>

  <p>返回$G=\mbox{LinearHypo}(\{\left(g_t,\alpha_t\right)\})$。</p>
</blockquote>

<p>由此可见，AdaBoost决策树需要加权决策树算法。对于有权重的算法，需要根据权重最小化$E_{in}$，通常有两种方法：</p>

<ul>
  <li>一种方法是通过算法加权，在计算$E_{in}$的地方嵌入权重计算，比如AdaBoost采用的最小化<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqweighted-Ein">加权误差</a>；</li>
  <li>另一种方法是将算法当成黑盒不变更，通过数据集加权，根据权重在bootstrap时“复制”数据，也就是加权的重采样。</li>
</ul>

<p>AdaBoost决策树通常采用后一种方法，AdaBoost＋sampling $\propto \mathbf u^{(t)}$＋$\mbox{DTree}(\tilde{\mathcal D}_t)$。</p>

<p>AdaBoost的<a href="/2015/01/adaptive-boosting/#AdaBoost-algorithm">$\alpha_t$通过错误率确定</a>。对于所有$\mathbf x_n$不同的完全成长决策树，$E_{in}(g_t)=0$，那么$E_{in}^{\mathbf u}(g_t)=0$，因此$\epsilon_t=0$并且$\alpha_t=\infty$。合适的方法是让决策树弱些，在部分数据集上训练剪枝的决策树。即使在$\tilde{\mathcal D}_t$上得到错误率为0的决策树$g_t$，回到$\mathcal D$上$\alpha_t$可能是大于、等于或小于0。剪枝可采用常规方法或只限制决策树高度，在数据重采样阶段已经包含了只抽取部分数据的功能。因此，AdaBoost决策树＝AdaBoost＋sampling $\propto \mathbf u^{(t)}$＋剪枝的$\mbox{DTree}(\tilde{\mathcal D}_t)$。</p>

<p>如果C&amp;RT的高度限制为不超过1，当用二分类的误差作为<a href="/2015/01/decision-tree/#mjx-eqn-eqdtree-decision-stump">不纯度</a>时，AdaBoost决策树就是<a href="/2015/01/adaptive-boosting/#AdaBoost-Stump">AdaBoost-Stump</a>，此时通常有$\epsilon_t\neq 0$，一般不再需要sampling。</p>

<h2 id="functional-gradient-steepest-descent">AdaBoost理论分析：最速函数梯度下降法</h2>

<p>AdaBoost的<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqadaboost-update-u">权重更新</a>可以合并为
\[
u_n^{(t+1)}=u_n^{(t)}\cdot\blacklozenge_t^{-y_ng_t(\mathbf x_n)}，
\]
由于$\blacklozenge_t=\exp(\alpha_t)$，因此
\[
u_n^{(t+1)}=u_n^{(t)}\cdot\exp\left(-y_n\alpha_tg_t\left(\mathbf x_n\right)\right)，
\]
那么
\begin{equation}
u_n^{(T+1)}=u_n^{(1)}\cdot\prod_{t=1}^T\exp\left(-y_n\alpha_tg_t\left(\mathbf x_n\right)\right)={1\over N}\exp\left(-y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)\right)。
\label{eq:un-t-plus-1}
\end{equation}
AdaBoost是<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqadaboost-Gx">分类器的线性组合</a>，$\sum_{t=1}^T\alpha_tg_t(\mathbf x)$是$\{g_t\}$在$\mathbf x$上的投票得分（voting score），也就是对AdaBoost，$u_n^{(T+1)}\propto \exp\left(-y_n\cdot\left(\mbox{voting score on }\mathbf x_n\right)\right)$。</p>

<p id="decrease-un">线性混合（linear blending），可以看作线性模型和以假设作为特征转换的结合
\[
G(\mathbf x_n)=\mbox{sign}\left(\overbrace{\sum_{t=1}^T\underbrace{\alpha_t}_{w_i}\underbrace{g_t(\mathbf x_n)}_{\phi_i(\mathbf x_n)}}^{\mbox{voting score}}\right)。
\]
对比<a href="/2015/01/linear-svm/#mjx-eqn-eqhard-margin-svm-origin-model">hard-margin的SVM</a>的边界${y_n\cdot\left(\mathbf w^T\phi(\mathbf x_n)+b\right)\over\lVert\mathbf w\rVert}$，投票得分可视为某种空间中非规范化的边界（距离）的度量，“$y_n$(voting score)=signed &amp; unnormalized margin”。期望$y_n$(voting score)是正的，且越大越好，那么$\exp(-y_n(\mbox{voting score}))$越小越好，$u_n^{(T+1)}$越小越好。AdaBoost的$\sum_{n=1}^Nu_n^{(t)}$随着$t$的增大越来越小，在最后一轮
\begin{equation}
\sum_{n=1}^Nu_n^{(T+1)}={1\over N}\sum_{n=1}^N\exp\left(-y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)\right)
\label{eq:sum-un-t-plus-1}
\end{equation}
达到最小，边界$y_n\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)$最大化实现large margin的效果。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png"><img src="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png" alt="AdaBoost的误差界" /></a><div class="caption">图 1:  AdaBoost的误差界 [<a href="/assets/images/2015-01-29-gradient-boosted-decision-tree-error-bound.png">PNG</a>]</div></div></div>

<p>令线性评分函数$s=\sum_{t=1}^T\alpha_tg_t\left(\mathbf x_n\right)$，AdaBoost的指数误差度量（exponential error measure）$\widehat{err}_{ADA}(s,y)=\exp(-ys)$是0/1误差$\widehat{err}_{0/1}(s,y)=[[ys\leq 1]]$的上界<sup id="fnref:other-error-bounds"><a href="#fn:other-error-bounds" class="footnote">1</a></sup>，如上图右所示，通过0/1误差的凸上界（convex upper bound）$\widehat{err}_{ADA}$作为算法误差度量（algorithmic error measure），通过上界误差最小化使0/1误差最小化。</p>

<p>AdaBoost通过增加函数$h(\mathbf x)$的方式，使基于\eqref{eq:sum-un-t-plus-1}的误差$\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t+1)}$最小化，
\begin{equation}
\begin{aligned}
\min_h\quad\widehat E_{ADA}
&amp;\overset{[1]}{=}{1\over N}\sum_{n=1}^N\exp\left(-y_n\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n)\right)\right)\\
&amp;\overset{[2]}{=}\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta h(\mathbf x_n)\right)
\overset{\mbox{taylor}}{\approx}\sum_{n=1}^Nu_n^{(t)}\left(1-y_n\eta h(\mathbf x_n)\right)\\
&amp;=\sum_{n=1}^Nu_n^{(t)}+\eta\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)，
\end{aligned}
\label{eq:min-E-ADA}
\end{equation}</p>

<ul>
  <li>[1]：增加函数$h(\mathbf x)$，由\eqref{eq:sum-un-t-plus-1}可得$\sum_{\tau=1}^t\alpha_\tau g_\tau\left(\mathbf x_n\right)=\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\left(\mathbf x_n\right)+\eta h(\mathbf x_n)$；</li>
  <li>[2]：由\eqref{eq:un-t-plus-1}可得$u_n^{(t)}={1\over N}\exp\left(-y_n\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\left(\mathbf x_n\right)\right)$。</li>
</ul>

<p>公式\eqref{eq:min-E-ADA}形如<a href="/2015/01/logistic-regression/#mjx-eqn-eqtaylor-expansion-Ein">梯度下降法最小化$E_{in}$</a>
\[
\min_{\lVert\mathbf v\rVert=1}E_{in}(\mathbf w_t+\eta\mathbf v)
\approx \underbrace{E_{in}(\mathbf w_t)}_{\mbox{known}}
+\underbrace{\eta}_{\mbox{given positive}}\mathbf v^T\underbrace{\nabla E_{in}(\mathbf w_t)}_{\mbox{known}}，
\]
好的$h(\mathbf x)$能最小化$\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)$。对二分类，$y_n$和$h(\mathbf x_n)$都属于$\{-1,+1\}$，那么
\[
\begin{aligned}
\sum_{n=1}^Nu_n^{(t)}\left(-y_nh(\mathbf x_n)\right)
&amp;=\sum_{n=1}^Nu_n^{(t)}
\left\{
\begin{aligned}
-1\quad\mbox{if }y_n=h(\mathbf x_n)\\
+1\quad\mbox{if }y_n\neq h(\mathbf x_n)
\end{aligned}
\right.\\
&amp;=-\sum_{n=1}^Nu_n^{(t)}+\sum_{n=1}^Nu_n^{(t)}
\left\{
\begin{aligned}
0\quad\mbox{if }y_n=h(\mathbf x_n)\\
2\quad\mbox{if }y_n\neq h(\mathbf x_n)
\end{aligned}
\right.\\
&amp;\overset{[1]}{=}-\sum_{n=1}^Nu_n^{(t)}+2E_{in}^{\mathbf u^{(t)}}(h)\cdot N，
\end{aligned}
\]</p>

<ul>
  <li>[1]：根据<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqweighted-Ein">AdaBoost的$E_{in}^\mathbf u$计算可得</a>。</li>
</ul>

<p>因此，也就是要使$E_{in}^{\mathbf u^{(t)}}(h)$变小，这就是AdaBoost中算法$\mathcal A$的任务，找出一个好的函数方向$h$。</p>

<p>AdaBoost通过近似最小化$\min_h\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta h(\mathbf x_n)\right)$，公式\eqref{eq:min-E-ADA}的$[2]$等式，找到新的分类器$g_t=h$之后，还需要找到最佳的$\eta$，
\[
\min_\eta\widehat E_{ADA}=\sum_{n=1}^Nu_n^{(t)}\exp\left(-y_n\eta g_t(\mathbf x_n)\right)，
\]
$\eta$越大步越好。最佳的$\eta_t$会比固定的$\eta$在短期内下降更快（greedily faster），在最优化中通常称为<strong>最速（最陡）下降</strong>（steepest descent）。对于分类正确和错误两种情形，$u_n^{(t)}\exp\left(-y_n\eta g_t(\mathbf x_n)\right)$分别为$u_n^{(t)}\exp(-\eta)$和$u_n^{(t)}\exp(+\eta)$，那么有
\[
\widehat E_{ADA}=\left(\sum_{n=1}^Nu_n^{(t)}\right)\cdot
\left(
(1-\epsilon_t)\exp(-\eta)+\epsilon_t\exp(+\eta)
\right)，
\]
$\epsilon_t$表示<a href="/2015/01/adaptive-boosting/#mjx-eqn-eqepsilon-t">错误率</a>。
通过${\partial\widehat E_{ADA}\over\partial\eta}=0$可得最速梯度步长$\eta_t=\ln\sqrt{1-\epsilon_t\over\epsilon_t}=\alpha_t$。</p>

<p>因此，AdaBoost是近似的函数梯度（functional gradient）最速下降法。</p>

<h2 id="section">任意误差函数的梯度提升</h2>

<p>AdaBoost可以表示为最优化的形式
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^N\exp\left(-y_n\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n)\right)\right)，
\end{equation}
每一轮找到$h$作为$g_t$，并决定该$g_t$要前进的距离$\eta_t$。利用更一般的误差函数，将AdaBoost推广到GradientBoost
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^Nerr\left(\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)+
\eta h(\mathbf x_n),y_n\right)。
\end{equation}
GradientBoost分为两步：（1）确定$h$；（2）确定$\eta$。由于要采用梯度下降法，需要平滑的误差函数$err$，$h$也不限于二分类，可以推广到实数输出。通过采用不同的误差函数$err$，GradientBoost可实现回归、soft分类等功能。</p>

<h2 id="section-1">梯度提升决策树</h2>

<p>对于回归问题，采用误差函数$err(s,y)=(s-y)^2$，令$s_n=\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau(\mathbf x_n)$可得
\begin{equation}
\min_\eta\min_h{1\over N}\sum_{n=1}^N\left(s_n+
\eta h(\mathbf x_n)-y_n\right)^2，
\label{eq:min-gradientboost-regression-Ein}
\end{equation}
内层最小化
\[
\begin{aligned}
\min_h\ldots
&amp;\overset{\mbox{taylor}}{\approx}\min_h\left({1\over N}\sum_{n=1}^N\underbrace{err(s_n,y_n)}_{\mbox{constant}}+{1\over N}\sum_{n=1}^N\eta h(\mathbf x_n)\left.{\partial err(s,y_n)\over\partial s}\right\rvert_{s=s_n}\right)\\
&amp;\overset{\quad\quad}{=}\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N2h(\mathbf x_n)(s_n-y_n)\right)。
\end{aligned}
\]
<del>如果对$h$无约束条件，那么$h(\mathbf x_n)=-\infty\cdot(s_n-y_n)$时取最小值。</del>事实上，只需要$h$的方向，$h$的大小（magnitude）通过步长$\eta$控制。利用拉格朗日乘子法的思想，避免求解复杂的约束优化问题，惩罚大的$h$
\[
\begin{aligned}
&amp;\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N\left(2h(\mathbf x_n)(s_n-y_n)+(h(\mathbf x_n))^2\right)\right)\\
\Longleftrightarrow&amp;\min_h\left(\mbox{constants}+{\eta\over N}\sum_{n=1}^N\left(\mbox{constant}+(h(\mathbf x_n)-(y_n-s_n))^2\right)\right)。
\end{aligned}
\]
去掉常数项，带惩罚的近似函数梯度是数据集$\{(\mathbf x_n,y_n-s_n)\}$上，基于平方误差的回归。$y_n-s_n$表示期望的值与目前能达到的值之间的差异，表示尚未达到的部分，称为余数（residual）。好的$h(\mathbf x_n)$需要弥补余数的差距。</p>

<p>［1/2］因此，GradientBoost的回归问题就是通过余数上的回归找到$g_t=h$。</p>

<p>当$g_t$确定后，继续\eqref{eq:min-gradientboost-regression-Ein}的外层最小化
\[
\min_\eta{1\over N}\sum_{n=1}^N(s_n+\eta g_t(\mathbf x_n)-y_n)^2\Leftrightarrow\min_\eta{1\over N}\sum_{n=1}^N((y_n-s_n)-\eta g_t(\mathbf x_n))^2，
\]
这是单变量的线性回归，非常容易求解，
\begin{equation}
\eta={\sum_{n=1}^Ng_t(\mathbf x_n)(y_n-s_n)\over\sum_{n=1}^Ng_t^2(\mathbf x_n)}。
\label{eq:gbdt-eta}
\end{equation}</p>

<p>［2/2］因此，GradientBoost的回归问题通过单变量回归求解最优的$\eta$作为$\alpha_t$。</p>

<blockquote>
  <h4 id="gbdtgradient-boosted-decision-tree">梯度提升决策树（GBDT，gradient boosted decision tree）</h4>
  <hr />
  <p>初始化$s_1=s_2=\ldots=s_N=0$；</p>

  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>利用$\mathcal A(\{(\mathbf x_n,y_n-s_n)\})$得到$g_t$，其中$\mathcal A$是基于平方误差的回归算法（例如C&amp;RT）；</li>
    <li>利用\eqref{eq:gbdt-eta}更新步长$\alpha_t=\mbox{OneVarLinearRegression}(\{(g_t(\mathbf x_n),y_n-s_n)\})$；</li>
    <li>更新$s_n\leftarrow s_n+\alpha_tg_t(\mathbf x_n)$；</li>
  </ol>

  <p>返回$G(\mathbf x)=\sum_{t=1}^T\alpha_tg_t(\mathbf x)$。</p>
</blockquote>

<p>GBDT就是AdaBoost决策树的回归版本。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:other-error-bounds">
      <p><a href="/2015/01/linear-models-for-classification/#error-bound">其它误差界</a>可参考线性分类模型的相关资料。 <a href="#fnref:other-error-bounds" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习三原则</title>
      <link href="http://qianjiye.de/2015/01/three-learning-principles" />
      <pubdate>2015-01-28T20:05:37+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/three-learning-principles</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">使用奥卡姆剃刀</h2>

<blockquote>
  <p>An explanation of the data should be made as simple as possible, but no simpler.         <br />
—Albert Einstein? (1879-1955)</p>

  <hr />

  <p>entia non sunt multiplicanda praeter necessitatem (entities must not be multiplied beyond necessity)       <br />
—William of Occam (1287-1347) </p>
</blockquote>

<p>奥卡姆剃刀（Occam’s rezor）：剃掉不必要的解释。对机器学习，适合数据的最简单模型也是最合理的模型。</p>

<ul>
  <li>简单的假设$h$：小的$\Omega(h)$，假设的参数少；</li>
  <li>简单的模型$\mathcal H$：小的$\Omega(\mathcal H)$，包含较少的假设，成长函数增长很慢。</li>
</ul>

<p>当$\Omega(\mathcal H)$小时，$\Omega(h)$也小。当假设集大小为$2^\ell$时，每个假设最多有$\ell$个参数<sup id="fnref:why-ell-parameters"><a href="#fn:why-ell-parameters" class="footnote">1</a></sup>。在实际应用中，通过正则化或从简单模型开始尝试，都可以得到简单的假设。</p>

<p>对于简单模型，$m_\mathcal H(N)$小，难以将数据拟合好（拟合好的概率为$m_{\mathcal H}(N)\over 2^N$<sup id="fnref:why-ration"><a href="#fn:why-ration" class="footnote">2</a></sup>）。对简单的模型，如果数据被分开，那么数据是规律的；对于复杂的模型，如果数据能分开，就不能判断数据是否有规律（复杂模型能把任何数据分开）。</p>

<p>在实际应用中，从简单的线性模型开始尝试，经常考量数据是否被模型过度表示（data over-modeled）。</p>

<h2 id="section-1">避免抽样偏差</h2>

<p>如果数据通过有偏抽样得到<a href="#Darrell_Huff_2002">[1]</a>，学习到的结果也是有偏的。</p>

<p>若从$P_1(\mathbf x,y)$的数据中学习，却在$P_2\neq P_1$的数据中测试，VC理论不适用。相当于学了数学却要参加英语考试。VC理论的前提是训练和测试数据都iid来自同一分布。</p>

<p>通过信用卡用户的信用记录，判断是否给新顾客信用卡。——由于没有未开通信用卡用户的信息，这两者分布可能很不一样……</p>

<p>在实际应用中，尽可能的了解测试环境，使训练环境和测试环境尽量一致。</p>

<h2 id="section-2">绝不偷看数据</h2>

<blockquote>
  <p>If you torture the data long enough, it will confess.</p>
</blockquote>

<p>使用数据的任何过程都相当于间接偷看了数据。为了让VC维可靠，选择$\Phi$时不应当<a href="/2015/01/nonlinear-transformation/#human-learning">偷看数据</a>。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png"><img src="/assets/images/2015-01-28-three-learning-principles-snoop-data.png" alt="简单的偷看也会导致结果偏差很大" /></a><div class="caption">图 1:  简单的偷看也会导致结果偏差很大 [<a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png">PNG</a>]</div></div></div>

<p>对使用同样数据集$\mathcal D$的论文，后来作者针对以前论文改进，阅读以前论文也就相当于偷看资料。若把这些论文看成一篇长长的论文，付出的模型复杂度为$d_{VC}(\cup_m\mathcal H_m)$，泛化能力差。</p>

<p>偷看数据很难避免，合理处理偷看数据：</p>

<p><img src="/assets/images/2015-01-28-three-learning-principles-deal-with-snooping.png" alt="合理处理偷看数据" /></p>

<p>“be blind”是指尽量避免用数据做决定，不要在看了数据之后再决定采用什么样的特征等操作。也就是避免human learning的复杂度进入。</p>

<h2 id="section-3">其它三原则</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-tools.png" alt="三大工具" /></a><div class="caption">图 2:  三大工具 [<a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png" alt="三大理论边界" /></a><div class="caption">图 3:  三大理论边界 [<a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png">PNG</a>]</div></div></div>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="Darrell_Huff_2002">[1]达莱尔·哈夫, <i>统计陷阱</i>. 上海: 上海财经大学出版社, 2002.</span>

</li></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-ell-parameters">
      <p>为什么最多$\ell$个参数？ <a href="#fnref:why-ell-parameters" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-ration">
      <p>这个比率什么意思？ <a href="#fnref:why-ration" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>验证</title>
      <link href="http://qianjiye.de/2015/01/validation" />
      <pubdate>2015-01-27T23:28:10+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/validation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">模型选择问题</h2>

<p>若有$M$个<a href="/assets/images/2015-01-27-validation-so-many-models.png">候选模型</a>$\mathcal H_1,\mathcal H_2,\ldots,\mathcal H_M$和相应的算法$\mathcal A_1,\mathcal A_2,\ldots,\mathcal A_M$，如何选择$\mathcal H_{m^*}$使得$g_{m^*}=\mathcal A_{m^*}(\mathcal D)$有低的$E_{out}(g_{m^*})$？</p>

<p>由于$P(\mathbf x)$和$P(y|\mathbf x)$未知，那么$E_{out}$未也知……</p>

<h4 id="section-1">一、利用数据可视化不可行</h4>

<p>只有一些数据集……基于视觉化的选择是“<a href="/2015/01/nonlinear-transformation/#human-learning">human learning</a>”，并且高维度的数据不能视觉化。</p>

<h4 id="ein">二、利用$E_{in}$很危险</h4>

<p>如果利用$E_{in}$选择，高维特征变换通常犹豫低维，非正则化方法通常优于正则化方法。若$\mathcal A_1$在$\mathcal H_1$最小化$E_{in}$，$\mathcal A_2$在$\mathcal H_2$最小化$E_{in}$，二者再择优$g_{m^*}$在$\mathcal H_1\cup\mathcal H_2$中得到最小的$E_{in}$，这样增加了额外的模型复杂度，VC维$d_{VC}(\mathcal H_1\cup\mathcal H_2)$变大了，泛化能力差。</p>

<h4 id="etest">三、利用$E_{test}$是作弊</h4>

<p>根据finite-bin Hoeffding可得
\[
E_{out}(g_{m^*})\leq E_{test}(g_{m^*})+O\left(\sqrt{\log M\over N_{test}}\right)，
\]
看上去很美，$\mathcal D_{test}$是没用于模型训来的干净数据，可是$\mathcal D_{test}$（相当于老师的考卷）从哪里来呢？</p>

<h4 id="einetesteval">四、$E_{in}$和$E_{test}$折中的合法作弊方案$E_{val}$</h4>

<ul>
  <li>$\mathcal D_{val}\subset\mathcal D$；</li>
  <li>可以获取的；</li>
  <li>若$\mathcal D_{val}$没用于$\mathcal A_m$，那么它是干净的，就像测试数据一样。</li>
</ul>

<h2 id="section-2">单一验证集</h2>

<p>数据$\mathcal D$的划分和相应关系如下：</p>

<p>\begin{align*}
E_{in}(h)\quad&amp;\quad&amp;\quad&amp;\quad &amp;E_{val}(h)\\
\uparrow\quad\quad&amp;\quad&amp;\quad&amp;\quad &amp;\uparrow\;\;\,\,\\
\quad\underbrace{\mathcal D}_{\mbox{size }N}\quad\,&amp;\rightarrow&amp;\underbrace{\mathcal D_{train}}_{\mbox{size }N-K}\quad\quad\,&amp;\cup&amp;\underbrace{\mathcal D_{val}}_{\mbox{size }K}\;\\
\downarrow\quad\quad&amp;\quad &amp;\downarrow\quad\quad\quad\;&amp;\quad&amp;\quad\\
g_m=\mathcal A_m(\mathcal D)&amp;\quad &amp;g_m^-=\mathcal A_m(\mathcal D_{trian})&amp;\quad&amp;\quad
\end{align*}</p>

<p>$\mathcal D_{val}\subset\mathcal D$称为<strong>验证集</strong>（validation set），用于模拟测试集。$\mathcal D_{val}$是随机从$\mathcal D$中抽取的$K$个样本，那么$\mathcal D_{val}\overset{iid}{\sim} P(\mathbf x,y)$，通过数据建立了$E_{val}$与$E_{out}$的联系。确保$\mathcal D_{val}$是干净的，$\mathcal A_m$只使用了$\mathcal D_{train}$进行模型选择（也就是训练得到模型参数，从$\mathcal H$中选出$h$）。</p>

<p>原来使用$\mathcal D$扮演两个角色，既要计算$E_{in}$进行模型选择，又要通过算法得到$g$，两个角色导致资料被污染。利用$D_{val}$，通过最佳$E_{val}$进行模型选择
\[
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{val}(\mathcal A_m(\mathcal D_{train})))，
\]
可得如下误差保证
\begin{equation}
E_{out}(g_m^-)\leq E_{val}(g_m^-)+O\left(\sqrt{\log M\over K}\right)，
\end{equation}
但是只用$N-K$个训练模型out-of-sample误差会偏大（也可从学习曲线看出，理论上若要成立，还需更严格的限制条件），
\[
E_{out}\left(\underbrace{g_{m^*}}_{\mathcal A_m^*(\mathcal D)}\right)\leq E_{out}\left(\underbrace{g_{m^*}^-}_{\mathcal A_m^*(\mathcal D_{train})}\right)，
\]
因此，
\[
E_{out}(g_{m^*})\leq E_{out}(g_{m^*}^-)\leq E_{val}(g_{m^*}^-)+O\left(\sqrt{\log M\over K}\right)。
\]</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-27-validation-model-selection.png"><img src="/assets/images/2015-01-27-validation-model-selection.png" alt="基于验证集的模型选择方案" /></a><div class="caption">图 1:  基于验证集的模型选择方案 [<a href="/assets/images/2015-01-27-validation-model-selection.png">PNG</a>]</div></div></div>

<p>模型选择整个方案如上图所示，得到$g_{m^*}^-$之后，再回到原来整个数据集上得到$g_{m^*}$效果会更好<sup id="fnref:is-it-necessary"><a href="#fn:is-it-necessary" class="footnote">1</a></sup>。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-27-validation-vlidation-example.png"><img src="/assets/images/2015-01-27-validation-vlidation-example.png" alt="模型选择的学习曲线" /></a><div class="caption">图 2:  模型选择的学习曲线 [<a href="/assets/images/2015-01-27-validation-vlidation-example.png">PNG</a>]</div></div></div>

<p>上图是在$\mathcal H_{\Phi_5}$和$\mathcal H_{\Phi_{10}}$中进行模型选择的学习曲线。$g_{m^*}$的效果要优于$g_{m^*}^-$。利用$E_{in}$总会选择到复杂的模型，利用$E_{out}$的作弊方案选择结果总最优。随着验证集不断增大，用于模型选择的训练集不断减小，所以$g_{m^*}^-$甚至会比$g_{\widehat m}$效果差，对很小的训练集，采用$E_{in}$还算不错的模型选择方案。</p>

<p>对大的验证集样本数$K$，有$E_{val}(g^-)\approx E_{out}(g^-)$，但$g_{m^*}^-$通常比$g_{m^*}$糟糕；对小的$K$，有$g_m^-\approx g_m$和$E_{out}(g)\approx E_{out}(g^-)$，但$E_{val}$和$E_{out}$差异较大；
\[
E_{out}(g)\underset{\mbox{small }K}{\approx}E_{out}(g^-)\underset{\mbox{large }K}{\approx}E_{val}(g^-)。
\]</p>

<p>从时间上看，由于部分数据当作了验证集，在训练集上选择每个模型的时间会缩短。</p>

<p>$K={N\over 5}$通常是不错的选择。</p>

<h2 id="section-3">留1交叉验证</h2>

<p>当在验证集的$K=1$的极端情况下，$g^-$和$g$就会非常接近，但$E_{out}$和$E_{val}$差异就很大。能否在$K=1$时找到方案，使得$E_{out}\approx E_{val}$？✅</p>

<p>当$K=1$时，验证集$\mathcal D_{val}^{(n)}=\{(\mathbf x_n,y_n)\}$，误差为$E_{val}^{(n)}(g_n^-)=err(g_n^-(\mathbf x_n),y_n)=e_n$，将留1交叉验证（leave-one-out cross validation）误差
\begin{equation}
E_{loocv}(\mathcal H,\mathcal A)={1\over N}\sum_{n=1}^Ne_n={1\over N}\sum_{n=1}^Nerr(g_n^-(\mathbf x_n),y_n)
\end{equation}
作为$E_{out}(g)$的近似，$E_{loocv}(\mathcal H,\mathcal A)\approx E_{out}(g)$，然后进行模型选择，
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{loocv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-example.png"><img src="/assets/images/2015-01-27-validation-loocv-example.png" alt="loocv选择常数模型而非线性模型" /></a><div class="caption">图 3:  loocv选择常数模型而非线性模型 [<a href="/assets/images/2015-01-27-validation-loocv-example.png">PNG</a>]</div></div></div>

<p>用$\underset{\mathcal D_n}{\varepsilon}$表示在训练集上的数学期望，那么有<sup id="fnref:how-expectation-do"><a href="#fn:how-expectation-do" class="footnote">2</a></sup>
\begin{aligned}
\underset{\mathcal D}{\varepsilon}E_{loocv}(\mathcal H,\mathcal A) = \underset{\mathcal D}{\varepsilon}{1\over N}\sum_{n=1}^Ne_n 
&amp;= {1\over N}\sum_{n=1}^N\underset{\mathcal D}{\varepsilon}e_n\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}\underset{(\mathbf x_n,y_n)}{\varepsilon}err(g_n^-(\mathbf x_n),y_n)\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}E_{out}(g_n^-)\\
&amp;={1\over N}\sum_{n=1}^N\overline{E_{out}}(N-1)\\
&amp;=\overline{E_{out}}(N-1)，
\end{aligned}
因此可得$E_{loocv}(\mathcal H,\mathcal A)$和$E_{out}(g^-)$联系紧密，通常称作$E_{out}(g)$几乎无偏的估计（almost unbiased estimate）。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-practice.jpg"><img src="/assets/images/2015-01-27-validation-loocv-practice.jpg" alt="loocv手写识别示例" /></a><div class="caption">图 4:  loocv手写识别示例 [<a href="/assets/images/2015-01-27-validation-loocv-practice.jpg">JPG</a>]</div></div></div>

<p>上图手写识别例子中，通过验证确定选择多少维多项式特征。若用$E_{in}$，特征维度越多越好；利用$E_{loocv}$（图中标注为$E_{cv}$），会选到较低纬度的特征。</p>

<h2 id="v-fold-cross-validation">V-fold交叉验证</h2>

<p>由于loocv需要训练$N$次，时间复杂度非常大，在实际中并不总是可行的。但也有特例，线性回归的的loocv容易计算。通过单点估计误差波动较大，结果不是很稳定，曲线上有些跳动的点。如何降低loocv的计算量？</p>

<p>将数据集$\mathcal D$随机分为$V$等份（loocv相当于将数据集分为$N$等份），$V-1$份用于训练模型，剩余的1份用于验证，这称为V-fold交叉验证，
\begin{equation}
E_{cv}(\mathcal H,\mathcal A)={1\over V}\sum_{v=1}^VE_{val}^{(v)}(g_v^-)，
\end{equation}
模型选择方式为
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{cv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<p>通常情况，$V=10$。</p>

<p>通常，V-fold交叉验证要优于单一验证集方法，计算量也更大，5-fold或10-fold通常都会工作得很好，实际中loocv并不常用。</p>

<h2 id="section-4">小结</h2>

<p>各种模型选择的关系：</p>

<ul>
  <li>模型训练（初赛）：从假设集中选择；</li>
  <li>验证方案（复赛）：从训练好的模型中选择；</li>
  <li>测试：衡量最终的表现（测试集只在此时才能使用1次）。</li>
</ul>

<p>由于资料污染，以及付出了模型复杂度代价等因素，通常验证的结果仍然会比最终测试结果乐观。因此，提交测试结果而非验证结果更客观。</p>

<h2 id="section-5">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-6">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-it-necessary">
      <p><a href="/2015/01/image-classification-knn-based-introduction/#is-validation-set-need">并不是所有的人都这样做</a>…… <a href="#fnref:is-it-necessary" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-expectation-do">
      <p>数学期望如何分离计算的？ <a href="#fnref:how-expectation-do" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>正则化</title>
      <link href="http://qianjiye.de/2015/01/regularization" />
      <pubdate>2015-01-26T17:50:30+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/regularization</guid>
      <content:encoded>&lt;![CDATA[<p>正则化来源于处理函数逼近（function approximation）中的病态问题（ill-posed problem）。克服过拟合的一个方法是从简单模型开始尝试；正则化是相反的思路，从复杂模型的假设集开始，通过正则化约束求解得到未过拟合的简单模型（复杂项的系数很小或接近0）。</p>

<p>正则化等价于结构风险最小化（SRM，structural risk minimuzation）<a href="#lihang_sml_2012">[1, P. 9]</a>，它是结构风险最小化策略的实现，通过在经验风险上加一个正则化项或惩罚项实现<a href="#lihang_sml_2012">[1, P. 13]</a>。正则化符合奥卡姆剃刀（Occam’s rezor）原理：在所有可能选择的模型中，能够很好解释已知数据并且十分简单才是最好的模型。从贝叶斯估计的角度看，正则化项对应于模型的先验概率，可以假设复杂的模型有较大的先验概率<a href="#lihang_sml_2012">[1, P. 14]</a>。</p>

<p>本文的主要参考资料是机器学习基石<a href="#lin_ml_regularization_2014">[2]</a>。</p>

<h2 id="section">带约束回归</h2>

<p>对于$x\in\mathbb R$的Q阶多项式变换$\Phi_Q(x)=\left(1,x,x^2,\ldots,x^Q\right)$，为了方便用$\mathbf w$代替回归系数$\tilde{\mathbf w}$。10次和2次空间中回归问题的假设集$\mathcal H_{10}$和$\mathcal H_2$分别表示为
\[
\begin{aligned}
&amp;w_0+w_1x+w_2x^2+w_3x^3+\ldots,w_{10}x^{10}\\
&amp;w_0+w_1x+w_2x^2。
\end{aligned}
\]
若$w_3=w_4=\ldots=w_{10}=0$，则$\mathcal H_2=\mathcal H_{10}$，也就是$\mathcal H_2$的回归问题可以用带约束的$\mathcal H_{10}$实现
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }w_3=w_4=\ldots=w_{10}=0。
\]
正则化可以看作带约束的优化$E_{in}$。</p>

<p>稍微放松约束条件，任意8个系数为0，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H’_2$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}\left[\left[w_q\neq 0\right]\right]\leq 3。
\]
$\mathcal H’_2$比$\mathcal H_2$宽松，但比$\mathcal H_{10}$过拟合风险低，$\mathcal H_2\subset\mathcal H’_2\subset\mathcal H_{10}$。求解稀疏形式（含8个0系数）$\mathcal H’_2$中的假设非常困难，NP-hard。</p>

<p>进一步放松约束条件，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H(C)$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}w_q^2\leq C。
\]
$\mathcal H(C)$和$\mathcal H’_2$有交集（overlap），对$C\geq 0$存在嵌套结构
\[
\mathcal H(0)\subset\mathcal H(1.126)\subset\ldots\subset\mathcal H(1126)\subset\ldots\subset\mathcal H(\infty)=\mathcal H(10)。
\]
从正则化假设集$\mathcal H(C)$的到的最优解就是正则化假设$\mathbf w_{REG}$。</p>

<h2 id="section-1">拉格朗日乘子法</h2>

<p>根据上述推导，正则化回归问题的向量表示形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}\sum_{n=1}^N\left(\mathbf w^T\mathbf z_n-y_n\right)^2\qquad\mbox{s.t. }\sum_{q=0}^Qw_q^2\leq C，
\end{equation}
进一步记为矩阵形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}(\mathbf Z\mathbf w-\mathbf y)^T(\mathbf Z\mathbf w-\mathbf y)\qquad\mbox{s.t. }\mathbf w^T\mathbf w\leq C，
\label{eq:constrained-Ein-matrix}
\end{equation}
事实上$\mathbf w$位于半径为$\sqrt C$的球中。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-gradient-descent.png"><img src="/assets/images/2015-01-26-regularization-gradient-descent.png" alt="正则化约束的梯度下降法" /></a><div class="caption">图 1:  正则化约束的梯度下降法 [<a href="/assets/images/2015-01-26-regularization-gradient-descent.png">PNG</a>]</div></div></div>

<p>上图展示了正则化约束的梯度下降法，蓝色的椭圆曲线表示梯度相同的等高线，红色的圆形表示约束条件。没有正则化约束时，$\mathbf w$沿着$-\nabla E_{in}(\mathbf w)$方向达到最优解$\mathbf w_{lin}$，梯度方向指出了到达最优解的方式。有正则化约束时，大部分情况，最优解都在球面$\mathbf w^T\mathbf w=C$上。$-\nabla E_{in}(\mathbf w)$可以分解为绿色和红色$\mathbf w$（球切面的法向量）两个方向，如果已经在球面上，仍然继续沿着$\mathbf w$下降，会破坏约束条件。正则化梯度下降法，可看作在绿色箭头方向作用下接近最优解。达到最优解的条件是满足约束且不能继续下降，也就是$-\nabla E_{in}(\mathbf w)$平行于$\mathbf w$，那么有$-\nabla E_{in}(\mathbf w_{REG})\propto\mathbf w_{REG}$，此时绿色方向的分量为0，不再下降，优化过程结束。</p>

<p>利用拉格朗日乘子$\lambda&gt;0$，达到最优解的条件是
\begin{equation}
\nabla E_{in}(\mathbf w_{REG})+{2\lambda\over N}\mathbf w_{REG}=0。
\label{eq:nabla-E-w-reg}
\end{equation}
因为$\nabla E_{in}(\mathbf w_{REG})={2\over N}\left(\mathbf Z^T\mathbf Z\mathbf w_{REG}-\mathbf Z^T\mathbf y\right)$，所以可得最优解<sup id="fnref:why-regularize-all"><a href="#fn:why-regularize-all" class="footnote">1</a></sup>
\begin{equation}
\mathbf w_{REG}\leftarrow\left(\mathbf Z^T\mathbf Z+\lambda\mathbf I\right)^{-1}\mathbf Z^T\mathbf y。
\end{equation}
$\mathbf Z^T\mathbf Z$是半正定的，当$\lambda&gt;0$时，上述逆矩阵总存在。正则化的线性回归在统计学中称为<strong>脊回归</strong>（ridge regression）。</p>

<p>求解\eqref{eq:nabla-E-w-reg}等价于最小化增广误差（augmented error）
\begin{equation}
\mathbf w_{REG}\leftarrow \arg\min_{\mathbf w}E_{aug}(\mathbf w)\quad \lambda\geq 0，
\label{eq:Eaug-minimization}
\end{equation}
其中增广误差
\begin{equation}
E_{aug}(\mathbf w)=E_{in}(\mathbf w)+{\lambda\over N}\mathbf w^T\mathbf w，
\label{eq:E-aug}
\end{equation}
$\mathbf w^T\mathbf w$称为正则化项（regularizer）。带约束优化$E_{in}$，可通过无约束优化$E_{aug}(\mathbf w)$高效求解，每个$C$都有对应的$\lambda$，大的$\lambda$对应着小的$C$，也对应着短的$\mathbf w$。当$\lambda=1$或$C=\infty$或$C\geq\lVert\mathbf w_{LIN}\rVert^2$（相当于红色的圆已经把$\mathbf w_{LIN}$包含在内）时，相当于没有进行正则化。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-regularize-regression.png"><img src="/assets/images/2015-01-26-regularization-regularize-regression.png" alt="不同系数下正则化的效果" /></a><div class="caption">图 2:  不同系数下正则化的效果 [<a href="/assets/images/2015-01-26-regularization-regularize-regression.png">PNG</a>]</div></div></div>

<p>$\lambda$相当于对过拟合的惩罚因子，上图展示了不同$\lambda$惩罚下的效果。</p>

<p>${\lambda\over N}\mathbf w^T\mathbf w$称为权重衰减（weight-decay）正则化，可推广到“任意变换 ＋ 线性模型”。</p>

<h2 id="section-2">勒让德多项式</h2>

<p>当$x_n\in[-1,1]$和$Q$很大时，$x_n^q$会变得非常小，除精确度因素影响外，还需要很大的$w_q$才能体现$x_n^q$的影响，这就与正则化的目的有些“矛盾”，过度惩罚了高次项。对于$\mathcal Z$空间的特征
\[
\Phi(\mathbf x)=\left(1,x,x^2,\ldots,x^Q\right)，
\]
特征之间彼此非正交，对低次项容忍度较大，对高次项惩罚力度更大。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png"><img src="/assets/images/2015-01-26-regularization-legendre-polynomials.png" alt="勒让德多项式" /></a><div class="caption">图 3:  勒让德多项式 [<a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png">PNG</a>]</div></div></div>

<p>为改善这一问题，可以考虑在多项式空间找到一组正交的基函数（orthonormal basis function），也称为勒让德多项式（legendre polynomials），构造如上图所示的新多项式变换
\[
\Phi(\mathbf x)=\left(1,L_1(x),L_2(x),\ldots,L_Q(x)\right)。
\]</p>

<h2 id="vc">VC维分析</h2>

<p>带约束$E_{in}$优化\eqref{eq:constrained-Ein-matrix}的VC上界
\begin{equation}
E_{out}(\mathbf w)\leq E_{in}(\mathbf w)+\Omega(\mathcal H(C))，
\label{eq:vc-bound}
\end{equation}
采用与$C$等价的$\lambda$时，可以用优化\eqref{eq:Eaug-minimization}实现，在没有限定$\mathcal H(C)$的情况下，通过优化$E_{aug}$间接获得了VC维的保证。对比\eqref{eq:E-aug}和\eqref{eq:vc-bound}，$\mathbf w^T\mathbf w=\Omega(\mathbf w)$衡量了单一假设的复杂度，$\Omega(\mathcal H(C))$衡量了整个假设集的复杂度。如果${\lambda\over N}\Omega(\mathbf w)$能很好的表示$\Omega(\mathcal H(C))$，衡量$E_{out}$时，$E_{aug}$是比$E_{in}$更好中介。</p>

<p>对$\mathcal Z$空间的非正则化方法，$d_{VC}(\mathcal H)=\tilde d+1$。事实上，采用正则化考虑的假设集$\mathcal H(C)$要小于$\mathcal H$。采用了正则化后，有效（effective）VC维$d_{EFF}(\mathcal H,\mathcal A)\leq d_{VC}(\mathcal H)$，其中$\mathcal A$为正则化算法。因此，正则化方法具有更好的泛化性能。增大$\lambda$使$C$变小，从而使$\mathcal H(C)$变小，使得$d_{EFF}(\mathcal H,\mathcal A)$减小。</p>

<h2 id="section-3">正则化的推广</h2>

<p>除权重衰减（weight-decay）正则化外，还有很多其它的正则化方法。正则化的约束条件应当向着目标函数方向，选择正则化方法的思路包括：</p>

<ul>
  <li>目标相关（target-dependent）：利用目标的特性，比如已知目标函数的对称性，可采用对称正则化$\sum[[q\mbox{ is odd}]]w_q^2$；</li>
  <li>合理性（plausible）：使结果更加光滑和简单，比如要对随机或确定性噪声鲁棒，可采用稀疏的$L_1$正则化$\sum |w_q|$；</li>
  <li>友好（friendly）：易于优化，比如采用除权重衰减的$L_2$正则化$\sum w_q^2$。</li>
</ul>

<p>如果正则化选择不合适，还有$\lambda=0$这道防线，可以避免危害。以上正则化选择思路和<a href="/2014/12/machine-learning-noise-and-error/#error-measurement">误差度量</a>一致：用户相关（user-dependent）、合理性、友好。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png"><img src="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png" alt="［左］：L2正则化；［右］L1正则化" /></a><div class="caption">图 4:  ［左］：L2正则化；［右］L1正则化 [<a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png">PNG</a>]</div></div></div>

<p>$L_1$正则化在需要稀疏解时很有用。上图右是$L_1$正则化示意图，$L_1$正则化
\begin{equation}
\Omega(\mathbf w)=\sum_{q=0}^Q|w_q|=\lVert\mathbf w\rVert_1，
\end{equation}
虽然不可微分，但它是凸的，解是稀疏的（$\mathbf w$有很多0元素）。$-\nabla E_{in}$可分解到垂直于边界面的方向（边界面的法向量方向，如上图右红色箭头所示）和沿边界面的方向。当到达边界面后，如果继续沿着法向量方向下降，会破坏约束条件，沿着面的方向如果还能下降，则继续沿着面的方向下降，直到停在菱形球的顶点，或者直到$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$（沿边界面的方向分量为0）。边界面的法向量只和$\mathbf w$的符号有关，如果要$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$比较困难，通常会停在菱形球的顶点，该点在坐标轴上，必有元素为0。</p>

<h2 id="lambda">最优$\lambda$</h2>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png"><img src="/assets/images/2015-01-26-regularization-noise-and-lambda.png" alt="噪声对性能的影响" /></a><div class="caption">图 5:  噪声对性能的影响 [<a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png">PNG</a>]</div></div></div>

<p>上图表明，噪声等级越高，正则化的惩罚力度$\lambda$越大。实际上，噪声的等级不可预知，只有通过实验的方法选择最佳$\lambda$，也就是通过<a href="">验证</a>（validation）选择最佳$\lambda$。</p>

<h2 id="section-4">正则化实例</h2>

<p>本节内容源于机器学习<a href="#ng_ml_r_2014">[3]</a>网络课程，这里没有对增加的偏移项$x_0=1$的系数正则化，且$y\in\{0,1\}$。</p>

<h3 id="section-5">正则化线性回归</h3>

<h4 id="section-6">一、代价函数</h4>

<p>\begin{equation}
J(\boldsymbol\theta) = \frac{1}{2m}\left( \sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)^2 + \lambda\sum_{j=1}^n\theta_j^2 \right)
\label{eq:cf-linear-regression-r}
\end{equation}</p>

<h4 id="section-7">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<p>迭代过程可以化为如下形式：
\begin{equation*}
\theta_j := \theta_j\left(1 - \alpha\frac{\lambda}{m} \right) - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)};~~(j = 1, 2, \ldots, n)
\end{equation*}</p>

<p>通常$1 - \alpha\frac{\lambda}{m} &lt; 1$，与非正则化的梯度下降法比较，$\theta_j$减小更快。</p>

<h3 id="logistic">正则化Logistic回归</h3>

<h4 id="section-8">一、代价函数</h4>

<p>\begin{equation}
\begin{aligned}
J(\boldsymbol\theta)  = &amp;-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)\right)\right) \\
&amp; + \frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
\end{aligned}
\label{eq:cf-logistic-regression-r}
\end{equation}</p>

<h4 id="section-9">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<h3 id="matlab">Matlab实现</h3>

<p>第一步：实现Logistic函数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>g <span class="p">=</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span>z<span class="p">)</span><span class="w"></span>
<span class="n">g</span> <span class="p">=</span> <span class="mf">1.0</span> <span class="o">./</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="nb">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">));</span>
<span class="k">end</span></code></pre></div>

<p>第二步：实现代价函数（包含梯度计算）</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>[J, grad] <span class="p">=</span><span class="w"> </span><span class="nf">costFunctionReg</span><span class="p">(</span>theta, X, y, lambda<span class="p">)</span><span class="w"></span>
<span class="n">m</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">y</span><span class="p">);</span> <span class="c">% number of training examples</span>

<span class="n">h</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="n">J</span> <span class="p">=</span> <span class="o">-</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">+</span> <span class="c">...</span>
    <span class="n">lambda</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">sum</span><span class="p">(</span><span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">grad</span> <span class="p">=</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)])</span> <span class="o">/</span> <span class="n">m</span><span class="p">;</span>

<span class="k">end</span></code></pre></div>

<p>第三步：估计参数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="n">initial_theta</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">lambda</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">options</span> <span class="p">=</span> <span class="n">optimset</span><span class="p">(</span><span class="s">&#39;GradObj&#39;</span><span class="p">,</span> <span class="s">&#39;on&#39;</span><span class="p">,</span> <span class="s">&#39;MaxIter&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">);</span>
<span class="p">[</span><span class="n">theta</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">exit_flag</span><span class="p">]</span> <span class="p">=</span> <span class="c">...</span>
	<span class="n">fminunc</span><span class="p">(@(</span><span class="n">t</span><span class="p">)(</span><span class="n">costFunctionReg</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda</span><span class="p">)),</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">options</span><span class="p">);</span></code></pre></div>

<h2 id="section-10">参考资料</h2>

<ol class="bibliography"><li><span id="lihang_sml_2012">[1]李航, <i>统计学习方法</i>. 北京: 清华大学出版社, 2012.</span>

</li>
<li><span id="lin_ml_regularization_2014">[2]H.-T. Lin, “Lecture 14: Regularization.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li>
<li><span id="ng_ml_r_2014">[3]A. Ng, “Regularization: The problem of overfitting.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-11">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-regularize-all">
      <p>为什么正则化包括$x_0=1$的偏移项系数，两者有何区别？ <a href="#fnref:why-regularize-all" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>过拟合的危害</title>
      <link href="http://qianjiye.de/2015/01/hazard-of-overfitting" />
      <pubdate>2015-01-26T13:47:38+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/hazard-of-overfitting</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">初识过拟合</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png" alt="［左］：好的拟合；［右］：过拟合" /></a><div class="caption">图 1:  ［左］：好的拟合；［右］：过拟合 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png">PNG</a>]</div></div></div>

<ul>
  <li>差的泛化（bad generalization）：低的$E_{in}$高的$E_{out}$，$E_{out}-E_{in}$很大；</li>
  <li>过拟合（overfitting）：$E_{in}$降低时$E_{out}$升高；</li>
  <li>欠拟合（underfitting）：$E_{in}$升高时$E_{out}$也在升高。</li>
</ul>

<p>上图右采用了4次多项式变换$\Phi$和$\mathcal Z$空间的线性拟合，$N=5$个点时存在唯一解<sup id="fnref:is-unique"><a href="#fn:is-unique" class="footnote">1</a></sup>，$E_{in}=0$，过拟合了。</p>

<p>泛化能力描述的是既成的状态，过拟合描述的是变化过程。解决欠拟合可采用<a href="/2015/01/nonlinear-transformation">非线性特征变换</a>，解决过拟合更复杂。过拟合主要受噪声和数据量的影响。</p>

<h2 id="section-1">过拟合的特性</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png" alt="［左］：10次多项式的含噪数据；［右］：50次多项式的无噪数据" /></a><div class="caption">图 2:  ［左］：10次多项式的含噪数据；［右］：50次多项式的无噪数据 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png">PNG</a>]</div></div></div>

<p>上图展示了分别用2次和10次多项式拟合1含噪和无噪数据的效果。结果有些意外，2次多项式的性能都要优于10次多项式。</p>

<p>下图的学习曲线表明，当数据量$N$较小时，10次多项式的$E_{in}$和$E_{out}$之间差距较大，泛化误差更大，这和VC界一致，因为10次多项式的$d_{VC}$较大。因此，当数据量较少时，用简单的模型更合适得到较好的结果。</p>

<p>对于上图右不带噪声的数据，10次多项式的表现仍然很差。这是由于目标函数过于复杂，生成的数据很像噪声。可以这样理解，50次多项式生成的无噪数据和10次多项式生成的数据加入噪声相似。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png" alt="2次和10次多项式的学习曲线" /></a><div class="caption">图 3:  2次和10次多项式的学习曲线 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png">PNG</a>]</div></div></div>

<p>假设数据产生的方式为
\[
y=f(x)+\epsilon\sim\mbox{Gaussian}\left(\sum_{q=0}^{Q_f}\alpha_qx^q,\sigma^2\right)，
\]</p>

<p>$\sigma^2$表示产生噪声的等级，$Q_f$是模型的复杂度，数据集的大小为$N$。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png" alt="不同参数影响下的过拟合图谱（越红过拟合越厉害）" /></a><div class="caption">图 4:  不同参数影响下的过拟合图谱（越红过拟合越厉害） [<a href="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png">PNG</a>]</div></div></div>

<p>实验时确保能产生包含模型最高次的数据，过拟合采用$E_{out}(g_{10})-E_{out}(g_{2})$度量。上图分别展示了固定模型复杂度和噪声等级下的过拟合图谱，红色表示过拟合强，蓝色表示过拟合弱。上图左固定住模型复杂度，通过$\sigma^2$产生的噪声称为随机噪声（stochastic noise）；上图右固定住噪声等级，通过模型复杂度$Q_f$导致的“噪声”称为确定性噪声（deterministic noise）。</p>

<p>事实上，过拟合很容易发生：</p>

<ul>
  <li>当数据量$N$少的时候，</li>
  <li>当随机噪声大的时候，</li>
  <li>当确定性噪声大的时候，</li>
  <li>当模型复杂$d_{VC}$大的时候，</li>
</ul>

<p>这几种情况都容易发生过拟合。</p>

<p>确定性噪声大表示目标函数太复杂，机器难以学会。复杂模型产生的数据就像就像含有随机噪声一样，它就像伪随机数发生器（pseudo-random generator）。确定性噪声与随机噪声不同的地方包括：（1）当$\mathcal H$变复杂时，确定性噪声会减小；（2）固定$\mathbf x$后，确定性噪声也是固定的。</p>

<h2 id="section-2">克服过拟合</h2>

<p>克服过拟合的方法：</p>

<ul>
  <li>从简单的模型开始尝试；</li>
  <li>数据清洗或剪枝；</li>
  <li>根据已有数据生成更多数据（data hinting）；</li>
  <li><a href="/2015/01/regularization">正则化</a>；</li>
  <li><a href="/2015/01/validation">验证</a>（validation）。</li>
</ul>

<h4 id="data-cleaning">一、数据清洗或剪枝</h4>

<p>可以利用<a href="/2014/12/machine-learning-anomaly-detection">异常检测</a>的方法，探测出离群点，然后改变类别标签（数据清洗）或者移除异常点（数据剪枝），通常探测离群点的方法包括：</p>

<ul>
  <li>离本类很远，离其它类却很近；</li>
  <li>被当前分类器错误分类；</li>
  <li>……</li>
</ul>

<p>数据清洗或剪枝对性能的影响难以把握，有时对提升效果可能非常微弱。</p>

<h4 id="data-hinting">二、数据生成（data hinting）</h4>

<p>根据已有数据或已知规则产生新的数据。比如字符识别的时候，通过旋转等方式生成新的字符样本。</p>

<p>但是需要注意，新加入的样本不再是来自原来的概率分布，不再是i.i.d.（independent identically distributed）。</p>

<h2 id="section-3">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-unique">
      <p>4次多项式变换在$N=5$个点时存在唯一解？不对吧！ <a href="#fnref:is-unique" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>非线性特征变换</title>
      <link href="http://qianjiye.de/2015/01/nonlinear-transformation" />
      <pubdate>2015-01-25T19:03:12+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/nonlinear-transformation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">非线性变换</h2>

<p>线性假设集（分类器）的类别之间的判别界是线性的，低VC维可使$E_{in}$和$E_{out}$接近，但无法分类线性不可分数据。线性分类器应用于线性不可分数据，会导致很大的$E_{in}$，$E_{out}$也会很大。如何突破线性分类器的局限，对线性不可分数据分类？</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png"><img src="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png" alt="［左］：线性不可分；［中］：圆可分；［右］Z空间线性可分" /></a><div class="caption">图 1:  ［左］：线性不可分；［中］：圆可分；［右］Z空间线性可分 [<a href="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png">PNG</a>]</div></div></div>

<p>上图左的数据$\mathcal D$虽然线性不可分，但是可以用上图中所示的圆分开
\[
h_{SEP}(\mathbf x)=\mbox{sign}\left(0.6-x_1^2-x_2^2\right)，
\]
令$\tilde{\mathbf w}^T=[0.6,-1,-1],\mathbf z=\left[1,x_1^2,x_2^2\right]^T$，上式可以记为
\[
h(\mathbf x)=\mbox{sign}\left(\tilde{\mathbf w}^T\mathbf z\right)，
\]
这就相当于通过<strong>非线性特征变换</strong>$\Phi: \mathbf x\in\mathcal X\mapsto\mathbf z\in\mathcal Z$，将$\mathcal X$空间中线性不可分数据变到线性可分的$\mathcal Z$空间，如上图右所示。</p>

<p>通过变换$\Phi_2(\mathbf x)=\left(1,x_1,x_2,x_1^2,x_1x_2,x_2^2\right)$，可以使得$\mathcal Z$空间的感知器和$\mathcal X$空间的二次假设等价，
\[
\mathcal H_{\Phi_2}=\left\{h(\mathbf x):h(\mathbf x)=\tilde h(\Phi_2(\mathbf x))\mbox{ for some linear }\tilde h\mbox{ on }\mathcal Z\right\}
\]
可以实现$\mathcal X$空间的所有二次曲线判别界，当然也包括线性的特殊情况，使得$E_{in}$有机会更小。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation.png"><img src="/assets/images/2015-01-25-nonlinear-transformation.png" alt="非线性变换步骤" /></a><div class="caption">图 2:  非线性变换步骤 [<a href="/assets/images/2015-01-25-nonlinear-transformation.png">PNG</a>]</div></div></div>

<p>上图展示了使用非线性变换的步骤。首先通过变换$\Phi$将数据从$\mathcal X$空间映射到$\mathcal Z$空间；然后在$\mathcal Z$空间利用线性分类算法$\mathcal A$得到线性判别界；最后返回
\begin{equation}
g(\mathbf x)=\mbox{sign}\left(\tilde{\mathbf w}^T\Phi(\mathbf x)\right)，
\end{equation}
逆变换$\Phi^{-1}$不一定存在。</p>

<p>非线性变换$\Phi$和$\mathcal Z$空间的线性模型算法$\mathcal A$，不仅可以用于分类，而且可用于回归。</p>

<h2 id="section-1">复杂度与性能分析</h2>

<p>若原始特征是$d$维，$Q$次多项式特征变换$\Phi_{Q}(\mathbf x)$后的特征空间维度$\tilde d+1$为$\binom{Q+d}{Q}$，空间复杂度为$O\left(Q^d\right)$。当$Q$很大时，新空间中的计算和存储代价都极大。新空间中$d_{VC}\left(\mathcal H_{\Phi_Q}\right)\leq \tilde d+1$，当$Q$很大时$d_{VC}$也会很大。当$d_{VC}$增加时，用于训练的数据量也要增加，需要考虑训练集的数据量是否足够。</p>

<div class="image_line" id="human-learning"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png"><img src="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png" alt="选择不同特征变换" /></a><div class="caption">图 3:  选择不同特征变换 [<a href="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png">PNG</a>]</div></div></div>

<p>上图展示了人工基于视觉的选择，不同特征变换下，$d_{VC}$从6降到了1。事实上，此时的模型复杂度需要考虑人工付出的$d_{VC}$代价，这是“human learning ＋ machine learning”。对于机器学习，人工偷看了数据付出的代价也必须加以考量。</p>

<p>对于特征变换，$Q$次变换可以在$Q-1$次的基础上进行
\[
\Phi_{Q}(\mathbf x)=\left(\Phi_{Q-1}(\mathbf x),x_1^Q,x_1^{Q-1}x_2,\ldots,x_d^Q\right)，
\]
也就是存在嵌套关系
\[
\mathcal H_{\Phi_0}\subset\mathcal H_{\Phi_1}\subset\mathcal H_{\Phi_2}\subset\ldots\subset\mathcal H_{\Phi_Q}，
\]
那么$d_{VC}$按上述次序递增（$\leq$），$E_{in}$按上述次序递减（$\geq$）。高次变换能得到$E_{in}$非常小的结果，然而$E_{in}$仅仅是中间产物，并<a href="/2014/12/machine-learning-the-vc-dimension/#vc-and-errors">不能说明$E_{out}$会很小</a>。合理的方法是从$H_{\Phi_1}$开始尝试，线性模型是首选，如果效果不达标再考虑高次的特征变换。</p>

<h2 id="section-2">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>线性分类模型</title>
      <link href="http://qianjiye.de/2015/01/linear-models-for-classification" />
      <pubdate>2015-01-25T12:23:40+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/linear-models-for-classification</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">回归用于分类</h2>

<p>线性分类器、线性回归和logistic回归，都采用了同样的线性评分函数
\[
s=\mathbf w^T\mathbf x
\]
它们之间的对比如下：
<img src="/assets/images/2015-01-25-linear-models-for-classification-linear-models.png" alt="线性模型" id="linear-models" /></p>

<p>最小化线性分类器的$E_{in}(\mathbf w)$更困难，它是NP-Hard，能否用回归方法解决分类问题？✅</p>

<p>线性分类器、线性回归和logistic回归，它们的误差函数分别可记为
\[
\mbox{err}_{0/1}(s,y)=[[\mbox{sign}(ys)\neq 1]];\quad
\mbox{err}_{SQR}(s,y)=(ys-1)^2;\quad
\mbox{err}_{CE}(s,y)=\ln(1+\exp(-ys))。
\]</p>

<div class="image_line" id="error-bound"><div class="image_card"><a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png"><img src="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png" alt="误差曲线对比" /></a><div class="caption">图 1:  误差曲线对比 [<a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png">PNG</a>]</div></div></div>

<p>上图展示了误差曲线的对比，为了比较方便，用$\mbox{err}_{SCE}(s,y)=\log_2(1+\exp(-ys))$代替$\mbox{err}_{CE}$。从图中容易看出
\[
\mbox{err}_{0/1}(s,y)\leq\mbox{err}_{SCE}(s,y)={1\over\ln 2}\mbox{err}_{CE}(s,y)，
\]
因此可得
\[
E_{in}^{0/1}(\mathbf w)\leq E_{in}^{SCE}(\mathbf w)={1\over\ln 2}E_{in}^{CE}(\mathbf w)\quad\mbox{and}\quad
E_{out}^{0/1}(\mathbf w)\leq E_{out}^{SCE}(\mathbf w)={1\over\ln 2}E_{out}^{CE}(\mathbf w)，
\]
从而可得
\[
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+\Omega^{0/1}\quad\mbox{or}\quad
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+{1\over\ln 2}\Omega^{CE}，
\]
$E_{out}^{0/1}$和$E_{in}^{SQR}$之间也存在同样的关系。从以上关系可以看出，做到$E_{in}^{CE}(\mathbf w)$很小时也可使$E_{out}^{0/1}(\mathbf w)$很小，那么用线性或logistic回归也可解决线性分类问题，
\[
g(\mathbf x)=\mbox{sign}(\mathbf w_{REG}^T\mathbf x)。
\]</p>

<p>PLA在数据线性可分时效率较高否则需要采用pocket算法，线性或logistic回归“容易”优化但采用了比$err_{0/1}$松散的误差上限。</p>

<p>可用线性回归设置PLA、pocket或logistic回归的初始值$\mathbf w_0$，logistic回归的计算复杂度和pocket相当，通常logistic回归的性能优于pocket。</p>

<h2 id="section-1">随机梯度下降法</h2>

<p>迭代优化时，参数更新可以表示为
\begin{equation*}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\mathbf v\quad(t=0,1,\ldots)。
\end{equation*}
PLA每次采用一个数据更新参数，但logistic的梯度下降法每次采用全部数据更新参数，显然logistic更新过程计算量大很多。logistic回归和pocket效率差不多，能否使logistic回归和PLA一样快呢？✅</p>

<p>logistic回归采用的参数更新方法是
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta{1\over N}\sum_{n=1}^N\theta\left(-y_n\mathbf w^T\mathbf x_n\right)(y_n\mathbf x_n)，
\end{equation}
按梯度负方向$\mathbf v=-\nabla E_{in}(\mathbf w)$更新。通过$n$个点计算可估计梯度，极端情况用1个点计算估计梯度，称为随机梯度。随机梯度可视为真实梯度与零均值噪声之和，经过足够过的迭代次数，平均的真实梯度和平均的随机梯度基本相同，可利用随机梯度更新参数，
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)(y_n\mathbf x_n)，
\end{equation}
这就是<strong>随机梯度下降法</strong>（SGD，stochastic gradient descent）。</p>

<p>随机梯度法的优点是简单且计算量小，有利于大数据和在线学习；其缺点是稳定性欠佳，尤其是$\eta$很大时。随机梯度法实现时需要处理两个问题：</p>

<ol>
  <li>停止条件：梯度下降法可通过梯度是否接近零作为停止条件，但是随机梯度法没有梯度计算，难以确定停止条件，通常用足够大的迭代次数$t$作为停止条件；</li>
  <li>选择合适的$\eta$：通常利用交叉验证选择，经验表明$\eta=0.1$在大多数情况下是不错的选择。</li>
</ol>

<p>回顾PLA的参数更新过程
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+1\cdot\left[\left[-y_n\neq\mbox{sign}(\mathbf w_t^T\mathbf x_n)\right]\right](y_n\mathbf x_n)，
\end{equation}
随机梯度下降法的logistic回归想当于soft-PLA，用$\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)$表示更新的力度；当$\eta=1$并且$\mathbf w_t^T\mathbf x$很大时，PLA和随机梯度下降法的logistic回归相似。利用随机梯度下降法的线性回归可以表示为
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+2\eta\left(y_n-\mathbf w_t^T\mathbf x_n\right)\mathbf x_n，
\end{equation}
$y_n-\mathbf w_t^T\mathbf x_n$表示错得越多，更新力度越大。</p>

<h2 id="multiple-classes">多分类问题</h2>

<p>采用one-vs-all的数据分割策略，利用logistic回归进行软性（softly）分类，选择“概率”大的类别
\begin{equation}
g(\mathbf x)=\arg\max_{k\in\mathcal Y}\theta\left(\mathbf w_{[k]}^T\mathbf x\right)=\arg\max_{k\in\mathcal Y}\mathbf w_{[k]}^T\mathbf x。
\end{equation}
one-vs-all方式的优点是简单易推广，并且很容易并行化训练每个分类器；它的坏处是当类别数$K$很大时，数据集$\mathcal D_{[k]}$的不平衡（unbalance）问题凸显。不平衡数据导致logistic回归通过误差最小化求解参数时，倾向于选择有利于数据量多的类别的假设。事实上，有专门的多分类logistic模型，例如<a href="/2015/01/image-classification-svm-and-softmax-based-linear-classifier/#softmax-classifier">softmax分类器</a>。</p>

<p>one-vs-one的方法有利于克服one-vs-all的数据不平衡问题，采用投票机制判断类别，类似循环赛，
\begin{equation}
g(\mathbf x)=\mbox{tournament champion}\left\{\mathbf w_{[k,l]}^T\mathbf x\right\}。
\end{equation}
one-vs-one方式训练每个分类器数据量较少，因此比较有效率，它克服了数据不平衡，以及利用了循环赛机制，所以更稳定；它的坏处是分类器数目更多，导致空间存储增大，预测时间增加，需要更多的训练<sup id="fnref:need-more-training"><a href="#fn:need-more-training" class="footnote">1</a></sup>，并且存在<a href="/2014/10/multiple-classes/#anbiguous-regions">有争议的判别区间</a>。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:need-more-training">
      <p>每个分类器数据少了，训练时间复杂度会增加吗？ <a href="#fnref:need-more-training" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（4）：随机森林</title>
      <link href="http://qianjiye.de/2015/01/random-forest" />
      <pubdate>2015-01-24T17:33:22+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/random-forest</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">随机森林</h2>

<p>bagging通过投票或平均的方法，可以减少variance；决策树功能强大， 但是有很大的variance。能否将二者融合起来，优势互补？</p>

<p>［1/3］random forest（RF） = bagging + fully-grown C&amp;RT tree</p>

<p>random描述了bagging中bootstrapping过程的随机性；forest表示很多树的组合。</p>

<blockquote>
  <h4 id="section-1">随机森林算法</h4>
  <hr />
  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>通过bootstrapping方法从$\mathcal D$中抽取大小为$N’$的数据集$\tilde{\mathcal D}_t$；</li>
    <li>通过决策树算法$\mbox{DTree}(\tilde{\mathcal D}_t)$得到$g_t$。</li>
  </ol>

  <p>返回$G=\mbox{Uniform}(\{g_t\})$就是随机森林。</p>
</blockquote>

<p>不同的$g_t$是进行分类器融合的关键。bagging通过bootstrapping的方法制造数据的随机性，从而得到不同的$g_t$。</p>

<p>另一种得到不同$g_t$的方法是从$\mathbf x$中随机抽取$d’$维特征：</p>

<ul>
  <li>随机抽取索引为$i_1,i_2,\ldots,i_{d’}$的特征，特种空间从高维到低维投影，$\Phi(\mathbf x)=\left(x_{i_1},x_{i_1},\ldots,x_{i_{d’}}\right)$；</li>
  <li>$\mathcal Z\in\mathbb R^{d’}$是$\mathcal X\in\mathbb R^d$的<strong>随机子空间</strong>（random subspace）；</li>
  <li>通常$d’\ll d$，对大的$d$这样更高效<sup id="fnref:small-subspace"><a href="#fn:small-subspace" class="footnote">1</a></sup>；</li>
</ul>

<p>RF的原作者建议每次在C&amp;RT找$b(\mathbf x)$时，都重采样得到新的$d’$维特征子空间，让得到的树更不一样：</p>

<p>［2/3］RF ＝ bagging ＋ random-subspace C&amp;RT。</p>

<p>随机从$\mathbf x$中采样$d’$维特征可记为$\Phi(\mathbf x)=\mathbf P\mathbf x$，利用$\mathbf P$的第$i$随机抽取1维特征，这样的行属于自然基（natural basis）。</p>

<p>采用<strong>随机组合方式</strong>，利用随机的行$\mathbf p_i$对特征进行投影（组合），$\phi_i(\mathbf x)=\mathbf p_i^T\mathbf x$，可以得到更强大的特征空间。通常采用的是低维投影，$\mathbf p_i$中只有$d’’$个非零元素。随机子空间是$d’’=1$的特殊情况，且$\mathbf p_i$属于自然基。</p>

<p>RF的原作者建议每次在C&amp;RT找$b(\mathbf x)$时，都进行$d’$的随机低维投影（组合）：</p>

<p>［3/3］RF ＝ bagging ＋ random-combination C&amp;RT</p>

<p>采用随机组合方式的C&amp;RT树，每个分支函数$b(\mathbf x)$相当于感知器（线性分类器）。</p>

<h2 id="oob">OOB方法</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png"><img src="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png" alt="out-of-sample数据点" /></a><div class="caption">图 1:  out-of-sample数据点 [<a href="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png">PNG</a>]</div></div></div>

<p>采用bagging的时候，没被选中数据点称为out-of-bag（OOB）数据点，如上图左所示，星号标注的点表示没有对训练任何$g_t$有贡献。当$N’=N$时，对每次训练$g_t$的数据集$(\mathbf x_n,y_n)$是OOB的概率是$\left(1-{1\over N}\right)^N$，如果$N$很大时，这个概率是${1\over e}$。$g_t$对应数据集OOB数据大小约为${N\over e}$，这表明数据集中有不少点（大约1/3）没有参与训练。</p>

<p>OOB数据可以看作用于验证的数据，如上图右所示。但是通常不需要验证$g_t$，因为即使$g_t$效果不理想，融合后的分类器$G$仍然可以达到很好的效果。$G_n^-$表示$\{\mathbf x_n,y_n\}$是OOB数据点的分类器的集合，上图左最下一行$G_n^-=\mbox{average}(g_2,g_3,g_T)$，利用OOB数据集校验的误差定义为
\begin{equation}
E_{oob}(G)={1\over N}\sum_{n=1}^Nerr\left(y_n,G_n^-(\mathbf x_n)\right)，
\end{equation}
利用$E_{oob}$，bagging和RF可以实现自验证（self-validation）。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-oob-validation.png"><img src="/assets/images/2015-01-24-random-forest-oob-validation.png" alt="［左］：验证集方法［右］：OOB集方法" /></a><div class="caption">图 2:  ［左］：验证集方法［右］：OOB集方法 [<a href="/assets/images/2015-01-24-random-forest-oob-validation.png">PNG</a>]</div></div></div>

<p>上图是传统验证方法和$E_{oob}$的对比，$E_{oob}$通常能很准确的衡量$G$的性能。利用$E_{oob}$进行$d’’$等参数选择，通常不需要重新训练<sup id="fnref:why-not-re-training"><a href="#fn:why-not-re-training" class="footnote">2</a></sup>。</p>

<h2 id="section-2">特征选择</h2>

<p>特征选择就是移除冗余（redundant）和不相关（irrelevant）的特征。主要优点包括：</p>

<ul>
  <li>高效：让假设集和简单，预测时间变短；</li>
  <li>提升泛化能力：移除特征的同时也移除了那些特征的噪声；</li>
  <li>增强可理解性：剩余的特征对结果的解释性更强；</li>
</ul>

<p>但也存在对应的缺点：</p>

<ul>
  <li>计算量大：从特征空间选择重要的特征子集本身是组合优化问题；</li>
  <li>过拟合：恰好选到那些结果看似很好的特征组合；</li>
  <li>误解释：特别是存在过拟合时，可能得到结果的错误解释，或者只能得出关联性而非因果关系。</li>
</ul>

<p>决策树本身具备特征选择的能力，每次在某个特征上进行分割，用到的那些特征就是被选择的特征，这和decision stump类似。</p>

<p>特征选择的简单理想情况是不考虑特征组合的影响，计算每个特征的重要性，从$d$维特征中选择最重要的$d’$维特征。通过线性模型容易实现
\[
score = \mathbf w^T\mathbf x=\sum_{i=1}^dw_ix_i，
\]
对良好的$\mathbf w$（对特征给出合理评分），第$i$维特征的重要性$\mbox{importance}(i)=|w_i|$，大的数值对得分贡献大。$\mathbf w$可通过数据进行学习得到。</p>

<p>对于非线性模型，特征选择通常比较复杂。虽然RF是非线模型，但是由于内在的机制，采用<strong>随机测试</strong>（random test）也能方便选择特征。如果特征$i$很重要，用随机值$\mathbf x_{n,i}$代替该特征就会极大降低性能。产生这些随机值的方法包括：</p>

<ul>
  <li>通过均分分布或高斯分布产生：真实数据的分布$P(x_i)$可能并不服从这些分布，不仅加入了噪声，而且改变了分布，不是理想的方法。</li>
  <li>bootstrap或者组合（permutation）方法：这样就保持了原来的分布$P(x_i)$，组合方法重新排列原始特征（类似洗牌）。</li>
</ul>

<p>利用组合方法重排特征进行性能测试称为<strong>组合测试</strong>（permutation test），
\[
\mbox{importance}(i)=\mbox{importance}(\mathcal D)-\mbox{importance}(\mathcal D^{(p)})，
\]
$\mathcal D^{(p)}$表示$\mathcal D$的特征$\{x_{n,i}\}$经过重新“洗牌”。组合测试是一种统计工具，可以用于类似RF的其它非线性模型。</p>

<p>通常需要重新训来呢得到$\mbox{importance}(\mathcal D^{(p)})$，但是可RF利用OOB不需重新训练，
\[
\mbox{importance}(i)=E_{oob}(G)-E_{oob}^{(p)}(G)，
\]
得到$E_{oob}^{(p)}(G)$的方法是，在计算过程中需要$x_{n,i}$的地方，用组合的OOB值代替$x_{n,i}$。</p>

<p>在实际中，RF通过“permutation + OOB”进行特征选择，通常不仅高效而且有效。</p>

<h2 id="rf">RF特性</h2>

<p>通常随机森林需要的树越多越好🌲🌲🌲🌲，$\bar g=\lim_{T\rightarrow\infty} G$。通过增减树判断随机森林是否稳定，确保有足够多的树，如果不够，继续增加🌲。</p>

<p>台湾大学在KDDCup 2013中发现，随机森林的$E_{val}$表现依赖初始的种子点，最终通过将树增加到12000课，固定种子为1，夺得了冠军🏆。</p>

<h4 id="section-3">以下图片展示了随机森林的优点：</h4>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-large-margin.png"><img src="/assets/images/2015-01-24-random-forest-large-margin.png" alt="通过多棵树得到平滑和类似最大边界的判别界" /></a><div class="caption">图 3:  通过多棵树得到平滑和类似最大边界的判别界 [<a href="/assets/images/2015-01-24-random-forest-large-margin.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg"><img src="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg" alt="容易得到鲁棒的非线性模型" /></a><div class="caption">图 4:  容易得到鲁棒的非线性模型 [<a href="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg">JPG</a>]</div></div></div>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-noise-corrected.jpg"><img src="/assets/images/2015-01-24-random-forest-noise-corrected.jpg" alt="通过投票机制消除噪声的干扰" /></a><div class="caption">图 5:  通过投票机制消除噪声的干扰 [<a href="/assets/images/2015-01-24-random-forest-noise-corrected.jpg">JPG</a>]</div></div></div>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:small-subspace">
      <p>这种方法也可以用于其它机器学习模型。 <a href="#fnref:small-subspace" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-not-re-training">
      <p>为什么不需要重新训练？ <a href="#fnref:why-not-re-training" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
