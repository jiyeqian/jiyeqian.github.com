<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2014-11-18T09:51:46+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>机器学习: 神经网络</title>
      <link href="http://qianjiye.de/2014/11/machine-learning-neural-networks" />
      <pubdate>2014-11-09T11:09:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/11/machine-learning-neural-networks</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">简介</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-10-21-neural-networks_1.png"><img src="/assets/images/2014-10-21-neural-networks_1.png" alt="神经网络结构" /></a><div class="caption">Figure 1:  神经网络结构 [<a href="/assets/images/2014-10-21-neural-networks_1.png">PNG</a>]</div></div></div>

<p>神经网络是神经元分层级联构成的网络，除输入层外每个神经元对应一个计算模型。最左边和最右边的层分别称为输入（input）和输出（output）层，中间两层为隐藏层（hidden layer）。</p>

<p>当特征数目巨大时，简单的Logistic回归无法满足需求。神经网络用于解决复杂的非线性问题，可以看成是Logistic回归的组合，上图中每个橙色的神经元（除输入层之外）都对应一个Logistic方程。</p>

<p>对于分类问题，输入层输入原始数据，隐藏层的每个神经元可视为提取一种特征，输出层的每个神经元对应所属类别的概率（不是类别标签）。输入数据所属的类别是输出层概率最大神经元对应的类别。</p>

<p>神经网络通过前向传播计算给定输入对应的输出，通过误差反向传播估计权值矩阵。</p>

<h2 id="section-1">前向传播计算</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-10-21-neural-networks_2.png"><img src="/assets/images/2014-10-21-neural-networks_2.png" alt="神经网络前向传播计算" /></a><div class="caption">Figure 2:  神经网络前向传播计算 [<a href="/assets/images/2014-10-21-neural-networks_2.png">PNG</a>]</div></div></div>

<p>神经网络前向传播，从输入到输出，逐层计算。上图所示<a href="#ng_ml_nnr_2014">[1, P. 23]</a>，假设权值矩阵$\Theta^{(l-1)}$已知，第$l$层可通过第$l-1$层和权值矩阵前向计算，</p>

<p>\begin{equation}
\mathbf a^{(l)} = g\left(\mathbf\Theta^{(l-1)}\mathbf a^{(l-1)}\right),
\label{eq:forward-propagation}
\end{equation}</p>

<p>$g$是<a href="/2014/10/machine-learning-logistic-regression/#mjx-eqn-eqsigmoid-function">Logistic函数</a>，每层额外增加了一个$\mathbf a_0^{(l)}= 1$的偏移（bias），$\mathbf\Theta^{(l-1)}$的行数为第$i$层神经元个数，列数为第$l-1$层神经元个数加$1$。</p>

<p>输出层（第$L$层）神经元的输出$\mathbf a^{(L)}$确定输入特征所属的类别。</p>

<p>如果上图去掉隐藏层只有输入和输出层，这就相当于一个Logistic回归模型。</p>

<h2 id="section-2">反向参数估计</h2>

<p>神经网络通过反向传播估计权值矩阵$\Theta$，参数估计仍然是最小化代价函数。通过BP算法（BackPropagation algorithm），输出层的误差向输入层逐层反向传播，利用梯度下降法，估计权值矩阵。</p>

<h3 id="section-3">代价函数</h3>

<p>神经网络的神经元是Logistic模型，存在和Logistic模型类似的代价函数</p>

<p>\begin{equation}
\begin{aligned}
J(\Theta) = &amp;-\frac{1}{m}\sum_{i=1}^{m}\sum_{k=1}^{K}\left(y_k^{(i)}\log \left(h_\Theta\left(\mathbf x^{(i)} \right) \right)_k + \left(1 - y_k^{(i)}\right)\log\left(1 -  \left(h_\Theta\left(\mathbf x^{(i)} \right) \right)_k \right) \right) \\ 
&amp;+\frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}\left(\Theta_{ji}^{(l)}\right)^2.
\end{aligned}
\label{eq:cf_nn}
\end{equation}</p>

<p>$h_\Theta (x) \in \mathbb{R}^K$，$\left(h_\Theta (x)\right)_k = \mathbf a_k^{(L)} $是输出层第$k$个神经元的输出，可由前向传播公式\eqref{eq:forward-propagation}计算；$s_l$表示第$l$层神经元的个数（不含bias unit）；神经网络有$L$层，$m$个样本，$K$个输出。</p>

<p>如果代价函数\eqref{eq:cf_nn}是非凸（non-convex）函数<sup id="fnref:if_no_global_minimum"><a href="#fn:if_no_global_minimum" class="footnote">1</a></sup>，理论上可能会陷入局部极值，事实上，即使不能保证取得全局极值，梯度下降法也能很好的最小化代价函数，使得神经网络工作良好<a href="#ng_ml_nnl_2014">[2, P. 30]</a>。</p>

<p>对比<a href="/2014/10/machine-learning-regularization/#mjx-eqn-eqcf-logistic-regression-r">正则化Logistic回归的代价函数</a>，由于神经网络有$K$个输出，前半部分相当于$K$个Logistic回归的代价函数之和，后半部分是非bias神经元洗漱组成的正则化项，$\mathbf a_0^{(l)} = 1$对应的系数$\mathbf \Theta_{j0}^{(l)}$和Logistic回归一样，不包含在正则化系数中。</p>

<h3 id="section-4">参数估计</h3>

<p>通过最小化代价函数$\min_\Theta J(\Theta)$估计模型的所有参数矩阵$\Theta^{(l)}$，采用梯度下降法时需计算代价函数$J(\Theta)$及其梯度$\mathbf D_{ij}^{(l)}$，
\begin{equation*}
\mathbf D_{ij}^{(l)} = \frac{\partial J(\Theta)}{\partial\Theta_{ij}^{(l)}}.
\end{equation*}</p>

<p>第$l$层的误差记为$\mathbf\delta^{(l)}$，$\mathbf\delta_j^{(l)}$表示第$l$层的第$j$个神经元的误差，对于$\mathbf a_0^{(l)} = 1$的bias节点$\mathbf\delta_0^{(l)}=0$。输出层（$l=L$）的误差为
\begin{equation}
\mathbf\delta^{(L)} = \mathbf a^{(L)} - \mathbf y, 
\label{eq:error-bp-1}
\end{equation}
对于隐藏层$(l = L-1, L-2, \ldots, 2)$，误差通过权值矩阵$\Theta^{(l)}$从输出层向各隐藏层反向传播，
\begin{equation}
\mathbf\delta^{(l)} = \left(\Theta^{(l)}\right)^T\mathbf\delta^{(l+1)} .* g’\left(\mathbf z^{(l)}\right), 
\label{eq:error-bp-2}
\end{equation}</p>

<p>其中，$\mathbf z^{(l)} = \Theta^{(l)}\mathbf a^{(l)}$，$g’\left(\mathbf z^{(l)}\right) = \mathbf a^{(l)} .* \left(1 - \mathbf a^{(l)}\right)$。<code>.*</code>借用了Matlab中对应元素相乘的运算符。</p>

<p>Coursera的<a href="https://share.coursera.org/wiki/index.php/ML:Neural_Networks:_Learning">课程Wiki</a>和Michael Nielsen<a href="#nielsen_nndl_2014">[3]</a>的第二章给出了BP算法的推导过程<sup id="fnref:parameter_estimation"><a href="#fn:parameter_estimation" class="footnote">2</a></sup>。</p>

<blockquote>
  <h4 id="bp">BP算法</h4>
  <hr />
  <p>训练集：$\left\{\left(\mathbf x^{(1)}, \mathbf y^{(1)}\right),\ldots,\left(\mathbf x^{(m)}, \mathbf y^{(m)}\right)\right\}$。 </p>

  <p>初始化： <br />
1. $\Delta_{ij}^{(l)} = 0$； <br />
2. 随机数初始化$\Theta_{ij}^{(l)}$为$[-\epsilon, \epsilon]$的值，$\epsilon=\frac{\sqrt{6}}{\sqrt{L_{in} + L_{out}}}$由神经元数目确定，其中，$L_{in} = s_l$，$L_{out}=s_{l+1}$。<sup id="fnref:initial_theta"><a href="#fn:initial_theta" class="footnote">3</a></sup>  </p>

  <p>for $i=1$ to $m$ {  <br />
1. 初始化输入层，$\mathbf a^{(1)} = \mathbf x^{(i)}$； <br />
2. 利用前向传播\eqref{eq:forward-propagation}，计算各层神经元的值$\mathbf a^{(l)}~~(l = 2, 3,\ldots, L)$；<br />
3. 利用反向传播\eqref{eq:error-bp-1}和\eqref{eq:error-bp-2}，计算各层误差$\mathbf \delta^{(l)}$； <br />
4. 更新$\Delta_{ij}^{(l)}$，$\Delta_{ij}^{(l)} := \Delta_{ij}^{(l)} + \mathbf a_j^{(l)}\delta_i^{(l+1)}$<sup id="fnref:vector_update_Delta"><a href="#fn:vector_update_Delta" class="footnote">4</a></sup>（$\mathbf a^{(l)}$也须补$\mathbf a_0^{(l)}=1$）； <br />
5. 计算梯度$\mathbf D_{ij}^{(l)}$，
\begin{equation}
\mathbf D_{ij}^{(l)} := \left\{
\begin{aligned}
&amp; \frac{1}{m}\left(\Delta_{ij}^{(l)} + \lambda\Theta_{ij}^{(l)}\right) &amp; (j \neq 0) \\
&amp; \frac{1}{m}\Delta_{ij}^{(l)} &amp; (j = 0)
\end{aligned} 
\right. .
\end{equation}
}</p>
</blockquote>

<h3 id="section-5">实现细节</h3>

<p>算法技巧：矩阵展成（unroll）向量：</p>

<ol>
  <li><code class="highlight language-matlab"><span class="n">thetaVec</span> <span class="p">=</span> <span class="p">[</span><span class="n">Theta1</span><span class="p">(:);</span> <span class="n">Theta2</span><span class="p">(:);</span> <span class="n">Theta3</span><span class="p">(:)]</span></code>；</li>
  <li>将向量化的待估参数作为costFunction的参数；</li>
  <li>costFunction内部再将向量还原为矩阵计算梯度；</li>
  <li>梯度向量化输出<code class="highlight language-matlab"><span class="n">DVec</span> <span class="p">=</span> <span class="p">[</span><span class="n">D1</span><span class="p">(:);</span> <span class="n">D2</span><span class="p">(:);</span> <span class="n">D3</span><span class="p">(:)]</span></code>。</li>
</ol>

<p>算法技巧：梯度检查（gradient checking）：</p>

<p>梯度检测方法也可推广到其它需要计算代价函数及其梯度的地方，比如logistic回归的代价函数。</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">for</span> <span class="nb">i</span> <span class="p">=</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">n</span>
   <span class="n">thetaPlus</span> <span class="p">=</span> <span class="n">theta</span><span class="p">;</span>
   <span class="n">thetaPlus</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="n">thetaPlus</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="o">+</span> <span class="n">EPSILON</span><span class="p">;</span>
   <span class="n">thetaMinus</span> <span class="p">=</span> <span class="n">theta</span><span class="p">;</span>
   <span class="n">thetaMinus</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="n">thetaMinus</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> – <span class="n">EPSILON</span><span class="p">;</span>
   <span class="n">gradApprox</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="p">(</span><span class="n">J</span><span class="p">(</span><span class="n">thetaPlus</span><span class="p">)</span> – <span class="n">J</span><span class="p">(</span><span class="n">thetaMinus</span><span class="p">));</span>
<span class="k">end</span></code></pre></div>

<blockquote>
  <p>theta 是$\Theta$的向量化，正常情况有gradApprox$\approx$DVec，通过比较gradApprox 与BP 算法所得DVec 的差距判断BP 算法的代价函数及其优化算法是否有subtle bugs。</p>
</blockquote>

<div class="highlight"><pre><code class="language-matlab"><span class="c">% If your backpropagation implementation is correct, then the relative difference will be small (less than 1e-9). </span>
<span class="n">diff</span> <span class="p">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">gradApprox</span> <span class="o">-</span> <span class="n">DVec</span><span class="p">)</span> <span class="o">/</span> <span class="n">norm</span><span class="p">(</span><span class="n">gradApprox</span> <span class="o">+</span> <span class="n">DVec</span><span class="p">);</span></code></pre></div>

<blockquote>
  <p>梯度检查应当在训练神经网络之前，可以通过构造一个新的较小规模的神经网络进行检验；若每次训练都检测梯度，速度很慢。</p>
</blockquote>

<p>注意事项：</p>

<p>不可将$\Theta_{ij}^{(l)}$初始化为$0$，若初始化为$0$，每层的所有神经元都是一样的。随机数初始化$-\epsilon\leq\Theta_{ij}^{(l)}\leq\epsilon$，选择$\epsilon$的有效策略是根据每层神经元的数目取$\epsilon=\frac{\sqrt{6}}{\sqrt{L_{in} + L_{out}}}~(L_{in} = s_l,L_{out}=s_{l+1})$，例如：</p>

<div class="highlight"><pre><code class="language-matlab"><span class="n">Theta1</span> <span class="p">=</span>  <span class="nb">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">INIT_EPSILON</span><span class="p">)</span> <span class="o">-</span> <span class="n">INIT_EPSILON</span><span class="p">;</span>
<span class="n">Theta2</span> <span class="p">=</span>  <span class="nb">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">INIT_EPSILON</span><span class="p">)</span> <span class="o">-</span> <span class="n">INIT_EPSILON</span><span class="p">;</span></code></pre></div>

<h2 id="section-6">应用</h2>

<p>卡内基梅隆大学基于神经网络的自动驾驶系统<a href="#pomerleau_alvinn_1989">[5]</a>，一些Matlab代码和数据还可以从<a href="http://www.cs.cmu.edu/afs/cs/academic/class/15782-f06/matlab/alvinn/">这里</a>找到。</p>

<h2 id="section-7">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_nnr_2014">[1]A. Ng, “Neural Networks: Representation.” Coursera, 2014.</span>

[<a href="https://class.coursera.org/ml-007">Online</a>]

</li>
<li><span id="ng_ml_nnl_2014">[2]A. Ng, “Neural Networks: Learning.” Coursera, 2014.</span>

[<a href="https://class.coursera.org/ml-007">Online</a>]

</li>
<li><span id="nielsen_nndl_2014">[3]M. A. Nielsen, <i>Neural Networks and Deep Learning</i>. Determination Press, 2014.</span>

[<a href="http://neuralnetworksanddeeplearning.com">Online</a>]

</li>
<li><span id="ng_ml_nnl_pe_2014">[4]A. Ng, “Programming Exercise 4: Neural Networks Learning.” Coursera, 2014.</span>

[<a href="https://class.coursera.org/ml-007">Online</a>]

</li>
<li><span id="pomerleau_alvinn_1989">[5]D. A. Pomerleau, “ALVINN, an autonomous land vehicle in a neural network,” Carnegie Mellon University, 1989.</span>

[<a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=2874&amp;context=compsci">Online</a>]

</li></ol>

<h3 id="section-8">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:if_no_global_minimum">
      <p>如果非凸函数，梯度下降法不能确定取得的是全局还是局部极值，可通过<a href="https://class.coursera.org/ml-007/forum/thread?thread_id=1089#comment-3416">取不同初始值多次求解增强鲁棒性</a>。 <a href="#fnref:if_no_global_minimum" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:parameter_estimation">
      <p>这两篇博客（<a href="http://blog.csdn.net/abcjennifer/article/details/7758797">1</a>、<a href="http://blog.csdn.net/sheng_ai/article/details/19931347">2</a>）也给出了BP算法的推导过程，但是采用了形如<a href="/2014/10/machine-learning-linear-regression/#mjx-eqn-eqcost_function_linear_regression">线性回归的代价函数</a>。 <a href="#fnref:parameter_estimation" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:initial_theta">
      <p>不可将$\Theta_{ij}^{(l)}$初始化为$0$。若初始化为$0$，每层的所有神经元都一样<a href="#ng_ml_nnl_2014">[2, Pp. 25-26]</a>，每层只能学习到一种特征。$\epsilon$的取值方案参考课程习题脚注<a href="#ng_ml_nnl_pe_2014">[4, P. 7]</a>或<a href="https://share.coursera.org/wiki/index.php/ML:Neural_Networks:_Learning">课程Wiki</a>。 <a href="#fnref:initial_theta" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:vector_update_Delta">
      <p>更新的向量形式$\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}\left(\mathbf a^{(l)}\right)^T$。这一步是怎么来的？有何意义？ <a href="#fnref:vector_update_Delta" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>CSS Essential</title>
      <link href="http://qianjiye.de/2014/10/css-essential" />
      <pubdate>2014-10-25T15:37:41+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/10/css-essential</guid>
      <content:encoded>&lt;![CDATA[<blockquote>
  <h4 id="what-is-css">What is CSS?</h4>
  <hr />
  <p>The basic goal of the Cascading Stylesheet (CSS) language is to allow a browser engine to paint elements of the page with specific features, like colors, positioning, or decorations. </p>

  <p>CSS主要作用是设定元素（通常称为盒子）的属性，并将设定这些元素在页面的位置关系。CSS解决的主要问题是：    </p>

  <ol>
    <li>如何选择指定的元素？选择器（Selector）   </li>
    <li>如何设定元素的属性？盒子模型（Box Model）   </li>
    <li>如何设置元素间的位置关系？定位机制（Positioning Scheme）</li>
  </ol>
</blockquote>

<p>本文主要介绍CSS的基本用法，包括如何使用选择器，如何设定样式以及如何布局定位，这些涉及到选择器、盒子模型、普通流、可视化格式模型和块格式化环境等核心概念，理解这些核心概念是熟练运用CSS的基础。</p>

<p>若要详细了解相关内容，可参考文中链接，以及<a href="https://developer.mozilla.org/en-US/docs/Web/CSS" title="Cascading Style Sheets">MDN</a>、<a href="http://www.w3.org/Style/CSS/" title="Cascading Style Sheets home page">W3</a>和<a href="http://www.w3school.com.cn/css/index.asp" title="CSS 教程">w3school</a>关于CSS的详细介绍。</p>

<h2 id="section">基础知识</h2>

<h3 id="section-1">基本语法</h3>

<p>CCS语法元素主要由选择器，属性和值构成，通过规则给选择器范围内的属性赋值。   </p>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-25-css-essential_css-syntax-ruleset.png" alt="CSS语法" />
<div class="caption">CSS语法（规则）</div>
</div>
</div>

<!---
<div class="image_card">
<img src="/assets/images/2014-10-21-pla_1.png" alt="CSS语法">
<div class="caption">CSS语法（规则）</div>
</div>
--->

<h4 id="section-2">各部分元素含义：</h4>

<ul>
  <li><code>div p</code>：属性选择器</li>
  <li><code>#id</code>：id选择器</li>
  <li><code>first_line</code>：伪元素（pseudo-element）</li>
  <li><code>background-color</code>：属性（property）</li>
  <li><code>red</code>：值（value）</li>
</ul>

<h3 id="section-3">基本选择器</h3>

<p>选择器相当于作用域规则，选择属性设置起作用的范围。另一个相关概念是<a href="#block-formatting-context">块格式化环境</a>。</p>

<h4 id="section-4">常用选择器</h4>

<table>
  <tbody>
    <tr>
      <td>*</td>
      <td>通用选择器，匹配任何元素。</td>
    </tr>
    <tr>
      <td>E</td>
      <td>标签选择器，匹配所有使用E标签的元素。</td>
    </tr>
    <tr>
      <td>.info</td>
      <td>class选择器，匹配所有class属性中包含info的元素。</td>
    </tr>
    <tr>
      <td>#footer</td>
      <td>id选择器，匹配所有id属性等于footer的元素。</td>
    </tr>
  </tbody>
</table>

<p><strong>id选择器和class选择器的区别：</strong></p>

<ul>
  <li>在CSS文件中，id加前缀<code>#</code>，class用<code>.</code>；</li>
  <li>同一个页面id只可使用一次，class可多次引用：id是一个标签，用于区分不同的结构和内容，就象名字；class是一个样式，可套在任何结构和内容上，就象衣服，同一内容也可以套多个class的样式；</li>
  <li>从概念上说不一样：id是先找到结构/内容，再给它定义样式；class是先定义好一种样式，再套给多个结构/内容。</li>
</ul>

<div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;style&gt;</span>
<span class="nc">.content</span> <span class="p">{</span><span class="k">font-size</span><span class="o">:</span> <span class="m">1.2em</span><span class="p">;</span> <span class="k">line-height</span><span class="o">:</span> <span class="m">200%</span><span class="p">}</span>
<span class="nc">.emphasis</span> <span class="p">{</span><span class="k">font-weight</span><span class="o">:</span> <span class="k">bold</span><span class="p">}</span>
<span class="nf">#lily</span> <span class="p">{</span><span class="k">color</span><span class="o">:</span> <span class="nb">white</span><span class="p">;</span> <span class="k">background</span><span class="o">:</span> <span class="nb">black</span><span class="p">}</span>
<span class="nt">&lt;/style&gt;</span>
<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;content emphasis&quot;</span> <span class="na">id=</span><span class="s">&quot;lily&quot;</span><span class="nt">&gt;</span>The flower of lily of the valley is like tinkler, be born at spending cauline top to show raceme.<span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;content&quot;</span> <span class="na">id=</span><span class="s">&quot;lavender&quot;</span><span class="nt">&gt;</span>The air was fragrant with lavender.<span class="nt">&lt;/div&gt;</span></code></pre></div>

<h4 id="section-5">多选择器组合</h4>

<table>
  <tbody>
    <tr>
      <td>E,F</td>
      <td>多元素选择器，同时匹配所有E元素或F元素，E和F之间用逗号分隔。</td>
    </tr>
    <tr>
      <td>E F</td>
      <td>后代元素选择器，匹配所有属于E元素后代的F元素，E和F之间用空格分隔。</td>
    </tr>
    <tr>
      <td>E &gt; F</td>
      <td>子元素选择器，匹配所有E元素的子元素F。</td>
    </tr>
    <tr>
      <td>E + F</td>
      <td>毗邻元素选择器，匹配所有紧随E元素之后的同级元素F。</td>
    </tr>
  </tbody>
</table>

<p>如果两个选择器紧连，表示同时满足两个条件的内容。</p>

<div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;style&gt;</span>
<span class="nt">div</span><span class="nc">.content</span> <span class="p">{</span><span class="k">font-size</span><span class="o">:</span> <span class="m">1.2em</span><span class="p">;</span> <span class="k">line-height</span><span class="o">:</span> <span class="m">200%</span><span class="p">}</span>
<span class="nt">div</span><span class="nc">.emphasis</span> <span class="p">{</span><span class="k">font-weight</span><span class="o">:</span> <span class="k">bold</span><span class="p">}</span>
<span class="nt">div</span><span class="nf">#lily</span> <span class="p">{</span><span class="k">color</span><span class="o">:</span> <span class="nb">white</span><span class="p">;</span> <span class="k">background</span><span class="o">:</span> <span class="nb">black</span><span class="p">}</span>
<span class="nt">&lt;/style&gt;</span>
<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;content emphasis&quot;</span> <span class="na">id=</span><span class="s">&quot;lily&quot;</span><span class="nt">&gt;</span>
The flower of lily of the valley is like tinkler, be born at spending cauline top to show raceme.
<span class="nt">&lt;/div&gt;</span></code></pre></div>

<p>上例中，<code>div.emphasis</code>表示套用<code>.emphasis</code>样式的<code>div</code>标签。</p>

<h3 id="section-6">优先级别</h3>

<p>基本规则是<code>行内样式 &gt; id样式 &gt; class样式 &gt; 标签名样式</code>，也就是，选择越具体优先级越高。如下元素：   </p>

<div class="highlight"><pre><code class="language-css" data-lang="css"><span class="o">&lt;</span><span class="nt">div</span> <span class="nt">id</span><span class="o">=</span><span class="s2">&quot;ID&quot;</span> <span class="nt">class</span><span class="o">=</span><span class="s2">&quot;CLASS&quot;</span> <span class="nt">style</span><span class="o">=</span><span class="s2">&quot;color:black;&quot;</span><span class="o">&gt;&lt;/</span><span class="nt">div</span><span class="o">&gt;</span></code></pre></div>

<p>作用在其上样式的优先级从低到高是<code>div &lt; .CLASS &lt; div.CLASS &lt; #ID &lt; div#ID &lt; #ID.CLASS &lt; div#ID.CLASS</code>。</p>

<p><strong>继承与覆盖：</strong></p>

<p>子元素没有设置的属性会从父元素继承而来。同一元素的同一属性如有多次设置，优先级高的覆盖优先级低的；若是同一优先级，后设设置覆盖前设置。</p>

<div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;style&gt;</span>
<span class="nt">div</span> <span class="p">{</span><span class="k">font-size</span><span class="o">:</span> <span class="m">1em</span><span class="p">}</span>
<span class="nt">div</span><span class="nc">.content</span> <span class="p">{</span><span class="k">font-size</span><span class="o">:</span> <span class="m">1.2em</span><span class="p">;</span> <span class="k">line-height</span><span class="o">:</span> <span class="m">200%</span><span class="p">}</span>
<span class="nt">div</span><span class="nc">.emphasis</span> <span class="p">{</span><span class="k">font-size</span><span class="o">:</span> <span class="m">1.4em</span><span class="p">;</span> <span class="k">font-weight</span><span class="o">:</span> <span class="k">bold</span><span class="p">}</span>
<span class="nt">div</span><span class="nf">#lily</span> <span class="p">{</span><span class="k">color</span><span class="o">:</span> <span class="nb">white</span><span class="p">;</span> <span class="k">background</span><span class="o">:</span> <span class="nb">black</span><span class="p">}</span>
<span class="nt">&lt;/style&gt;</span>
<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;content emphasis&quot;</span> <span class="na">id=</span><span class="s">&quot;lily&quot;</span><span class="nt">&gt;</span>
The flower of lily of the valley is like tinkler, be born at spending cauline top to show raceme.
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">&quot;water_lily&quot;</span><span class="nt">&gt;&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span></code></pre></div>

<p>上例中，<code>div</code>设定的<code>font-size</code>优先级太低，不会生效；<code>.emphasis</code>覆盖<code>.content</code>的<code>font-size</code>，<code>#lily</code>的<code>font-size</code>最终为<code>1.4em</code>；<code>#water_lily</code>继承了<code>#lily</code>的所有属性。</p>

<h3 id="section-7">属性赋值</h3>

<p>确定属性最终取值要<a href="http://www.w3.org/TR/2001/WD-css3-values-20010713/#specified" title="Specified, computed, and actual values">经历3步</a>（<a href="http://www.w3.org/TR/CSS2/cascade.html#value-stages" title="Specified, computed, and actual values">CSS2经历4步</a>）：首先获取CSS样式中的指定值（specified value），然后如有必要则转换为绝对值或计算值（computed value），最后根据局部环境的约束再转换为实际值（actual value）。</p>

<p>指定值可能是绝对值（例如：<code>2mm</code>、<code>red</code>等），也可能是相对值（例如：<code>auto</code>、<code>1.2em</code>、<code>12%</code>等）。对于绝对值而言不需要计算即可获得计算值，相对值需要再借助参考值计算获得计算值。如果属性没有指定值，它的取值继承父元素。</p>

<p>在特定的客户端环境，可能还需要将计算值转换为实际值，比如可能需要将小数的边界近似取整。</p>

<blockquote>
  <h4 id="section-8">常用的赋值规则</h4>
  <hr />
  <ol>
    <li><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/color_value" title="&lt;color&gt;">颜色</a>赋值的三种形式：关键字、RGB空间、HSL空间；</li>
    <li><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/length" title="&lt;length&gt;">长度</a>赋值的两种形式：以<code>em</code>、<code>ex</code>、<code>ch</code>、<code>rem</code>、<code>vw</code>、<code>vh</code>、<code>vmin</code>、<code>vmax</code>为单位的相对赋值，以<code>cm</code>、<code>mm</code>、<code>in</code>、<code>pt</code>、<code>pc</code>、<code>px</code>为单位的绝对赋值；</li>
    <li><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/percentage" title="&lt;percentage&gt;">百分数</a>赋值：<code>width</code>、<code>margin</code>和<code>padding</code>等接受百分数赋值。</li>
  </ol>

  <p>示例：    </p>

  <p><code>em</code>等单位和百分数都是相对赋值，需要继承父属性的参考值。<code>em</code>是针对字体大小的值，$w$ <code>em</code> = $w$ $\times$ <code>font-size</code>。</p>

  <div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;div</span> <span class="na">style=</span><span class="s">&quot;font-size:18px;&quot;</span><span class="nt">&gt;</span>
  Full size text (18px)
  <span class="nt">&lt;span</span> <span class="na">style=</span><span class="s">&quot;font-size:50%;&quot;</span><span class="nt">&gt;</span>50%<span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">style=</span><span class="s">&quot;font-size:200%;&quot;</span><span class="nt">&gt;</span>200%<span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/div&gt;</span></code></pre></div>
  <p>上述代码中，<code>50%</code>从父属性继承而来的值是<code>18px</code>，然后再乘以<code>50%</code>（等价于<code>0.5em</code>），实际大小是<code>9px</code>（<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/percentage" title="&lt;percentage&gt;">查看效果</a>）。</p>
</blockquote>

<p>当一个属性可以有多个方向可设置值时，存在形如以下简写的赋值规则：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">位置</th>
      <th style="text-align: left">赋值规则</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/images/2014-10-25-css-essential_border1.png" alt="1" /></td>
      <td style="text-align: left"><code>border-width: 1em</code></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/images/2014-10-25-css-essential_border2.png" alt="2" /></td>
      <td style="text-align: left"><code>border-width: 1em 2em</code></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/images/2014-10-25-css-essential_border3.png" alt="3" /></td>
      <td style="text-align: left"><code>border-width: 1em 2em 3em</code></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/images/2014-10-25-css-essential_border4.png" alt="4" /></td>
      <td style="text-align: left"><code>border-width: 1em 2em 3em 4em</code></td>
    </tr>
  </tbody>
</table>

<h2 id="section-9">盒子模型</h2>

<p>CSS将HTML的元素（可认为是标签）定义为适合CSS处理的矩形盒（rectangular box）。<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/box_model">盒子模型（box model）</a>描述了这些矩形盒的尺寸、属性（颜色、背景和边框等）和位置特性，浏览器根据盒子模型实现页面的渲染与显示。</p>

<p>按照HTML的元素是否新开一行可分为块（block-level）元素和内联（inline）元素，这一特性对设置元素的布局至关重要。</p>

<blockquote>
  <h4 id="htmlblock-levelinline">HTML的块（block-level）元素和内联（inline）元素</h4>
  <hr />
  <p><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Block-level_elements">块元素</a>充满父元素的所有空间，每个块元素都会另起一个新行显示。块元素之内还可以包含块元素和行内元素。HTML定义的块元素包括<code>&lt;div&gt;, &lt;span&gt;, &lt;p&gt;</code>等。<a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Inline_elemente">内联元素</a>只占据标签包含内容的空间，不会另起新行显示。内联元素通常只包含内联元素。HTML定义的内联元素包括<code>&lt;span&gt;, &lt;code&gt;, &lt;textarea&gt;</code>等。   </p>

  <p><img src="/assets/images/2014-10-25-css-essential_css_box-intro.png" alt="d" /> </p>

  <p>上例中，<code>&lt;p&gt;</code>是块元素，新起一行显示，并且撑满了行，<code>&lt;em&gt;</code>是内联元素，紧接上一元素显示。</p>
</blockquote>

<p>CSS的<code>display</code>属性可设定HTML元素生成盒子的类型是块还是内联，常用的属性值有<code>block, inline, inline-block, none</code>。将<code>display</code>属性设为<code>block</code>，可将内联元素转为块元素。盒子模型有四类边：margin edge，border edge，padding edge，content edge。    </p>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-25-css-essential_box_model.gif" alt="CSS语法" />
<div class="caption">盒子模型的四类边</div>
</div>
</div>

<p><code>.box {with: ...; height: ...}</code>设置的是只是<code>Content</code>尺寸。相关边的的设置方法是：</p>

<div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nc">.box</span> <span class="p">{</span>
    <span class="k">width</span><span class="o">:</span> <span class="o">...</span><span class="p">;</span>
    <span class="k">height</span><span class="o">:</span> <span class="o">...</span><span class="p">;</span>
    <span class="k">padding</span><span class="o">:</span> <span class="o">...</span><span class="p">;</span>
    <span class="k">border</span><span class="o">:</span> <span class="o">...</span><span class="p">;</span>
    <span class="k">margin</span><span class="o">:</span> <span class="o">...</span><span class="p">;</span>
<span class="p">}</span></code></pre></div>

<p>内联元素设置属性<code>height</code>和<code>width</code>是没有用的，致使它变宽变大的原因是内部元素的宽高<code>+padding</code>。</p>

<p>满足一定条件俩个盒子的外边届（margin）会叠加，使得估计这俩个盒子的位置关系变得复杂。</p>

<blockquote>
  <h4 id="margin-collapsing">外边叠加（margin collapsing）</h4>
  <hr />
  <p>上边距（top margin）和下边距（bottom margin）有时会叠加，叠加后两者最大值作为两者间的边距。发生外边叠加的3种情况（<a href="http://www.cnblogs.com/cuishengli/archive/2012/06/22/2558859.html#CSS 外边距合并">图解</a>）<sup id="fnref:ccs_master"><a href="#fn:ccs_master" class="footnote">1</a></sup>：</p>

  <ol>
    <li>兄弟（Adjacent siblings）块：相邻块中，兄的下边界和弟的上边界会叠加；</li>
    <li>父与首尾孩子（Parent and first/last child）块：父块和首个孩子的margin-top之间不被任何东西分隔，则它们会叠加；父块和最后孩子的margin-bottom之间不被任何东西分隔，则它们会叠加；</li>
    <li>空块（Empty blocks）：不存在border、padding、inline content、height或min-height分隔块的margin-top和margin-bottom，上下边界会叠加。</li>
  </ol>

  <p>注意事项：</p>

  <ul>
    <li>当与负边界叠加时，叠加后的边界是最大正边界和最小边界之和；</li>
    <li>浮动的（floating）和绝对定位的（absolutely positioned）元素不参与外边叠加（这是因为创建了新的<a href="#block-formatting-context">块格式化环境</a>，而边界叠加只发生在同一块格式化环境）。</li>
  </ul>

</blockquote>

<h2 id="section-10">可视化格式模型</h2>

<blockquote>
  <h4 id="section-11">可视化格式模型解决的主要问题</h4>
  <hr />
  <ol>
    <li>如何生成盒子？</li>
    <li>盒子如何在页面布局？</li>
  </ol>
</blockquote>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Visual_formatting_model">可视化格式模型（Visual formatting model）</a>是用于处理网页文档并显示到虚拟设备上的算法，该模型将文档中的每个元素生成符合盒子模型的盒子，然后对这些模型进行布局。可视化格式模型包括盒子的生成和定位两部分。</p>

<h3 id="box-generation">生成机制（Box Generation）</h3>

<p>生成盒子的类型通过CSS属性<code>display</code>设定，当设定属性为<code>block</code>、<code>list-item</code>和<code>table</code>时，生成块盒子，当设定属性为<code>inline</code>、<code>inline-block</code>和<code>inline-table</code>时，生成内联盒子。<a href="#htmlblock-levelinline">HTML元素的属性</a>决定了该元素生成盒子类型的默认值，块元素默认生成块盒子，内联元素默认生成内联盒子。不同类型盒子的定位机制不同。</p>

<h3 id="positioning-scheme">定位机制（Positioning Scheme）</h3>

<p>CSS的盒子有3种基本定位机制：普通流（normal flow）、浮动（floats）和绝对定位（absolute position），默认定位机制是普通流。在普通流中，盒子一个接一个排列，floats算法可以将盒子从普通流中抽出来，绝对定位通过包含它盒子的坐标系统来定位。</p>

<h4 id="normal-flow">Normal Flow</h4>

<blockquote>
  <h4 id="normal-flow-1">如何进入普通流（normal flow）</h4>
  <hr />
  <p>CCS将盒子的<code>position</code>属性设置为<code>static</code>或<code>relative</code>，并且将<code>float</code>属性设置为<code>none</code>。默认值<code>position: static</code>，<code>float: none</code>。</p>

  <p>普通流可以理解为盒子按照读入的先后次序依次处理，就像水流一样连续有序，每个页面对应一个流。浮动和绝对定位，可将读入序列中的某些盒子从这个流中抽取出来，单独处理。</p>
</blockquote>

<p>在普通流中，块盒子（block-level boxes ）和内联盒子（inline boxes）分别从纵向和横向对元素进行布局。块盒子通过垂直的方式一个接一个的排列，盒子之间的距离通过垂直方向的边界（margin-top和margin-bottom）控制（计算距离时要注意盒子<a href="#margin-collapsing">外边叠加问题</a>）。内联盒子通过水平方式排列，设置垂自方向的padding、borders和margins无效。水平排列的内联盒子通过行盒子（line box）组织在一起，行盒子的高度总是足够容纳包含在其中的所有盒子，可以通过设置行高（line height）控制行盒子的高度。因此，改变内联盒子尺寸的参数只有水平方向上的borders、padding、margins以及line height。    </p>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-25-css-essential_css-syntax-ruleset_line_box.jpeg" alt="CSS语法" />
<div class="caption">包含在行盒子中的内联元素</div>
</div>
</div>

<p>CSS2.1可以设置<code>display</code>属性为<code>inline-block</code>，融合inline和block的属性。在水平方向按内联盒子的方式布局，同时可以像块盒子一样设置widths、heights和垂自方向的 margins、padding。 </p>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-25-css-essential_relative.png" alt="设置relative的效果" />
<div class="caption">设置relative的效果"position: relative; left: 20px; top: 20px;"</div>
</div>
</div>

<h4 id="floats">Floats</h4>

<blockquote>
  <h4 id="floats-1">如何使用浮动模式（floats）</h4>
  <hr />
  <p>CCS将盒子的<code>float</code>属性设置为<code>left</code>或<code>right</code>，并且将<code>position</code>属性设置为<code>static</code>或<code>relative</code>。</p>

  <p><code>float</code>的非<code>none</code>属性暗示了盒子是<code>block</code>类型，因此，非块类型盒子的<code>display</code>属性会因为设置了<code>float</code>属性而改变为块类型。</p>
</blockquote>

<p>当盒子采用floats算法定位时，盒子会从普通流中被抽取出来，向左或向右移动，直到遇到父盒子或设置了float属性盒子的边界。</p>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-25-css-essential_floats.png" alt="设置floats的效果" />
<div class="caption">设置<code>float</code>的效果</div>
</div>
</div>

<p>上图3个红色的方块，两个左浮（<code>float: left</code>），一个右浮。第二个左浮窗口位于第一个左浮动窗口右边，如果再增加左浮窗口，会不断的照此叠加，充满父盒子后会换行继续显示。</p>

<p>一个盒子设置了浮动后，会影响它的兄弟元素，具体的影响方式较为复杂，这要视乎这些兄弟元素是块级元素还是内联元素，若是块级元素会无视这个浮动的块框，使自身尽可能与这个浮动元素处于同一行，导致被浮动元素覆盖，除非这些<code>div</code>设置了宽度，并且父元素的宽度不足以包含它们，这样兄弟元素才会被强制换行；若是内联元素，则会尽可能围绕浮动元素。</p>

<p>浮动元素脱离了普通流，因此包含它的父元素不会因为这个浮动元素的存在而自动撑高，这就造成了高度塌陷。下图所示，由于左边盒子浮动而脱离了普通流，父元素的高度只是由<code>span</code>盒子决定，看起来就像父元素高度塌陷了。</p>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-25-css-essential_clearfloat1.png" alt="浮动的影响" />
<div class="caption">浮动的影响</div>
</div>
</div>

<p>当浮动影响到盒子的布局时，需要<a href="#clearing-floats">清除浮动</a>。</p>

<h4 id="absolute-positioning">Absolute Positioning</h4>

<blockquote>
  <h4 id="absolute-positioning-1">如何采用绝对定位（absolute positioning）</h4>
  <hr />
  <p>CCS将盒子的<code>position</code>属性设置为<code>absolute</code>或<code>fixed</code>。</p>

  <p>当设置为<code>fixed</code>的时候，盒子的位置相对于浏览器可见的视窗固定，即使拖动浏览器的滚动条，盒子的位置也固定不变。</p>

</blockquote>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-25-css-essential_absolute.png" alt="设置absolute的效果" />
<div class="caption">设置absolute的效果"position: absolute; left: 20px; top: 20px;"</div>
</div>
</div>

<h4 id="clearing-floats">清除浮动（clearing floats）</h4>

<p>由于浮动元素会影响它的兄弟元素的位置和父元素产生高度塌陷，需要清除浮动。</p>

<p>常用的清除浮动方法是<code>clear: both</code>，<code>clear</code>的属性值<code>both</code>、<code>left</code>、<code>right</code>、<code>none</code>、<code>inherit</code> 分别代表在元素左右两侧不允许出现浮动元素、左侧不允许出现浮动元素、右侧不允许出现浮动元素、不清除浮动、继承父元素的值。</p>

<p>但是，<code>clear</code>只是清除了浮动对兄弟元素的影响，而高度塌陷问题还没有解决，需要更高级的清除浮动——闭合浮动。为什么叫闭合浮动？因为浮动的元素脱离了普通流，对于它的父元素，它并没有闭合，这时候就需要闭合浮动了。</p>

<blockquote>
  <h4 id="section-12">闭合浮动的3种方法</h4>
  <hr />
  <p>（1）空<code>div</code>方法</p>

  <div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;box&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;main left&quot;</span><span class="nt">&gt;</span>我设置了左浮动 float: left<span class="nt">&lt;/div&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">style=</span><span class="s">&quot;clear: both;&quot;</span><span class="nt">&gt;&lt;/div&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;aside&quot;</span><span class="nt">&gt;</span>我是页脚，我的上面添加了一个设置了 clear: both 的空 div<span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span></code></pre></div>
  <p>空<code>div</code>方法很方便，但是加入了没有涵义的<code>div</code>，这违背了结构与表现分离的原则，并且后期维护也不方便。</p>

  <p>（2）<code>overflow</code>方法</p>

  <div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;box&quot;</span> <span class="na">style=</span><span class="s">&quot;overflow: hidden; *zoom: 1;&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;main left&quot;</span><span class="nt">&gt;</span>我设置了左浮动 float: left<span class="nt">&lt;/div&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;aside left&quot;</span><span class="nt">&gt;</span>我是页脚，但是我也设置了左浮动。<span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span></code></pre></div>
  <p>当元素内包含会超出父元素边界的子元素时，<code>overflow</code>方法可能会覆盖掉有用的子元素，或是产生了多余的滚动条。</p>

  <p>（3）<code>:after</code>伪元素的方法</p>

  <div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;style&gt;</span>
    <span class="nc">.clearfix</span> <span class="p">{</span><span class="c">/* 触发 hasLayout */</span> <span class="n">zoom</span><span class="o">:</span> <span class="m">1</span><span class="p">;</span> <span class="p">}</span>
    <span class="nc">.clearfix</span><span class="nd">:after</span> <span class="p">{</span><span class="k">content</span><span class="o">:</span> <span class="s1">&#39;.&#39;</span><span class="p">;</span> <span class="k">display</span><span class="o">:</span> <span class="k">block</span><span class="p">;</span> <span class="k">height</span><span class="o">:</span> <span class="m">0</span><span class="p">;</span> <span class="k">clear</span><span class="o">:</span> <span class="k">both</span><span class="p">;</span> <span class="k">visibility</span><span class="o">:</span> <span class="k">hidden</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">&lt;/style&gt;</span>
<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;box clearfix&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;main left&quot;</span><span class="nt">&gt;</span>我设置了左浮动 float: left<span class="nt">&lt;/div&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;aside left&quot;</span><span class="nt">&gt;</span>我是页脚，但是我也设置了左浮动。<span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span></code></pre></div>
  <p>这个办法不但完美兼容主流浏览器，并且也很方便，使用重用的类，可以减轻代码编写，另外网页的结构也会更加清晰。</p>
</blockquote>

<p>清除浮动的详细介绍可参考<a href="http://kayosite.com/remove-floating-style-in-detail.html">《详说清除浮动》</a>（<a href="/assets/images/../html/clearfloat.html">示例</a>）。</p>

<h2 id="section-13">块格式化环境</h2>

<blockquote>
  <h4 id="block-formatting-context">块格式化环境（block formatting context）</h4>
  <hr />
  <p>块格式化环境是CCS渲染Web页面的一块区域，块盒子在该区域内布局。</p>

  <p>块格式化环境对（<code>float</code>）定位和清除（<code>clear</code>）浮动至关重要，定位和清除浮动只对同一块格式化环境中的对象有效。<code>float</code>不会影响到其它块格式化环境中的盒子，<code>clear</code>只清除同一块格式化环境中之前的float效果。</p>

  <p>简单来说，块格式化环境是一种属性，这种属性会影响着元素的定位以及与其兄弟元素之间的相互作用。</p>
</blockquote>

<p>块格式化环境就是一个作用范围，可理解为一个独立的容器，这个容器的里盒子的布局与这个容器外的不相干。</p>

<p>块格式化环境不存在嵌套包含关系，块格式化环境只包含该环境内的对象，不会再包含该环境中对象再创建的块格式化环境。（A block formatting context contains everything inside of the element creating it that is not also inside a descendant element that creates a new block formatting context.）</p>

<blockquote>
  <h4 id="section-14">创建块格式化环境的条件（满足任意一条即可）</h4>
  <hr />
  <ul>
    <li>the root element or something that contains it；</li>
    <li><code>float</code>设置为<strong>非</strong><code>none</code>；</li>
    <li><code>position</code>设置为<code>absolute</code>或<code>fixed</code>；</li>
    <li><code>display</code>设置为<code>inline-block</code>、<code>table-cell</code>、<code>table-caption</code>、<code>flex</code>或<code>inline-flex</code>；</li>
    <li><code>overflow</code>设置为<strong>非</strong><code>visible</code>。</li>
  </ul>
</blockquote>

<p>块格式化环境主要有三个特性（详见<a href="http://www.cnblogs.com/leejersey/p/3991400.html">《详说 Block Formatting Contexts (块级格式化上下文)》</a>，<a href="/assets/images/../html/bfc.html">示例</a>）：</p>

<ol>
  <li>阻止<a href="#margin-collapsing">外边距折叠</a>；    </li>
  <li>包含浮动的元素（<a href="#clearing-floats">清除浮动</a>之<code>overflow</code>方法）；   </li>
  <li>阻止元素被浮动元素覆盖。 </li>
</ol>

<h2 id="section-15">高级选择器</h2>

<h4 id="css-21-">CSS 2.1 属性选择器</h4>

<table>
  <tbody>
    <tr>
      <td>E[att]</td>
      <td>匹配所有具有att属性的E元素，不考虑它的值。（注意：E在此处可以省略，比如”[cheacked]”。以下同。）</td>
    </tr>
    <tr>
      <td>E[att=val]</td>
      <td>匹配所有att属性等于”val”的E元素。</td>
    </tr>
    <tr>
      <td>E[att~=val]</td>
      <td>匹配所有att属性具有多个空格分隔的值、其中一个值等于”val”的E元素。</td>
    </tr>
    <tr>
      <td>E[att|=val]</td>
      <td>匹配所有att属性具有多个连字号分隔（hyphen-separated）的值、其中一个值以”val”开头的E元素，主要用于lang属性，比如”en”、”en-us”、”en-gb”等等。</td>
    </tr>
  </tbody>
</table>

<p>示例：</p>

<div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">p</span><span class="o">[</span><span class="nt">title</span><span class="o">]</span> <span class="p">{</span> <span class="k">color</span><span class="o">:</span><span class="m">#f00</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">div</span><span class="o">[</span><span class="nt">class</span><span class="o">=</span><span class="nt">error</span><span class="o">]</span> <span class="p">{</span> <span class="k">color</span><span class="o">:</span><span class="m">#f00</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">td</span><span class="o">[</span><span class="nt">headers</span><span class="o">~=</span><span class="nt">col1</span><span class="o">]</span> <span class="p">{</span> <span class="k">color</span><span class="o">:</span><span class="m">#f00</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">p</span><span class="o">[</span><span class="nt">lang</span><span class="o">|=</span><span class="nt">en</span><span class="o">]</span> <span class="p">{</span> <span class="k">color</span><span class="o">:</span><span class="m">#f00</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">blockquote</span><span class="o">[</span><span class="nt">class</span><span class="o">=</span><span class="nt">quote</span><span class="o">][</span><span class="nt">cite</span><span class="o">]</span> <span class="p">{</span> <span class="k">color</span><span class="o">:</span><span class="m">#f00</span><span class="p">;</span> <span class="p">}</span></code></pre></div>

<h4 id="css-21-pseudo-classes">CSS 2.1 伪类（pseudo-classes）</h4>

<table>
  <tbody>
    <tr>
      <td>E:first-child</td>
      <td>匹配父元素的第一个子元素。</td>
    </tr>
    <tr>
      <td>E:link</td>
      <td>匹配所有未被点击的链接。</td>
    </tr>
    <tr>
      <td>E:visited</td>
      <td>匹配所有已被点击的链接。</td>
    </tr>
    <tr>
      <td>E:active</td>
      <td>匹配鼠标已经其上按下、还没有释放的E元素。</td>
    </tr>
    <tr>
      <td>E:hover</td>
      <td>匹配鼠标悬停其上的E元素。</td>
    </tr>
    <tr>
      <td>E:focus</td>
      <td>匹配获得当前焦点的E元素。</td>
    </tr>
    <tr>
      <td>E:lang(c)</td>
      <td>匹配lang属性等于c的E元素。</td>
    </tr>
  </tbody>
</table>

<p>示例：</p>

<div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">p</span><span class="nd">:first-child</span> <span class="p">{</span> <span class="k">font-style</span><span class="o">:</span><span class="k">italic</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">input</span><span class="o">[</span><span class="nt">type</span><span class="o">=</span><span class="nt">text</span><span class="o">]</span><span class="nd">:focus</span> <span class="p">{</span> <span class="k">color</span><span class="o">:</span><span class="m">#000</span><span class="p">;</span> <span class="k">background</span><span class="o">:</span><span class="m">#ffe</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">input</span><span class="o">[</span><span class="nt">type</span><span class="o">=</span><span class="nt">text</span><span class="o">]</span><span class="nd">:focus:hover</span> <span class="p">{</span> <span class="k">background</span><span class="o">:</span><span class="m">#fff</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">q</span><span class="nd">:lang</span><span class="o">(</span><span class="nt">sv</span><span class="o">)</span> <span class="p">{</span> <span class="k">quotes</span><span class="o">:</span> <span class="s2">&quot;\201D&quot;</span> <span class="s2">&quot;\201D&quot;</span> <span class="s2">&quot;\2019&quot;</span> <span class="s2">&quot;\2019&quot;</span><span class="p">;</span> <span class="p">}</span></code></pre></div>

<h4 id="css-21-pseudo-elements">CSS 2.1 伪元素（pseudo-elements）</h4>

<table>
  <tbody>
    <tr>
      <td>E:first-line</td>
      <td>匹配E元素的第一行。</td>
    </tr>
    <tr>
      <td>E:first-letter</td>
      <td>匹配E元素的第一个字母。</td>
    </tr>
    <tr>
      <td>E:before</td>
      <td>在E元素之前插入生成的内容。</td>
    </tr>
    <tr>
      <td>E:after</td>
      <td>在E元素之后插入生成的内容。</td>
    </tr>
  </tbody>
</table>

<p>示例：</p>

<div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">p</span><span class="nd">:first-line</span> <span class="p">{</span> <span class="k">font-weight</span><span class="o">:</span><span class="k">bold</span><span class="p">;</span> <span class="k">color</span><span class="p">;</span><span class="m">#600</span><span class="p">;</span> <span class="p">}</span>
<span class="nc">.preamble</span><span class="nd">:first-letter</span> <span class="p">{</span> <span class="k">font-size</span><span class="o">:</span><span class="m">1.5em</span><span class="p">;</span> <span class="k">font-weight</span><span class="o">:</span><span class="k">bold</span><span class="p">;</span> <span class="p">}</span>
<span class="nc">.cbb</span><span class="nd">:before</span> <span class="p">{</span> <span class="k">content</span><span class="o">:</span><span class="s2">&quot;&quot;</span><span class="p">;</span> <span class="k">display</span><span class="o">:</span><span class="k">block</span><span class="p">;</span> <span class="k">height</span><span class="o">:</span><span class="m">17px</span><span class="p">;</span> <span class="k">width</span><span class="o">:</span><span class="m">18px</span><span class="p">;</span> <span class="k">background</span><span class="o">:</span><span class="sx">url(top.png)</span> <span class="k">no-repeat</span> <span class="m">0</span> <span class="m">0</span><span class="p">;</span> <span class="k">margin</span><span class="o">:</span><span class="m">0</span> <span class="m">0</span> <span class="m">0</span> <span class="m">-18px</span><span class="p">;</span> <span class="p">}</span>
<span class="nt">a</span><span class="nd">:link:after</span> <span class="p">{</span> <span class="k">content</span><span class="o">:</span> <span class="s2">&quot; (&quot;</span> <span class="n">attr</span><span class="p">(</span><span class="n">href</span><span class="p">)</span> <span class="s2">&quot;) &quot;</span><span class="p">;</span> <span class="p">}</span></code></pre></div>

<p>更多关于CSS选选择器类容可参考<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference">CSS reference</a>。</p>

<h2 id="section-16">使用技巧</h2>

<blockquote>
  <h4 id="important">!important规则</h4>
  <hr />
  <p>多条CSS语句互相冲突时，具有!important的语句将覆盖其他语句。由于IE不支持!important，所以也可以利用它区分不同的浏览器。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">h1</span> <span class="p">{</span><span class="k">color</span><span class="o">:</span> <span class="nb">red</span> <span class="cp">!important</span><span class="p">;</span> <span class="k">color</span><span class="o">:</span> <span class="nb">blue</span><span class="p">;}</span></code></pre></div>
</blockquote>

<blockquote>
  <h4 id="section-17">容器水平居中</h4>
  <hr />
  <p>先为该容器设置一个明确宽度，然后将margin的水平值设为auto即可。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">div</span><span class="nf">#container</span> <span class="p">{</span><span class="k">width</span><span class="o">:</span> <span class="m">760px</span><span class="p">;</span> <span class="k">margin</span><span class="o">:</span> <span class="m">0</span> <span class="k">auto</span><span class="p">;}</span></code></pre></div>
</blockquote>

<blockquote>
  <h4 id="section-18">禁止自动换行</h4>
  <hr />
  <p>文字在一行中显示完成，不要自动换行。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">h1</span> <span class="p">{</span> <span class="k">white-space</span><span class="o">:</span> <span class="k">nowrap</span><span class="p">;</span> <span class="p">}</span></code></pre></div>
</blockquote>

<blockquote>
  <h4 id="section-19">图片宽度自适应</h4>
  <hr />
  <p>如何使得较大的图片，能够自动适应小容器的宽度？</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">img</span> <span class="p">{</span><span class="k">max-width</span><span class="o">:</span> <span class="m">100%</span><span class="p">}</span></code></pre></div>
</blockquote>

<blockquote>
  <h4 id="link">设置link状态的顺序</h4>
  <hr />
  <p>link的四种状态，需要按照下面的前后顺序进行设置。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">a</span><span class="nd">:link</span> 
<span class="nt">a</span><span class="nd">:visited</span> 
<span class="nt">a</span><span class="nd">:hover</span> 
<span class="nt">a</span><span class="nd">:active</span></code></pre></div>
</blockquote>

<blockquote>
  <h4 id="text-transformfont-variant">Text-transform和Font Variant</h4>
  <hr />
  <p>Text-transform用于将所有字母变成小写字母、大写字母或首字母大写。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">p</span> <span class="p">{</span><span class="k">text-transform</span><span class="o">:</span> <span class="k">uppercase</span><span class="p">}</span> 
<span class="nt">p</span> <span class="p">{</span><span class="k">text-transform</span><span class="o">:</span> <span class="k">lowercase</span><span class="p">}</span> 
<span class="nt">p</span> <span class="p">{</span><span class="k">text-transform</span><span class="o">:</span> <span class="k">capitalize</span><span class="p">}</span></code></pre></div>
  <p>Font Variant用于将字体变成小型的大写字母（即与小写字母等高的大写字母）。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">p</span> <span class="p">{</span><span class="k">font-variant</span><span class="o">:</span> <span class="k">small-caps</span><span class="p">}</span></code></pre></div>
</blockquote>

<blockquote>
  <h4 id="section-20">用图片充当列表标志</h4>
  <hr />
  <p>默认情况下，浏览器使用一个黑圆圈作为列表标志，可以用图片取代它。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">ul</span> <span class="p">{</span><span class="k">list-style</span><span class="o">:</span> <span class="k">none</span><span class="p">}</span>
<span class="nt">ul</span> <span class="nt">li</span> <span class="p">{</span>
    <span class="k">background-image</span><span class="o">:</span> <span class="sx">url(&quot;path-to-your-image&quot;)</span><span class="p">;</span>
    <span class="k">background-repeat</span><span class="o">:</span> <span class="k">none</span><span class="p">;</span>
    <span class="k">background-position</span><span class="o">:</span> <span class="m">0</span> <span class="m">0.5em</span><span class="p">;</span> 
<span class="p">}</span></code></pre></div>
</blockquote>

<blockquote>
  <h4 id="section-21">用图片替换文字</h4>
  <hr />
  <p>在标题栏中使用图片，但是又必须保证搜索引擎能够读到标题。</p>

  <div class="highlight"><pre><code class="language-css" data-lang="css"><span class="nt">h1</span> <span class="p">{</span> 
    <span class="k">text-indent</span><span class="o">:</span> <span class="m">-9999px</span><span class="p">;</span> 
    <span class="k">background</span><span class="o">:</span> <span class="sx">url(&quot;h1-image.jpg&quot;)</span> <span class="k">no-repeat</span><span class="p">;</span> 
    <span class="k">width</span><span class="o">:</span> <span class="m">200px</span><span class="p">;</span>
    <span class="k">height</span><span class="o">:</span> <span class="m">50px</span><span class="p">;</span>
<span class="p">}</span></code></pre></div>
</blockquote>

<h2 id="section-22">预处理器</h2>

<p>CSS预处理器（css preprocessor）的基本思想是，用一种专门的编程语言，进行网页样式设计，然后再编译成CSS文件。常用的CSS预处理器有<a href="http://lesscss.org">Less</a>、<a href="http://sass-lang.com">Sass</a>等。</p>

<h3 id="less">Less</h3>

<p><a href="http://lesscss.org">Less</a>使用变量（variables）、混合（mixins）、函数（functions）和许多其他的技术，让你的CSS更具维护性、主题性、扩展性。Less可运行在Node环境，浏览器环境和Rhino环境，同时也有3种可选工具供你编译文件和监视任何改变。</p>

<p>具体用法可参考Bootstrap中文网的<a href="http://www.bootcss.com/p/lesscss/" title="LESS « 一种动态样式语言">Less教程</a>。</p>

<h3 id="sass--compass">Sass &amp; Compass</h3>

<p><a href="http://sass-lang.com">Sass</a>使用变量（variables）、混合（mixins）、嵌套规则（nested rules）、内联导入（inline imports）等，让CSS更加优雅和强大。Sass让CSS更好的组织、体积更小、速度更快。</p>

<p><a href="http://compass-style.org">Compass</a>是Sass的工具库（toolkit）。Sass本身只是一个编译器，Compass在它的基础上，封装了一系列有用的模块和模板，补充Sass的功能。它们之间的关系，有点像Javascript和jQuery、Ruby和Rails、python和Django的关系。</p>

<p>具体使用可参考阮一峰的<a href="http://www.ruanyifeng.com/blog/2012/06/sass.html" title="SASS用法指南">Sass</a>和<a href="http://www.ruanyifeng.com/blog/2012/11/compass.html" title="Compass用法指南">Compass</a>用法指南。</p>

<h2 id="section-23">参考资料</h2>

<ol>
  <li><a href="https://developer.mozilla.org/en-US/docs/Web/CSS" title="Cascading Style Sheets">MDN: CSS</a></li>
  <li><a href="http://www.w3.org/Style/CSS/" title="Cascading Style Sheets home page">W3: Cascading Style Sheets home page</a></li>
  <li><a href="http://www.w3school.com.cn/css/index.asp" title="CSS 教程">w3school: CSS 教程</a></li>
  <li><a href="http://www.w3.org/TR/2001/WD-css3-values-20010713/#specified" title="Specified, computed, and actual values">W3: Specified, computed, and actual values</a></li>
  <li><a href="http://www.w3.org/TR/css3-values/" title="CSS Values and Units Module Level 3">W3: CSS Values and Units Module Level 3</a></li>
  <li><a href="http://www.w3.org/TR/2011/REC-css3-color-20110607/">W3: CSS Color Module Level 3</a></li>
  <li><a href="http://dev.w3.org/csswg/css-box/">W3: CSS basic box model</a></li>
  <li><a href="http://dev.w3.org/csswg/css-grid/">W3: CSS Grid Layout Module Level 1</a></li>
  <li><a href="http://dev.w3.org/csswg/css-flexbox/">W3: CSS Flexible Box Layout Module Level 1</a></li>
  <li><a href="http://www.ruanyifeng.com/blog/2010/03/css_cookbook.html">阮一峰：CSS使用技巧</a>    </li>
  <li><a href="http://www.ruanyifeng.com/blog/2009/03/css_selectors.html">阮一峰：CSS选择器笔记</a></li>
  <li><a href="http://www.cnblogs.com/cuishengli/archive/2012/06/22/2558859.html">cuishengli：CSS 框模型概述</a></li>
  <li><a href="http://www.cnblogs.com/leejersey/p/3991400.html">leejersey：详说 Block Formatting Contexts (块级格式化上下文)</a></li>
  <li><a href="http://kayosite.com/remove-floating-style-in-detail.html">Kayo：详说清除浮动</a></li>
  <li><a href="http://www.catswhocode.com/blog/8-css-preprocessors-to-speed-up-development-time" title="8 CSS preprocessors to speed up development time">Jean: 8 CSS preprocessors to speed up development time</a></li>
  <li><a href="http://www.bootcss.com/p/lesscss/" title="LESS « 一种动态样式语言">LESS « 一种动态样式语言</a></li>
  <li><a href="http://www.ruanyifeng.com/blog/2012/06/sass.html" title="SASS用法指南">阮一峰：SASS用法指南</a></li>
  <li><a href="http://www.ruanyifeng.com/blog/2012/11/compass.html" title="Compass用法指南">阮一峰：Compass用法指南</a></li>
</ol>

<h3 id="section-24">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:ccs_master">
      <p>也可参考”CSS Mastery: Advanced Web Standards Solutions, Second Edition”一书的”Chapter 3: Visual Formatting Model Overview”。 <a href="#fnref:ccs_master" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习: 感知器算法</title>
      <link href="http://qianjiye.de/2014/10/machine-learning-perceptron-learning-algorithm" />
      <pubdate>2014-10-21T18:09:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/10/machine-learning-perceptron-learning-algorithm</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">问题描述</h2>

<p>对于线性二分类问题<br />
\begin{equation}
y = \left\{
\begin{aligned}
&amp; +1 &amp; \sum\nolimits_{i=1}^dw_ix_i &gt; \mbox{threshold} \\
&amp; -1 &amp; \sum\nolimits_{i=1}^dw_ix_i &lt; \mbox{threshold}
\end{aligned}
\right. 
\end{equation}</p>

<p>也可以记为
\begin{equation}
h(x) = \mbox{sign}\left(\sum_{i=1}^dw_ix_i - \mbox{threshold}\right) = \mbox{sign}\left(\sum_{i=0}^dw_ix_i\right) = \mbox{sign}\left(\mathbf{w^Tx}\right)
\end{equation} <br />
其中，$w_0 = -\mbox{threshold}, x_0 = +1$。</p>

<p>问：如何估计模型模型$h(x)$的参数$\mathbf{w}$？  <br />
答：感知器算法（PLA，Perceptron Learning Algorithm）。</p>

<h2 id="section-1">感知器算法</h2>

<p>感知器算法通过迭代更新模型参数，直到没有错分的样本点。  </p>

<blockquote>
  <h4 id="pla">PLA</h4>
  <hr />
  <p>repeat until a full cycle of not encountering mistakes { <br />
1. 找到参数$\mathbf w_t$时对应错分的样本点$\left(\mathbf x_{n(t)}, y_{n(t)}\right)$，$\mbox{sign}\left(\mathbf w^T \mathbf x_{n(t)}\right) \neq y_{n(t)}$；     <br />
2. 修正参数，$\mathbf w_{t+1}\leftarrow \mathbf w_t + y_{n(t)}\mathbf x_{n(t)}$。  <br />
}</p>
</blockquote>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-21-pla_1.png" alt="PLA更新模型参数示意图" />
<div class="caption">PLA更新模型参数示意图</div>
</div>
</div>

<p>PLA更新模型参数解释： <br />
1. 当$y=+1$时，若分错，$\mathbf w^T \mathbf x &lt; 0$，表示$\mathbf{w}$和$\mathbf x$的夹角太大（大于90度），需要调整$\mathbf w$，使其与$\mathbf x$的夹角变小；<br />
2. 当$y=-1$时，若分错，$\mathbf w^T \mathbf x &gt; 0$，表示$\mathbf{w}$和$\mathbf x$的夹角太小（小于90度），需要调整$\mathbf w$，使其与$\mathbf x$的夹角变大。   </p>

<p>通过参数更新规则可知  <br />
\[
\mathbf w_{t+1} ＝ \mathbf w_t + y_{n}\mathbf x_{n}
\]<br />
两边转置后同时乘上$y_n\mathbf x_n$，可得
\[
y_n\mathbf w^T_{t+1} \mathbf x_n \geq y_n\mathbf w^T_t\mathbf x_n
\]
这表明，参数更新始终在试图纠正模型参数。  </p>

<p><strong>注意事项</strong>：$\mathbf w$是决策界（判别面）的法向量。</p>

<h2 id="section-2">理论分析</h2>

<blockquote>
  <ol>
    <li>PLA算法会终止么？</li>
    <li>能否从候选模式$h$中学习到目标模式$f$？</li>
  </ol>
</blockquote>

<p>如果数据集$\mathcal D$线性可分，存在一个完美$\mathbf w_f$，使得对数据集中所有样本点$y_n = \mbox{sign}\left(\mathbf w_f^T\mathbf x_n\right)$，对于任意一个样本点总有</p>

<p>\begin{equation}
y_{n(t)}\mathbf w_f^T\mathbf x_{n(t)} \geq \min_n y_n\mathbf x_f^T\mathbf x_n &gt; 0
\end{equation}</p>

<p>根据感知器算法的更新规则可知
\begin{equation}
\begin{aligned}
\mathbf w_f^T\mathbf w_{t+1} 
&amp; =  \mathbf w_f^T\left(\mathbf w_t + y_{n(t)}\mathbf x_{n(t)}\right) \\
&amp; \geq \mathbf w_f^T\mathbf w_t + \min_n y_n\mathbf x_f^T\mathbf x_n \\
&amp; &gt; \mathbf w_f^T\mathbf w_t 
\end{aligned}
\end{equation}
由此可见，参数更新后，$\mathbf w_{t+1}$<em>可能会</em>更加接近$\mathbf w_f$。但是，还不能确定是由于向量间夹角变小还是$\mathbf w_{t+1}$长度变大导致的内积增加。
\begin{equation}
\begin{aligned}
\|\mathbf w_{t+1}\|^2
&amp; = \|\mathbf w_t + y_{n(t)}\mathbf x_{n(t)}\|^2 \\
&amp; = \|\mathbf w_t\|^2 + \|y_{n(t)}\mathbf x_{n(t)}\|^2 + 2y_{n(t)}\mathbf w_t^T\mathbf x_{n(t)} \\
&amp; \leq \|\mathbf w_t\|^2 + \|y_{n(t)}\mathbf x_{n(t)}\|^2 \\
&amp; \leq \|\mathbf w_t\|^2 + \max_n\|\mathbf x_{n}\|^2
\end{aligned}
\end{equation}
由此可见，每次更新的时候，向量长度的增加是有限的，最多增加样本最长向量的长度。</p>

<p>事实上，从$\mathbf w_0$开始，经过$T$次迭代后有
\begin{equation}
\frac{\mathbf w_f^T}{\|\mathbf w_f\|}\frac{\mathbf w_T}{\|\mathbf w_T\|}\geq
\sqrt T \times \mbox{constant}
\label{eq:need_to_be_done_1}
\end{equation}
PLA算法迭代次数的上界满足$T\leq R^2/\rho^2$，其中
\begin{equation}
R^2 = \max_n \|\mathbf x_n\|^2,~~\rho=\min_n y_n\frac{\mathbf w_f^T}{\|\mathbf w_f\|}\mathbf x_n
\label{eq:need_to_be_done_2}
\end{equation}</p>

<p>相关的证明如下：  <br />
<img src="/assets/images/2014-10-21-pla_2.jpg" alt="相关的证明" /></p>

<p><strong>结论：</strong>     <br />
1. 对于线性可分的样本集合，通过PLA修正模型参数，$\mathbf w_f$和$\mathbf w_t$的内积增长快，$\mathbf w_t$的长度增长慢，$\mathbf w_t$越来越靠近$\mathbf w_f$，最终算最终收敛； <br />
2. 对于未知的样本集，作用在其上的PLA算法可能长时间不收敛，导致这样的情况可能是迭代次数不够（理论上的参数$T$由于目标模型$f$未知而难以估计）或者样本集存在噪声（线性不可分）。</p>

<h2 id="pocket-pla">Pocket PLA</h2>

<p>判断样本集是否线性可分的复杂度为NP-hard。实际上，通常样本集存在一些噪声，不可能严格的线性可分，PLA算法无法满足收敛条件。Pocket PLA通过改变PLA迭代结束的条件和参数更新规则仍然可以估计模型参数。</p>

<blockquote>
  <h4 id="pocket-pla-1">Pocket PLA</h4>
  <hr />
  <p>repeat until enough iterations {<br />
1. 随机抽取参数$\mathbf w_t$时对应错分的样本点$\left(\mathbf x_{n(t)}, y_{n(t)}\right)$，$\mbox{sign}\left(\mathbf w^T \mathbf x_{n(t)}\right) \neq y_{n(t)}$；     <br />
2. 修正参数，$\mathbf w_{t+1}\leftarrow \mathbf w_t + y_{n(t)}\mathbf x_{n(t)}$；<br />
3. 如果$\mathbf w_{t+1}$在样本集上的表现优于$\hat{\mathbf w}$，$\hat{\mathbf w}\leftarrow \mathbf w_{t+1}$。 <br />
}</p>
</blockquote>

<p>从第3步可知，Pocket PLA的算法时间复杂度要高于PLA，如果对于线性可分的样本集，Pocket PLA比PLA慢。</p>

<h2 id="section-3">思考问题</h2>

<ol>
  <li>PLA和梯度下降法有无联系？</li>
  <li>在分类性能上PLA求解的线性模型和Logistic回归有何差别？</li>
  <li>如何推导公式\eqref{eq:need_to_be_done_1}\eqref{eq:need_to_be_done_2}？ <a href="https://class.coursera.org/ntumlone-002/forum/thread?thread_id=28">答案</a></li>
</ol>

<h2 id="section-4">參考資料</h2>

<ol>
  <li><a href="https://class.coursera.org/ntumlone-002">機器學習基石(Machine Learning Foundations)</a>    </li>
  <li><a href="http://www.cs.columbia.edu/~mcollins/courses/6998-2012/notes/perc.converge.pdf">Convergence Proof for the Perceptron Algorithm</a></li>
</ol>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习: 正则化</title>
      <link href="http://qianjiye.de/2014/10/machine-learning-regularization" />
      <pubdate>2014-10-20T00:00:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/10/machine-learning-regularization</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">为什么需要正则化</h2>

<p>过拟合（overfitting）是指模型可以在训练集上表现出色，在新数据上性能却很差。解决过拟合问题的方法：</p>

<ul>
  <li>减少特征数目：手工选择特征、利用模型选择；</li>
  <li>正则化（regularization）：保留所有特征，但是减小$\theta_j$，使特征对预测$y$贡献小。</li>
</ul>

<p>正则化通过在代价函数中加入正则化项限制模型参数，避免过拟合。</p>

<p>线性回归和Logistic回归的代价函数追加的正则化项是$\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$。</p>

<ul>
  <li>$\lambda$称为正则化参数，增大$\lambda$以减小过拟合；</li>
  <li>$\lambda$过大（$10^{10}$）时，有$\theta_j\approx 0~~(j = 1,2,\ldots,n)$，则$h_\theta(x) = \theta_0$，这会导致欠拟合（underfitting）；</li>
  <li>正则化只作用于$j\ge 1$的非常数项，实际上，正则化常数项对结果影响也不大。</li>
</ul>

<p>资料来源：<a href="#ng_ml_r_2014">[1]</a>。</p>

<p>bias &amp; variance:</p>

<ul>
  <li>high bias: 欠拟合；</li>
  <li>high variance: 过拟合。</li>
</ul>

<h2 id="section-1">正则化线性回归</h2>

<h3 id="section-2">代价函数</h3>

<p>\begin{equation}
J(\theta) = \frac{1}{2m}\left( \sum_{i=1}^m\left( h_\theta\left(x^{(i)}\right) - y^{(i)} \right)^2 + \lambda\sum_{j=1}^n\theta_j^2 \right)
\label{eq:cf-linear-regression-r}
\end{equation}</p>

<h3 id="section-3">梯度下降法估计参数</h3>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_\theta\left(x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_\theta\left(x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<p>迭代过程可以化为如下形式：
\begin{equation*}
\theta_j := \theta_j\left(1 - \alpha\frac{\lambda}{m} \right) - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_\theta\left(x^{(i)}\right) - y^{(i)} \right)x_j^{(i)};~~(j = 1, 2, \ldots, n)
\end{equation*}</p>

<p>通常$1 - \alpha\frac{\lambda}{m} &lt; 1$，与非正则化的梯度下降法比较，$\theta_j$减小更快。</p>

<h3 id="section-4">正规方程估计参数</h3>

<p>\begin{equation}
\theta = \left(X^TX + \lambda
\begin{bmatrix}
0  &amp;   &amp;        &amp; \\
   &amp; 1 &amp;        &amp; \\
   &amp;   &amp; \ddots &amp; \\
   &amp;   &amp;        &amp; 1
\end{bmatrix}
\right)^{-1}X^Ty
\end{equation}</p>

<p>可以证明，加入正则化项后矩阵始终可逆。</p>

<h2 id="logistic">正则化Logistic回归</h2>

<h3 id="section-5">代价函数</h3>

<p>\begin{equation}
\begin{aligned}
J(\theta)  = &amp;-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_\theta\left(x^{(i)}\right)\right)\right) \\
&amp; + \frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
\end{aligned}
\label{eq:cf-logistic-regression-r}
\end{equation}</p>

<h3 id="section-6">梯度下降法估计参数</h3>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_\theta\left(x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_\theta\left(x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<h3 id="matlab">Matlab实现</h3>

<p>第一步：实现Logistic函数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>g <span class="p">=</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span>z<span class="p">)</span><span class="w"></span>
<span class="n">g</span> <span class="p">=</span> <span class="mf">1.0</span> <span class="o">./</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="nb">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">));</span>
<span class="k">end</span></code></pre></div>

<p>第二步：实现代价函数（包含梯度计算）</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>[J, grad] <span class="p">=</span><span class="w"> </span><span class="nf">costFunctionReg</span><span class="p">(</span>theta, X, y, lambda<span class="p">)</span><span class="w"></span>
<span class="n">m</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">y</span><span class="p">);</span> <span class="c">% number of training examples</span>

<span class="n">h</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="n">J</span> <span class="p">=</span> <span class="o">-</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">+</span> <span class="c">...</span>
    <span class="n">lambda</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">sum</span><span class="p">(</span><span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">grad</span> <span class="p">=</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)])</span> <span class="o">/</span> <span class="n">m</span><span class="p">;</span>

<span class="k">end</span></code></pre></div>

<p>第三步：估计参数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="n">initial_theta</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">lambda</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">options</span> <span class="p">=</span> <span class="n">optimset</span><span class="p">(</span><span class="s">&#39;GradObj&#39;</span><span class="p">,</span> <span class="s">&#39;on&#39;</span><span class="p">,</span> <span class="s">&#39;MaxIter&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">);</span>
<span class="p">[</span><span class="n">theta</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">exit_flag</span><span class="p">]</span> <span class="p">=</span> <span class="c">...</span>
	<span class="n">fminunc</span><span class="p">(@(</span><span class="n">t</span><span class="p">)(</span><span class="n">costFunctionReg</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda</span><span class="p">)),</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">options</span><span class="p">);</span></code></pre></div>

<h2 id="section-7">思考问题</h2>

<ol>
  <li>如何推导正则化线性回归的正规方程解？</li>
  <li>求解正则化线性回归的正规方程时，为何矩阵始终可逆？</li>
  <li>如何选取合适的$\lambda$？</li>
</ol>

<h2 id="section-8">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_r_2014">[1]A. Ng, “Regularization: The problem of overfitting.” Coursera, 2014.</span>

[<a href="https://class.coursera.org/ml-007">Online</a>]

</li></ol>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习: 多分类问题</title>
      <link href="http://qianjiye.de/2014/10/machine-learning-multiple-classification" />
      <pubdate>2014-10-20T00:00:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/10/machine-learning-multiple-classification</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">问题描述</h2>

<p>许多分类器主要是为了解决二分类问题，对只有1和0两个类别标签对数据分类，比如Logistic回归和SVM。多分类问题是对两个以上类别标签的数据集分类。</p>

<p>解决多分类问题的思路：</p>

<ol>
  <li>多个二分类器的组合；</li>
  <li>直接采用多分类器。</li>
</ol>

<h2 id="one-vs-all">one-vs-all</h2>

<p>针对每类训练一个它与其余所有数据的二分类器，若有$N(N &gt; 2)$个类别，就需要训练$N$个分类器。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2014-10-20-machine-learning-multiple-classification_1.png"><img src="/assets/images/2014-10-20-machine-learning-multiple-classification_1.png" alt="one-vs-all也叫one-vs-rest" /></a><div class="caption">Figure 1:  one-vs-all也叫one-vs-rest [<a href="/assets/images/2014-10-20-machine-learning-multiple-classification_1.png">PNG</a>]</div></div></div>

<p>Logistic回归解决多分类问题<a href="#ng_ml_lr_2014">[1, Pp. 30-31]</a>：</p>

<ol>
  <li>针对每一类$i$训练一个Logistic分类器$h_\theta^{(i)}(x)$，这是第$i$类与其它类别的二分类问题；</li>
  <li>$x$所属的类别$c$满足$h_\theta^{(c)}(x) = \max_ih_\theta^{(i)}(x)$（属于概率最大的那个类别）。</li>
</ol>

<h3 id="section-1">存在的问题</h3>

<p>one-vs-all可能导致数据不均衡，其中一类的数据很少，其余的数据很多。</p>

<h2 id="section-2">神经网络</h2>

<p>神经网络是扩展Logistic模型组合的one-vs-all方法。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2014-10-20-multiple-classification.png"><img src="/assets/images/2014-10-20-multiple-classification.png" alt="神经网络的one-vs-all策略" /></a><div class="caption">Figure 2:  神经网络的one-vs-all策略 [<a href="/assets/images/2014-10-20-multiple-classification.png">PNG</a>]</div></div></div>

<p>注意其中的输出向量是0和1组成的向量，<strong>而非</strong>输出类别标签<sup id="fnref:class_label_method"><a href="#fn:class_label_method" class="footnote">1</a></sup>，$K(K \geq 3)$类则输出层需要$K$个神经元，$K＝2$时输出层只需要一个神经元<a href="#ng_ml_nnl_2014">[2, P. 2]</a>。</p>

<h2 id="section-3">思考问题</h2>

<ol>
  <li>神经网络能避免one-vs-all导致的数据不平衡问题吗？</li>
</ol>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="ng_ml_lr_2014">[1]A. Ng, “Logistic Regression.” Coursera, 2014.</span>

[<a href="https://class.coursera.org/ml-007">Online</a>]

</li>
<li><span id="ng_ml_nnl_2014">[2]A. Ng, “Neural Networks: Learning.” Coursera, 2014.</span>

[<a href="https://class.coursera.org/ml-007">Online</a>]

</li></ol>

<h3 id="section-5">脚注</h3>
<div class="footnotes">
  <ol>
    <li id="fn:class_label_method">
      <p>神经网络的输出不是$1,2,3,\ldots$这样的类别标签，Logistic回归模型输出属于某一类的概率，输入特征属于输出概率最靠近$1$的类别。 <a href="#fnref:class_label_method" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习: Logistic回归</title>
      <link href="http://qianjiye.de/2014/10/machine-learning-logistic-regression" />
      <pubdate>2014-10-19T00:00:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/10/machine-learning-logistic-regression</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">模型介绍</h2>

<div class="image_line">
<div class="image_card">
<img src="/assets/images/2014-10-19-logistic_regression_0.png" alt="Logistic函数" />
<div class="caption">图1 Logistic函数</div>
</div>
</div>

<p>Logistic回归（Logistic Regression）用于解决二分类问题，而非回归问题。Logistic函数将回归问题转化为了分类问题。</p>

<p>Logistic回归模型：
\begin{equation}
h_\theta(x) = g\left(\theta^Tx\right)
\end{equation}
其中
\begin{equation}
g\left(z\right) = \frac{1}{1 + e^{-z}}
\label{eq:sigmoid-function}
\end{equation}</p>

<blockquote>
  <p>上式也称为sigmoid function、logistic function，如<a href="#fig1">图1</a>所示。</p>
</blockquote>

<p>分类问题的判别条件如下：
\begin{equation}
y = \left\{
\begin{aligned}
&amp; 1 &amp; h_\theta(x) \ge 0.5 \\
&amp; 0 &amp; h_\theta(x) &lt; 0.5
\end{aligned}
\right. 
\end{equation}
也就是，若$\theta^Tx \ge 0$，则$y = 1$；若$\theta^Tx &lt; 0$，则$y = 0$。Logistic回归模型可以看作是计算属于类别1的概率
\begin{equation}
h_\theta\left(x\right) = \frac{1}{1 + e^{-\theta^Tx}} = P\left(y=1\big|x; \theta\right)
\end{equation}</p>

<p>因此，对于而分类问题，有
\begin{equation}
P\left(y=0\big|x; \theta\right) ＝ 1 - P\left(y=1\big|x; \theta\right) ＝ 1 - h_\theta\left(x\right)
\end{equation}</p>

<p>$\theta^Tx = 0$称为决策界（Decision Boundary）。决策界可以时线性的，也可以是非线性的。</p>

<p><img src="/assets/images/2014-10-19-logistic_regression_2.png" alt="线性决策界" /> </p>

<div class="caption">图2 线性决策界</div>

<p><img src="/assets/images/2014-10-19-logistic_regression_3.png" alt="非线性决策界" /></p>

<div class="caption">图3 非线性决策界</div>

<h2 id="section-1">代价函数</h2>

<p>线性回归的代价函数框架为：</p>

<p>\begin{equation}
J(\theta) = \frac{1}{m}\sum_{i=1}^{m}\frac{1}{2}{\left(h_{\theta}\left(x^{(i)}\right) - y^{(i)}\right)^2}
\end{equation}</p>

<p>令</p>

<p>\begin{equation}
\mbox{Cost}\left(h_\theta(x), y\right) = \frac{1}{2}\left( h_\theta(x) - y \right) ^ 2
\end{equation}</p>

<p>当$h_\theta(x)$为Logistic回归模型（<a href="#fig4">图4</a>左）和线性回归模型（<a href="#fig4">图4</a>右）时，分别为非凸函数和凸函数，非凸函数不能用梯度下降法找到全局最优解。因此，Logistic回归需要采用新的代价函数才能用梯度下降法求解。</p>

<div class="image_line" id="cost_function_curve"><div class="image_card"><a href="/assets/images/2014-10-19-logistic_regression_1.png"><img src="/assets/images/2014-10-19-logistic_regression_1.png" alt="代价函数" /></a><div class="caption">Figure 1:  代价函数 [<a href="/assets/images/2014-10-19-logistic_regression_1.png">PNG</a>]</div></div></div>

<p>Logistic回归采用</p>

<p>\begin{equation}
\mbox{Cost}\left(h_\theta(x), y\right) = \left\{
\begin{aligned}
&amp; -\log\left(h_\theta(x)\right) &amp; y=1 \\
&amp; -\log\left(1-h_\theta(x)\right) &amp; y=0
\end{aligned}
\right. 
\end{equation}</p>

<p>上式等价于</p>

<p>\begin{equation}
\mbox{Cost}\left(h_\theta(x), y\right) = -y\log\left(h_\theta(x)\right) - (1 - y)\log\left(1-h_\theta(x)\right)
\end{equation}</p>

<p>因此，Logistic回归的代价函数为</p>

<p>\begin{equation}
\begin{aligned}
J(\theta)<br />
= &amp; \frac{1}{m}\sum_{i=1}^{m}\mbox{Cost}\left(h_\theta\left(x^{(i)}\right), y^{(i)}\right) \\
= &amp; -\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_\theta\left(x^{(i)}\right)\right)\right)
\end{aligned}
\label{eq:cost_function_logistic_regression}
\end{equation}</p>

<blockquote>
  <p>若套用线性回归的代价函数，则$J(\theta)$非凸，不利于优化算法。该代价函数可从统计中最大似然估计（maximum likehood estimation）的角度推导。</p>
</blockquote>

<h2 id="section-2">参数估计</h2>

<p>参数估计是通过最小化代价函数\eqref{eq:cost_function_logistic_regression}，求解模型参数$\theta$。</p>

<p>\[
\min_\theta J(\theta)
\]</p>

<h3 id="section-3">梯度下降法</h3>

<p>貌似线性回归的梯度下降法的结构，但注意$h_\theta$的定义不同。</p>

<p>repeat until convergence {
\[
\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}~~~~~~(j = 0, 1, \ldots, n)
\]
}</p>

<p><strong>注意事项</strong></p>

<ul>
  <li>特征尺度规范化对加速Logistic回归的梯度下降法依然有效；</li>
  <li>其它注意事项同梯度下降法求解线性回归参数。</li>
</ul>

<p><img src="/assets/images/2014-10-19-logistic_regression_4.png" alt="采用Matlab的优化框架求解模型参数" /></p>

<div class="caption">图5 采用Matlab的优化框架求解模型参数</div>

<h3 id="section-4">其它算法</h3>

<ul>
  <li>Conjugate gradient</li>
  <li>BFGS</li>
  <li>L-BFGS</li>
</ul>

<blockquote>
  <p>这几种算法不需要手工选择学习率$\alpha$，通常比梯度下降法快，但是更复杂。</p>
</blockquote>

<h2 id="section-5">思考问题</h2>

<ol>
  <li>代价函数如何求偏导？</li>
</ol>

<h2 id="section-6">应用范例</h2>

<h2 id="section-7">参考资料</h2>

<ol>
  <li><a href="https://class.coursera.org/ml-007">Machine Learning （Andrew Ng）</a>  </li>
  <li><a href="http://en.wikipedia.org/wiki/Logistic_regression">Wikipedia: Logistic regression</a></li>
</ol>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习: 线性回归</title>
      <link href="http://qianjiye.de/2014/10/machine-learning-linear-regression" />
      <pubdate>2014-10-19T00:00:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2014/10/machine-learning-linear-regression</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">模型介绍</h2>

<p><img src="/assets/images/2014-10-19-linear_regression_0.png" alt="linear regression" /></p>

<p>线性回归（Linear Regression）的回归函数（hypothesis）为
\begin{equation}
h_\theta(x) = \theta^Tx = \theta_0x_0 + \theta_1x_1 + \cdots  + \theta_nx_n
\label{eq:hypothesis_linear_regression}
\end{equation}
其中，常数项$x_0 = 1$。</p>

<p>代价函数（cost function）为
\begin{equation}
J(\theta) = \frac{1}{2m}\sum_{i=1}^{m}{\left(h_{\theta}\left(x^{(i)}\right) - y^{(i)}\right)^2}
\label{eq:cost_function_linear_regression}
\end{equation}
其中，$x^{(i)} = \left(x_1^{(i)}, x_2^{(i)}, \cdots, x_n^{(i)}\right)$， $m$为样本数量，$n$为特征数量。</p>

<h2 id="section-1">参数估计</h2>

<p>参数估计是通过最小化代价函数\eqref{eq:cost_function_linear_regression}，求解模型参数$\theta$。
\[
\min_\theta J(\theta)
\]
通常有两种解法：万能的梯度下降法（gradient descent）和正规方程（normal equation）的解析解（也就是线性回归的最小二乘解）。</p>

<h3 id="section-2">梯度下降法</h3>

<p>repeat until convergence {
\[
\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta)~~~~~~(j = 0, 1, \ldots, n)
\]
}<br />
也就是<br />
repeat until convergence {
\[
\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_j^{(i)}~~~~~~(j = 0, 1, \ldots, n)
\]
}  <br />
每轮循环的时候同时更新$\theta_j$（下图左边为正确更新方式。<em>不能</em>在同一轮循环中，先更新部分$\theta_j$，再利用已更新的$\theta_j$更新其它$\theta_j$）。  <br />
<img src="/assets/images/2014-10-19-linear_regression_1.png" alt="同时更新$\theta_j$" /> <br />
特征的尺度如果相差太大，需要进行尺度规范化提高收敛速度，常用的规范化方法是
\[
\hat x_i = \frac{x_i - x_{mean}}{x_{max}-x_{min}}
\]
或者
\[
\hat x_i = \frac{x_i - x_{mean}}{x_{std}}
\]</p>

<p><strong>注意事项：</strong>   </p>

<ul>
  <li>线性回归的代价函数$J(\theta)$不存在局部极值（local optima），存在全局极值；</li>
  <li>将所有特征归一（feature scaling）到统一的尺度$-1\le x_i\le 1$有助于提高梯度下降法的速度（不归一化$x_0$）；</li>
  <li>学习率$\alpha$太小收敛慢，太大可能错过极值点而不收敛，过大的$\alpha$甚至可能导致$J(\theta)$不降反升；</li>
  <li>在迭代过程中保持$\alpha$不变，梯度下降步长也会自动减小，因为梯度会不断减小。</li>
</ul>

<p>尺度归一化效果： <br />
<img src="/assets/images/2014-10-19-linear_regression_2.png" alt="尺度归一化效果示例" /><br />
梯度下降步长自动减小：<br />
<img src="/assets/images/2014-10-19-linear_regression_3.png" alt="梯度下降步长自动减小" /></p>

<h3 id="section-3">正规方程求解</h3>

<p>正规方程求解也就是线性回归的最小二乘解为
\begin{equation}
\theta = \left(X^TX\right)^{-1}X^Ty
\end{equation}</p>

<p><strong>注意事项：</strong>     </p>

<p>$X^TX$可能不可逆，导致的原因可能是冗余特征（redundant features）和特征数目过多（$n$太多而$m$太少），解决的办法：   </p>

<ul>
  <li>冗余特征线性相关（e.g. $x_1 = 2x_2$）：删除线性相关特征；</li>
  <li>特征数目过多（e.g. $m \le n$）：删除特征、正则化（regularization）。</li>
</ul>

<p>Matlab Code：</p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="n">pinv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span></code></pre></div>

<p>其中，pinv函数可以处理$X^TX$不可逆的情况，而inv函数不行。</p>

<h3 id="section-4">求解方法比较</h3>

<table>
  <thead>
    <tr>
      <th>Gradient Descent</th>
      <th>Normal Equation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>需要$\alpha$</td>
      <td>不需要$\alpha$</td>
    </tr>
    <tr>
      <td>需要迭代</td>
      <td>不需要迭代</td>
    </tr>
    <tr>
      <td>当特征数$n$很大时（$10^6$）工作良好</td>
      <td>$n$很大时很慢</td>
    </tr>
    <tr>
      <td>特征需要尺度规范化</td>
      <td>特征不需要尺度规范化</td>
    </tr>
  </tbody>
</table>

<h2 id="section-5">多项式回归</h2>

<p>当$x_1 = x, x_2 = x^2, x_3 = x^3, \ldots $时，多项式回归（polynomial regression）\eqref{eq:hypothesis_polynomial_regression}可以直接转化为线性模型\eqref{eq:hypothesis_linear_regression}。
\begin{equation}
h_\theta(x) = \theta^Tx = \theta_0x_0 + \theta_1x + \theta_2x^2 ＋ \theta_3x^3 \cdots  + \theta_nx^n
\label{eq:hypothesis_polynomial_regression}
\end{equation}</p>

<p><strong>注意事项：</strong> <br />
构造多项式特征，借助多项式回归，可以利用线性回归模型解决非线性问题。</p>

<h2 id="section-6">思考问题</h2>

<ol>
  <li>如何通过收敛判断梯度下降法是否应该停止迭代？</li>
  <li>特征尺度规范化（feature scaling）为何能提高梯度下降法收敛速度？</li>
  <li>为什么正规方程估计参数不需要特征尺度规范化？</li>
</ol>

<h2 id="section-7">应用范例</h2>

<h2 id="section-8">参考资料</h2>

<p><a href="https://class.coursera.org/ml-007">Machine Learning （Andrew Ng）</a>    <br />
<a href="http://en.wikipedia.org/wiki/Linear_regression">Wikipedia: Linear regression</a></p>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>基于Jekyll的GitHub建站指南</title>
      <link href="http://qianjiye.de/2012/07/host-your-pages-at-github-using-jekyll" />
      <pubdate>2012-07-01T00:00:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2012/07/host-your-pages-at-github-using-jekyll</guid>
      <content:encoded>&lt;![CDATA[<p>简介：本文主要介绍利用jekyll在github上搭建站点的方法与原理。</p>

<p><span id="jekyll-and-github"></span></p>

<h2 id="jekyllgithub">jekyll与github的关系</h2>

<p>github站点是位于username.github.com仓库中的静态页面。利用高效的工具生成高质量的静态页面是github建站的王道。<a href="http://jekyllrb.com/">jekyll</a>就是用<a href="http://www.ruby-lang.org/">ruby</a><a href="http://jekyllbootstrap.com/lessons/jekyll-introduction.html">制造静态站点的的ruby解析引擎</a>（构建网站时ruby不是必会的）。github除了能构建独立的站点外，还可以为每个项目建立站点。github提供了<a href="https://help.github.com/articles/creating-pages-with-the-automatic-generator">自动</a>和<a href="https://help.github.com/articles/creating-project-pages-manually">手动</a>建立项目站点的方法。</p>

<p>github标配有jekyll解析引擎，上传的站点可以代由github的jekyll解析为静态页面。如果<a href="https://help.github.com/articles/files-that-start-with-an-underscore-are-missing">不需要github用jekyll处理上传的站点文件</a>，可以在根目录下添加一个.nojekyll文件。</p>

<p><a href="https://help.github.com/articles/using-jekyll-with-pages">github使用jekyll的_config.yml</a>和用户本地jekyll的不同，它的功能有限，github运行jekyll带有<code>--safe</code>参数。如果用户本地的jekyll使用了自定义插件，github的解析会出错，启用了本地自定义插件的用户可以上传本地解析好的静态页面到github。</p>

<p>由于本地和gihub的<a href="https://help.github.com/articles/using-jekyll-with-pages">jekyll版本</a>不同，即使本地正常解析的页面也可能会在github上解析出错。下面的表格在github上<code>Jekyll 0.11.0 with Liquid 2.2.2</code>会出错：</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">功能  <span class="p">|</span>   快捷键  <span class="p">|</span>   快捷键  <span class="p">|</span>  功能
-------: <span class="p">|</span> -------: <span class="p">|</span> :------- <span class="p">|</span> :-------
上一节点  <span class="p">|</span>   <span class="sb">`</span>p<span class="sb">`</span>    <span class="p">|</span>    <span class="sb">`</span>n<span class="sb">`</span>   <span class="p">|</span> 下一节点  
<span class="o">||</span>    <span class="sb">`</span>m<span class="sb">`</span>   <span class="p">|</span> 菜单</code></pre></div>

<h2 id="jekyll">jekyll驱动网站原理</h2>

<p><a href="http://chen.yanping.me/cn/blog/2011/12/15/building-static-sites-with-jekyll/">用jekyll构建静态网站</a>很容易。模板、数据和美化是jekyll建站的三要素。jekyll自动将数据注入模板，通过美化，得到站点。这里可以看到<a href="https://github.com/mojombo/jekyll/wiki/Sites">一堆用jekyll打造的站点</a>，大部分都可以<code>git clone</code>回来学习参考。<br />
<!--more--></p>

<h3 id="jekyll-1">jekyll的模板</h3>

<p>jekyll模板就是带有变量的html格式文件。jekyll的模板用<a href="http://liquidmarkup.org/">Liquid</a>语言描述，定义了页面框架。Liquid通过（Output）和标签（Tag）两种标记（markup），即可描述页面的结构，具体可参阅<a href="https://github.com/Shopify/liquid/wiki/Liquid-for-Designers">Liquid for Designers</a>。jekyll对Liquid的标签进行了<a href="https://github.com/mojombo/jekyll/wiki/Liquid-Extensions">扩展</a>。Liquid模板语言对模板数据描述（当然也需要html），生成了站点页面的骨架。Liquid所需要的jekyll的<a href="https://github.com/mojombo/jekyll/wiki/template-data">模板数据</a>在这儿可以找到。除此之外，<a href="https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter">YAML Front Matter</a>定义的变量也可以作为模板数据。</p>

<h3 id="jekyll-2">jekyll的数据</h3>

<p>jekyll的数据是用<a href="http://daringfireball.net/projects/markdown/">markdown</a>、<a href="http://textile.sitemonks.com/">textile</a>等标记语言写的文档。这些格式的文档解析为html格式后，注入jekyll模板的<code>&#123;&#123; content &#125;&#125;</code>，就有了网站的页面。jekyll支持的markdown解析器（将markdown转换为html）有：<span id="markdown"></span><a href="https://github.com/rtomayko/rdiscount/">rdiscount</a>、<a href="http://kramdown.rubyforge.org/">kramdown</a>、<a href="https://github.com/tanoku/redcarpet/">redcarpet</a>、<a href="http://maruku.rubyforge.org/">maruku</a>（jekyll默认）、<a href="http://deveiate.org/projects/BlueCloth/">bluecloth</a>。为了方便处理<script type="math/tex">\LaTeX</script>公式，也有人hack了jekyll，<a href="http://yangzetian.github.com/2012/04/15/jekyll-pandoc/">将pandoc作为markdown的解析器</a>。一个更方便的方法是通过<a href="https://github.com/dsanson/jekyll-pandoc-plugin">jekyll-pandoc-plugin</a>插件，启用pandoc解析器。这些hack后的jekyll启用pandoc当然不会在github上生效，只能用于本机解析后，上传静态页面。</p>

<h3 id="jekyll-3">jekyll的美化</h3>

<p>美化就是用CSS和javascript对html描述的页面进行渲染，美化网页。<a href="http://twitter.github.com/bootstrap/">twitter bootstrap</a>是一套极易上手的页面美化工具。twitter bootstrap还提供了<a href="http://960.gs/">960网格布局</a>，只要按照它约定的方式对页面结构定义、对html标签的<code>class</code>命名，网页的布局美化可谓快又好。</p>

<h2 id="jekyll-bootstrap">在jekyll-bootstrap基础上搭建网站</h2>

<p>jekyll是一套根据相应规程生成网站的工具。如果按照这套法则，从头开始仍然麻烦。<a href="http://jekyllbootstrap.com/">jekyll-bootstrap</a>就是一个jekyll构建站点的demo，并提供了一些<a href="http://jekyllbootstrap.com/api/bootstrap-api.html">额外的api增强jekyll的功能</a>，在此基础上构建站点相当快捷容易。除此之外，<a href="http://octopress.org/">octopress</a>也是基于jekyll上的不错的工具套件。</p>

<h3 id="section">目录结构</h3>

<p>jekyll-bootstrap的<a href="https://github.com/mojombo/jekyll/wiki/usage">目录结构</a>中，只需要将markdown文档放到_posts目录下，<code>jekyll --server</code>（新版采用<code>jekyll serve</code>命令），即可在http://localhost:4000看到页面内容，见<a href="http://jekyllbootstrap.com/usage/jekyll-quick-start.html">快速入门示范</a>。_posts中的数据文档，通过注入_layouts定义的模板（_layouts的模板一般指向了_includes/themes中的模板），渲染页面的CSS和JS文档在assets/themes中，一些解析markdown用到的ruby插件放在_plugins目录。通过<code>jekyll --server</code>（新版采用<code>jekyll serve</code>命令）最终生成的静态页面在_sites目录。在更新github上站点的时候，<code>git push</code>可以不必推送_sites目录，将页面的解析留给github，这样做的前提条件是本地未启用自定义插件，_config.yml设置<code>safe = true</code>进行解析。如果本地启用了自定义插件，解析任务就不能交给github做了，上传本地解析好的静态页面到github即可。</p>

<p>jekyll-bootstrap的_includes/JB中有一些常用的工具，用于列表显示、评论等，可参看_includes/themes中主题的相关html文档学习。</p>

<p>_includes/themes中的主题一般包含default.html、post.html和page.html三个文档。default.html定义了网站的最上层框架（模板），post.html和page.html是其子框架（模板）。<a href="http://jekyllbootstrap.com/lessons/jekyll-introduction.html#posts_and_pages">post和page有别</a>；<code>rake page</code>命令生成的页面按page.html解析，markdown文件的<a href="https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter">YAML Front Matter</a>中<code>layout: page</code>；<code>rake post</code>命令生成的页面按post.html解析，markdown文件的<a href="https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter">YAML Front Matter</a>中<code>layout: post</code>。生成好的html子页面通过default.html的<code>&#123;&#123; content &#125;&#125;</code>变量调用，生成整个页面。</p>

<h3 id="section-1">自定义</h3>

<p>站点生成需要用到_config.yml<a href="https://github.com/mojombo/jekyll/wiki/configuration">配置文件</a>，<code>markdown</code>变量定义了解析markdown用的<a href="#markdown">解析器</a>。当然也可自定义变量，比如在<code>JB:</code>下定义一个二级变量<code>RSS_path: /atom.xml</code>（注意缩进）。在html页面中，就可以用<code>&#123;&#123; site.JB.RSS_path &#125;&#125;</code>得其值。<a href="https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter">YAML Front Matter</a>中也可以自定义变量，其中的<code>title</code>变量可以用<code>&#123;&#123; page.title &#125;&#125;</code>访问到。也就是说，站点的全局变量在_config.yml中定义，用<code>site.</code>访问，页面的变量在<a href="https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter">YAML Front Matter</a>中定义，用<code>page.</code>访问，更多的模板变量可参考<a href="https://github.com/mojombo/jekyll/wiki/template-data">模板数据</a>。</p>

<p>_includes/JB中的插件可以在_includes/custom中重新自定义，方法可仿照_includes/JB中的。如果要_includes/custom中的插件生效，需要在_config.yml中将相应的变量设为<code>custom</code>，设置线索可见_includes/JB中的插件。</p>

<h3 id="section-2">小结</h3>

<p><a href="http://jekyllbootstrap.com/lessons/jekyll-introduction.html#how_jekyll_generates_the_final_static_files">jekyll生成静态页面的过程</a>就是先搜集站点的原始数据，通过计算，生成用于页面显示的结构化数据（最终的html静态页面）。结构化数据来源有两方面：一方面是文件中的配置文件，如_config.yml和markdown的<a href="https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter">YAML Front Matter</a>；另一方面通过目录结构和jekyll定义的解析法则，产生数据。站点的全局数据用<code>site.</code>访问，页面数据用<code>page.</code>访问。有了这些结构化的数据后，jekyll再按照用户定义的模板，用相应的结构化数据替换模板中的变量。用户编写的插件是为了计算出满足用户特定需求的数据，但是这些自定义插件不能不github的jekyll解析支持。</p>

<h2 id="jekyll-4">jekyll的装饰部件</h2>

<p>这些装饰部件中，如果本地的jekyll使用了自定义的插件，github的jeklly解析器不会支持这些自定义插件。</p>

<h3 id="section-3">图片与文件</h3>

<p>站点需要的图片直接存放在<code>assets/images</code>文件夹中，可以在_config.yml中定义一个形如<code>img_url: http://jiyeqian.github.com/assets/images</code>的变量，然后在markdown文件需要用到图片的地方插入类似<code>![git代码库结构](&#123;&#123; site.img_url &#125;&#125;/2012-06-27-git-transport.png)</code>的代码即可显示图像。</p>

<p>如果图和文件较多，这里有一些<a href="/2011/09/web-cloud-life/">图片和文件托管的网络资源</a>供参考。</p>

<h3 id="section-4">代码高亮</h3>

<p>网页代码高亮的一般原理是先用JS或其它脚本语言对代码的进行解析，并提根据不同程的序语言提取关键字、变量、常量、注释，然后将代码层次结构用html标签描述，最后用CSS着色。</p>

<p>代码高亮的方案有很多，比如：<a href="https://gist.github.com/1027674">转帖gist代码的插件</a>，<a href="http://google-code-prettify.googlecode.com/svn/trunk/README.html">google-code-prettify</a>，<a href="https://github.com/rsim/blog.rayapps.com/blob/master/_plugins/pygments_cache_patch.rb">利用pygments高亮代码的插件</a>，octopress的<a href="http://octopress.org/docs/plugins/backtick-codeblock/">backtick-codeblock</a>，如果需要在线展示html、js、CSS及其效果，当然还是用<a href="http://octopress.org/docs/plugins/jsfiddle-tag/">jsfiddle插件</a>。</p>

<p>pygments和rouge是github可支持的代码高亮方案(不支持coderay高亮)。利用pygments，须先在_config.yml中设置<code>pygments: true</code>，并嵌入生成的相应CSS到页面的<code>&lt;head&gt;&lt;/head&gt;</code>之中。   </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>pygmentize -S default -f html <span class="p">|</span> sed <span class="s1">&#39;s/^/.highlight code /g&#39;</span> &gt; default.css</code></pre></div>

<p>在pygments的CSS选择器前都加上<code>.highlight code</code>，防止pygments的CSS影响<a href="#mathjax">mathjax</a>公式的CSS。<a href="http://www.stehem.net/2012/02/14/how-to-get-pygments-to-work-with-jekyll.html">pygments也可能会和bootstrap.min.css冲突</a>，需要修改css。上面的<code>pygmentize</code>命令就是pygments代码高亮的效果。代码高亮的highlight标签使用方法<a href="https://github.com/mojombo/jekyll/wiki/Liquid-Extensions">可以参考这里</a>。</p>

<p>另一个比较特殊的代码高亮插件是<a href="http://octopress.org/docs/plugins/include-code/">include-code</a>，可以直接显示目录中的代码文件，在_config.yml中设置好<code>code_dir</code>参数后，直接用<code>&#123;% include_code excerpt.rb %&#125;</code>，即可显示高亮代码（布局可自己定义，代码高亮的CSS可以用pygments的）。<a href="https://gist.github.com/2890453#working-with-code-partials">pygments也支持类似的方法</a>，但效果不太好。</p>

<p><span id="mathjax"></span></p>

<h3 id="latex"><script type="math/tex">\LaTeX</script>公式</h3>

<p>github可支持的<script type="math/tex">\LaTeX</script>方案需要绕过自定义插件，利用类似<a href="http://www.mathjax.org/">mathjax</a>的javascript方案或采用支持<script type="math/tex">\LaTeX</script>的markdown解析器（比如<a href="http://maruku.rubyforge.org/">maruku</a>）。</p>

<p><a href="http://www.mathjax.org/">mathjax</a>通过javascript的方式生成<script type="math/tex">\LaTeX</script>公式可以参考<a href="http://chen.yanping.me/cn/blog/2012/03/10/octopress-with-latex/">在Octopress中使用<script type="math/tex">\LaTeX</script></a>，不过，不必把markdown解析引擎设置为kramdown。当markdown解析引擎为kramdown时，只需要在页面中插入下面这段代码：</p>

<div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span> <span class="na">src=</span><span class="s">&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;</span><span class="nt">&gt;&lt;/script&gt;</span></code></pre></div>

<p>下面这段代码：</p>

<div class="highlight"><pre><code class="language-html" data-lang="html">$$ 
e^x = \sum\_{n=0}^\infty \frac{x^n}{n!} = \lim\_{n\rightarrow\infty} (1+x/n)^n 
$$</code></pre></div>

<p>显示的效果：
<script type="math/tex"> 
e^x = \sum\_{n=0}^\infty \frac{x^n}{n!} = \lim\_{n\rightarrow\infty} (1+x/n)^n 
</script>
显示行内公式<script type="math/tex">\alpha + \beta</script>的代码如下：</p>

<div class="highlight"><pre><code class="language-html" data-lang="html">$$\alpha + \beta$$</code></pre></div>

<p>但是kramdown的解析引擎和转帖gist代码的插件、直接高亮文件中代码的插件include-code有冲突。</p>

<p>利用<a href="https://gist.github.com/834610">mathjax插件</a>定义的新标签，也可插入<script type="math/tex">\LaTeX</script>公式。这段代码<code>&#123;% math %&#125; e&#94;x = \sum\_{n=0}&#94;\infty \frac{x&#94;n}{n!} = \lim\_{n\rightarrow\infty} (1+x/n)&#94;n &#123;% endmath %&#125;</code>也可显示和上面一样的公式，利用标签<code>&#123;% m %&#125; \alpha + \beta &#123;% em %&#125;</code>可显示行内公式<script type="math/tex">\alpha + \beta</script>。mathjax还<a href="http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers">支持公式编号</a>，引用公式\eqref{eq:sample}很方便。</p>

<p>\begin{equation}
  \int_0^\infty \frac{x^3}{e^x-1}\,dx = \frac{\pi^4}{15}
  \label{eq:sample}
\end{equation}</p>

<p>另外一些支持<script type="math/tex">\LaTeX</script>公式的方案可参考：Kramdown的<a href="http://kramdown.rubyforge.org/syntax.html#math-blocks">Math Blocks</a>、<a href="http://maruku.rubyforge.org/math.xhtml">Maruku的公式支持</a>。 其他和学术写作相关的插件有：<a href="https://github.com/inukshuk/jekyll-scholar">jekyll-scholar</a>、<a href="https://github.com/archome/jekyll-citation">jekyll-citation</a>、<a href="https://github.com/pablooliveira/bibjekyll">bibjekyll</a>。</p>

<h3 id="section-5">其它</h3>

<p>显示相关文件的插件用<a href="https://github.com/LawrenceWoodman/related_posts-jekyll_plugin">related_posts-jekyll_plugin</a>、<a href="https://github.com/sebcioz/jekyll-only_first_p">只显示第一段</a>的插件，可解析类似wordpress的<code>&lt;!--more--&gt;</code>标记的<a href="https://gist.github.com/986665">excerpt插件</a>，美化引用格式的<a href="http://octopress.org/docs/plugins/blockquote/">blockquote插件</a>。<a href="http://octopress.org/docs/plugins/">octopress的插件</a>可以直接用于jekyll中。</p>

<h3 id="section-6">小结</h3>

<p>要将jekyll的页面托管在github时，推荐尽量不用github之外的插件。代码高亮用pygments，markdown的解析器用kramdown更利于对公式的解析，如果还要其它一些美化，就直接插html代码吧！</p>

<h2 id="jekyll-5">常用的Jekyll变量</h2>

<h2 id="section-7">一些技巧</h2>

<h3 id="gist">直接插入gist代码</h3>

<p>因为markdown的语法可以兼容html，在情非得已的情况下，直接查html代码。如果转帖gist的代码，直接在markdown文件中插入：</p>

<div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;script </span><span class="na">src=</span><span class="s">&quot;https://gist.github.com/834610.js?file=Jekyll nd Octopress Liquid tag for MathJax.rb&quot;</span><span class="nt">&gt;&lt;/script&gt;</span></code></pre></div>

<p>即可得：
<script src="https://gist.github.com/834610.js?file=Jekyll nd Octopress Liquid tag for MathJax.rb"></script></p>

<h3 id="section-8">页内跳转</h3>

<p>为了方便页内快速跳转，可建立空内容的锚点。比如
~~~html
<span id="jekyll-and-github"></span>
##jekyll与github的关系
~~~
既可用</p>

<div class="highlight"><pre><code class="language-html" data-lang="html">[回去看看](#jekyll-and-github)</code></pre></div>

<p>实现页内跳转，试试，<a href="#jekyll-and-github">回去看看</a>。如果用的是kramdown解释器，上例中空锚点行下须有一空行。</p>

<h3 id="section-9">表格不断行</h3>

<p>表格某一栏不断行的处理：</p>

<div class="highlight"><pre><code class="language-html" data-lang="html"><span class="nt">&lt;span</span> <span class="na">style=</span><span class="s">&quot;white-space:nowrap&quot;</span><span class="nt">&gt;</span>git clone username@host:/path/to/repository<span class="nt">&lt;/span&gt;</span></code></pre></div>

<!---
点击[到这里看效果]()。
--->

<h3 id="section-10">引用本站其它网页</h3>

<div class="highlight"><pre><code class="language-text" data-lang="text">{% post_url your_markdown_file_name %}</code></pre></div>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>李纯明博士报告安排</title>
      <link href="http://qianjiye.de/2012/06/lab-notice" />
      <pubdate>2012-06-27T00:00:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2012/06/lab-notice</guid>
      <content:encoded>&lt;![CDATA[<blockquote>

  <ol>
    <li>地点在虎溪校区数学与统计学院510；</li>
    <li>意见和报告相关的交流可在本文后留言。</li>
  </ol>
</blockquote>

<h2 id="section">报告1：图像处理中的数学方法</h2>
<ul>
  <li>时间：7月2日，星期一 上午10:00  </li>
  <li>地点：数学与统计学院5楼信息系会议室   </li>
  <li>摘要：介绍图像处理中的几个重要问题及其数学方法：1. 图像去噪中的Perona-Malik模型，各向异性扩散模型（Anisotropic Diffusion）；2. 图像分割的变分方法；3. 基于光流（Optical Flow）的运动分析及其在图像配准中的应用。这些图像处理问题都可以用类似的变分原理来建模与数值计算。总结图像处理中常用的能量泛函和偏微分方程，及其数值求解过程。 </li>
</ul>

<p><a href="#leave_a_note">我有话要说⋯⋯</a></p>

<h2 id="section-1">报告2：活动轮廓模型与水平集方法</h2>
<ul>
  <li>时间：7月4日，星期三 上午10:00  </li>
  <li>地点：数学与统计学院5楼信息系会议室  </li>
  <li>摘要：本报告主要内容包括：1. 经典的参数化活动轮廓模型（Active  Contour Models）；2. 驱动曲线演化的外力，如Gradient Vector Flow；3. 几何活动轮廓模型与水平集方法；4. 基于变分原理的水平集方法；5. 无需重新初始化的变分水平集方法。      </li>
</ul>

<p><a href="#leave_a_note">我有话要说⋯⋯</a></p>

<h2 id="section-2">报告3：基于区域的图像分割方法与偏移场估计</h2>
<ul>
  <li>时间：7月6日，星期五 上午10:00</li>
  <li>地点：数学与统计学院5楼信息系会议室</li>
  <li>摘要：本报告先介绍几个经典的基于区域的图像分割模型，包括Mumford-Shah模型与Chan-Vese模型，及其局限性。引入Region-Scalable Fitting模型，通过对分片常量（Piecewise Constant）模型的局部化，克服了经典的基于区域的图像分割模型无法对付intensity inhomogeneity的困难。进一步建立了同时分割与偏移估计的能量极小化模型。    </li>
</ul>

<p><a href="#leave_a_note">我有话要说⋯⋯</a></p>

<h2 id="section-3">报告4：图像分割的一些新方法</h2>
<ul>
  <li>时间：7月9日，星期一 上午10:00  </li>
  <li>地点：数学与统计学院5楼信息系会议室 </li>
  <li>摘要：本报告介绍几个最新的图像分割方法，包括全局凸的图像分割模型与Split Bregman，Non-Local Active Contours等；基于Fuzzy C-means的图像分割模型及其推广；医学影像分析中的基于Atlas的图像分割方法。    </li>
</ul>

<p><a href="#leave_a_note">我有话要说⋯⋯</a></p>

<h2 id="section-4">报告5：时间序列磁共振图像分割</h2>
<ul>
  <li>时间：7月11日，星期三 上午10:00  </li>
  <li>地点：数学与统计学院5楼信息系会议室  </li>
  <li>摘要：本报告介绍当前医学影像分析中的一个热点问题：时间序列图像的分割。在医学的研究与临床应用中经常需要对同一个病人在不同的时间进行扫描，因此得到一系列的图像（longitudinal images）或四维的图像。对这种时间序列图像的分割既要保证分割结果的连贯性，又能检测出病变和结构性变化，比如脑萎缩。本报告针对磁共振脑成像的应用，提出了一个新的四维图像分割模型，有效地保证了对时间序列图像的分割的连贯性。    </li>
</ul>

<p><a href="#leave_a_note">我有话要说⋯⋯</a></p>

<h2 id="section-5">李纯明博士介绍</h2>

<blockquote>
  <p><strong>李纯明，美国康涅狄格大学电子工程博士，复旦大学数学硕士, 福建师范大学数学系本科。2005年至2009年在范德堡大学医学成像科学研究所（Vanderbilt University Institute of Imaging Science）从事博士后研究工作。2009年至今在宾夕法尼亚大学 （University of Pennsylvania） 影像系担任高级研究员，兼任卡内基梅隆大学生物医学工程博士学位论文答辩委员会成员和南京军区总医院客座教授。</strong>    </p>
</blockquote>

<p>李博士的专长是图像处理、医学影像分析和计算机视觉。以第一作者身份在这些领域的顶级期刊和国际会议上发表了多篇具有高度原创性和广泛国际影响的学术论文。<code>这些论文总共被引用累计1500余次，其中一篇关于水平集方法（Level Set Method）的论文于2005年发表至今已经被引用高达800多次。</code></p>

<p>李博士担任二十余家国际权威专业期刊和顶级国际会议的审稿人及程序委员会委员，包括IEEE Trans. on Image Processing， IEEE Trans. on Medical Imaging， IEEE Trans. on Pattern Analysis and Machine Intelligence， Medical Image Analysis， Medical Physics， Magnetic Resonance Imaging  （MRI）等几乎所有图像处理，计算机视觉和医学影像领域的主流期刊，以及 IEEE International Conference on Computer Vision and Pattern Recognition （CVPR）, International Conference on Computer Vision （ICCV）， Medical Image Computing and Computer Assisted Intervention （MICCAI） 等顶级国际会议。李博士曾应邀到卡内基梅隆大学，俄亥俄州立大学，康涅狄格大学，佛罗里达州立大学，清华大学，复旦大学，重庆大学，南京理工大学，华东师范大学，北京师范大学，电子科技大学，厦门大学，南京军区总医院，江苏省人民医院等国内外大学和医院讲学。
李博士在图像处理领域的一系列研究成果已被世界各国的诸多科研和工程人员广泛应用于工程（包括计算机视觉与图像处理）、生物、医学等领域的科研和技术开发。李博士所建立的模型在图像处理、医学影像和计算机视觉领域中被广泛采用和深入研究。他的一系列基于水平集的图像分割的模型不仅被大量期刊和会议文章所引用，还被一些研究生教材收录，包括国内的科学出版社出版的《图像处理的偏微分方程方法》，或者被国内外一些大学的研究生课程列为重要参考文献 。李博士在磁共振成像的偏移场校正（MRI bias correction） 等医学成像领域的若干重要课题中也取得了世界领先的研究成果，成功地解决了超高场强的磁共振成像中的偏移场校正的难题。李博士目前的主要从事医学影像分析的技术开发及其临床应用，包括多发性硬化症，各种中枢神经系统疾病的计算机辅助诊断的研究，肿瘤精确定位与测量，手术计划与临床随访等等。<code>李博士开发的基于超声波图像分割的颈动脉内-中膜厚度的测量技术已经被辉瑞（世界最大的制药公司）的全球研发总部采用，并成功地用于治疗动脉硬化的药物开发的临床试验。</code></p>

<p><span id="leave_a_note"></span></p>

]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>外国诗歌赏析</title>
      <link href="http://qianjiye.de/2011/10/foreign-poems" />
      <pubdate>2011-10-08T23:09:00+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2011/10/foreign-poems</guid>
      <content:encoded>&lt;![CDATA[<h4 id="section">目录：</h4>
<ol>
  <li><a href="#普希金">普希金</a>：纪念碑</li>
  <li><a href="#何塞·黎萨尔">何塞·黎萨尔</a>：我最后的告别   </li>
</ol>

<p><span id="普希金"></span></p>

<blockquote>
  <h4 id="section-1">纪念碑（俄国 普希金）</h4>
  <hr />
  <p>我给自己建起了一座非手造的纪念碑<br />
人民走向那里的小径永远不会荒芜<br />
它将自己坚定不屈的头颅高高昂起<br />
高过亚历山大的石柱<br />
不，我绝不会死去，心活在神圣的竖琴中<br />
它将比我的骨灰活得更久，永不消亡<br />
只要在这个月照的世界上还有一个诗人<br />
我的名声就会传扬  </p>

  <p>整个伟大的俄罗斯都会听到我的传闻<br />
各种各样的语言都会呼唤我的姓名<br />
无论骄傲的斯拉夫人的子孙<br />
还是芬兰人、山野的通古斯人、卡尔梅克人<br />
我将长时期地受到人民的尊敬和爱戴<br />
因为我用竖琴唤起了人民善良的感情<br />
因为我歌颂过自由，在我的残酷的时代<br />
我还曾为死者呼吁同情<br />
啊，我的缪斯，你要听从上天的吩咐<br />
既不怕受人欺侮，也不希求什么桂冠<br />
什么诽谤，什么赞扬，一概视若粪土<br />
也不必理睬那些笨蛋  </p>
</blockquote>

<p><span id="何塞·黎萨尔"></span></p>

<blockquote>
  <h4 id="section-2">我最后的告别（菲律宾 何塞·黎萨尔）</h4>
  <hr />
  <p>永别了，敬爱的祖国，阳光爱抚的国土，<br />
您是东海的明珠，我们失去的乐园。<br />
我忧愤的生命，将为您而愉快地献出，<br />
即使它将更加辉煌壮丽和生气盎然，<br />
为了您的幸福，我也乐意向您奉献。  </p>

  <p>在烽烟四起的沙场，恶战方酣，<br />
人们毫不犹豫、毫不悔恨地英勇献身。<br />
不管死于何处，在翠柏、月桂或百合旁边，<br />
还是在绞架上、旷野间、更不管是阵亡，还是悲惨地殉难，<br />
只要是祖国和国家的需要，全都一样光荣。</p>

  <p>在迎接曙光时，我将安息长眠，<br />
黎明将冲破黑夜，阳光要普照人间。<br />
假如您需要颜料来把黎明渲染，<br />
请让我的热血奔流在美好的时辰，<br />
让它把这新生的曙光染得更加金光闪闪。</p>

  <p>我少年时代，美梦翩翩，<br />
我青年时代，理想常燃。<br />
我切盼有—天，能看到您这东海明珠的容颜，<br />
您乌黑的眸厂不再流泪，眉宇的皱纹得到舒展，<br />
没有怨恨重重，更没有血迹斑斑。</p>

  <p>……</p>

  <p>当黑夜沉沉笼罩陵园，<br />
唯有死者守护着它，彻底不眠。<br />
请不要打扰他们的休息和神秘的安恬，<br />
也许您会听见一曲高歌，海上管弦，<br />
那就是我呀！亲爱的祖国，我在为您引吭高歌，抚奏六弦。</p>

  <p>没有十字架，没有墓碑，也没有任何铭志，<br />
当我的坟墓已荒烟野蔓，人们不再把我怀念；<br />
就让人们夷成原野，把土地犁翻，<br />
当我的骨灰还留在人间，<br />
就让它化为尘十，覆盖着祖国的良田。</p>

  <p>即使您已把我忘记，我也心地坦然，<br />
我将遨游在您的高山和草原，<br />
把优美嘹亮的歌声送到您的耳边。<br />
芳香、光亮、清丽、妙语、歌声和叹息，<br />
都永远是我忠贞本质的表现。</p>

  <p>我崇敬的祖国，哀怨中的哀怨，<br />
亲爱的菲律宾同胞，请听我诀别的赠言：<br />
我离开大家、离开亲人和挚爱的华颜，<br />
我去的地方没有奴隶和刽子手，也没有暴君，<br />
那儿不会戕害忠良，那儿是上帝主持的青天。</p>

  <p>永别了！我的父母、兄弟，我的亲眷，<br />
还有我那失去家园的童年侣伴。<br />
感谢吧，我可以摆脱艰辛的生活；歇歇双肩，<br />
永别了！我心爱的异国姑娘，我的朋友，我的欢乐，<br />
永别了！亲爱的人们，死就是安息，<br />
就是长眠。</p>
</blockquote>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
