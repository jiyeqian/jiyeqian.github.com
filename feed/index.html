<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2015-01-29T17:35:17+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>分类器融合（5）：梯度提升决策树</title>
      <link href="http://qianjiye.de/2015/01/gradient-boosted-decision-tree" />
      <pubdate>2015-01-29T16:12:28+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/gradient-boosted-decision-tree</guid>
      <content:encoded>&lt;![CDATA[
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>机器学习三原则</title>
      <link href="http://qianjiye.de/2015/01/three-learning-principles" />
      <pubdate>2015-01-28T20:05:37+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/three-learning-principles</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">使用奥卡姆剃刀</h2>

<blockquote>
  <p>An explanation of the data should be made as simple as possible, but no simpler.         <br />
—Albert Einstein? (1879-1955)</p>

  <hr />

  <p>entia non sunt multiplicanda praeter necessitatem (entities must not be multiplied beyond necessity)       <br />
—William of Occam (1287-1347) </p>
</blockquote>

<p>奥卡姆剃刀（Occam’s rezor）：剃掉不必要的解释。对机器学习，适合数据的最简单模型也是最合理的模型。</p>

<ul>
  <li>简单的假设$h$：小的$\Omega(h)$，假设的参数少；</li>
  <li>简单的模型$\mathcal H$：小的$\Omega(\mathcal H)$，包含较少的假设，成长函数增长很慢。</li>
</ul>

<p>当$\Omega(\mathcal H)$小时，$\Omega(h)$也小。当假设集大小为$2^\ell$时，每个假设最多有$\ell$个参数<sup id="fnref:why-ell-parameters"><a href="#fn:why-ell-parameters" class="footnote">1</a></sup>。在实际应用中，通过正则化或从简单模型开始尝试，都可以得到简单的假设。</p>

<p>对于简单模型，$m_\mathcal H(N)$小，难以将数据拟合好（拟合好的概率为$m_{\mathcal H}(N)\over 2^N$<sup id="fnref:why-ration"><a href="#fn:why-ration" class="footnote">2</a></sup>）。对简单的模型，如果数据被分开，那么数据是规律的；对于复杂的模型，如果数据能分开，就不能判断数据是否有规律（复杂模型能把任何数据分开）。</p>

<p>在实际应用中，从简单的线性模型开始尝试，经常考量数据是否被模型过度表示（data over-modeled）。</p>

<h2 id="section-1">避免抽样偏差</h2>

<p>如果数据通过有偏抽样得到<a href="#Darrell_Huff_2002">[1]</a>，学习到的结果也是有偏的。</p>

<p>若从$P_1(\mathbf x,y)$的数据中学习，却在$P_2\neq P_1$的数据中测试，VC理论不适用。相当于学了数学却要参加英语考试。VC理论的前提是训练和测试数据都iid来自同一分布。</p>

<p>通过信用卡用户的信用记录，判断是否给新顾客信用卡。——由于没有未开通信用卡用户的信息，这两者分布可能很不一样……</p>

<p>在实际应用中，尽可能的了解测试环境，使训练环境和测试环境尽量一致。</p>

<h2 id="section-2">绝不偷看数据</h2>

<blockquote>
  <p>If you torture the data long enough, it will confess.</p>
</blockquote>

<p>使用数据的任何过程都相当于间接偷看了数据。为了让VC维可靠，选择$\Phi$时不应当<a href="/2015/01/nonlinear-transformation/#human-learning">偷看数据</a>。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png"><img src="/assets/images/2015-01-28-three-learning-principles-snoop-data.png" alt="简单的偷看也会导致结果偏差很大" /></a><div class="caption">图 1:  简单的偷看也会导致结果偏差很大 [<a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png">PNG</a>]</div></div></div>

<p>对使用同样数据集$\mathcal D$的论文，后来作者针对以前论文改进，阅读以前论文也就相当于偷看资料。若把这些论文看成一篇长长的论文，付出的模型复杂度为$d_{VC}(\cup_m\mathcal H_m)$，泛化能力差。</p>

<p>偷看数据很难避免，合理处理偷看数据：</p>

<p><img src="/assets/images/2015-01-28-three-learning-principles-deal-with-snooping.png" alt="合理处理偷看数据" /></p>

<p>“be blind”是指尽量避免用数据做决定，不要在看了数据之后再决定采用什么样的特征等操作。也就是避免human learning的复杂度进入。</p>

<h2 id="section-3">其它三原则</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-tools.png" alt="三大工具" /></a><div class="caption">图 2:  三大工具 [<a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png" alt="三大理论边界" /></a><div class="caption">图 3:  三大理论边界 [<a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png">PNG</a>]</div></div></div>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="Darrell_Huff_2002">[1]达莱尔·哈夫, <i>统计陷阱</i>. 上海: 上海财经大学出版社, 2002.</span>

</li></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-ell-parameters">
      <p>为什么最多$\ell$个参数？ <a href="#fnref:why-ell-parameters" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-ration">
      <p>这个比率什么意思？ <a href="#fnref:why-ration" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>验证</title>
      <link href="http://qianjiye.de/2015/01/validation" />
      <pubdate>2015-01-27T23:28:10+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/validation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">模型选择问题</h2>

<p>若有$M$个<a href="/assets/images/2015-01-27-validation-so-many-models.png">候选模型</a>$\mathcal H_1,\mathcal H_2,\ldots,\mathcal H_M$和相应的算法$\mathcal A_1,\mathcal A_2,\ldots,\mathcal A_M$，如何选择$\mathcal H_{m^*}$使得$g_{m^*}=\mathcal A_{m^*}(\mathcal D)$有低的$E_{out}(g_{m^*})$？</p>

<p>由于$P(\mathbf x)$和$P(y|\mathbf x)$未知，那么$E_{out}$未也知……</p>

<h4 id="section-1">一、利用数据可视化不可行</h4>

<p>只有一些数据集……基于视觉化的选择是“<a href="/2015/01/nonlinear-transformation/#human-learning">human learning</a>”，并且高维度的数据不能视觉化。</p>

<h4 id="ein">二、利用$E_{in}$很危险</h4>

<p>如果利用$E_{in}$选择，高维特征变换通常犹豫低维，非正则化方法通常优于正则化方法。若$\mathcal A_1$在$\mathcal H_1$最小化$E_{in}$，$\mathcal A_2$在$\mathcal H_2$最小化$E_{in}$，二者再择优$g_{m^*}$在$\mathcal H_1\cup\mathcal H_2$中得到最小的$E_{in}$，这样增加了额外的模型复杂度，VC维$d_{VC}(\mathcal H_1\cup\mathcal H_2)$变大了，泛化能力差。</p>

<h4 id="etest">三、利用$E_{test}$是作弊</h4>

<p>根据finite-bin Hoeffding可得
\[
E_{out}(g_{m^*})\leq E_{test}(g_{m^*})+O\left(\sqrt{\log M\over N_{test}}\right)，
\]
看上去很美，$\mathcal D_{test}$是没用于模型训来的干净数据，可是$\mathcal D_{test}$（相当于老师的考卷）从哪里来呢？</p>

<h4 id="einetesteval">四、$E_{in}$和$E_{test}$折中的合法作弊方案$E_{val}$</h4>

<ul>
  <li>$\mathcal D_{val}\subset\mathcal D$；</li>
  <li>可以获取的；</li>
  <li>若$\mathcal D_{val}$没用于$\mathcal A_m$，那么它是干净的，就像测试数据一样。</li>
</ul>

<h2 id="section-2">单一验证集</h2>

<p>数据$\mathcal D$的划分和相应关系如下：</p>

<p>\begin{align*}
E_{in}(h)\quad&amp;\quad&amp;\quad&amp;\quad &amp;E_{val}(h)\\
\uparrow\quad\quad&amp;\quad&amp;\quad&amp;\quad &amp;\uparrow\;\;\,\,\\
\quad\underbrace{\mathcal D}_{\mbox{size }N}\quad\,&amp;\rightarrow&amp;\underbrace{\mathcal D_{train}}_{\mbox{size }N-K}\quad\quad\,&amp;\cup&amp;\underbrace{\mathcal D_{val}}_{\mbox{size }K}\;\\
\downarrow\quad\quad&amp;\quad &amp;\downarrow\quad\quad\quad\;&amp;\quad&amp;\quad\\
g_m=\mathcal A_m(\mathcal D)&amp;\quad &amp;g_m^-=\mathcal A_m(\mathcal D_{trian})&amp;\quad&amp;\quad
\end{align*}</p>

<p>$\mathcal D_{val}\subset\mathcal D$称为<strong>验证集</strong>（validation set），用于模拟测试集。$\mathcal D_{val}$是随机从$\mathcal D$中抽取的$K$个样本，那么$\mathcal D_{val}\overset{iid}{\sim} P(\mathbf x,y)$，通过数据建立了$E_{val}$与$E_{out}$的联系。确保$\mathcal D_{val}$是干净的，$\mathcal A_m$只使用了$\mathcal D_{train}$进行模型选择（也就是训练得到模型参数，从$\mathcal H$中选出$h$）。</p>

<p>原来使用$\mathcal D$扮演两个角色，既要计算$E_{in}$进行模型选择，又要通过算法得到$g$，两个角色导致资料被污染。利用$D_{val}$，通过最佳$E_{val}$进行模型选择
\[
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{val}(\mathcal A_m(\mathcal D_{train})))，
\]
可得如下误差保证
\begin{equation}
E_{out}(g_m^-)\leq E_{val}(g_m^-)+O\left(\sqrt{\log M\over K}\right)，
\end{equation}
但是只用$N-K$个训练模型out-of-sample误差会偏大（也可从学习曲线看出，理论上若要成立，还需更严格的限制条件），
\[
E_{out}\left(\underbrace{g_{m^*}}_{\mathcal A_m^*(\mathcal D)}\right)\leq E_{out}\left(\underbrace{g_{m^*}^-}_{\mathcal A_m^*(\mathcal D_{train})}\right)，
\]
因此，
\[
E_{out}(g_{m^*})\leq E_{out}(g_{m^*}^-)\leq E_{val}(g_{m^*}^-)+O\left(\sqrt{\log M\over K}\right)。
\]</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-27-validation-model-selection.png"><img src="/assets/images/2015-01-27-validation-model-selection.png" alt="基于验证集的模型选择方案" /></a><div class="caption">图 1:  基于验证集的模型选择方案 [<a href="/assets/images/2015-01-27-validation-model-selection.png">PNG</a>]</div></div></div>

<p>模型选择整个方案如上图所示，得到$g_{m^*}^-$之后，再回到原来整个数据集上得到$g_{m^*}$效果会更好<sup id="fnref:is-it-necessary"><a href="#fn:is-it-necessary" class="footnote">1</a></sup>。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-27-validation-vlidation-example.png"><img src="/assets/images/2015-01-27-validation-vlidation-example.png" alt="模型选择的学习曲线" /></a><div class="caption">图 2:  模型选择的学习曲线 [<a href="/assets/images/2015-01-27-validation-vlidation-example.png">PNG</a>]</div></div></div>

<p>上图是在$\mathcal H_{\Phi_5}$和$\mathcal H_{\Phi_{10}}$中进行模型选择的学习曲线。$g_{m^*}$的效果要优于$g_{m^*}^-$。利用$E_{in}$总会选择到复杂的模型，利用$E_{out}$的作弊方案选择结果总最优。随着验证集不断增大，用于模型选择的训练集不断减小，所以$g_{m^*}^-$甚至会比$g_{\widehat m}$效果差，对很小的训练集，采用$E_{in}$还算不错的模型选择方案。</p>

<p>对大的验证集样本数$K$，有$E_{val}(g^-)\approx E_{out}(g^-)$，但$g_{m^*}^-$通常比$g_{m^*}$糟糕；对小的$K$，有$g_m^-\approx g_m$和$E_{out}(g)\approx E_{out}(g^-)$，但$E_{val}$和$E_{out}$差异较大；
\[
E_{out}(g)\underset{\mbox{small }K}{\approx}E_{out}(g^-)\underset{\mbox{large }K}{\approx}E_{val}(g^-)。
\]</p>

<p>从时间上看，由于部分数据当作了验证集，在训练集上选择每个模型的时间会缩短。</p>

<p>$K={N\over 5}$通常是不错的选择。</p>

<h2 id="section-3">留1交叉验证</h2>

<p>当在验证集的$K=1$的极端情况下，$g^-$和$g$就会非常接近，但$E_{out}$和$E_{val}$差异就很大。能否在$K=1$时找到方案，使得$E_{out}\approx E_{val}$？✅</p>

<p>当$K=1$时，验证集$\mathcal D_{val}^{(n)}=\{(\mathbf x_n,y_n)\}$，误差为$E_{val}^{(n)}(g_n^-)=err(g_n^-(\mathbf x_n),y_n)=e_n$，将留1交叉验证（leave-one-out cross validation）误差
\begin{equation}
E_{loocv}(\mathcal H,\mathcal A)={1\over N}\sum_{n=1}^Ne_n={1\over N}\sum_{n=1}^Nerr(g_n^-(\mathbf x_n),y_n)
\end{equation}
作为$E_{out}(g)$的近似，$E_{loocv}(\mathcal H,\mathcal A)\approx E_{out}(g)$，然后进行模型选择，
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{loocv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-example.png"><img src="/assets/images/2015-01-27-validation-loocv-example.png" alt="loocv选择常数模型而非线性模型" /></a><div class="caption">图 3:  loocv选择常数模型而非线性模型 [<a href="/assets/images/2015-01-27-validation-loocv-example.png">PNG</a>]</div></div></div>

<p>用$\underset{\mathcal D_n}{\varepsilon}$表示在训练集上的数学期望，那么有<sup id="fnref:how-expectation-do"><a href="#fn:how-expectation-do" class="footnote">2</a></sup>
\begin{aligned}
\underset{\mathcal D}{\varepsilon}E_{loocv}(\mathcal H,\mathcal A) = \underset{\mathcal D}{\varepsilon}{1\over N}\sum_{n=1}^Ne_n 
&amp;= {1\over N}\sum_{n=1}^N\underset{\mathcal D}{\varepsilon}e_n\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}\underset{(\mathbf x_n,y_n)}{\varepsilon}err(g_n^-(\mathbf x_n),y_n)\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}E_{out}(g_n^-)\\
&amp;={1\over N}\sum_{n=1}^N\overline{E_{out}}(N-1)\\
&amp;=\overline{E_{out}}(N-1)，
\end{aligned}
因此可得$E_{loocv}(\mathcal H,\mathcal A)$和$E_{out}(g^-)$联系紧密，通常称作$E_{out}(g)$几乎无偏的估计（almost unbiased estimate）。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-practice.jpg"><img src="/assets/images/2015-01-27-validation-loocv-practice.jpg" alt="loocv手写识别示例" /></a><div class="caption">图 4:  loocv手写识别示例 [<a href="/assets/images/2015-01-27-validation-loocv-practice.jpg">JPG</a>]</div></div></div>

<p>上图手写识别例子中，通过验证确定选择多少维多项式特征。若用$E_{in}$，特征维度越多越好；利用$E_{loocv}$（图中标注为$E_{cv}$），会选到较低纬度的特征。</p>

<h2 id="v-fold-cross-validation">V-fold交叉验证</h2>

<p>由于loocv需要训练$N$次，时间复杂度非常大，在实际中并不总是可行的。但也有特例，线性回归的的loocv容易计算。通过单点估计误差波动较大，结果不是很稳定，曲线上有些跳动的点。如何降低loocv的计算量？</p>

<p>将数据集$\mathcal D$随机分为$V$等份（loocv相当于将数据集分为$N$等份），$V-1$份用于训练模型，剩余的1份用于验证，这称为V-fold交叉验证，
\begin{equation}
E_{cv}(\mathcal H,\mathcal A)={1\over V}\sum_{v=1}^VE_{val}^{(v)}(g_v^-)，
\end{equation}
模型选择方式为
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{cv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<p>通常情况，$V=10$。</p>

<p>通常，V-fold交叉验证要优于单一验证集方法，计算量也更大，5-fold或10-fold通常都会工作得很好，实际中loocv并不常用。</p>

<h2 id="section-4">小结</h2>

<p>各种模型选择的关系：</p>

<ul>
  <li>模型训练（初赛）：从假设集中选择；</li>
  <li>验证方案（复赛）：从训练好的模型中选择；</li>
  <li>测试：衡量最终的表现（测试集只在此时才能使用1次）。</li>
</ul>

<p>由于资料污染，以及付出了模型复杂度代价等因素，通常验证的结果仍然会比最终测试结果乐观。因此，提交测试结果而非验证结果更客观。</p>

<h2 id="section-5">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-6">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-it-necessary">
      <p><a href="/2015/01/image-classification-knn-based-introduction/#is-validation-set-need">并不是所有的人都这样做</a>…… <a href="#fnref:is-it-necessary" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-expectation-do">
      <p>数学期望如何分离计算的？ <a href="#fnref:how-expectation-do" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>正则化</title>
      <link href="http://qianjiye.de/2015/01/regularization" />
      <pubdate>2015-01-26T17:50:30+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/regularization</guid>
      <content:encoded>&lt;![CDATA[<p>正则化来源于处理函数逼近（function approximation）中的病态问题（ill-posed problem）。克服过拟合的一个方法是从简单模型开始尝试；正则化是相反的思路，从复杂模型的假设集开始，通过正则化约束求解得到未过拟合的简单模型（复杂项的系数很小或接近0）。</p>

<p>正则化等价于结构风险最小化（SRM，structural risk minimuzation）<a href="#lihang_sml_2012">[1, P. 9]</a>，它是结构风险最小化策略的实现，通过在经验风险上加一个正则化项或惩罚项实现<a href="#lihang_sml_2012">[1, P. 13]</a>。正则化符合奥卡姆剃刀（Occam’s rezor）原理：在所有可能选择的模型中，能够很好解释已知数据并且十分简单才是最好的模型。从贝叶斯估计的角度看，正则化项对应于模型的先验概率，可以假设复杂的模型有较大的先验概率<a href="#lihang_sml_2012">[1, P. 14]</a>。</p>

<p>本文的主要参考资料是机器学习基石<a href="#lin_ml_regularization_2014">[2]</a>。</p>

<h2 id="section">带约束回归</h2>

<p>对于$x\in\mathbb R$的Q阶多项式变换$\Phi_Q(x)=\left(1,x,x^2,\ldots,x^Q\right)$，为了方便用$\mathbf w$代替回归系数$\tilde{\mathbf w}$。10次和2次空间中回归问题的假设集$\mathcal H_{10}$和$\mathcal H_2$分别表示为
\[
\begin{aligned}
&amp;w_0+w_1x+w_2x^2+w_3x^3+\ldots,w_{10}x^{10}\\
&amp;w_0+w_1x+w_2x^2。
\end{aligned}
\]
若$w_3=w_4=\ldots=w_{10}=0$，则$\mathcal H_2=\mathcal H_{10}$，也就是$\mathcal H_2$的回归问题可以用带约束的$\mathcal H_{10}$实现
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }w_3=w_4=\ldots=w_{10}=0。
\]
正则化可以看作带约束的优化$E_{in}$。</p>

<p>稍微放松约束条件，任意8个系数为0，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H’_2$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}\left[\left[w_q\neq 0\right]\right]\leq 3。
\]
$\mathcal H’_2$比$\mathcal H_2$宽松，但比$\mathcal H_{10}$过拟合风险低，$\mathcal H_2\subset\mathcal H’_2\subset\mathcal H_{10}$。求解稀疏形式（含8个0系数）$\mathcal H’_2$中的假设非常困难，NP-hard。</p>

<p>进一步放松约束条件，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H(C)$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}w_q^2\leq C。
\]
$\mathcal H(C)$和$\mathcal H’_2$有交集（overlap），对$C\geq 0$存在嵌套结构
\[
\mathcal H(0)\subset\mathcal H(1.126)\subset\ldots\subset\mathcal H(1126)\subset\ldots\subset\mathcal H(\infty)=\mathcal H(10)。
\]
从正则化假设集$\mathcal H(C)$的到的最优解就是正则化假设$\mathbf w_{REG}$。</p>

<h2 id="section-1">拉格朗日乘子法</h2>

<p>根据上述推导，正则化回归问题的向量表示形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}\sum_{n=1}^N\left(\mathbf w^T\mathbf z_n-y_n\right)^2\qquad\mbox{s.t. }\sum_{q=0}^Qw_q^2\leq C，
\end{equation}
进一步记为矩阵形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}(\mathbf Z\mathbf w-\mathbf y)^T(\mathbf Z\mathbf w-\mathbf y)\qquad\mbox{s.t. }\mathbf w^T\mathbf w\leq C，
\label{eq:constrained-Ein-matrix}
\end{equation}
事实上$\mathbf w$位于半径为$\sqrt C$的球中。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-gradient-descent.png"><img src="/assets/images/2015-01-26-regularization-gradient-descent.png" alt="正则化约束的梯度下降法" /></a><div class="caption">图 1:  正则化约束的梯度下降法 [<a href="/assets/images/2015-01-26-regularization-gradient-descent.png">PNG</a>]</div></div></div>

<p>上图展示了正则化约束的梯度下降法，蓝色的椭圆曲线表示梯度相同的等高线，红色的圆形表示约束条件。没有正则化约束时，$\mathbf w$沿着$-\nabla E_{in}(\mathbf w)$方向达到最优解$\mathbf w_{lin}$，梯度方向指出了到达最优解的方式。有正则化约束时，大部分情况，最优解都在球面$\mathbf w^T\mathbf w=C$上。$-\nabla E_{in}(\mathbf w)$可以分解为绿色和红色$\mathbf w$（球切面的法向量）两个方向，如果已经在球面上，仍然继续沿着$\mathbf w$下降，会破坏约束条件。正则化梯度下降法，可看作在绿色箭头方向作用下接近最优解。达到最优解的条件是满足约束且不能继续下降，也就是$-\nabla E_{in}(\mathbf w)$平行于$\mathbf w$，那么有$-\nabla E_{in}(\mathbf w_{REG})\propto\mathbf w_{REG}$，此时绿色方向的分量为0，不再下降，优化过程结束。</p>

<p>利用拉格朗日乘子$\lambda&gt;0$，达到最优解的条件是
\begin{equation}
\nabla E_{in}(\mathbf w_{REG})+{2\lambda\over N}\mathbf w_{REG}=0。
\label{eq:nabla-E-w-reg}
\end{equation}
因为$\nabla E_{in}(\mathbf w_{REG})={2\over N}\left(\mathbf Z^T\mathbf Z\mathbf w_{REG}-\mathbf Z^T\mathbf y\right)$，所以可得最优解<sup id="fnref:why-regularize-all"><a href="#fn:why-regularize-all" class="footnote">1</a></sup>
\begin{equation}
\mathbf w_{REG}\leftarrow\left(\mathbf Z^T\mathbf Z+\lambda\mathbf I\right)^{-1}\mathbf Z^T\mathbf y。
\end{equation}
$\mathbf Z^T\mathbf Z$是半正定的，当$\lambda&gt;0$时，上述逆矩阵总存在。正则化的线性回归在统计学中称为<strong>脊回归</strong>（ridge regression）。</p>

<p>求解\eqref{eq:nabla-E-w-reg}等价于最小化增广误差（augmented error）
\begin{equation}
\mathbf w_{REG}\leftarrow \arg\min_{\mathbf w}E_{aug}(\mathbf w)\quad \lambda\geq 0，
\label{eq:Eaug-minimization}
\end{equation}
其中增广误差
\begin{equation}
E_{aug}(\mathbf w)=E_{in}(\mathbf w)+{\lambda\over N}\mathbf w^T\mathbf w，
\label{eq:E-aug}
\end{equation}
$\mathbf w^T\mathbf w$称为正则化项（regularizer）。带约束优化$E_{in}$，可通过无约束优化$E_{aug}(\mathbf w)$高效求解，每个$C$都有对应的$\lambda$，大的$\lambda$对应着小的$C$，也对应着短的$\mathbf w$。当$\lambda=1$或$C=\infty$或$C\geq\lVert\mathbf w_{LIN}\rVert^2$（相当于红色的圆已经把$\mathbf w_{LIN}$包含在内）时，相当于没有进行正则化。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-regularize-regression.png"><img src="/assets/images/2015-01-26-regularization-regularize-regression.png" alt="不同系数下正则化的效果" /></a><div class="caption">图 2:  不同系数下正则化的效果 [<a href="/assets/images/2015-01-26-regularization-regularize-regression.png">PNG</a>]</div></div></div>

<p>$\lambda$相当于对过拟合的惩罚因子，上图展示了不同$\lambda$惩罚下的效果。</p>

<p>${\lambda\over N}\mathbf w^T\mathbf w$称为权重衰减（weight-decay）正则化，可推广到“任意变换 ＋ 线性模型”。</p>

<h2 id="section-2">勒让德多项式</h2>

<p>当$x_n\in[-1,1]$和$Q$很大时，$x_n^q$会变得非常小，除精确度因素影响外，还需要很大的$w_q$才能体现$x_n^q$的影响，这就与正则化的目的有些“矛盾”，过度惩罚了高次项。对于$\mathcal Z$空间的特征
\[
\Phi(\mathbf x)=\left(1,x,x^2,\ldots,x^Q\right)，
\]
特征之间彼此非正交，对低次项容忍度较大，对高次项惩罚力度更大。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png"><img src="/assets/images/2015-01-26-regularization-legendre-polynomials.png" alt="勒让德多项式" /></a><div class="caption">图 3:  勒让德多项式 [<a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png">PNG</a>]</div></div></div>

<p>为改善这一问题，可以考虑在多项式空间找到一组正交的基函数（orthonormal basis function），也称为勒让德多项式（legendre polynomials），构造如上图所示的新多项式变换
\[
\Phi(\mathbf x)=\left(1,L_1(x),L_2(x),\ldots,L_Q(x)\right)。
\]</p>

<h2 id="vc">VC维分析</h2>

<p>带约束$E_{in}$优化\eqref{eq:constrained-Ein-matrix}的VC上界
\begin{equation}
E_{out}(\mathbf w)\leq E_{in}(\mathbf w)+\Omega(\mathcal H(C))，
\label{eq:vc-bound}
\end{equation}
采用与$C$等价的$\lambda$时，可以用优化\eqref{eq:Eaug-minimization}实现，在没有限定$\mathcal H(C)$的情况下，通过优化$E_{aug}$间接获得了VC维的保证。对比\eqref{eq:E-aug}和\eqref{eq:vc-bound}，$\mathbf w^T\mathbf w=\Omega(\mathbf w)$衡量了单一假设的复杂度，$\Omega(\mathcal H(C))$衡量了整个假设集的复杂度。如果${\lambda\over N}\Omega(\mathbf w)$能很好的表示$\Omega(\mathcal H(C))$，衡量$E_{out}$时，$E_{aug}$是比$E_{in}$更好中介。</p>

<p>对$\mathcal Z$空间的非正则化方法，$d_{VC}(\mathcal H)=\tilde d+1$。事实上，采用正则化考虑的假设集$\mathcal H(C)$要小于$\mathcal H$。采用了正则化后，有效（effective）VC维$d_{EFF}(\mathcal H,\mathcal A)\leq d_{VC}(\mathcal H)$，其中$\mathcal A$为正则化算法。因此，正则化方法具有更好的泛化性能。增大$\lambda$使$C$变小，从而使$\mathcal H(C)$变小，使得$d_{EFF}(\mathcal H,\mathcal A)$减小。</p>

<h2 id="section-3">正则化的推广</h2>

<p>除权重衰减（weight-decay）正则化外，还有很多其它的正则化方法。正则化的约束条件应当向着目标函数方向，选择正则化方法的思路包括：</p>

<ul>
  <li>目标相关（target-dependent）：利用目标的特性，比如已知目标函数的对称性，可采用对称正则化$\sum[[q\mbox{ is odd}]]w_q^2$；</li>
  <li>合理性（plausible）：使结果更加光滑和简单，比如要对随机或确定性噪声鲁棒，可采用稀疏的$L_1$正则化$\sum |w_q|$；</li>
  <li>友好（friendly）：易于优化，比如采用除权重衰减的$L_2$正则化$\sum w_q^2$。</li>
</ul>

<p>如果正则化选择不合适，还有$\lambda=0$这道防线，可以避免危害。以上正则化选择思路和<a href="/2014/12/machine-learning-noise-and-error/#error-measurement">误差度量</a>一致：用户相关（user-dependent）、合理性、友好。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png"><img src="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png" alt="［左］：L2正则化；［右］L1正则化" /></a><div class="caption">图 4:  ［左］：L2正则化；［右］L1正则化 [<a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png">PNG</a>]</div></div></div>

<p>$L_1$正则化在需要稀疏解时很有用。上图右是$L_1$正则化示意图，$L_1$正则化
\begin{equation}
\Omega(\mathbf w)=\sum_{q=0}^Q|w_q|=\lVert\mathbf w\rVert_1，
\end{equation}
虽然不可微分，但它是凸的，解是稀疏的（$\mathbf w$有很多0元素）。$-\nabla E_{in}$可分解到垂直于边界面的方向（边界面的法向量方向，如上图右红色箭头所示）和沿边界面的方向。当到达边界面后，如果继续沿着法向量方向下降，会破坏约束条件，沿着面的方向如果还能下降，则继续沿着面的方向下降，直到停在菱形球的顶点，或者直到$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$（沿边界面的方向分量为0）。边界面的法向量只和$\mathbf w$的符号有关，如果要$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$比较困难，通常会停在菱形球的顶点，该点在坐标轴上，必有元素为0。</p>

<h2 id="lambda">最优$\lambda$</h2>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png"><img src="/assets/images/2015-01-26-regularization-noise-and-lambda.png" alt="噪声对性能的影响" /></a><div class="caption">图 5:  噪声对性能的影响 [<a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png">PNG</a>]</div></div></div>

<p>上图表明，噪声等级越高，正则化的惩罚力度$\lambda$越大。实际上，噪声的等级不可预知，只有通过实验的方法选择最佳$\lambda$，也就是通过<a href="">验证</a>（validation）选择最佳$\lambda$。</p>

<h2 id="section-4">正则化实例</h2>

<p>本节内容源于机器学习<a href="#ng_ml_r_2014">[3]</a>网络课程，这里没有对增加的偏移项$x_0=1$的系数正则化，且$y\in\{0,1\}$。</p>

<h3 id="section-5">正则化线性回归</h3>

<h4 id="section-6">一、代价函数</h4>

<p>\begin{equation}
J(\boldsymbol\theta) = \frac{1}{2m}\left( \sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)^2 + \lambda\sum_{j=1}^n\theta_j^2 \right)
\label{eq:cf-linear-regression-r}
\end{equation}</p>

<h4 id="section-7">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<p>迭代过程可以化为如下形式：
\begin{equation*}
\theta_j := \theta_j\left(1 - \alpha\frac{\lambda}{m} \right) - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)};~~(j = 1, 2, \ldots, n)
\end{equation*}</p>

<p>通常$1 - \alpha\frac{\lambda}{m} &lt; 1$，与非正则化的梯度下降法比较，$\theta_j$减小更快。</p>

<h3 id="logistic">正则化Logistic回归</h3>

<h4 id="section-8">一、代价函数</h4>

<p>\begin{equation}
\begin{aligned}
J(\boldsymbol\theta)  = &amp;-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)\right)\right) \\
&amp; + \frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
\end{aligned}
\label{eq:cf-logistic-regression-r}
\end{equation}</p>

<h4 id="section-9">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<h3 id="matlab">Matlab实现</h3>

<p>第一步：实现Logistic函数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>g <span class="p">=</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span>z<span class="p">)</span><span class="w"></span>
<span class="n">g</span> <span class="p">=</span> <span class="mf">1.0</span> <span class="o">./</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="nb">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">));</span>
<span class="k">end</span></code></pre></div>

<p>第二步：实现代价函数（包含梯度计算）</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>[J, grad] <span class="p">=</span><span class="w"> </span><span class="nf">costFunctionReg</span><span class="p">(</span>theta, X, y, lambda<span class="p">)</span><span class="w"></span>
<span class="n">m</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">y</span><span class="p">);</span> <span class="c">% number of training examples</span>

<span class="n">h</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="n">J</span> <span class="p">=</span> <span class="o">-</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">+</span> <span class="c">...</span>
    <span class="n">lambda</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">sum</span><span class="p">(</span><span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">grad</span> <span class="p">=</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)])</span> <span class="o">/</span> <span class="n">m</span><span class="p">;</span>

<span class="k">end</span></code></pre></div>

<p>第三步：估计参数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="n">initial_theta</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">lambda</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">options</span> <span class="p">=</span> <span class="n">optimset</span><span class="p">(</span><span class="s">&#39;GradObj&#39;</span><span class="p">,</span> <span class="s">&#39;on&#39;</span><span class="p">,</span> <span class="s">&#39;MaxIter&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">);</span>
<span class="p">[</span><span class="n">theta</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">exit_flag</span><span class="p">]</span> <span class="p">=</span> <span class="c">...</span>
	<span class="n">fminunc</span><span class="p">(@(</span><span class="n">t</span><span class="p">)(</span><span class="n">costFunctionReg</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda</span><span class="p">)),</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">options</span><span class="p">);</span></code></pre></div>

<h2 id="section-10">参考资料</h2>

<ol class="bibliography"><li><span id="lihang_sml_2012">[1]李航, <i>统计学习方法</i>. 北京: 清华大学出版社, 2012.</span>

</li>
<li><span id="lin_ml_regularization_2014">[2]H.-T. Lin, “Lecture 14: Regularization.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li>
<li><span id="ng_ml_r_2014">[3]A. Ng, “Regularization: The problem of overfitting.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-11">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-regularize-all">
      <p>为什么正则化包括$x_0=1$的偏移项系数，两者有何区别？ <a href="#fnref:why-regularize-all" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>过拟合的危害</title>
      <link href="http://qianjiye.de/2015/01/hazard-of-overfitting" />
      <pubdate>2015-01-26T13:47:38+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/hazard-of-overfitting</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">初识过拟合</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png" alt="［左］：好的拟合；［右］：过拟合" /></a><div class="caption">图 1:  ［左］：好的拟合；［右］：过拟合 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png">PNG</a>]</div></div></div>

<ul>
  <li>差的泛化（bad generalization）：低的$E_{in}$高的$E_{out}$，$E_{out}-E_{in}$很大；</li>
  <li>过拟合（overfitting）：$E_{in}$降低时$E_{out}$升高；</li>
  <li>欠拟合（underfitting）：$E_{in}$升高时$E_{out}$也在升高。</li>
</ul>

<p>上图右采用了4次多项式变换$\Phi$和$\mathcal Z$空间的线性拟合，$N=5$个点时存在唯一解<sup id="fnref:is-unique"><a href="#fn:is-unique" class="footnote">1</a></sup>，$E_{in}=0$，过拟合了。</p>

<p>泛化能力描述的是既成的状态，过拟合描述的是变化过程。解决欠拟合可采用<a href="/2015/01/nonlinear-transformation">非线性特征变换</a>，解决过拟合更复杂。过拟合主要受噪声和数据量的影响。</p>

<h2 id="section-1">过拟合的特性</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png" alt="［左］：10次多项式的含噪数据；［右］：50次多项式的无噪数据" /></a><div class="caption">图 2:  ［左］：10次多项式的含噪数据；［右］：50次多项式的无噪数据 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png">PNG</a>]</div></div></div>

<p>上图展示了分别用2次和10次多项式拟合1含噪和无噪数据的效果。结果有些意外，2次多项式的性能都要优于10次多项式。</p>

<p>下图的学习曲线表明，当数据量$N$较小时，10次多项式的$E_{in}$和$E_{out}$之间差距较大，泛化误差更大，这和VC界一致，因为10次多项式的$d_{VC}$较大。因此，当数据量较少时，用简单的模型更合适得到较好的结果。</p>

<p>对于上图右不带噪声的数据，10次多项式的表现仍然很差。这是由于目标函数过于复杂，生成的数据很像噪声。可以这样理解，50次多项式生成的无噪数据和10次多项式生成的数据加入噪声相似。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png" alt="2次和10次多项式的学习曲线" /></a><div class="caption">图 3:  2次和10次多项式的学习曲线 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png">PNG</a>]</div></div></div>

<p>假设数据产生的方式为
\[
y=f(x)+\epsilon\sim\mbox{Gaussian}\left(\sum_{q=0}^{Q_f}\alpha_qx^q,\sigma^2\right)，
\]</p>

<p>$\sigma^2$表示产生噪声的等级，$Q_f$是模型的复杂度，数据集的大小为$N$。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png" alt="不同参数影响下的过拟合图谱（越红过拟合越厉害）" /></a><div class="caption">图 4:  不同参数影响下的过拟合图谱（越红过拟合越厉害） [<a href="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png">PNG</a>]</div></div></div>

<p>实验时确保能产生包含模型最高次的数据，过拟合采用$E_{out}(g_{10})-E_{out}(g_{2})$度量。上图分别展示了固定模型复杂度和噪声等级下的过拟合图谱，红色表示过拟合强，蓝色表示过拟合弱。上图左固定住模型复杂度，通过$\sigma^2$产生的噪声称为随机噪声（stochastic noise）；上图右固定住噪声等级，通过模型复杂度$Q_f$导致的“噪声”称为确定性噪声（deterministic noise）。</p>

<p>事实上，过拟合很容易发生：</p>

<ul>
  <li>当数据量$N$少的时候，</li>
  <li>当随机噪声大的时候，</li>
  <li>当确定性噪声大的时候，</li>
  <li>当模型复杂$d_{VC}$大的时候，</li>
</ul>

<p>这几种情况都容易发生过拟合。</p>

<p>确定性噪声大表示目标函数太复杂，机器难以学会。复杂模型产生的数据就像就像含有随机噪声一样，它就像伪随机数发生器（pseudo-random generator）。确定性噪声与随机噪声不同的地方包括：（1）当$\mathcal H$变复杂时，确定性噪声会减小；（2）固定$\mathbf x$后，确定性噪声也是固定的。</p>

<h2 id="section-2">克服过拟合</h2>

<p>克服过拟合的方法：</p>

<ul>
  <li>从简单的模型开始尝试；</li>
  <li>数据清洗或剪枝；</li>
  <li>根据已有数据生成更多数据（data hinting）；</li>
  <li><a href="/2015/01/regularization">正则化</a>；</li>
  <li><a href="/2015/01/validation">验证</a>（validation）。</li>
</ul>

<h4 id="data-cleaning">一、数据清洗或剪枝</h4>

<p>可以利用<a href="/2014/12/machine-learning-anomaly-detection">异常检测</a>的方法，探测出离群点，然后改变类别标签（数据清洗）或者移除异常点（数据剪枝），通常探测离群点的方法包括：</p>

<ul>
  <li>离本类很远，离其它类却很近；</li>
  <li>被当前分类器错误分类；</li>
  <li>……</li>
</ul>

<p>数据清洗或剪枝对性能的影响难以把握，有时对提升效果可能非常微弱。</p>

<h4 id="data-hinting">二、数据生成（data hinting）</h4>

<p>根据已有数据或已知规则产生新的数据。比如字符识别的时候，通过旋转等方式生成新的字符样本。</p>

<p>但是需要注意，新加入的样本不再是来自原来的概率分布，不再是i.i.d.（independent identically distributed）。</p>

<h2 id="section-3">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-unique">
      <p>4次多项式变换在$N=5$个点时存在唯一解？不对吧！ <a href="#fnref:is-unique" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>非线性特征变换</title>
      <link href="http://qianjiye.de/2015/01/nonlinear-transformation" />
      <pubdate>2015-01-25T19:03:12+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/nonlinear-transformation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">非线性变换</h2>

<p>线性假设集（分类器）的类别之间的判别界是线性的，低VC维可使$E_{in}$和$E_{out}$接近，但无法分类线性不可分数据。线性分类器应用于线性不可分数据，会导致很大的$E_{in}$，$E_{out}$也会很大。如何突破线性分类器的局限，对线性不可分数据分类？</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png"><img src="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png" alt="［左］：线性不可分；［中］：圆可分；［右］Z空间线性可分" /></a><div class="caption">图 1:  ［左］：线性不可分；［中］：圆可分；［右］Z空间线性可分 [<a href="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png">PNG</a>]</div></div></div>

<p>上图左的数据$\mathcal D$虽然线性不可分，但是可以用上图中所示的圆分开
\[
h_{SEP}(\mathbf x)=\mbox{sign}\left(0.6-x_1^2-x_2^2\right)，
\]
令$\tilde{\mathbf w}^T=[0.6,-1,-1],\mathbf z=\left[1,x_1^2,x_2^2\right]^T$，上式可以记为
\[
h(\mathbf x)=\mbox{sign}\left(\tilde{\mathbf w}^T\mathbf z\right)，
\]
这就相当于通过<strong>非线性特征变换</strong>$\Phi: \mathbf x\in\mathcal X\mapsto\mathbf z\in\mathcal Z$，将$\mathcal X$空间中线性不可分数据变到线性可分的$\mathcal Z$空间，如上图右所示。</p>

<p>通过变换$\Phi_2(\mathbf x)=\left(1,x_1,x_2,x_1^2,x_1x_2,x_2^2\right)$，可以使得$\mathcal Z$空间的感知器和$\mathcal X$空间的二次假设等价，
\[
\mathcal H_{\Phi_2}=\left\{h(\mathbf x):h(\mathbf x)=\tilde h(\Phi_2(\mathbf x))\mbox{ for some linear }\tilde h\mbox{ on }\mathcal Z\right\}
\]
可以实现$\mathcal X$空间的所有二次曲线判别界，当然也包括线性的特殊情况，使得$E_{in}$有机会更小。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation.png"><img src="/assets/images/2015-01-25-nonlinear-transformation.png" alt="非线性变换步骤" /></a><div class="caption">图 2:  非线性变换步骤 [<a href="/assets/images/2015-01-25-nonlinear-transformation.png">PNG</a>]</div></div></div>

<p>上图展示了使用非线性变换的步骤。首先通过变换$\Phi$将数据从$\mathcal X$空间映射到$\mathcal Z$空间；然后在$\mathcal Z$空间利用线性分类算法$\mathcal A$得到线性判别界；最后返回
\begin{equation}
g(\mathbf x)=\mbox{sign}\left(\tilde{\mathbf w}^T\Phi(\mathbf x)\right)，
\end{equation}
逆变换$\Phi^{-1}$不一定存在。</p>

<p>非线性变换$\Phi$和$\mathcal Z$空间的线性模型算法$\mathcal A$，不仅可以用于分类，而且可用于回归。</p>

<h2 id="section-1">复杂度与性能分析</h2>

<p>若原始特征是$d$维，$Q$次多项式特征变换$\Phi_{Q}(\mathbf x)$后的特征空间维度$\tilde d+1$为$\binom{Q+d}{Q}$，空间复杂度为$O\left(Q^d\right)$。当$Q$很大时，新空间中的计算和存储代价都极大。新空间中$d_{VC}\left(\mathcal H_{\Phi_Q}\right)\leq \tilde d+1$，当$Q$很大时$d_{VC}$也会很大。当$d_{VC}$增加时，用于训练的数据量也要增加，需要考虑训练集的数据量是否足够。</p>

<div class="image_line" id="human-learning"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png"><img src="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png" alt="选择不同特征变换" /></a><div class="caption">图 3:  选择不同特征变换 [<a href="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png">PNG</a>]</div></div></div>

<p>上图展示了人工基于视觉的选择，不同特征变换下，$d_{VC}$从6降到了1。事实上，此时的模型复杂度需要考虑人工付出的$d_{VC}$代价，这是“human learning ＋ machine learning”。对于机器学习，人工偷看了数据付出的代价也必须加以考量。</p>

<p>对于特征变换，$Q$次变换可以在$Q-1$次的基础上进行
\[
\Phi_{Q}(\mathbf x)=\left(\Phi_{Q-1}(\mathbf x),x_1^Q,x_1^{Q-1}x_2,\ldots,x_d^Q\right)，
\]
也就是存在嵌套关系
\[
\mathcal H_{\Phi_0}\subset\mathcal H_{\Phi_1}\subset\mathcal H_{\Phi_2}\subset\ldots\subset\mathcal H_{\Phi_Q}，
\]
那么$d_{VC}$按上述次序递增（$\leq$），$E_{in}$按上述次序递减（$\geq$）。高次变换能得到$E_{in}$非常小的结果，然而$E_{in}$仅仅是中间产物，并<a href="/2014/12/machine-learning-the-vc-dimension/#vc-and-errors">不能说明$E_{out}$会很小</a>。合理的方法是从$H_{\Phi_1}$开始尝试，线性模型是首选，如果效果不达标再考虑高次的特征变换。</p>

<h2 id="section-2">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>线性分类模型</title>
      <link href="http://qianjiye.de/2015/01/linear-models-for-classification" />
      <pubdate>2015-01-25T12:23:40+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/linear-models-for-classification</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">回归用于分类</h2>

<p>线性分类器、线性回归和logistic回归，都采用了同样的线性评分函数
\[
s=\mathbf w^T\mathbf x
\]
它们之间的对比如下：
<img src="/assets/images/2015-01-25-linear-models-for-classification-linear-models.png" alt="线性模型" /></p>

<p>最小化线性分类器的$E_{in}(\mathbf w)$更困难，它是NP-Hard，能否用回归方法解决分类问题？✅</p>

<p>线性分类器、线性回归和logistic回归，它们的误差函数分别可记为
\[
\mbox{err}_{0/1}(s,y)=[[\mbox{sign}(ys)\neq 1]];\quad
\mbox{err}_{SQR}(s,y)=(ys-1)^2;\quad
\mbox{err}_{CE}(s,y)=\ln(1+\exp(-ys))。
\]</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png"><img src="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png" alt="误差曲线对比" /></a><div class="caption">图 1:  误差曲线对比 [<a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png">PNG</a>]</div></div></div>

<p>上图展示了误差曲线的对比，为了比较方便，用$\mbox{err}_{SCE}(s,y)=\log_2(1+\exp(-ys))$代替$\mbox{err}_{CE}$。从图中容易看出
\[
\mbox{err}_{0/1}(s,y)\leq\mbox{err}_{SCE}(s,y)={1\over\ln 2}\mbox{err}_{CE}(s,y)，
\]
因此可得
\[
E_{in}^{0/1}(\mathbf w)\leq E_{in}^{SCE}(\mathbf w)={1\over\ln 2}E_{in}^{CE}(\mathbf w)\quad\mbox{and}\quad
E_{out}^{0/1}(\mathbf w)\leq E_{out}^{SCE}(\mathbf w)={1\over\ln 2}E_{out}^{CE}(\mathbf w)，
\]
从而可得
\[
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+\Omega^{0/1}\quad\mbox{or}\quad
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+{1\over\ln 2}\Omega^{CE}，
\]
$E_{out}^{0/1}$和$E_{in}^{SQR}$之间也存在同样的关系。从以上关系可以看出，做到$E_{in}^{CE}(\mathbf w)$很小时也可使$E_{out}^{0/1}(\mathbf w)$很小，那么用线性或logistic回归也可解决线性分类问题，
\[
g(\mathbf x)=\mbox{sign}(\mathbf w_{REG}^T\mathbf x)。
\]</p>

<p>PLA在数据线性可分时效率较高否则需要采用pocket算法，线性或logistic回归“容易”优化但采用了比$err_{0/1}$松散的误差上限。</p>

<p>可用线性回归设置PLA、pocket或logistic回归的初始值$\mathbf w_0$，logistic回归的计算复杂度和pocket相当，通常logistic回归的性能优于pocket。</p>

<h2 id="section-1">随机梯度下降法</h2>

<p>迭代优化时，参数更新可以表示为
\begin{equation*}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\mathbf v\quad(t=0,1,\ldots)。
\end{equation*}
PLA每次采用一个数据更新参数，但logistic的梯度下降法每次采用全部数据更新参数，显然logistic更新过程计算量大很多。logistic回归和pocket效率差不多，能否使logistic回归和PLA一样快呢？✅</p>

<p>logistic回归采用的参数更新方法是
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta{1\over N}\sum_{n=1}^N\theta\left(-y_n\mathbf w^T\mathbf x_n)(y_n\mathbf x_n\right)，
\end{equation}
按梯度负方向$\mathbf v=-\nabla E_{in}(\mathbf w)$更新。通过$n$个点计算可估计梯度，极端情况用1个点计算估计梯度，称为随机梯度。随机梯度可视为真实梯度与零均值噪声之和，经过足够过的迭代次数，平均的真实梯度和平均的随机梯度基本相同，可利用随机梯度更新参数，
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)(y_n\mathbf x_n)，
\end{equation}
这就是<strong>随机梯度下降法</strong>（SGD，stochastic gradient descent）。</p>

<p>随机梯度法的优点是简单且计算量小，有利于大数据和在线学习；其缺点是稳定性欠佳，尤其是$\eta$很大时。随机梯度法实现时需要处理两个问题：</p>

<ol>
  <li>停止条件：梯度下降法可通过梯度是否接近零作为停止条件，但是随机梯度法没有梯度计算，难以确定停止条件，通常用足够大的迭代次数$t$作为停止条件；</li>
  <li>选择合适的$\eta$：通常利用交叉验证选择，经验表明$\eta=0.1$在大多数情况下是不错的选择。</li>
</ol>

<p>回顾PLA的参数更新过程
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+1\cdot\left[\left[-y_n\neq\mbox{sign}(\mathbf w_t^T\mathbf x_n)\right]\right](y_n\mathbf x_n)，
\end{equation}
随机梯度下降法的logistic回归想当于soft-PLA，用$\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)$表示更新的力度；当$\eta=1$并且$\mathbf w_t^T\mathbf x$很大时，PLA和随机梯度下降法的logistic回归相似。利用随机梯度下降法的线性回归可以表示为
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+2\eta\left(y_n-\mathbf w_t^T\mathbf x_n\right)\mathbf x_n，
\end{equation}
$y_n-\mathbf w_t^T\mathbf x_n$表示错得越多，更新力度越大。</p>

<h2 id="multiple-classes">多分类问题</h2>

<p>采用one-vs-all的数据分割策略，利用logistic回归进行软性（softly）分类，选择“概率”大的类别
\begin{equation}
g(\mathbf x)=\arg\max_{k\in\mathcal Y}\theta\left(\mathbf w_{[k]}^T\mathbf x\right)=\arg\max_{k\in\mathcal Y}\mathbf w_{[k]}^T\mathbf x。
\end{equation}
one-vs-all方式的优点是简单易推广，并且很容易并行化训练每个分类器；它的坏处是当类别数$K$很大时，数据集$\mathcal D_{[k]}$的不平衡（unbalance）问题凸显。不平衡数据导致logistic回归通过误差最小化求解参数时，倾向于选择有利于数据量多的类别的假设。事实上，有专门的多分类logistic模型，例如<a href="/2015/01/image-classification-svm-and-softmax-based-linear-classifier/#softmax-classifier">softmax分类器</a>。</p>

<p>one-vs-one的方法有利于克服one-vs-all的数据不平衡问题，采用投票机制判断类别，类似循环赛，
\begin{equation}
g(\mathbf x)=\mbox{tournament champion}\left\{\mathbf w_{[k,l]}^T\mathbf x\right\}。
\end{equation}
one-vs-one方式训练每个分类器数据量较少，因此比较有效率，它克服了数据不平衡，以及利用了循环赛机制，所以更稳定；它的坏处是分类器数目更多，导致空间存储增大，预测时间增加，需要更多的训练<sup id="fnref:need-more-training"><a href="#fn:need-more-training" class="footnote">1</a></sup>，并且存在<a href="/2014/10/multiple-classes/#anbiguous-regions">有争议的判别区间</a>。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:need-more-training">
      <p>每个分类器数据少了，训练时间复杂度会增加吗？ <a href="#fnref:need-more-training" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（4）：随机森林</title>
      <link href="http://qianjiye.de/2015/01/random-forest" />
      <pubdate>2015-01-24T17:33:22+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/random-forest</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">随机森林</h2>

<p>bagging通过投票或平均的方法，可以减少variance；决策树功能强大， 但是有很大的variance。能否将二者融合起来，优势互补？</p>

<p>［1/3］random forest（RF） = bagging + fully-grown C&amp;RT tree</p>

<p>random描述了bagging中bootstrapping过程的随机性；forest表示很多树的组合。</p>

<blockquote>
  <h4 id="section-1">随机森林算法</h4>
  <hr />
  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>通过bootstrapping方法从$\mathcal D$中抽取大小为$N’$的数据集$\tilde{\mathcal D}_t$；</li>
    <li>通过决策树算法$\mbox{DTree}(\tilde{\mathcal D}_t)$得到$g_t$。</li>
  </ol>

  <p>返回$G=\mbox{Uniform}(\{g_t\})$就是随机森林。</p>
</blockquote>

<p>不同的$g_t$是进行分类器融合的关键。bagging通过bootstrapping的方法制造数据的随机性，从而得到不同的$g_t$。</p>

<p>另一种得到不同$g_t$的方法是从$\mathbf x$中随机抽取$d’$维特征：</p>

<ul>
  <li>随机抽取索引为$i_1,i_2,\ldots,i_{d’}$的特征，特种空间从高维到低维投影，$\Phi(\mathbf x)=\left(x_{i_1},x_{i_1},\ldots,x_{i_{d’}}\right)$；</li>
  <li>$\mathcal Z\in\mathbb R^{d’}$是$\mathcal X\in\mathbb R^d$的<strong>随机子空间</strong>（random subspace）；</li>
  <li>通常$d’\ll d$，对大的$d$这样更高效<sup id="fnref:small-subspace"><a href="#fn:small-subspace" class="footnote">1</a></sup>；</li>
</ul>

<p>RF的原作者建议每次在C&amp;RT找$b(\mathbf x)$时，都重采样得到新的$d’$维特征子空间，让得到的树更不一样：</p>

<p>［2/3］RF ＝ bagging ＋ random-subspace C&amp;RT。</p>

<p>随机从$\mathbf x$中采样$d’$维特征可记为$\Phi(\mathbf x)=\mathbf P\mathbf x$，利用$\mathbf P$的第$i$随机抽取1维特征，这样的行属于自然基（natural basis）。</p>

<p>采用<strong>随机组合方式</strong>，利用随机的行$\mathbf p_i$对特征进行投影（组合），$\phi_i(\mathbf x)=\mathbf p_i^T\mathbf x$，可以得到更强大的特征空间。通常采用的是低维投影，$\mathbf p_i$中只有$d’’$个非零元素。随机子空间是$d’’=1$的特殊情况，且$\mathbf p_i$属于自然基。</p>

<p>RF的原作者建议每次在C&amp;RT找$b(\mathbf x)$时，都进行$d’$的随机低维投影（组合）：</p>

<p>［3/3］RF ＝ bagging ＋ random-combination C&amp;RT</p>

<p>采用随机组合方式的C&amp;RT树，每个分支函数$b(\mathbf x)$相当于感知器（线性分类器）。</p>

<h2 id="oob">OOB方法</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png"><img src="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png" alt="out-of-sample数据点" /></a><div class="caption">图 1:  out-of-sample数据点 [<a href="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png">PNG</a>]</div></div></div>

<p>采用bagging的时候，没被选中数据点称为out-of-bag（OOB）数据点，如上图左所示，星号标注的点表示没有对训练任何$g_t$有贡献。当$N’=N$时，对每次训练$g_t$的数据集$(\mathbf x_n,y_n)$是OOB的概率是$\left(1-{1\over N}\right)^N$，如果$N$很大时，这个概率是${1\over e}$。$g_t$对应数据集OOB数据大小约为${N\over e}$，这表明数据集中有不少点（大约1/3）没有参与训练。</p>

<p>OOB数据可以看作用于验证的数据，如上图右所示。但是通常不需要验证$g_t$，因为即使$g_t$效果不理想，融合后的分类器$G$仍然可以达到很好的效果。$G_n^-$表示$\{\mathbf x_n,y_n\}$是OOB数据点的分类器的集合，上图左最下一行$G_n^-=\mbox{average}(g_2,g_3,g_T)$，利用OOB数据集校验的误差定义为
\begin{equation}
E_{oob}(G)={1\over N}\sum_{n=1}^Nerr\left(y_n,G_n^-(\mathbf x_n)\right)，
\end{equation}
利用$E_{oob}$，bagging和RF可以实现自验证（self-validation）。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-oob-validation.png"><img src="/assets/images/2015-01-24-random-forest-oob-validation.png" alt="［左］：验证集方法［右］：OOB集方法" /></a><div class="caption">图 2:  ［左］：验证集方法［右］：OOB集方法 [<a href="/assets/images/2015-01-24-random-forest-oob-validation.png">PNG</a>]</div></div></div>

<p>上图是传统验证方法和$E_{oob}$的对比，$E_{oob}$通常能很准确的衡量$G$的性能。利用$E_{oob}$进行$d’’$等参数选择，通常不需要重新训练<sup id="fnref:why-not-re-training"><a href="#fn:why-not-re-training" class="footnote">2</a></sup>。</p>

<h2 id="section-2">特征选择</h2>

<p>特征选择就是移除冗余（redundant）和不相关（irrelevant）的特征。主要优点包括：</p>

<ul>
  <li>高效：让假设集和简单，预测时间变短；</li>
  <li>提升泛化能力：移除特征的同时也移除了那些特征的噪声；</li>
  <li>增强可理解性：剩余的特征对结果的解释性更强；</li>
</ul>

<p>但也存在对应的缺点：</p>

<ul>
  <li>计算量大：从特征空间选择重要的特征子集本身是组合优化问题；</li>
  <li>过拟合：恰好选到那些结果看似很好的特征组合；</li>
  <li>误解释：特别是存在过拟合时，可能得到结果的错误解释，或者只能得出关联性而非因果关系。</li>
</ul>

<p>决策树本身具备特征选择的能力，每次在某个特征上进行分割，用到的那些特征就是被选择的特征，这和decision stump类似。</p>

<p>特征选择的简单理想情况是不考虑特征组合的影响，计算每个特征的重要性，从$d$维特征中选择最重要的$d’$维特征。通过线性模型容易实现
\[
score = \mathbf w^T\mathbf x=\sum_{i=1}^dw_ix_i，
\]
对良好的$\mathbf w$（对特征给出合理评分），第$i$维特征的重要性$\mbox{importance}(i)=|w_i|$，大的数值对得分贡献大。$\mathbf w$可通过数据进行学习得到。</p>

<p>对于非线性模型，特征选择通常比较复杂。虽然RF是非线模型，但是由于内在的机制，采用<strong>随机测试</strong>（random test）也能方便选择特征。如果特征$i$很重要，用随机值$\mathbf x_{n,i}$代替该特征就会极大降低性能。产生这些随机值的方法包括：</p>

<ul>
  <li>通过均分分布或高斯分布产生：真实数据的分布$P(x_i)$可能并不服从这些分布，不仅加入了噪声，而且改变了分布，不是理想的方法。</li>
  <li>bootstrap或者组合（permutation）方法：这样就保持了原来的分布$P(x_i)$，组合方法重新排列原始特征（类似洗牌）。</li>
</ul>

<p>利用组合方法重排特征进行性能测试称为<strong>组合测试</strong>（permutation test），
\[
\mbox{importance}(i)=\mbox{importance}(\mathcal D)-\mbox{importance}(\mathcal D^{(p)})，
\]
$\mathcal D^{(p)}$表示$\mathcal D$的特征$\{x_{n,i}\}$经过重新“洗牌”。组合测试是一种统计工具，可以用于类似RF的其它非线性模型。</p>

<p>通常需要重新训来呢得到$\mbox{importance}(\mathcal D^{(p)})$，但是可RF利用OOB不需重新训练，
\[
\mbox{importance}(i)=E_{oob}(G)-E_{oob}^{(p)}(G)，
\]
得到$E_{oob}^{(p)}(G)$的方法是，在计算过程中需要$x_{n,i}$的地方，用组合的OOB值代替$x_{n,i}$。</p>

<p>在实际中，RF通过“permutation + OOB”进行特征选择，通常不仅高效而且有效。</p>

<h2 id="rf">RF特性</h2>

<p>通常随机森林需要的树越多越好🌲🌲🌲🌲，$\bar g=\lim_{T\rightarrow\infty} G$。通过增减树判断随机森林是否稳定，确保有足够多的树，如果不够，继续增加🌲。</p>

<p>台湾大学在KDDCup 2013中发现，随机森林的$E_{val}$表现依赖初始的种子点，最终通过将树增加到12000课，估定种子为1，夺得了冠军🏆。</p>

<h4 id="section-3">以下图片展示了随机森林的优点：</h4>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-large-margin.png"><img src="/assets/images/2015-01-24-random-forest-large-margin.png" alt="通过多棵树得到平滑和类似最大边界的判别界" /></a><div class="caption">图 3:  通过多棵树得到平滑和类似最大边界的判别界 [<a href="/assets/images/2015-01-24-random-forest-large-margin.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg"><img src="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg" alt="容易得到鲁棒的非线性模型" /></a><div class="caption">图 4:  容易得到鲁棒的非线性模型 [<a href="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg">JPG</a>]</div></div></div>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-noise-corrected.jpg"><img src="/assets/images/2015-01-24-random-forest-noise-corrected.jpg" alt="通过投票机制消除噪声的干扰" /></a><div class="caption">图 5:  通过投票机制消除噪声的干扰 [<a href="/assets/images/2015-01-24-random-forest-noise-corrected.jpg">JPG</a>]</div></div></div>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:small-subspace">
      <p>这种方法也可以用于其它机器学习模型。 <a href="#fnref:small-subspace" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-not-re-training">
      <p>为什么不需要重新训练？ <a href="#fnref:why-not-re-training" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（3）：决策树</title>
      <link href="http://qianjiye.de/2015/01/decision-tree" />
      <pubdate>2015-01-23T22:49:52+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/decision-tree</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">决策树简介</h2>

<h4 id="section-1">常见的各种不同分类器融合策略：</h4>

<table>
  <thead>
    <tr>
      <th>融合类型</th>
      <th>混合（blending）</th>
      <th>学习（learning）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>均匀融合</td>
      <td>voting／averaging</td>
      <td>Bagging</td>
    </tr>
    <tr>
      <td>非均匀融合</td>
      <td>linear</td>
      <td>AdaBoost</td>
    </tr>
    <tr>
      <td>有条件融合</td>
      <td>stacking</td>
      <td>decision tree</td>
    </tr>
  </tbody>
</table>

<p>混合方法是选择$g_t$之后再融合，学习方法是在选择（学习）$g_t$的同时进行融合。</p>

<p>决策树是一种对实例分类的树形结构，由节点（node）和有向边（directed edge）组成，内部节点（internal node）表示特征或属性，叶节点（leaf node）表示类<a href="#lihang_sml_2012">[1, P. 55]</a>。决策树既可以看成if-then规则的集合，也可表示给定特征条件下类别的概率密度分布<a href="#lihang_sml_2012">[1, P. 56]</a>。从分类器融合的角度，决策树是一种<a href="/2015/01/blending-and-bagging/#mjx-eqn-eqconditional-blending-hypothesis">有条件分类器融合</a>的学习模型<a href="#lin_ml_dt_2015">[2]</a>。常用的决策树学习算法有ID3、C4.5和C&amp;RT（也记为CART）。</p>

<p>决策树在实际中很有用，它可解释性强（广泛应用于商业和医学数据分析），简单容易实现，能高效的学习和预测，但是它是启发式方法，理论基础较薄弱。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-23-decision-tree-decision-tree-example.png"><img src="/assets/images/2015-01-23-decision-tree-decision-tree-example.png" alt="［左］：观看MOOC课程的决策树［右］：递归定义的决策树算法" /></a><div class="caption">图 1:  ［左］：观看MOOC课程的决策树［右］：递归定义的决策树算法 [<a href="/assets/images/2015-01-23-decision-tree-decision-tree-example.png">PNG</a>]</div></div></div>

<p>上图左的决策树用来判断是否观看MOOC课程。决策树是分类器的有条件融合，在不同情况采用不同的$g_t(\mathbf x)$：</p>

<ul>
  <li>基本假设（base hypothesis）$g_t(\mathbf x)$：每条路径终点的叶子🍃，此处是常数。</li>
  <li>条件$q_t(\mathbf x)$：每条路径的内部节点，$\mathbf x$在路径$t$上么？上图左中菱形区域。</li>
</ul>

<p>决策树是递归结构，每个分支对应一颗子决策树
\[
G(\mathbf x)=\sum_{c=1}^C[[b(\mathbf x)=c]]\cdot G_c(\mathbf x)，
\]
$b(\mathbf x)$表示分支条件，$G_c(\mathbf x)$表示第$c$个分支的子树。</p>

<p>上图右展示了递归方式定义的决策树算法，从中可以看出，有4个方面需要决定：分支数目、分支条件、终止条件、基本假设。</p>

<h2 id="section-2">分类回归树</h2>

<p>分类回归树（C&amp;RT，classification and regression tree）是二叉树，<strong>分支数目</strong>$C=2$，<strong>基本假设</strong>$g_t(\mathbf x)$返回$E_{in}$最优时的常数。C&amp;RT的$g_t(\mathbf x)$比较简单：</p>

<ul>
  <li>二分类或多分类问题（基于0／1误差度量$E_{in}$）：$\{y_n\}$中占大多数的；</li>
  <li>回归问题（基于平方误差度量$E_{in}$）：$\{y_n\}$的平均。</li>
</ul>

<p>C&amp;RT通过基于不纯度函数的<strong>分支条件</strong>用decision stump进行二元分支
\[
b(\mathbf x)=\underset{\mbox{decision stumps }h(\mathbf x)}{\arg\min}\sum_{c=1}^2|\mathcal D_c\mbox{ with }h|\cdot\mbox{impurity}(\mathcal D_c\mbox{ with }h)，
\]
不纯度通过数据集大小加权。</p>

<p>回归的不纯度采用回归误差
\begin{equation}
\mbox{impurity}(\mathcal D)={1\over N}\sum_{n=1}^N(y_n-\bar y)^2，
\end{equation}
$\bar y$表示$\{y_n\}$的平均，分类的候选不纯度可采用分类误差
\begin{equation*}
\mbox{impurity}(\mathcal D)={1\over N}\sum_{n=1}^N[[y_n\neq y^*]]，
\end{equation*}
$y^*$表示$\{y_n\}$中占大多数的，通常采用Gini指数
\begin{equation}
\mbox{impurity}(\mathcal D)=1-\sum_{k=1}^K\left({\sum_{n=1}^N[[y_n=k]]\over N}\right)^2，
\end{equation}
或
\begin{equation*}
\mbox{impurity}(\mathcal D)=1-\max_{1\leq k\leq K}{\sum_{n=1}^N[[y_n=k]]\over N}，
\end{equation*}
只采用最优的$k=y^*$。</p>

<p>分类回归树“被迫”停止生长的两个<strong>终止条件</strong>：</p>

<ol>
  <li>所有$y_n$都相同，不纯度为0，返回$g_t(\mathbf x)=y_n$；</li>
  <li>所有$\mathbf x_n$都相同，不存在decision stump。</li>
</ol>

<p>这种被迫停止生长的树称为完全成长树（fully-grown tree）。</p>

<p>C&amp;AT = 完全成长树 ＋ 常数叶子🍃 ＋ 二元分支 ＋ 纯化。</p>

<h2 id="section-3">决策树剪枝</h2>

<p>如果所有的$\mathbf x_n$都不同，完全成长的决策树使得$E_{in}(G)=0$，这会导致过拟合（$E_{out}$很大），因为底层的树建立在很小的数据集$\mathcal D_c$上。也就是说，决策树的variance较大，数据很小的改变就可能得到很不一样的决策树。</p>

<p>决策树需要正则化机制避免过拟合。利用控制树叶数目$\Omega(G)$，正则化决策树
\begin{equation}
\underset{\mbox{all possible }G}{\arg\min}E_{in}(G)+\lambda\Omega(G)，
\end{equation}
称为剪枝（pruning）。通常是采用交叉验证选择$\lambda$。若要列举所有的$G$，计算量非常大，通常的做法是从完全成长树入手构造可能的$G$：</p>

<ul>
  <li>$G^{(0)}$为完全成长树；</li>
  <li>$G^{(i)}=\arg\min_GE_{in}(G)$，$G$表示从$G^{(i-1)}$中移除一片叶子（实际是合并叶子）。</li>
</ul>

<h2 id="section-4">决策树优势</h2>

<p>几乎没有哪种其它的机器学习算法拥有如此多优良特性，除非其它决策树。</p>

<h4 id="section-5">一、可解释性好</h4>

<h4 id="section-6">二、容易处理多分类问题</h4>

<h4 id="section-7">三、容易处理类别特征</h4>

<p>决策树通过decision stump
\begin{equation}
b(\mathbf x)=[[x_i\leq \theta]]+1\quad\theta\in\mathbb R，
\end{equation}
可以对数值特征进行分类；利用决策子集（decision subset）
\begin{equation}
b(\mathbf x)=[[x_i\in S]]+1\quad S\in\{1,2,\ldots,K\}，
\end{equation}
决策树也很容易进行基于类别特征的分类<sup id="fnref:categorical-feature"><a href="#fn:categorical-feature" class="footnote">1</a></sup>。</p>

<h4 id="section-8">四、容易处理遗失特征</h4>

<p>假设数据集中遗失了体重特征，人处理这类问题的方法有：</p>

<ul>
  <li>获取体重特征；</li>
  <li>用身高特征代替。</li>
</ul>

<p>决策树利用类似的代替思想，采用替代分支（surrogate branch）。在训练的时候训练可用的替代分支，利用替代分支可以得到和原来差不多的效果。当使用时遇到特征遗失，利用替代分支解决。</p>

<h4 id="section-9">五、高效的训练非线性模型</h4>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-23-decision-tree-C&amp;RT-vs-AdaBoost.png"><img src="/assets/images/2015-01-23-decision-tree-C&amp;RT-vs-AdaBoost.png" alt="C&amp;RT vs. AdaBoost" /></a><div class="caption">图 2:  C&amp;RT vs. AdaBoost [<a href="/assets/images/2015-01-23-decision-tree-C&amp;RT-vs-AdaBoost.png">PNG</a>]</div></div></div>

<h2 id="section-10">参考资料</h2>

<ol class="bibliography"><li><span id="lihang_sml_2012">[1]李航, <i>统计学习方法</i>. 北京: 清华大学出版社, 2012.</span>

</li>
<li><span id="lin_ml_dt_2015">[2]H.-T. Lin, “Lecture 9: Decision Tree.” Coursera, 2015.</span>

[<a href="https://class.coursera.org/ntumltwo-001/lecture">Online</a>]

</li></ol>

<h3 id="section-11">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:categorical-feature">
      <p>例如医生诊断时会给出症状相关的类别特征｛fever, pain, tired, sweaty｝。 <a href="#fnref:categorical-feature" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>图像分类（2）：多分类支持向量机和softmax分类器</title>
      <link href="http://qianjiye.de/2015/01/image-classification-svm-and-softmax-based-linear-classifier" />
      <pubdate>2015-01-20T12:18:40+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/image-classification-svm-and-softmax-based-linear-classifier</guid>
      <content:encoded>&lt;![CDATA[<p>本文主要参考<em>Convolutional Neural Networks for Visual Recognition</em><a href="#lifeifei_CNN_SVM_2015">[1]</a>课程笔记。</p>

<h2 id="section">预备知识</h2>

<p>k-NN在训练时只是记住了所有的样本，占用空间大，在识别时需和训练集的所有图片比较，耗费时间长。因此，需要开发新的方法克服kNN存在的问题，新方法包含两个关键部分：</p>

<ol>
  <li><strong>评分函数</strong>（score function）：将输入图像映射为所属类别的评分；</li>
  <li><strong>损失函数</strong>（loss function）：度量预测的评分与真实结果之间的一致性，也称为代价（cost）函数或目标（objective）函数。当评分函数输出结果与真实结果之间差异越大，损失函数输出越大。</li>
</ol>

<p>训练时，通过最小化损失函数，得到评分函数的参数；分类时，通过对输入图像所属类别评分，判断图像的类别。</p>

<p>训练集图像$\mathbf x_i\in\mathbb R^D(i=1,2,\ldots,N)$对应的标签$y_i\in 1,2,\ldots,K$，表示训练集有$N$张图像，每个图像表示为一个$D$维向量，图像可分为$K$个类别。对于CIFAR-10数据集，$N=50000,D=32\times 32\times 3,K=10$。评分函数$f:\mathbb R^D\mapsto \mathbb R^K$将图像数据映射为所属类别的评分。</p>

<h2 id="section-1">线性分类器</h2>

<p>线性分类器（linear classifier）就是一个评分函数，它是一个线性映射
\begin{equation}
f(\mathbf x_i,\mathbf W, \mathbf b)=\mathbf W\mathbf x_i+\mathbf b，
\label{multiclass-linear-classifier-1}
\end{equation}
其中，$\mathbf x_i$表示图像展成的$D\times 1$维的向量，$\mathbf W$是$K\times D$维的权值矩阵，$\mathbf b$是$K\times 1$维的偏移向量（bias vector）。对CIFAR-10数据集，该映射输入的输入是3072维向量，输出属于这10个类别的评分。$\mathbf W$的用每行表示一个分类器，因此可以并行计算。一旦得到这些参数$\{\mathbf W,\mathbf b\}$之后，不必像k-NN一样存储整个训练集，只需保存参数即可<sup id="fnref:CNN-f-mapping"><a href="#fn:CNN-f-mapping" class="footnote">1</a></sup>。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-imagemap.jpg"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-imagemap.jpg" alt="线性分类器示意" /></a><div class="caption">图 1:  线性分类器示意 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-imagemap.jpg">JPG</a>]</div></div></div>

<p>上图展示了线性分类器计算过程，将图像简化为4个像素代替，🐶的得分最高导致了🐱误判为🐶，这并不是一个良好的分类器。权值的正负号表示了某个位置的像素对分类结果是赞成还是反对，权值的大小表示强弱程度，从这个角度看就是投票模型。</p>

<p>线性分类器可以理解为模版匹配（template matching），$\mathbf W$的每一行对应一个模版，通过图像与模版的内积（inner product）<sup id="fnref:inner-product-similarity"><a href="#fn:inner-product-similarity" class="footnote">2</a></sup>判断图像与哪个模版最相似。从这个角度看，线性分类器也是最近邻分类器，并且只需和每类学习到的唯一模版比较，效率更高，匹配时采用内积而非$L_1$或$L_2$度量距离。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-templates.jpg"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-templates.jpg" alt="线性分类器权值矩阵图像化" /></a><div class="caption">图 2:  线性分类器权值矩阵图像化 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-templates.jpg">JPG</a>]</div></div></div>

<p>上图用图像的方式展示了线性分类器在CIFAR-10上学到的权值矩阵，这些图像相当于从每类学习到的模版。</p>

<p>若将图像追加一个值为1的“特征”，可将偏移向量$\mathbf b$合并到权值矩阵$\mathbf W$中，公式\eqref{multiclass-linear-classifier-1}可改写为更简练的形式
\begin{equation}
f(\mathbf x_i,\mathbf W)=\mathbf W\mathbf x_i。
\label{multiclass-linear-classifier-2}
\end{equation}</p>

<p>在机器学习中，将输入特征归一化是常用的技术。在实际中，将图像的每维特征（像素）减去均值中心化，对图像而言就是将每张图像减去平均图像，得到新图像的像素取值范围是$[-127,127]$。还可进一步将特征取值规范化到$[-1,1]$区间。</p>

<p>在线性分类器（评分函数）基础上，通过定义不同损失函数，可得到具备不同特性的多分类支持向量机和softmax分类器。</p>

<h2 id="multiclass-SVM">多分类支持向量机</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-margin.jpg"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-margin.jpg" alt="损失函数示意图" /></a><div class="caption">图 3:  损失函数示意图 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-margin.jpg">JPG</a>]</div></div></div>

<p>支持向量机期望评分函数在固定边界$\Delta$控制下，正确分类比错误分类输出更高的评分。$f(\mathbf x_i,\mathbf W)_j$表示图像$\mathbf x_i$属于类别$j$的评分，多分类支持向量机的损失函数定义为
\begin{equation}
L_i = \sum_{j\neq y_i}\max(0, f(\mathbf x_i,\mathbf W)_j-f(\mathbf x_i,\mathbf W)_{y_i}+\Delta)，
\label{eq:m-svm-loss}
\end{equation}
损失函数期望正确分类比错误分类输出更小的值。支持向量机期望正确分类比错误分类至少多得分$\Delta$，这样就没有损失，如上图所示，如果任何类别的评分落在红色区间，就会有损失累加。作出好的预测等价于最小化损失。</p>

<p>$\max(0,\cdots)$一般称为<strong>hinge损失</strong>，也称为<strong>最大边界损失</strong>（max-margin loss），$L_2$-SVM的平方损失$\max(0,\cdots)^2$惩罚力度更强。hinge损失比平方hinge损失更标准通用，但有的数据集平方hinge损失效果更好，可以通过交叉验证选择损失度量方式。</p>

<p>假设$f(\mathbf x_i,\mathbf W)＝[13, -7, 11], y_i=0,\Delta=10$，那么
\[
L_i=\max(0, -7-13+10)+\max(0,11-13+10)=8。
\]
上式右边第1项，正确分类得分（13）要高于错误分类（-7），支持向量机只关心是否二者差异至少为10（事实上二者差距为20分），因此输出为0；上式右边第2项，正确分类得分（13）高于错误分类（11），但二者差异只有2，因此损失了8。</p>

<p>将\eqref{multiclass-linear-classifier-2}代入\eqref{eq:m-svm-loss}可得
\begin{equation}
L_i = \sum_{j\neq y_i}\max(0, \mathbf w_j^T\mathbf x_i - \mathbf w_{y_i}^T\mathbf x_i +\Delta)，
\end{equation}
其中，$\mathbf w_j^T$是$\mathbf W$的第$j$行元素。</p>

<p>学习（训练）阶段的目标就是期望得到权值矩阵$\mathbf W$，使得正确分类的评分高于其它所有类别，并且使损失函数尽量小。</p>

<p>假设$\mathbf W$将一个数据集的每个样本都正确分类（对所有的$i$，$L_i=0$），$\mathbf W$却不是唯一的存在，当$\lambda&gt;0$时$\lambda\mathbf W$都能胜任。通过正则化惩罚（regularization penalty）$R(\mathbf W)$，可以消除$\mathbf W$的歧义。常用的正则化惩罚抑制$L_2$范数大的$\mathbf W$出现，
\[
R(\mathbf W)=\sum_k\sum_l\mathbf W_{k,l}^2，
\]
正则化只针对权值与输入数据无关。因此，多分类支持向量机的损失函数包括两部分，数据损失（data loss）和正则化损失（regularization loss），
\begin{equation}
L={1\over N}\sum_i\sum_{j\neq y_i}\max(0, \mathbf w_j^T\mathbf x_i - \mathbf w_{y_i}^T\mathbf x_i +\Delta)+\lambda \sum_k\sum_l\mathbf W_{k,l}^2。
\label{eq:regularization-loss-function}
\end{equation}</p>

<ol>
  <li>损失函数\eqref{eq:regularization-loss-function}采用\eqref{multiclass-linear-classifier-1}的权值$\mathbf w_j$包含偏移分量$b_j$，但正则化采用\eqref{multiclass-linear-classifier-2}的权值$\mathbf W$不包含偏移向量$\mathbf b$，实际应用中即使正则化了$\mathbf b$对结果影响也不大。</li>
  <li>由于增加了正则化项，正常情况下损失函数不可能到达0。</li>
  <li>控制正则化力度的参数$\lambda$仍然只能通过交叉验证选择。</li>
  <li>采用$L_2$正则化，可以导出<a href="\sum\_k\sum\_l\mathbf W\_{k,l}^2">支持向量机的最大边界特性</a>。</li>
</ol>

<p>正则化使得没有哪一个维度可以对评分造成很大的影响，通过惩罚大的权值提高了泛化（generalization）性能，降低了过拟合（overfitting）风险。当$\mathbf x=[1,1,1,1]^T$、$\mathbf w_1=[1,0,0,0]^T$和$\mathbf w_2=[0.25,0.25,0.25,0.25]^T$时，虽然$\mathbf w_1^T\mathbf x=\mathbf w_2^T\mathbf x=1$，但$L_2$对$\mathbf w_1$的惩罚是1对$\mathbf w_2$的惩罚只有0.25，因此结果偏爱$\mathbf w_2$。$L_2$惩罚偏爱取值小且分散的权值向量，最终得到的分类器会尽量考虑所有维度的输入，而非更偏爱哪一个维度<sup id="fnref:the-golden-mean"><a href="#fn:the-golden-mean" class="footnote">3</a></sup>。</p>

<p>$\Delta$和$\lambda$虽是两个不同的参数，但都是相同的折中效果。不需交叉验证选择$\Delta$，直接设置$\Delta=1.0$即可，只需通过交叉验证调节$\lambda$。放大$\mathbf W$可以放大评分，缩小$\mathbf W$也可缩小评分
，度量评分之间的差距的$\Delta$也同步放大或缩小，而调节$\lambda$可放缩$\mathbf W$，因此固定住$\Delta$只设置$\lambda$即可。</p>

<p>对于二分类支持向量机，<a href="/2015/01/kernel-logistic-regression/#mjx-eqn-equniform-soft-margin-svm">损失函数</a>表示为
\[
L=C\sum_{i=1}^N\max(0, 1-y_i\mathbf w^T\mathbf x_i)+R(\mathbf w)，
\]
其中$C$是超参数，$y_i\in\{-1,+1\}$。它可视为本文多分类问题简化为二分类的一个特例，$C$和$\lambda$都有相同的折中作用，$C\propto{1\over \lambda}$。</p>

<p>本文的多分类支持向量机，只是支持向量机解决多分类问题的方法之一。除此之外还有一对多（OVA，one-vs-all）策略和实际中很少使用的多对多（AVA，all-vs-all）。简单的OVA策略能很好处理多分类问题<a href="#Rifkin04indefense">[2]</a>，本文的方法是OVA的增强版<a href="#Weston99supportvector">[3]</a>，理论上数据损失项可达0，常规的OVA方法则不行。</p>

<h2 id="softmax-classifier">softmax分类器</h2>

<p>softmax分类器是logistic回归分类器在多分类问题的推广。$f_j(\mathbf z)={e^{z_j}\over\sum_k e^{z_k}}$被称为softmax函数（softmax function），它将实数转换为$[0,1]$区间的值。softmax分类器采用同样的评分函数\eqref{multiclass-linear-classifier-2}，但采用<strong>交叉熵损失</strong>（cross-entropy loss）函数
\begin{equation}
L
=-{1\over N}\sum_{i=1}^N\log\left({e^{f_{y_i}}\over\sum_j e^{f_j}}\right)+R(\mathbf W)
=-{1\over N}\sum_{i=1}^N\left(f_{y_i}-\log\sum_j e^{f_j}\right)+R(\mathbf W)。
\end{equation}</p>

<p>“真实”分布$p$和估计所得分布$q$之间的交叉熵定义为
\[
H(p,q)=-\sum_xp(x)\log q(x)。
\]
对softmax分类器，属于类别$y_i$概率的估计值$q={e^{f_{y_i}}\over\sum_j e^{f_j}}$，属于类别$y_i$概率的“真实”值应为$p=1$。</p>

<p>交叉熵可改写为熵与<a href="http://en.wikipedia.org/wiki/Kullback–Leibler_divergence">Kullback-Leibler散度</a>（divergence）之和的形式
\[
H(p,q)=H(p)+D_{KL}(p\| q)，
\]
其中$H(p)=-\sum_xp(x)\log p(x)$，对于本文分类问题$H(p)=0$。最小化代价函数等价于最小化两个分布之间的KL散度。通过交叉熵，期望能预测的分布能在正确分类的类别上概率达到最大。</p>

<p>softmax函数可以视为概率形式
\[
P(y_i|\mathbf x_i;\mathbf W)={e^{f_{y_i}}\over\sum_j e^{f_j}}，
\]
表示预测正确分类$y_i$的归一化概率。好的分类结果是$\prod_{i=1}^NP(y_i|\mathbf x_i;\mathbf W)$最大，这可认为是最大似然估计（MLE，maximum likelihood estimation）。正则化项$R(\mathbf W)$可认为源自权值矩阵的高斯先验（Gaussian prior），最小化损失函数相当于最大后验概率估计（maximum a posteriori）。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计<a href="#lihang_sml_2012">[4, P. 9]</a>。</p>

<p>编程实现时，$e^{f_{y_i}}$和$\sum_j e^{f_j}$的值可能很大，大数值相除不稳定，所以需要采用规范化技巧（normalization trick）。softmax函数可以写为等价的形式
\[
\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}=\frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}=\frac{e^{f_{y_i}+\log C}}{\sum_j e^{f_j+\log C}}，
\]
提高计算的稳定性，通常选择$\log C=-\max_jf_j$，将评分的最大值规范化为0。</p>

<h2 id="svm-vs-softmax">SVM vs. softmax</h2>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-svmvssoftmax.png"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-svmvssoftmax.png" alt="SVM和softmax的对比" /></a><div class="caption">图 4:  SVM和softmax的对比 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-svmvssoftmax.png">PNG</a>]</div></div></div>

<p>支持向量机的结果不易理解，softmax分类器给出了所属类别的“概率”解释。事实上，概率分布是平坦还是尖峰依赖于正则化参数$\lambda$。</p>

<p>当线性分类器输出$[1, -2, 0]$时，softmax函数输出“概率”
\[
[1, -2, 0]\rightarrow 
[e^1, e^{-2}, e^0]=
[2.71,0.14,1]\rightarrow
[0.7,0.04,0.26]。
\]
当增大正则化系数$\lambda$，这可能导致更小的权值，线性分类器的输出假设减小到$[0.5, -1, 0]$，此时softmax函数输出“概率”
\[
[0.5, -1, 0]\rightarrow 
[e^{0.5}, e^{-1}, e^0]=
[1.65,0.37,1]\rightarrow
[0.55,0.12,0.33]，
\]
概率分布变得更均匀。大的正则化系数$\lambda$导致权值变小，类别的输出概率更趋于均匀化（uniform）。因此，softmax函数输出的“概率”之间大小比较有意义，单独看某个“概率”值的大小没有明确意义，也就是相对大小有意义，绝对大小没意义。</p>

<p>多分类支持向量机和softmax分类器，在性能表现上通常很相近。假设$\mathbf x_i$属于第1类，对于$[10, -100, -100]$和$[10, 9, 9]$，多分类支持向量机都不再增加损失函数的值；但对于softmax分类器，$[10, 9, 9]$会比$[10, -100, -100]$让损失函数增加更大的值。softmax分类器永不满足，总是试图让正确的分类概率更大，损失函数的值更小；然而，只要多分类支持向量机满足边界条件，不论评分高低，不再调整评分，这可以看作是多分类支持向量机的一个特性，比如对于一个车辆分类器，它应该关注如何分类轿车和卡车等困难问题，而不应受已经评分很低🐸🐱🐶等的影响。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"><li><span id="lifeifei_CNN_SVM_2015">[1]F.-F. Li and A. Karpathy, “Linear classification: Support Vector Machine, Softmax.” GitHub, 2015.</span>

[<a href="http://cs231n.github.io/linear-classify/">Online</a>]

</li>
<li><span id="Rifkin04indefense">[2]R. Rifkin and A. Klautau, “In defense of one-vs-all classification,” <i>Journal of Machine Learning Research</i>, vol. 5, pp. 101–141, 2004.</span>

</li>
<li><span id="Weston99supportvector">[3]J. Weston and C. Watkins, “Support Vector Machines for Multi-Class Pattern Recognition,” in <i>European Symposium on Artificial Neural Networks</i>, Bruges (Belgium), 1999, pp. 219–224.</span>

[<a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es1999-461.pdf">Online</a>]

</li>
<li><span id="lihang_sml_2012">[4]李航, <i>统计学习方法</i>. 北京: 清华大学出版社, 2012.</span>

</li></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:CNN-f-mapping">
      <p>CNN也会将数据像素映射为得分，只是映射$f$会更复杂，参数更多。 <a href="#fnref:CNN-f-mapping" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:inner-product-similarity">
      <p>内积就是余弦相似度？ <a href="#fnref:inner-product-similarity" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:the-golden-mean">
      <p>多么美妙的中庸之道！ <a href="#fnref:the-golden-mean" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
