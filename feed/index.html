<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jiye Qian</title>
    <link href="http://qianjiye.de/feed/" rel="self" />
    <link href="http://qianjiye.de" />
    <lastbuilddate>2015-01-29T06:31:19+08:00</lastbuilddate>
    <webmaster>ccf.developer@gmail.com</webmaster>
    
    <item>
      <title>机器学习三原则</title>
      <link href="http://qianjiye.de/2015/01/three-learning-principles" />
      <pubdate>2015-01-28T20:05:37+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/three-learning-principles</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">使用奥卡姆剃刀</h2>

<blockquote>
  <p>An explanation of the data should be made as simple as possible, but no simpler.         <br />
—Albert Einstein? (1879-1955)</p>

  <hr />

  <p>entia non sunt multiplicanda praeter necessitatem (entities must not be multiplied beyond necessity)       <br />
—William of Occam (1287-1347) </p>
</blockquote>

<p>奥卡姆剃刀（Occam’s rezor）：剃掉不必要的解释。对机器学习，适合数据的最简单模型也是最合理的模型。</p>

<ul>
  <li>简单的假设$h$：小的$\Omega(h)$，假设的参数少；</li>
  <li>简单的模型$\mathcal H$：小的$\Omega(\mathcal H)$，包含较少的假设，成长函数增长很慢。</li>
</ul>

<p>当$\Omega(\mathcal H)$小时，$\Omega(h)$也小。当假设集大小为$2^\ell$时，每个假设最多有$\ell$个参数<sup id="fnref:why-ell-parameters"><a href="#fn:why-ell-parameters" class="footnote">1</a></sup>。在实际应用中，通过正则化或从简单模型开始尝试，都可以得到简单的假设。</p>

<p>对于简单模型，$m_\mathcal H(N)$小，难以将数据拟合好（拟合好的概率为$m_{\mathcal H}(N)\over 2^N$<sup id="fnref:why-ration"><a href="#fn:why-ration" class="footnote">2</a></sup>）。对简单的模型，如果数据被分开，那么数据是规律的；对于复杂的模型，如果数据能分开，就不能判断数据是否有规律（复杂模型能把任何数据分开）。</p>

<p>在实际应用中，从简单的线性模型开始尝试，经常考量数据是否被模型过度表示（data over-modeled）。</p>

<h2 id="section-1">避免抽样偏差</h2>

<p>如果数据通过有偏抽样得到<a href="#Darrell_Huff_2002">[1]</a>，学习到的结果也是有偏的。</p>

<p>若从$P_1(\mathbf x,y)$的数据中学习，却在$P_2\neq P_1$的数据中测试，VC理论不适用。相当于学了数学却要参加英语考试。VC理论的前提是训练和测试数据都iid来自同一分布。</p>

<p>通过信用卡用户的信用记录，判断是否给新顾客信用卡。——由于没有未开通信用卡用户的信息，这两者分布可能很不一样……</p>

<p>在实际应用中，尽可能的了解测试环境，使训练环境和测试环境尽量一致。</p>

<h2 id="section-2">绝不偷看数据</h2>

<blockquote>
  <p>If you torture the data long enough, it will confess.</p>
</blockquote>

<p>使用数据的任何过程都相当于间接偷看了数据。为了让VC维可靠，选择$\Phi$时不应当<a href="/2015/01/nonlinear-transformation/#human-learning">偷看数据</a>。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png"><img src="/assets/images/2015-01-28-three-learning-principles-snoop-data.png" alt="简单的偷看也会导致结果偏差很大" /></a><div class="caption">Figure 1:  简单的偷看也会导致结果偏差很大 [<a href="/assets/images/2015-01-28-three-learning-principles-snoop-data.png">PNG</a>]</div></div></div>

<p>对使用同样数据集$\mathcal D$的论文，后来作者针对以前论文改进，阅读以前论文也就相当于偷看资料。若把这些论文看成一篇长长的论文，付出的模型复杂度为$d_{VC}(\cup_m\mathcal H_m)$，泛化能力差。</p>

<p>偷看数据很难避免，合理处理偷看数据：</p>

<p><img src="/assets/images/2015-01-28-three-learning-principles-deal-with-snooping.png" alt="合理处理偷看数据" /></p>

<p>“be blind”是指尽量避免用数据做决定，不要在看了数据之后再决定采用什么样的特征等操作。也就是避免human learning的复杂度进入。</p>

<h2 id="section-3">其它三原则</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-tools.png" alt="三大工具" /></a><div class="caption">Figure 2:  三大工具 [<a href="/assets/images/2015-01-28-three-learning-principles-three-tools.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png"><img src="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png" alt="三大理论边界" /></a><div class="caption">Figure 3:  三大理论边界 [<a href="/assets/images/2015-01-28-three-learning-principles-three-theoretical-bounds.png">PNG</a>]</div></div></div>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"><li><span id="Darrell_Huff_2002">[1]达莱尔·哈夫, <i>统计陷阱</i>. 上海: 上海财经大学出版社, 2002.</span>

</li></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-ell-parameters">
      <p>为什么最多$\ell$个参数？ <a href="#fnref:why-ell-parameters" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-ration">
      <p>这个比率什么意思？ <a href="#fnref:why-ration" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>验证</title>
      <link href="http://qianjiye.de/2015/01/validation" />
      <pubdate>2015-01-27T23:28:10+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/validation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">模型选择问题</h2>

<p>若有$M$个<a href="/assets/images/2015-01-27-validation-so-many-models.png">候选模型</a>$\mathcal H_1,\mathcal H_2,\ldots,\mathcal H_M$和相应的算法$\mathcal A_1,\mathcal A_2,\ldots,\mathcal A_M$，如何选择$\mathcal H_{m^*}$使得$g_{m^*}=\mathcal A_{m^*}(\mathcal D)$有低的$E_{out}(g_{m^*})$？</p>

<p>由于$P(\mathbf x)$和$P(y|\mathbf x)$未知，那么$E_{out}$未也知……</p>

<h4 id="section-1">一、利用数据可视化不可行</h4>

<p>只有一些数据集……基于视觉化的选择是“<a href="/2015/01/nonlinear-transformation/#human-learning">human learning</a>”，并且高维度的数据不能视觉化。</p>

<h4 id="ein">二、利用$E_{in}$很危险</h4>

<p>如果利用$E_{in}$选择，高维特征变换通常犹豫低维，非正则化方法通常优于正则化方法。若$\mathcal A_1$在$\mathcal H_1$最小化$E_{in}$，$\mathcal A_2$在$\mathcal H_2$最小化$E_{in}$，二者再择优$g_{m^*}$在$\mathcal H_1\cup\mathcal H_2$中得到最小的$E_{in}$，这样增加了额外的模型复杂度，VC维$d_{VC}(\mathcal H_1\cup\mathcal H_2)$变大了，泛化能力差。</p>

<h4 id="etest">三、利用$E_{test}$是作弊</h4>

<p>根据finite-bin Hoeffding可得
\[
E_{out}(g_{m^*})\leq E_{test}(g_{m^*})+O\left(\sqrt{\log M\over N_{test}}\right)，
\]
看上去很美，$\mathcal D_{test}$是没用于模型训来的干净数据，可是$\mathcal D_{test}$（相当于老师的考卷）从哪里来呢？</p>

<h4 id="einetesteval">四、$E_{in}$和$E_{test}$折中的合法作弊方案$E_{val}$</h4>

<ul>
  <li>$\mathcal D_{val}\subset\mathcal D$；</li>
  <li>可以获取的；</li>
  <li>若$\mathcal D_{val}$没用于$\mathcal A_m$，那么它是干净的，就像测试数据一样。</li>
</ul>

<h2 id="section-2">单一验证集</h2>

<p>数据$\mathcal D$的划分和相应关系如下：</p>

<p>\begin{align*}
E_{in}(h)\quad&amp;\quad&amp;\quad&amp;\quad &amp;E_{val}(h)\\
\uparrow\quad\quad&amp;\quad&amp;\quad&amp;\quad &amp;\uparrow\;\;\,\,\\
\quad\underbrace{\mathcal D}_{\mbox{size }N}\quad\,&amp;\rightarrow&amp;\underbrace{\mathcal D_{train}}_{\mbox{size }N-K}\quad\quad\,&amp;\cup&amp;\underbrace{\mathcal D_{val}}_{\mbox{size }K}\;\\
\downarrow\quad\quad&amp;\quad &amp;\downarrow\quad\quad\quad\;&amp;\quad&amp;\quad\\
g_m=\mathcal A_m(\mathcal D)&amp;\quad &amp;g_m^-=\mathcal A_m(\mathcal D_{trian})&amp;\quad&amp;\quad
\end{align*}</p>

<p>$\mathcal D_{val}\subset\mathcal D$称为<strong>验证集</strong>（validation set），用于模拟测试集。$\mathcal D_{val}$是随机从$\mathcal D$中抽取的$K$个样本，那么$\mathcal D_{val}\overset{iid}{\sim} P(\mathbf x,y)$，通过数据建立了$E_{val}$与$E_{out}$的联系。确保$\mathcal D_{val}$是干净的，$\mathcal A_m$只使用了$\mathcal D_{train}$进行模型选择（也就是训练得到模型参数，从$\mathcal H$中选出$h$）。</p>

<p>原来使用$\mathcal D$扮演两个角色，既要计算$E_{in}$进行模型选择，又要通过算法得到$g$，两个角色导致资料被污染。利用$D_{val}$，通过最佳$E_{val}$进行模型选择
\[
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{val}(\mathcal A_m(\mathcal D_{train})))，
\]
可得如下误差保证
\begin{equation}
E_{out}(g_m^-)\leq E_{val}(g_m^-)+O\left(\sqrt{\log M\over K}\right)，
\end{equation}
但是只用$N-K$个训练模型out-of-sample误差会偏大（也可从学习曲线看出，理论上若要成立，还需更严格的限制条件），
\[
E_{out}\left(\underbrace{g_{m^*}}_{\mathcal A_m^*(\mathcal D)}\right)\leq E_{out}\left(\underbrace{g_{m^*}^-}_{\mathcal A_m^*(\mathcal D_{train})}\right)，
\]
因此，
\[
E_{out}(g_{m^*})\leq E_{out}(g_{m^*}^-)\leq E_{val}(g_{m^*}^-)+O\left(\sqrt{\log M\over K}\right)。
\]</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-27-validation-model-selection.png"><img src="/assets/images/2015-01-27-validation-model-selection.png" alt="基于验证集的模型选择方案" /></a><div class="caption">Figure 1:  基于验证集的模型选择方案 [<a href="/assets/images/2015-01-27-validation-model-selection.png">PNG</a>]</div></div></div>

<p>模型选择整个方案如上图所示，得到$g_{m^*}^-$之后，再回到原来整个数据集上得到$g_{m^*}$效果会更好<sup id="fnref:is-it-necessary"><a href="#fn:is-it-necessary" class="footnote">1</a></sup>。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-27-validation-vlidation-example.png"><img src="/assets/images/2015-01-27-validation-vlidation-example.png" alt="模型选择的学习曲线" /></a><div class="caption">Figure 2:  模型选择的学习曲线 [<a href="/assets/images/2015-01-27-validation-vlidation-example.png">PNG</a>]</div></div></div>

<p>上图是在$\mathcal H_{\Phi_5}$和$\mathcal H_{\Phi_{10}}$中进行模型选择的学习曲线。$g_{m^*}$的效果要优于$g_{m^*}^-$。利用$E_{in}$总会选择到复杂的模型，利用$E_{out}$的作弊方案选择结果总最优。随着验证集不断增大，用于模型选择的训练集不断减小，所以$g_{m^*}^-$甚至会比$g_{\widehat m}$效果差，对很小的训练集，采用$E_{in}$还算不错的模型选择方案。</p>

<p>对大的验证集样本数$K$，有$E_{val}(g^-)\approx E_{out}(g^-)$，但$g_{m^*}^-$通常比$g_{m^*}$糟糕；对小的$K$，有$g_m^-\approx g_m$和$E_{out}(g)\approx E_{out}(g^-)$，但$E_{val}$和$E_{out}$差异较大；
\[
E_{out}(g)\underset{\mbox{small }K}{\approx}E_{out}(g^-)\underset{\mbox{large }K}{\approx}E_{val}(g^-)。
\]</p>

<p>从时间上看，由于部分数据当作了验证集，在训练集上选择每个模型的时间会缩短。</p>

<p>$K={N\over 5}$通常是不错的选择。</p>

<h2 id="section-3">留1交叉验证</h2>

<p>当在验证集的$K=1$的极端情况下，$g^-$和$g$就会非常接近，但$E_{out}$和$E_{val}$差异就很大。能否在$K=1$时找到方案，使得$E_{out}\approx E_{val}$？✅</p>

<p>当$K=1$时，验证集$\mathcal D_{val}^{(n)}=\{(\mathbf x_n,y_n)\}$，误差为$E_{val}^{(n)}(g_n^-)=err(g_n^-(\mathbf x_n),y_n)=e_n$，将留1交叉验证（leave-one-out cross validation）误差
\begin{equation}
E_{loocv}(\mathcal H,\mathcal A)={1\over N}\sum_{n=1}^Ne_n={1\over N}\sum_{n=1}^Nerr(g_n^-(\mathbf x_n),y_n)
\end{equation}
作为$E_{out}(g)$的近似，$E_{loocv}(\mathcal H,\mathcal A)\approx E_{out}(g)$，然后进行模型选择，
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{loocv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-example.png"><img src="/assets/images/2015-01-27-validation-loocv-example.png" alt="loocv选择常数模型而非线性模型" /></a><div class="caption">Figure 3:  loocv选择常数模型而非线性模型 [<a href="/assets/images/2015-01-27-validation-loocv-example.png">PNG</a>]</div></div></div>

<p>用$\underset{\mathcal D_n}{\varepsilon}$表示在训练集上的数学期望，那么有<sup id="fnref:how-expectation-do"><a href="#fn:how-expectation-do" class="footnote">2</a></sup>
\begin{aligned}
\underset{\mathcal D}{\varepsilon}E_{loocv}(\mathcal H,\mathcal A) = \underset{\mathcal D}{\varepsilon}{1\over N}\sum_{n=1}^Ne_n 
&amp;= {1\over N}\sum_{n=1}^N\underset{\mathcal D}{\varepsilon}e_n\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}\underset{(\mathbf x_n,y_n)}{\varepsilon}err(g_n^-(\mathbf x_n),y_n)\\
&amp;={1\over N}\sum_{n=1}^N\underset{\mathcal D_n}{\varepsilon}E_{out}(g_n^-)\\
&amp;={1\over N}\sum_{n=1}^N\overline{E_{out}}(N-1)\\
&amp;=\overline{E_{out}}(N-1)，
\end{aligned}
因此可得$E_{loocv}(\mathcal H,\mathcal A)$和$E_{out}(g^-)$联系紧密，通常称作$E_{out}(g)$几乎无偏的估计（almost unbiased estimate）。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-27-validation-loocv-practice.jpg"><img src="/assets/images/2015-01-27-validation-loocv-practice.jpg" alt="loocv手写识别示例" /></a><div class="caption">Figure 4:  loocv手写识别示例 [<a href="/assets/images/2015-01-27-validation-loocv-practice.jpg">JPG</a>]</div></div></div>

<p>上图手写识别例子中，通过验证确定选择多少维多项式特征。若用$E_{in}$，特征维度越多越好；利用$E_{loocv}$（图中标注为$E_{cv}$），会选到较低纬度的特征。</p>

<h2 id="v-fold-cross-validation">V-fold交叉验证</h2>

<p>由于loocv需要训练$N$次，时间复杂度非常大，在实际中并不总是可行的。但也有特例，线性回归的的loocv容易计算。通过单点估计误差波动较大，结果不是很稳定，曲线上有些跳动的点。如何降低loocv的计算量？</p>

<p>将数据集$\mathcal D$随机分为$V$等份（loocv相当于将数据集分为$N$等份），$V-1$份用于训练模型，剩余的1份用于验证，这称为V-fold交叉验证，
\begin{equation}
E_{cv}(\mathcal H,\mathcal A)={1\over V}\sum_{v=1}^VE_{val}^{(v)}(g_v^-)，
\end{equation}
模型选择方式为
\begin{equation}
m^*=\underset{1\leq m\leq M}{\arg\min}(E_m=E_{cv}(\mathcal H_m,\mathcal A_m))。
\end{equation}</p>

<p>通常情况，$V=10$。</p>

<p>通常，V-fold交叉验证要优于单一验证集方法，计算量也更大，5-fold或10-fold通常都会工作得很好，实际中loocv并不常用。</p>

<h2 id="section-4">小结</h2>

<p>各种模型选择的关系：</p>

<ul>
  <li>模型训练（初赛）：从假设集中选择；</li>
  <li>验证方案（复赛）：从训练好的模型中选择；</li>
  <li>测试：衡量最终的表现（测试集只在此时才能使用1次）。</li>
</ul>

<p>由于资料污染，以及付出了模型复杂度代价等因素，通常验证的结果仍然会比最终测试结果乐观。因此，提交测试结果而非验证结果更客观。</p>

<h2 id="section-5">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-6">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-it-necessary">
      <p><a href="/2015/01/image-classification-knn-based-introduction/#is-validation-set-need">并不是所有的人都这样做</a>…… <a href="#fnref:is-it-necessary" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:how-expectation-do">
      <p>数学期望如何分离计算的？ <a href="#fnref:how-expectation-do" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>正则化</title>
      <link href="http://qianjiye.de/2015/01/regularization" />
      <pubdate>2015-01-26T17:50:30+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/regularization</guid>
      <content:encoded>&lt;![CDATA[<p>正则化来源于处理函数逼近（function approximation）中的病态问题（ill-posed problem）。克服过拟合的一个方法是从简单模型开始尝试；正则化是相反的思路，从复杂模型的假设集开始，通过正则化约束求解得到未过拟合的简单模型（复杂项的系数很小或接近0）。</p>

<p>正则化等价于结构风险最小化（SRM，structural risk minimuzation）<a href="#lihang_sml_2012">[1, P. 9]</a>，它是结构风险最小化策略的实现，通过在经验风险上加一个正则化项或惩罚项实现<a href="#lihang_sml_2012">[1, P. 13]</a>。正则化符合奥卡姆剃刀（Occam’s rezor）原理：在所有可能选择的模型中，能够很好解释已知数据并且十分简单才是最好的模型。从贝叶斯估计的角度看，正则化项对应于模型的先验概率，可以假设复杂的模型有较大的先验概率<a href="#lihang_sml_2012">[1, P. 14]</a>。</p>

<p>本文的主要参考资料是机器学习基石<a href="#lin_ml_regularization_2014">[2]</a>。</p>

<h2 id="section">带约束回归</h2>

<p>对于$x\in\mathbb R$的Q阶多项式变换$\Phi_Q(x)=\left(1,x,x^2,\ldots,x^Q\right)$，为了方便用$\mathbf w$代替回归系数$\tilde{\mathbf w}$。10次和2次空间中回归问题的假设集$\mathcal H_{10}$和$\mathcal H_2$分别表示为
\[
\begin{aligned}
&amp;w_0+w_1x+w_2x^2+w_3x^3+\ldots,w_{10}x^{10}\\
&amp;w_0+w_1x+w_2x^2。
\end{aligned}
\]
若$w_3=w_4=\ldots=w_{10}=0$，则$\mathcal H_2=\mathcal H_{10}$，也就是$\mathcal H_2$的回归问题可以用带约束的$\mathcal H_{10}$实现
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }w_3=w_4=\ldots=w_{10}=0。
\]
正则化可以看作带约束的优化$E_{in}$。</p>

<p>稍微放松约束条件，任意8个系数为0，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H’_2$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}\left[\left[w_q\neq 0\right]\right]\leq 3。
\]
$\mathcal H’_2$比$\mathcal H_2$宽松，但比$\mathcal H_{10}$过拟合风险低，$\mathcal H_2\subset\mathcal H’_2\subset\mathcal H_{10}$。求解稀疏形式（含8个0系数）$\mathcal H’_2$中的假设非常困难，NP-hard。</p>

<p>进一步放松约束条件，得到用带约束的$\mathcal H_{10}$表示的$\mathcal H(C)$
\[
\min_{\mathbf w\in\mathbb R^{10+1}} E_{in}(\mathbf w)\quad\mbox{s.t. }\sum_{q=0}^{10}w_q^2\leq C。
\]
$\mathcal H(C)$和$\mathcal H’_2$有交集（overlap），对$C\geq 0$存在嵌套结构
\[
\mathcal H(0)\subset\mathcal H(1.126)\subset\ldots\subset\mathcal H(1126)\subset\ldots\subset\mathcal H(\infty)=\mathcal H(10)。
\]
从正则化假设集$\mathcal H(C)$的到的最优解就是正则化假设$\mathbf w_{REG}$。</p>

<h2 id="section-1">拉格朗日乘子法</h2>

<p>根据上述推导，正则化回归问题的向量表示形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}\sum_{n=1}^N\left(\mathbf w^T\mathbf z_n-y_n\right)^2\qquad\mbox{s.t. }\sum_{q=0}^Qw_q^2\leq C，
\end{equation}
进一步记为矩阵形式
\begin{equation}
\min_{\mathbf w\in\mathbb R^{Q+1}}E_{in}(\mathbf w)=
{1\over N}(\mathbf Z\mathbf w-\mathbf y)^T(\mathbf Z\mathbf w-\mathbf y)\qquad\mbox{s.t. }\mathbf w^T\mathbf w\leq C，
\label{eq:constrained-Ein-matrix}
\end{equation}
事实上$\mathbf w$位于半径为$\sqrt C$的球中。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-gradient-descent.png"><img src="/assets/images/2015-01-26-regularization-gradient-descent.png" alt="正则化约束的梯度下降法" /></a><div class="caption">Figure 1:  正则化约束的梯度下降法 [<a href="/assets/images/2015-01-26-regularization-gradient-descent.png">PNG</a>]</div></div></div>

<p>上图展示了正则化约束的梯度下降法，蓝色的椭圆曲线表示梯度相同的等高线，红色的圆形表示约束条件。没有正则化约束时，$\mathbf w$沿着$-\nabla E_{in}(\mathbf w)$方向达到最优解$\mathbf w_{lin}$，梯度方向指出了到达最优解的方式。有正则化约束时，大部分情况，最优解都在球面$\mathbf w^T\mathbf w=C$上。$-\nabla E_{in}(\mathbf w)$可以分解为绿色和红色$\mathbf w$（球切面的法向量）两个方向，如果已经在球面上，仍然继续沿着$\mathbf w$下降，会破坏约束条件。正则化梯度下降法，可看作在绿色箭头方向作用下接近最优解。达到最优解的条件是满足约束且不能继续下降，也就是$-\nabla E_{in}(\mathbf w)$平行于$\mathbf w$，那么有$-\nabla E_{in}(\mathbf w_{REG})\propto\mathbf w_{REG}$，此时绿色方向的分量为0，不再下降，优化过程结束。</p>

<p>利用拉格朗日乘子$\lambda&gt;0$，达到最优解的条件是
\begin{equation}
\nabla E_{in}(\mathbf w_{REG})+{2\lambda\over N}\mathbf w_{REG}=0。
\label{eq:nabla-E-w-reg}
\end{equation}
因为$\nabla E_{in}(\mathbf w_{REG})={2\over N}\left(\mathbf Z^T\mathbf Z\mathbf w_{REG}-\mathbf Z^T\mathbf y\right)$，所以可得最优解<sup id="fnref:why-regularize-all"><a href="#fn:why-regularize-all" class="footnote">1</a></sup>
\begin{equation}
\mathbf w_{REG}\leftarrow\left(\mathbf Z^T\mathbf Z+\lambda\mathbf I\right)^{-1}\mathbf Z^T\mathbf y。
\end{equation}
$\mathbf Z^T\mathbf Z$是半正定的，当$\lambda&gt;0$时，上述逆矩阵总存在。正则化的线性回归在统计学中称为<strong>脊回归</strong>（ridge regression）。</p>

<p>求解\eqref{eq:nabla-E-w-reg}等价于最小化增广误差（augmented error）
\begin{equation}
\mathbf w_{REG}\leftarrow \arg\min_{\mathbf w}E_{aug}(\mathbf w)\quad \lambda\geq 0，
\label{eq:Eaug-minimization}
\end{equation}
其中增广误差
\begin{equation}
E_{aug}(\mathbf w)=E_{in}(\mathbf w)+{\lambda\over N}\mathbf w^T\mathbf w，
\label{eq:E-aug}
\end{equation}
$\mathbf w^T\mathbf w$称为正则化项（regularizer）。带约束优化$E_{in}$，可通过无约束优化$E_{aug}(\mathbf w)$高效求解，每个$C$都有对应的$\lambda$，大的$\lambda$对应着小的$C$，也对应着短的$\mathbf w$。当$\lambda=1$或$C=\infty$或$C\geq\lVert\mathbf w_{LIN}\rVert^2$（相当于红色的圆已经把$\mathbf w_{LIN}$包含在内）时，相当于没有进行正则化。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-regularize-regression.png"><img src="/assets/images/2015-01-26-regularization-regularize-regression.png" alt="不同系数下正则化的效果" /></a><div class="caption">Figure 2:  不同系数下正则化的效果 [<a href="/assets/images/2015-01-26-regularization-regularize-regression.png">PNG</a>]</div></div></div>

<p>$\lambda$相当于对过拟合的惩罚因子，上图展示了不同$\lambda$惩罚下的效果。</p>

<p>${\lambda\over N}\mathbf w^T\mathbf w$称为权重衰减（weight-decay）正则化，可推广到“任意变换 ＋ 线性模型”。</p>

<h2 id="section-2">勒让德多项式</h2>

<p>当$x_n\in[-1,1]$和$Q$很大时，$x_n^q$会变得非常小，除精确度因素影响外，还需要很大的$w_q$才能体现$x_n^q$的影响，这就与正则化的目的有些“矛盾”，过度惩罚了高次项。对于$\mathcal Z$空间的特征
\[
\Phi(\mathbf x)=\left(1,x,x^2,\ldots,x^Q\right)，
\]
特征之间彼此非正交，对低次项容忍度较大，对高次项惩罚力度更大。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png"><img src="/assets/images/2015-01-26-regularization-legendre-polynomials.png" alt="勒让德多项式" /></a><div class="caption">Figure 3:  勒让德多项式 [<a href="/assets/images/2015-01-26-regularization-legendre-polynomials.png">PNG</a>]</div></div></div>

<p>为改善这一问题，可以考虑在多项式空间找到一组正交的基函数（orthonormal basis function），也称为勒让德多项式（legendre polynomials），构造如上图所示的新多项式变换
\[
\Phi(\mathbf x)=\left(1,L_1(x),L_2(x),\ldots,L_Q(x)\right)。
\]</p>

<h2 id="vc">VC维分析</h2>

<p>带约束$E_{in}$优化\eqref{eq:constrained-Ein-matrix}的VC上界
\begin{equation}
E_{out}(\mathbf w)\leq E_{in}(\mathbf w)+\Omega(\mathcal H(C))，
\label{eq:vc-bound}
\end{equation}
采用与$C$等价的$\lambda$时，可以用优化\eqref{eq:Eaug-minimization}实现，在没有限定$\mathcal H(C)$的情况下，通过优化$E_{aug}$间接获得了VC维的保证。对比\eqref{eq:E-aug}和\eqref{eq:vc-bound}，$\mathbf w^T\mathbf w=\Omega(\mathbf w)$衡量了单一假设的复杂度，$\Omega(\mathcal H(C))$衡量了整个假设集的复杂度。如果${\lambda\over N}\Omega(\mathbf w)$能很好的表示$\Omega(\mathcal H(C))$，衡量$E_{out}$时，$E_{aug}$是比$E_{in}$更好中介。</p>

<p>对$\mathcal Z$空间的非正则化方法，$d_{VC}(\mathcal H)=\tilde d+1$。事实上，采用正则化考虑的假设集$\mathcal H(C)$要小于$\mathcal H$。采用了正则化后，有效（effective）VC维$d_{EFF}(\mathcal H,\mathcal A)\leq d_{VC}(\mathcal H)$，其中$\mathcal A$为正则化算法。因此，正则化方法具有更好的泛化性能。增大$\lambda$使$C$变小，从而使$\mathcal H(C)$变小，使得$d_{EFF}(\mathcal H,\mathcal A)$减小。</p>

<h2 id="section-3">正则化的推广</h2>

<p>除权重衰减（weight-decay）正则化外，还有很多其它的正则化方法。正则化的约束条件应当向着目标函数方向，选择正则化方法的思路包括：</p>

<ul>
  <li>目标相关（target-dependent）：利用目标的特性，比如已知目标函数的对称性，可采用对称正则化$\sum[[q\mbox{ is odd}]]w_q^2$；</li>
  <li>合理性（plausible）：使结果更加光滑和简单，比如要对随机或确定性噪声鲁棒，可采用稀疏的$L_1$正则化$\sum |w_q|$；</li>
  <li>友好（friendly）：易于优化，比如采用除权重衰减的$L_2$正则化$\sum w_q^2$。</li>
</ul>

<p>如果正则化选择不合适，还有$\lambda=0$这道防线，可以避免危害。以上正则化选择思路和<a href="/2014/12/machine-learning-noise-and-error/#error-measurement">误差度量</a>一致：用户相关（user-dependent）、合理性、友好。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png"><img src="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png" alt="［左］：L2正则化；［右］L1正则化" /></a><div class="caption">Figure 4:  ［左］：L2正则化；［右］L1正则化 [<a href="/assets/images/2015-01-26-regularization-L2-and-L1-regularizer.png">PNG</a>]</div></div></div>

<p>$L_1$正则化在需要稀疏解时很有用。上图右是$L_1$正则化示意图，$L_1$正则化
\begin{equation}
\Omega(\mathbf w)=\sum_{q=0}^Q|w_q|=\lVert\mathbf w\rVert_1，
\end{equation}
虽然不可微分，但它是凸的，解是稀疏的（$\mathbf w$有很多0元素）。$-\nabla E_{in}$可分解到垂直于边界面的方向（边界面的法向量方向，如上图右红色箭头所示）和沿边界面的方向。当到达边界面后，如果继续沿着法向量方向下降，会破坏约束条件，沿着面的方向如果还能下降，则继续沿着面的方向下降，直到停在菱形球的顶点，或者直到$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$（沿边界面的方向分量为0）。边界面的法向量只和$\mathbf w$的符号有关，如果要$-\nabla E_{in}(\mathbf w)$平行$\mathbf w$比较困难，通常会停在菱形球的顶点，该点在坐标轴上，必有元素为0。</p>

<h2 id="lambda">最优$\lambda$</h2>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png"><img src="/assets/images/2015-01-26-regularization-noise-and-lambda.png" alt="噪声对性能的影响" /></a><div class="caption">Figure 5:  噪声对性能的影响 [<a href="/assets/images/2015-01-26-regularization-noise-and-lambda.png">PNG</a>]</div></div></div>

<p>上图表明，噪声等级越高，正则化的惩罚力度$\lambda$越大。实际上，噪声的等级不可预知，只有通过实验的方法选择最佳$\lambda$，也就是通过<a href="">验证</a>（validation）选择最佳$\lambda$。</p>

<h2 id="section-4">正则化实例</h2>

<p>本节内容源于机器学习<a href="#ng_ml_r_2014">[3]</a>网络课程，这里没有对增加的偏移项$x_0=1$的系数正则化，且$y\in\{0,1\}$。</p>

<h3 id="section-5">正则化线性回归</h3>

<h4 id="section-6">一、代价函数</h4>

<p>\begin{equation}
J(\boldsymbol\theta) = \frac{1}{2m}\left( \sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)^2 + \lambda\sum_{j=1}^n\theta_j^2 \right)
\label{eq:cf-linear-regression-r}
\end{equation}</p>

<h4 id="section-7">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<p>迭代过程可以化为如下形式：
\begin{equation*}
\theta_j := \theta_j\left(1 - \alpha\frac{\lambda}{m} \right) - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)};~~(j = 1, 2, \ldots, n)
\end{equation*}</p>

<p>通常$1 - \alpha\frac{\lambda}{m} &lt; 1$，与非正则化的梯度下降法比较，$\theta_j$减小更快。</p>

<h3 id="logistic">正则化Logistic回归</h3>

<h4 id="section-8">一、代价函数</h4>

<p>\begin{equation}
\begin{aligned}
J(\boldsymbol\theta)  = &amp;-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)+\left(1-y^{(i)}\right)\log \left(1-h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right)\right)\right) \\
&amp; + \frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
\end{aligned}
\label{eq:cf-logistic-regression-r}
\end{equation}</p>

<h4 id="section-9">二、梯度下降法估计参数</h4>

<p>repeat until convergence {
\begin{equation*}
\begin{aligned}
\theta_0 &amp; := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_0^{(i)} \\ <br />
\theta_j &amp; := \theta_j - \alpha\frac{1}{m}\left(\sum_{i=1}^m\left( h_{\boldsymbol\theta}\left(\mathbf x^{(i)}\right) - y^{(i)} \right)x_j^{(i)} + \lambda\theta_j\right)~~(j = 1, 2, \ldots, n)
\end{aligned}
\end{equation*}
}</p>

<h3 id="matlab">Matlab实现</h3>

<p>第一步：实现Logistic函数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>g <span class="p">=</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span>z<span class="p">)</span><span class="w"></span>
<span class="n">g</span> <span class="p">=</span> <span class="mf">1.0</span> <span class="o">./</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="nb">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">));</span>
<span class="k">end</span></code></pre></div>

<p>第二步：实现代价函数（包含梯度计算）</p>

<div class="highlight"><pre><code class="language-matlab"><span class="k">function</span><span class="w"> </span>[J, grad] <span class="p">=</span><span class="w"> </span><span class="nf">costFunctionReg</span><span class="p">(</span>theta, X, y, lambda<span class="p">)</span><span class="w"></span>
<span class="n">m</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">y</span><span class="p">);</span> <span class="c">% number of training examples</span>

<span class="n">h</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="n">J</span> <span class="p">=</span> <span class="o">-</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">.*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">+</span> <span class="c">...</span>
    <span class="n">lambda</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">sum</span><span class="p">(</span><span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">grad</span> <span class="p">=</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="n">theta</span><span class="p">(</span><span class="mi">2</span><span class="p">:</span><span class="k">end</span><span class="p">)])</span> <span class="o">/</span> <span class="n">m</span><span class="p">;</span>

<span class="k">end</span></code></pre></div>

<p>第三步：估计参数</p>

<div class="highlight"><pre><code class="language-matlab"><span class="n">initial_theta</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">lambda</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">options</span> <span class="p">=</span> <span class="n">optimset</span><span class="p">(</span><span class="s">&#39;GradObj&#39;</span><span class="p">,</span> <span class="s">&#39;on&#39;</span><span class="p">,</span> <span class="s">&#39;MaxIter&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">);</span>
<span class="p">[</span><span class="n">theta</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">exit_flag</span><span class="p">]</span> <span class="p">=</span> <span class="c">...</span>
	<span class="n">fminunc</span><span class="p">(@(</span><span class="n">t</span><span class="p">)(</span><span class="n">costFunctionReg</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda</span><span class="p">)),</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">options</span><span class="p">);</span></code></pre></div>

<h2 id="section-10">参考资料</h2>

<ol class="bibliography"><li><span id="lihang_sml_2012">[1]李航, <i>统计学习方法</i>. 北京: 清华大学出版社, 2012.</span>

</li>
<li><span id="lin_ml_regularization_2014">[2]H.-T. Lin, “Lecture 14: Regularization.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ntumlone">Online</a>]

</li>
<li><span id="ng_ml_r_2014">[3]A. Ng, “Regularization: The problem of overfitting.” Coursera, 2014.</span>

[<a href="https://www.coursera.org/course/ml">Online</a>]

</li></ol>

<h3 id="section-11">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:why-regularize-all">
      <p>为什么正则化包括$x_0=1$的偏移项系数，两者有何区别？ <a href="#fnref:why-regularize-all" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>过拟合的危害</title>
      <link href="http://qianjiye.de/2015/01/hazard-of-overfitting" />
      <pubdate>2015-01-26T13:47:38+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/hazard-of-overfitting</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">初识过拟合</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png" alt="［左］：好的拟合；［右］：过拟合" /></a><div class="caption">Figure 1:  ［左］：好的拟合；［右］：过拟合 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-good-vs-over-fitting.png">PNG</a>]</div></div></div>

<ul>
  <li>差的泛化（bad generalization）：低的$E_{in}$高的$E_{out}$，$E_{out}-E_{in}$很大；</li>
  <li>过拟合（overfitting）：$E_{in}$降低时$E_{out}$升高；</li>
  <li>欠拟合（underfitting）：$E_{in}$升高时$E_{out}$也在升高。</li>
</ul>

<p>上图右采用了4次多项式变换$\Phi$和$\mathcal Z$空间的线性拟合，$N=5$个点时存在唯一解<sup id="fnref:is-unique"><a href="#fn:is-unique" class="footnote">1</a></sup>，$E_{in}=0$，过拟合了。</p>

<p>泛化能力描述的是既成的状态，过拟合描述的是变化过程。解决欠拟合可采用<a href="/2015/01/nonlinear-transformation">非线性特征变换</a>，解决过拟合更复杂。过拟合主要受噪声和数据量的影响。</p>

<h2 id="section-1">过拟合的特性</h2>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png" alt="［左］：10次多项式的含噪数据；［右］：50次多项式的无噪数据" /></a><div class="caption">Figure 2:  ［左］：10次多项式的含噪数据；［右］：50次多项式的无噪数据 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-case-study.png">PNG</a>]</div></div></div>

<p>上图展示了分别用2次和10次多项式拟合1含噪和无噪数据的效果。结果有些意外，2次多项式的性能都要优于10次多项式。</p>

<p>下图的学习曲线表明，当数据量$N$较小时，10次多项式的$E_{in}$和$E_{out}$之间差距较大，泛化误差更大，这和VC界一致，因为10次多项式的$d_{VC}$较大。因此，当数据量较少时，用简单的模型更合适得到较好的结果。</p>

<p>对于上图右不带噪声的数据，10次多项式的表现仍然很差。这是由于目标函数过于复杂，生成的数据很像噪声。可以这样理解，50次多项式生成的无噪数据和10次多项式生成的数据加入噪声相似。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png" alt="2次和10次多项式的学习曲线" /></a><div class="caption">Figure 3:  2次和10次多项式的学习曲线 [<a href="/assets/images/2015-01-26-hazard-of-overfitting-learning-curves.png">PNG</a>]</div></div></div>

<p>假设数据产生的方式为
\[
y=f(x)+\epsilon\sim\mbox{Gaussian}\left(\sum_{q=0}^{Q_f}\alpha_qx^q,\sigma^2\right)，
\]</p>

<p>$\sigma^2$表示产生噪声的等级，$Q_f$是模型的复杂度，数据集的大小为$N$。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png"><img src="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png" alt="不同参数影响下的过拟合图谱（越红过拟合越厉害）" /></a><div class="caption">Figure 4:  不同参数影响下的过拟合图谱（越红过拟合越厉害） [<a href="/assets/images/2015-01-26-hazard-of-overfitting-overfitting-illustration.png">PNG</a>]</div></div></div>

<p>实验时确保能产生包含模型最高次的数据，过拟合采用$E_{out}(g_{10})-E_{out}(g_{2})$度量。上图分别展示了固定模型复杂度和噪声等级下的过拟合图谱，红色表示过拟合强，蓝色表示过拟合弱。上图左固定住模型复杂度，通过$\sigma^2$产生的噪声称为随机噪声（stochastic noise）；上图右固定住噪声等级，通过模型复杂度$Q_f$导致的“噪声”称为确定性噪声（deterministic noise）。</p>

<p>事实上，过拟合很容易发生：</p>

<ul>
  <li>当数据量$N$少的时候，</li>
  <li>当随机噪声大的时候，</li>
  <li>当确定性噪声大的时候，</li>
  <li>当模型复杂$d_{VC}$大的时候，</li>
</ul>

<p>这几种情况都容易发生过拟合。</p>

<p>确定性噪声大表示目标函数太复杂，机器难以学会。复杂模型产生的数据就像就像含有随机噪声一样，它就像伪随机数发生器（pseudo-random generator）。确定性噪声与随机噪声不同的地方包括：（1）当$\mathcal H$变复杂时，确定性噪声会减小；（2）固定$\mathbf x$后，确定性噪声也是固定的。</p>

<h2 id="section-2">克服过拟合</h2>

<p>克服过拟合的方法：</p>

<ul>
  <li>从简单的模型开始尝试；</li>
  <li>数据清洗或剪枝；</li>
  <li>根据已有数据生成更多数据（data hinting）；</li>
  <li><a href="/2015/01/regularization">正则化</a>；</li>
  <li><a href="/2015/01/validation">验证</a>（validation）。</li>
</ul>

<h4 id="data-cleaning">一、数据清洗或剪枝</h4>

<p>可以利用<a href="/2014/12/machine-learning-anomaly-detection">异常检测</a>的方法，探测出离群点，然后改变类别标签（数据清洗）或者移除异常点（数据剪枝），通常探测离群点的方法包括：</p>

<ul>
  <li>离本类很远，离其它类却很近；</li>
  <li>被当前分类器错误分类；</li>
  <li>……</li>
</ul>

<p>数据清洗或剪枝对性能的影响难以把握，有时对提升效果可能非常微弱。</p>

<h4 id="data-hinting">二、数据生成（data hinting）</h4>

<p>根据已有数据或已知规则产生新的数据。比如字符识别的时候，通过旋转等方式生成新的字符样本。</p>

<p>但是需要注意，新加入的样本不再是来自原来的概率分布，不再是i.i.d.（independent identically distributed）。</p>

<h2 id="section-3">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-4">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:is-unique">
      <p>4次多项式变换在$N=5$个点时存在唯一解？不对吧！ <a href="#fnref:is-unique" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>非线性特征变换</title>
      <link href="http://qianjiye.de/2015/01/nonlinear-transformation" />
      <pubdate>2015-01-25T19:03:12+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/nonlinear-transformation</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">非线性变换</h2>

<p>线性假设集（分类器）的类别之间的判别界是线性的，低VC维可使$E_{in}$和$E_{out}$接近，但无法分类线性不可分数据。线性分类器应用于线性不可分数据，会导致很大的$E_{in}$，$E_{out}$也会很大。如何突破线性分类器的局限，对线性不可分数据分类？</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png"><img src="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png" alt="［左］：线性不可分；［中］：圆可分；［右］Z空间线性可分" /></a><div class="caption">Figure 1:  ［左］：线性不可分；［中］：圆可分；［右］Z空间线性可分 [<a href="/assets/images/2015-01-25-nonlinear-transformation-circular-separable.png">PNG</a>]</div></div></div>

<p>上图左的数据$\mathcal D$虽然线性不可分，但是可以用上图中所示的圆分开
\[
h_{SEP}(\mathbf x)=\mbox{sign}\left(0.6-x_1^2-x_2^2\right)，
\]
令$\tilde{\mathbf w}^T=[0.6,-1,-1],\mathbf z=\left[1,x_1^2,x_2^2\right]^T$，上式可以记为
\[
h(\mathbf x)=\mbox{sign}\left(\tilde{\mathbf w}^T\mathbf z\right)，
\]
这就相当于通过<strong>非线性特征变换</strong>$\Phi: \mathbf x\in\mathcal X\mapsto\mathbf z\in\mathcal Z$，将$\mathcal X$空间中线性不可分数据变到线性可分的$\mathcal Z$空间，如上图右所示。</p>

<p>通过变换$\Phi_2(\mathbf x)=\left(1,x_1,x_2,x_1^2,x_1x_2,x_2^2\right)$，可以使得$\mathcal Z$空间的感知器和$\mathcal X$空间的二次假设等价，
\[
\mathcal H_{\Phi_2}=\left\{h(\mathbf x):h(\mathbf x)=\tilde h(\Phi_2(\mathbf x))\mbox{ for some linear }\tilde h\mbox{ on }\mathcal Z\right\}
\]
可以实现$\mathcal X$空间的所有二次曲线判别界，当然也包括线性的特殊情况，使得$E_{in}$有机会更小。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation.png"><img src="/assets/images/2015-01-25-nonlinear-transformation.png" alt="非线性变换步骤" /></a><div class="caption">Figure 2:  非线性变换步骤 [<a href="/assets/images/2015-01-25-nonlinear-transformation.png">PNG</a>]</div></div></div>

<p>上图展示了使用非线性变换的步骤。首先通过变换$\Phi$将数据从$\mathcal X$空间映射到$\mathcal Z$空间；然后在$\mathcal Z$空间利用线性分类算法$\mathcal A$得到线性判别界；最后返回
\begin{equation}
g(\mathbf x)=\mbox{sign}\left(\tilde{\mathbf w}^T\Phi(\mathbf x)\right)，
\end{equation}
逆变换$\Phi^{-1}$不一定存在。</p>

<p>非线性变换$\Phi$和$\mathcal Z$空间的线性模型算法$\mathcal A$，不仅可以用于分类，而且可用于回归。</p>

<h2 id="section-1">复杂度与性能分析</h2>

<p>若原始特征是$d$维，$Q$次多项式特征变换$\Phi_{Q}(\mathbf x)$后的特征空间维度$\tilde d+1$为$\binom{Q+d}{Q}$，空间复杂度为$O\left(Q^d\right)$。当$Q$很大时，新空间中的计算和存储代价都极大。新空间中$d_{VC}\left(\mathcal H_{\Phi_Q}\right)\leq \tilde d+1$，当$Q$很大时$d_{VC}$也会很大。当$d_{VC}$增加时，用于训练的数据量也要增加，需要考虑训练集的数据量是否足够。</p>

<div class="image_line" id="human-learning"><div class="image_card"><a href="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png"><img src="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png" alt="选择不同特征变换" /></a><div class="caption">Figure 3:  选择不同特征变换 [<a href="/assets/images/2015-01-25-nonlinear-transformation-visual-choices.png">PNG</a>]</div></div></div>

<p>上图展示了人工基于视觉的选择，不同特征变换下，$d_{VC}$从6降到了1。事实上，此时的模型复杂度需要考虑人工付出的$d_{VC}$代价，这是“human learning ＋ machine learning”。对于机器学习，人工偷看了数据付出的代价也必须加以考量。</p>

<p>对于特征变换，$Q$次变换可以在$Q-1$次的基础上进行
\[
\Phi_{Q}(\mathbf x)=\left(\Phi_{Q-1}(\mathbf x),x_1^Q,x_1^{Q-1}x_2,\ldots,x_d^Q\right)，
\]
也就是存在嵌套关系
\[
\mathcal H_{\Phi_0}\subset\mathcal H_{\Phi_1}\subset\mathcal H_{\Phi_2}\subset\ldots\subset\mathcal H_{\Phi_Q}，
\]
那么$d_{VC}$按上述次序递增（$\leq$），$E_{in}$按上述次序递减（$\geq$）。高次变换能得到$E_{in}$非常小的结果，然而$E_{in}$仅仅是中间产物，并<a href="/2014/12/machine-learning-the-vc-dimension/#vc-and-errors">不能说明$E_{out}$会很小</a>。合理的方法是从$H_{\Phi_1}$开始尝试，线性模型是首选，如果效果不达标再考虑高次的特征变换。</p>

<h2 id="section-2">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>线性分类模型</title>
      <link href="http://qianjiye.de/2015/01/linear-models-for-classification" />
      <pubdate>2015-01-25T12:23:40+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/linear-models-for-classification</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">回归用于分类</h2>

<p>线性分类器、线性回归和logistic回归，都采用了同样的线性评分函数
\[
s=\mathbf w^T\mathbf x
\]
它们之间的对比如下：
<img src="/assets/images/2015-01-25-linear-models-for-classification-linear-models.png" alt="线性模型" /></p>

<p>最小化线性分类器的$E_{in}(\mathbf w)$更困难，它是NP-Hard，能否用回归方法解决分类问题？✅</p>

<p>线性分类器、线性回归和logistic回归，它们的误差函数分别可记为
\[
\mbox{err}_{0/1}(s,y)=[[\mbox{sign}(ys)\neq 1]];\quad
\mbox{err}_{SQR}(s,y)=(ys-1)^2;\quad
\mbox{err}_{CE}(s,y)=\ln(1+\exp(-ys))。
\]</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png"><img src="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png" alt="误差曲线对比" /></a><div class="caption">Figure 1:  误差曲线对比 [<a href="/assets/images/2015-01-25-linear-models-for-classification-error-curves.png">PNG</a>]</div></div></div>

<p>上图展示了误差曲线的对比，为了比较方便，用$\mbox{err}_{SCE}(s,y)=\log_2(1+\exp(-ys))$代替$\mbox{err}_{CE}$。从图中容易看出
\[
\mbox{err}_{0/1}(s,y)\leq\mbox{err}_{SCE}(s,y)={1\over\ln 2}\mbox{err}_{CE}(s,y)，
\]
因此可得
\[
E_{in}^{0/1}(\mathbf w)\leq E_{in}^{SCE}(\mathbf w)={1\over\ln 2}E_{in}^{CE}(\mathbf w)\quad\mbox{and}\quad
E_{out}^{0/1}(\mathbf w)\leq E_{out}^{SCE}(\mathbf w)={1\over\ln 2}E_{out}^{CE}(\mathbf w)，
\]
从而可得
\[
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+\Omega^{0/1}\quad\mbox{or}\quad
E_{out}^{0/1}(\mathbf w)\leq{1\over\ln 2}E_{in}^{CE}(\mathbf w)+{1\over\ln 2}\Omega^{CE}，
\]
$E_{out}^{0/1}$和$E_{in}^{SQR}$之间也存在同样的关系。从以上关系可以看出，做到$E_{in}^{CE}(\mathbf w)$很小时也可使$E_{out}^{0/1}(\mathbf w)$很小，那么用线性或logistic回归也可解决线性分类问题，
\[
g(\mathbf x)=\mbox{sign}(\mathbf w_{REG}^T\mathbf x)。
\]</p>

<p>PLA在数据线性可分时效率较高否则需要采用pocket算法，线性或logistic回归“容易”优化但采用了比$err_{0/1}$松散的误差上限。</p>

<p>可用线性回归设置PLA、pocket或logistic回归的初始值$\mathbf w_0$，logistic回归的计算复杂度和pocket相当，通常logistic回归的性能优于pocket。</p>

<h2 id="section-1">随机梯度下降法</h2>

<p>迭代优化时，参数更新可以表示为
\begin{equation*}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\mathbf v\quad(t=0,1,\ldots)。
\end{equation*}
PLA每次采用一个数据更新参数，但logistic的梯度下降法每次采用全部数据更新参数，显然logistic更新过程计算量大很多。logistic回归和pocket效率差不多，能否使logistic回归和PLA一样快呢？✅</p>

<p>logistic回归采用的参数更新方法是
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta{1\over N}\sum_{n=1}^N\theta\left(-y_n\mathbf w^T\mathbf x_n)(y_n\mathbf x_n\right)，
\end{equation}
按梯度负方向$\mathbf v=-\nabla E_{in}(\mathbf w)$更新。通过$n$个点计算可估计梯度，极端情况用1个点计算估计梯度，称为随机梯度。随机梯度可视为真实梯度与零均值噪声之和，经过足够过的迭代次数，平均的真实梯度和平均的随机梯度基本相同，可利用随机梯度更新参数，
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+\eta\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)(y_n\mathbf x_n)，
\end{equation}
这就是<strong>随机梯度下降法</strong>（SGD，stochastic gradient descent）。</p>

<p>随机梯度法的优点是简单且计算量小，有利于大数据和在线学习；其缺点是稳定性欠佳，尤其是$\eta$很大时。随机梯度法实现时需要处理两个问题：</p>

<ol>
  <li>停止条件：梯度下降法可通过梯度是否接近零作为停止条件，但是随机梯度法没有梯度计算，难以确定停止条件，通常用足够大的迭代次数$t$作为停止条件；</li>
  <li>选择合适的$\eta$：通常利用交叉验证选择，经验表明$\eta=0.1$在大多数情况下是不错的选择。</li>
</ol>

<p>回顾PLA的参数更新过程
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+1\cdot\left[\left[-y_n\neq\mbox{sign}(\mathbf w_t^T\mathbf x_n)\right]\right](y_n\mathbf x_n)，
\end{equation}
随机梯度下降法的logistic回归想当于soft-PLA，用$\theta\left(-y_n\mathbf w_t^T\mathbf x_n\right)$表示更新的力度；当$\eta=1$并且$\mathbf w_t^T\mathbf x$很大时，PLA和随机梯度下降法的logistic回归相似。利用随机梯度下降法的线性回归可以表示为
\begin{equation}
\mathbf w_{t+1}\leftarrow \mathbf w_{t}+2\eta\left(y_n-\mathbf w_t^T\mathbf x_n\right)\mathbf x_n，
\end{equation}
$y_n-\mathbf w_t^T\mathbf x_n$表示错得越多，更新力度越大。</p>

<h2 id="multiple-classes">多分类问题</h2>

<p>采用one-vs-all的数据分割策略，利用logistic回归进行软性（softly）分类，选择“概率”大的类别
\begin{equation}
g(\mathbf x)=\arg\max_{k\in\mathcal Y}\theta\left(\mathbf w_{[k]}^T\mathbf x\right)=\arg\max_{k\in\mathcal Y}\mathbf w_{[k]}^T\mathbf x。
\end{equation}
one-vs-all方式的优点是简单易推广，并且很容易并行化训练每个分类器；它的坏处是当类别数$K$很大时，数据集$\mathcal D_{[k]}$的不平衡（unbalance）问题凸显。不平衡数据导致logistic回归通过误差最小化求解参数时，倾向于选择有利于数据量多的类别的假设。事实上，有专门的多分类logistic模型，例如<a href="/2015/01/image-classification-svm-and-softmax-based-linear-classifier/#softmax-classifier">softmax分类器</a>。</p>

<p>one-vs-one的方法有利于克服one-vs-all的数据不平衡问题，采用投票机制判断类别，类似循环赛，
\begin{equation}
g(\mathbf x)=\mbox{tournament champion}\left\{\mathbf w_{[k,l]}^T\mathbf x\right\}。
\end{equation}
one-vs-one方式训练每个分类器数据量较少，因此比较有效率，它克服了数据不平衡，以及利用了循环赛机制，所以更稳定；它的坏处是分类器数目更多，导致空间存储增大，预测时间增加，需要更多的训练<sup id="fnref:need-more-training"><a href="#fn:need-more-training" class="footnote">1</a></sup>，并且存在<a href="/2014/10/multiple-classes/#anbiguous-regions">有争议的判别区间</a>。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:need-more-training">
      <p>每个分类器数据少了，训练时间复杂度会增加吗？ <a href="#fnref:need-more-training" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（4）：随机森林</title>
      <link href="http://qianjiye.de/2015/01/random-forest" />
      <pubdate>2015-01-24T17:33:22+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/random-forest</guid>
      <content:encoded>&lt;![CDATA[<h2 id="section">随机森林</h2>

<p>bagging通过投票或平均的方法，可以减少variance；决策树功能强大， 但是有很大的variance。能否将二者融合起来，优势互补？</p>

<p>［1/3］random forest（RF） = bagging + fully-grown C&amp;RT tree</p>

<p>random描述了bagging中bootstrapping过程的随机性；forest表示很多树的组合。</p>

<blockquote>
  <h4 id="section-1">随机森林算法</h4>
  <hr />
  <p>对于$t=1,2,\ldots,T$，循环执行： </p>

  <ol>
    <li>通过bootstrapping方法从$\mathcal D$中抽取大小为$N’$的数据集$\tilde{\mathcal D}_t$；</li>
    <li>通过决策树算法$\mbox{DTree}(\tilde{\mathcal D}_t)$得到$g_t$。</li>
  </ol>

  <p>返回$G=\mbox{Uniform}(\{g_t\})$就是随机森林。</p>
</blockquote>

<p>不同的$g_t$是进行分类器融合的关键。bagging通过bootstrapping的方法制造数据的随机性，从而得到不同的$g_t$。</p>

<p>另一种得到不同$g_t$的方法是从$\mathbf x$中随机抽取$d’$维特征：</p>

<ul>
  <li>随机抽取索引为$i_1,i_2,\ldots,i_{d’}$的特征，特种空间从高维到低维投影，$\Phi(\mathbf x)=\left(x_{i_1},x_{i_1},\ldots,x_{i_{d’}}\right)$；</li>
  <li>$\mathcal Z\in\mathbb R^{d’}$是$\mathcal X\in\mathbb R^d$的<strong>随机子空间</strong>（random subspace）；</li>
  <li>通常$d’\ll d$，对大的$d$这样更高效<sup id="fnref:small-subspace"><a href="#fn:small-subspace" class="footnote">1</a></sup>；</li>
</ul>

<p>RF的原作者建议每次在C&amp;RT找$b(\mathbf x)$时，都重采样得到新的$d’$维特征子空间，让得到的树更不一样：</p>

<p>［2/3］RF ＝ bagging ＋ random-subspace C&amp;RT。</p>

<p>随机从$\mathbf x$中采样$d’$维特征可记为$\Phi(\mathbf x)=\mathbf P\mathbf x$，利用$\mathbf P$的第$i$随机抽取1维特征，这样的行属于自然基（natural basis）。</p>

<p>采用<strong>随机组合方式</strong>，利用随机的行$\mathbf p_i$对特征进行投影（组合），$\phi_i(\mathbf x)=\mathbf p_i^T\mathbf x$，可以得到更强大的特征空间。通常采用的是低维投影，$\mathbf p_i$中只有$d’’$个非零元素。随机子空间是$d’’=1$的特殊情况，且$\mathbf p_i$属于自然基。</p>

<p>RF的原作者建议每次在C&amp;RT找$b(\mathbf x)$时，都进行$d’$的随机低维投影（组合）：</p>

<p>［3/3］RF ＝ bagging ＋ random-combination C&amp;RT</p>

<p>采用随机组合方式的C&amp;RT树，每个分支函数$b(\mathbf x)$相当于感知器（线性分类器）。</p>

<h2 id="oob">OOB方法</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png"><img src="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png" alt="out-of-sample数据点" /></a><div class="caption">Figure 1:  out-of-sample数据点 [<a href="/assets/images/2015-01-24-random-forest-out-of-bag-examples.png">PNG</a>]</div></div></div>

<p>采用bagging的时候，没被选中数据点称为out-of-bag（OOB）数据点，如上图左所示，星号标注的点表示没有对训练任何$g_t$有贡献。当$N’=N$时，对每次训练$g_t$的数据集$(\mathbf x_n,y_n)$是OOB的概率是$\left(1-{1\over N}\right)^N$，如果$N$很大时，这个概率是${1\over e}$。$g_t$对应数据集OOB数据大小约为${N\over e}$，这表明数据集中有不少点（大约1/3）没有参与训练。</p>

<p>OOB数据可以看作用于验证的数据，如上图右所示。但是通常不需要验证$g_t$，因为即使$g_t$效果不理想，融合后的分类器$G$仍然可以达到很好的效果。$G_n^-$表示$\{\mathbf x_n,y_n\}$是OOB数据点的分类器的集合，上图左最下一行$G_n^-=\mbox{average}(g_2,g_3,g_T)$，利用OOB数据集校验的误差定义为
\begin{equation}
E_{oob}(G)={1\over N}\sum_{n=1}^Nerr\left(y_n,G_n^-(\mathbf x_n)\right)，
\end{equation}
利用$E_{oob}$，bagging和RF可以实现自验证（self-validation）。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-oob-validation.png"><img src="/assets/images/2015-01-24-random-forest-oob-validation.png" alt="［左］：验证集方法［右］：OOB集方法" /></a><div class="caption">Figure 2:  ［左］：验证集方法［右］：OOB集方法 [<a href="/assets/images/2015-01-24-random-forest-oob-validation.png">PNG</a>]</div></div></div>

<p>上图是传统验证方法和$E_{oob}$的对比，$E_{oob}$通常能很准确的衡量$G$的性能。利用$E_{oob}$进行$d’’$等参数选择，通常不需要重新训练<sup id="fnref:why-not-re-training"><a href="#fn:why-not-re-training" class="footnote">2</a></sup>。</p>

<h2 id="section-2">特征选择</h2>

<p>特征选择就是移除冗余（redundant）和不相关（irrelevant）的特征。主要优点包括：</p>

<ul>
  <li>高效：让假设集和简单，预测时间变短；</li>
  <li>提升泛化能力：移除特征的同时也移除了那些特征的噪声；</li>
  <li>增强可理解性：剩余的特征对结果的解释性更强；</li>
</ul>

<p>但也存在对应的缺点：</p>

<ul>
  <li>计算量大：从特征空间选择重要的特征子集本身是组合优化问题；</li>
  <li>过拟合：恰好选到那些结果看似很好的特征组合；</li>
  <li>误解释：特别是存在过拟合时，可能得到结果的错误解释，或者只能得出关联性而非因果关系。</li>
</ul>

<p>决策树本身具备特征选择的能力，每次在某个特征上进行分割，用到的那些特征就是被选择的特征，这和decision stump类似。</p>

<p>特征选择的简单理想情况是不考虑特征组合的影响，计算每个特征的重要性，从$d$维特征中选择最重要的$d’$维特征。通过线性模型容易实现
\[
score = \mathbf w^T\mathbf x=\sum_{i=1}^dw_ix_i，
\]
对良好的$\mathbf w$（对特征给出合理评分），第$i$维特征的重要性$\mbox{importance}(i)=|w_i|$，大的数值对得分贡献大。$\mathbf w$可通过数据进行学习得到。</p>

<p>对于非线性模型，特征选择通常比较复杂。虽然RF是非线模型，但是由于内在的机制，采用<strong>随机测试</strong>（random test）也能方便选择特征。如果特征$i$很重要，用随机值$\mathbf x_{n,i}$代替该特征就会极大降低性能。产生这些随机值的方法包括：</p>

<ul>
  <li>通过均分分布或高斯分布产生：真实数据的分布$P(x_i)$可能并不服从这些分布，不仅加入了噪声，而且改变了分布，不是理想的方法。</li>
  <li>bootstrap或者组合（permutation）方法：这样就保持了原来的分布$P(x_i)$，组合方法重新排列原始特征（类似洗牌）。</li>
</ul>

<p>利用组合方法重排特征进行性能测试称为<strong>组合测试</strong>（permutation test），
\[
\mbox{importance}(i)=\mbox{importance}(\mathcal D)-\mbox{importance}(\mathcal D^{(p)})，
\]
$\mathcal D^{(p)}$表示$\mathcal D$的特征$\{x_{n,i}\}$经过重新“洗牌”。组合测试是一种统计工具，可以用于类似RF的其它非线性模型。</p>

<p>通常需要重新训来呢得到$\mbox{importance}(\mathcal D^{(p)})$，但是可RF利用OOB不需重新训练，
\[
\mbox{importance}(i)=E_{oob}(G)-E_{oob}^{(p)}(G)，
\]
得到$E_{oob}^{(p)}(G)$的方法是，在计算过程中需要$x_{n,i}$的地方，用组合的OOB值代替$x_{n,i}$。</p>

<p>在实际中，RF通过“permutation + OOB”进行特征选择，通常不仅高效而且有效。</p>

<h2 id="rf">RF特性</h2>

<p>通常随机森林需要的树越多越好🌲🌲🌲🌲，$\bar g=\lim_{T\rightarrow\infty} G$。通过增减树判断随机森林是否稳定，确保有足够多的树，如果不够，继续增加🌲。</p>

<p>台湾大学在KDDCup 2013中发现，随机森林的$E_{val}$表现依赖初始的种子点，最终通过将树增加到12000课，估定种子为1，夺得了冠军🏆。</p>

<h4 id="section-3">以下图片展示了随机森林的优点：</h4>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-large-margin.png"><img src="/assets/images/2015-01-24-random-forest-large-margin.png" alt="通过多棵树得到平滑和类似最大边界的判别界" /></a><div class="caption">Figure 3:  通过多棵树得到平滑和类似最大边界的判别界 [<a href="/assets/images/2015-01-24-random-forest-large-margin.png">PNG</a>]</div></div></div>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg"><img src="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg" alt="容易得到鲁棒的非线性模型" /></a><div class="caption">Figure 4:  容易得到鲁棒的非线性模型 [<a href="/assets/images/2015-01-24-random-forest-robust-nonlinear-model.jpg">JPG</a>]</div></div></div>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-24-random-forest-noise-corrected.jpg"><img src="/assets/images/2015-01-24-random-forest-noise-corrected.jpg" alt="通过投票机制消除噪声的干扰" /></a><div class="caption">Figure 5:  通过投票机制消除噪声的干扰 [<a href="/assets/images/2015-01-24-random-forest-noise-corrected.jpg">JPG</a>]</div></div></div>

<h2 id="section-4">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-5">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:small-subspace">
      <p>这种方法也可以用于其它机器学习模型。 <a href="#fnref:small-subspace" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-not-re-training">
      <p>为什么不需要重新训练？ <a href="#fnref:why-not-re-training" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>分类器融合（3）：决策树</title>
      <link href="http://qianjiye.de/2015/01/decision-tree" />
      <pubdate>2015-01-23T22:49:52+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/decision-tree</guid>
      <content:encoded>&lt;![CDATA[<table>
  <thead>
    <tr>
      <th>融合类型</th>
      <th>混合</th>
      <th>学习</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>均匀融合</td>
      <td>voting／averaging</td>
      <td>Bagging</td>
    </tr>
    <tr>
      <td>非均匀融合</td>
      <td>linear</td>
      <td>AdaBoost</td>
    </tr>
    <tr>
      <td>有条件融合</td>
      <td>stacking</td>
      <td>decision tree</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>混合（blending）：得到$g_t$之后再融合；</li>
  <li>学习（learning）：学习$g_t$的同时进行融合。</li>
</ul>

<h2 id="section">简介</h2>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-23-decision-tree-decision-tree-example.png"><img src="/assets/images/2015-01-23-decision-tree-decision-tree-example.png" alt="［左］：观看MOOC课程的决策树［右］：递归定义的决策树算法" /></a><div class="caption">Figure 1:  ［左］：观看MOOC课程的决策树［右］：递归定义的决策树算法 [<a href="/assets/images/2015-01-23-decision-tree-decision-tree-example.png">PNG</a>]</div></div></div>

<p>上图左的决策树用来判断是否观看MOOC课程。决策树是<a href="/2015/01/blending-and-bagging/#mjx-eqn-eqconditional-blending-hypothesis">分类器有条件融合</a>的经典学习模型，在不同的情况下采用不同的$g_t$：</p>

<ul>
  <li>基本假设（base hypothesis）$g_t(\mathbf x)$：每条路径终点的叶子🍃，此处是常数。 </li>
  <li>条件$q_t(t)$：$\mathbf x$在路径$t$上么？上图左中菱形区域。</li>
</ul>

<p>决策树是递归结构，每个分支对应一颗子决策树
\[
G(\mathbf x)=\sum_{c=1}^C[[b(\mathbf x)=c]]\cdot G_c(\mathbf x)，
\]
$b(\mathbf x)$表示分支条件，$G_c(\mathbf x)$表示第$c$个分支的子树。</p>

<p>决策树在实际中很有用，它可解释性强（广泛应用于商业和医学数据分析），简单容易实现，能高效的学习和预测，但是它是启发式方法，理论基础较薄弱。</p>

<p>上图右展示了递归方式定义的决策树算法，从中可以看出，有4个方面需要决定：分支数目、分支条件、终止条件、基本假设。</p>

<h2 id="section-1">分类回归树</h2>

<p>分类回归树（C&amp;RT，classification and regression tree）是二叉树，<strong>分支数目</strong>$C=2$，<strong>基本假设</strong>$g_t(\mathbf x)$返回$E_{in}$最优时的常数：</p>

<ul>
  <li>二分类或多分类问题（0／1误差）：$\{y_n\}$中占大多数的；</li>
  <li>回归问题（平方误差）：$\{y_n\}$的平均。</li>
</ul>

<p>C&amp;RT通过基于不纯度函数的<strong>分支条件</strong>用decision stump进行二元分支
\[
b(\mathbf x)=\arg\min_{\mbox{decision stumps }h(\mathbf x)}\sum_{c=1}^2|\mathcal D_c\mbox{ with }h|\cdot\mbox{impurity}(\mathcal D_c\mbox{ with }h)，
\]
不纯度通过数据集大小加权。</p>

<p>回归的不纯度采用回归误差
\begin{equation}
\mbox{impurity}(\mathcal D)={1\over N}\sum_{n=1}^N(y_n-\bar y)^2，
\end{equation}
$\bar y$表示$\{y_n\}$的平均，分类的候选不纯度可采用分类误差
\begin{equation*}
\mbox{impurity}(\mathcal D)={1\over N}\sum_{n=1}^N[[y_n\neq y^*]]，
\end{equation*}
$y^*$表示$\{y_n\}$中占大多数的，通常采用Gini指数
\begin{equation}
\mbox{impurity}(\mathcal D)=1-\sum_{k=1}^K\left({\sum_{n=1}^N[[y_n=k]]\over N}\right)^2，
\end{equation}
或
\begin{equation*}
\mbox{impurity}(\mathcal D)=1-\max_{1\leq k\leq K}{\sum_{n=1}^N[[y_n=k]]\over N}，
\end{equation*}
只采用最优的$k=y^*$。</p>

<p>分类回归树“被迫”停止生长的两个<strong>终止条件</strong>：</p>

<ol>
  <li>所有$y_n$都相同，不纯度为0，返回$g_t(\mathbf x)=y_n$；</li>
  <li>所有$\mathbf x_n$都相同，不存在decision stump。</li>
</ol>

<p>这种被迫停止生长的树称为完全成长树（fully-grown tree）。</p>

<p>C&amp;AT = 完全成长树 ＋ 常数叶子🍃 ＋ 二元分支 ＋ 纯化。</p>

<h2 id="section-2">决策树剪枝</h2>

<p>如果所有的$\mathbf x_n$都不同，完全成长的决策树使得$E_{in}(G)=0$，这会导致过拟合（$E_{out}$很大），因为底层的树建立在很小的数据集$\mathcal D_c$上。也就是说，决策树的variance较大，数据很小的改变就可能得到很不一样的决策树。</p>

<p>决策树需要正则化机制避免过拟合。利用控制树叶数目$\Omega(G)$，正则化决策树
\begin{equation}
\arg\min_{\mbox{all possible }G}E_{in}(G)+\lambda\Omega(G)，
\end{equation}
称为剪枝（pruning）。通常是采用交叉验证选择$\lambda$。若要列举所有的$G$，计算量非常大，通常的做法是从完全成长树入手构造可能的$G$：</p>

<ul>
  <li>$G^{(0)}$为完全成长树；</li>
  <li>$G^{(i)}=\arg\min_GE_{in}(G)$，$G$表示从$G^{(i-1)}$中移除一片叶子（实际是合并叶子）。</li>
</ul>

<h2 id="section-3">决策树优势</h2>

<p>几乎没有哪种其它的机器学习算法能够拥有如此多优良特性，除非其它决策树，比如C4.5。</p>

<h4 id="section-4">一、可解释性好</h4>

<h4 id="section-5">二、容易处理多分类问题</h4>

<h4 id="section-6">三、容易处理类别特征</h4>

<p>决策树通过decision stump
\begin{equation}
b(\mathbf x)=[[x_i\leq \theta]]+1\quad\theta\in\mathbb R，
\end{equation}
可以对数值特征进行分类；利用决策子集（decision subset）
\begin{equation}
b(\mathbf x)=[[x_i\in S]]+1\quad S\in\{1,2,\ldots,K\}，
\end{equation}
决策树也很容易进行基于类别特征的分类<sup id="fnref:categorical-feature"><a href="#fn:categorical-feature" class="footnote">1</a></sup>。</p>

<h4 id="section-7">四、容易处理遗失特征</h4>

<p>假设数据集中遗失了体重特征，人处理这类问题的方法有：</p>

<ul>
  <li>获取体重特征；</li>
  <li>用身高特征代替。</li>
</ul>

<p>决策树利用类似的代替思想，采用替代分支（surrogate branch）。在训练的时候训练可用的替代分支，利用替代分支可以得到和原来差不多的效果。当使用时遇到特征遗失，利用替代分支解决。</p>

<h4 id="section-8">五、高效的训练非线性模型</h4>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-23-decision-tree-C&amp;RT-vs-AdaBoost.png"><img src="/assets/images/2015-01-23-decision-tree-C&amp;RT-vs-AdaBoost.png" alt="C&amp;RT vs. AdaBoost" /></a><div class="caption">Figure 2:  C&amp;RT vs. AdaBoost [<a href="/assets/images/2015-01-23-decision-tree-C&amp;RT-vs-AdaBoost.png">PNG</a>]</div></div></div>

<h2 id="section-9">参考资料</h2>

<ol class="bibliography"></ol>

<h3 id="section-10">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:categorical-feature">
      <p>例如医生诊断时会给出症状相关的类别特征｛fever, pain, tired, sweaty｝。 <a href="#fnref:categorical-feature" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>图像分类（2）：多分类支持向量机和softmax分类器</title>
      <link href="http://qianjiye.de/2015/01/image-classification-svm-and-softmax-based-linear-classifier" />
      <pubdate>2015-01-20T12:18:40+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/image-classification-svm-and-softmax-based-linear-classifier</guid>
      <content:encoded>&lt;![CDATA[<p>本文主要参考<em>Convolutional Neural Networks for Visual Recognition</em><a href="#lifeifei_CNN_SVM_2015">[1]</a>课程笔记。</p>

<h2 id="section">预备知识</h2>

<p>k-NN在训练时只是记住了所有的样本，占用空间大，在识别时需和训练集的所有图片比较，耗费时间长。因此，需要开发新的方法克服kNN存在的问题，新方法包含两个关键部分：</p>

<ol>
  <li><strong>评分函数</strong>（score function）：将输入图像映射为所属类别的评分；</li>
  <li><strong>损失函数</strong>（loss function）：度量预测的评分与真实结果之间的一致性，也称为代价（cost）函数或目标（objective）函数。当评分函数输出结果与真实结果之间差异越大，损失函数输出越大。</li>
</ol>

<p>训练时，通过最小化损失函数，得到评分函数的参数；分类时，通过对输入图像所属类别评分，判断图像的类别。</p>

<p>训练集图像$\mathbf x_i\in\mathbb R^D(i=1,2,\ldots,N)$对应的标签$y_i\in 1,2,\ldots,K$，表示训练集有$N$张图像，每个图像表示为一个$D$维向量，图像可分为$K$个类别。对于CIFAR-10数据集，$N=50000,D=32\times 32\times 3,K=10$。评分函数$f:\mathbb R^D\mapsto \mathbb R^K$将图像数据映射为所属类别的评分。</p>

<h2 id="section-1">线性分类器</h2>

<p>线性分类器（linear classifier）就是一个评分函数，它是一个线性映射
\begin{equation}
f(\mathbf x_i,\mathbf W, \mathbf b)=\mathbf W\mathbf x_i+\mathbf b，
\label{multiclass-linear-classifier-1}
\end{equation}
其中，$\mathbf x_i$表示图像展成的$D\times 1$维的向量，$\mathbf W$是$K\times D$维的权值矩阵，$\mathbf b$是$K\times 1$维的偏移向量（bias vector）。对CIFAR-10数据集，该映射输入的输入是3072维向量，输出属于这10个类别的评分。$\mathbf W$的用每行表示一个分类器，因此可以并行计算。一旦得到这些参数$\{\mathbf W,\mathbf b\}$之后，不必像k-NN一样存储整个训练集，只需保存参数即可<sup id="fnref:CNN-f-mapping"><a href="#fn:CNN-f-mapping" class="footnote">1</a></sup>。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-imagemap.jpg"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-imagemap.jpg" alt="线性分类器示意" /></a><div class="caption">Figure 1:  线性分类器示意 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-imagemap.jpg">JPG</a>]</div></div></div>

<p>上图展示了线性分类器计算过程，将图像简化为4个像素代替，🐶的得分最高导致了🐱误判为🐶，这并不是一个良好的分类器。权值的正负号表示了某个位置的像素对分类结果是赞成还是反对，权值的大小表示强弱程度，从这个角度看就是投票模型。</p>

<p>线性分类器可以理解为模版匹配（template matching），$\mathbf W$的每一行对应一个模版，通过图像与模版的内积（inner product）<sup id="fnref:inner-product-similarity"><a href="#fn:inner-product-similarity" class="footnote">2</a></sup>判断图像与哪个模版最相似。从这个角度看，线性分类器也是最近邻分类器，并且只需和每类学习到的唯一模版比较，效率更高，匹配时采用内积而非$L_1$或$L_2$度量距离。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-templates.jpg"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-templates.jpg" alt="线性分类器权值矩阵图像化" /></a><div class="caption">Figure 2:  线性分类器权值矩阵图像化 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-templates.jpg">JPG</a>]</div></div></div>

<p>上图用图像的方式展示了线性分类器在CIFAR-10上学到的权值矩阵，这些图像相当于从每类学习到的模版。</p>

<p>若将图像追加一个值为1的“特征”，可将偏移向量$\mathbf b$合并到权值矩阵$\mathbf W$中，公式\eqref{multiclass-linear-classifier-1}可改写为更简练的形式
\begin{equation}
f(\mathbf x_i,\mathbf W)=\mathbf W\mathbf x_i。
\label{multiclass-linear-classifier-2}
\end{equation}</p>

<p>在机器学习中，将输入特征归一化是常用的技术。在实际中，将图像的每维特征（像素）减去均值中心化，对图像而言就是将每张图像减去平均图像，得到新图像的像素取值范围是$[-127,127]$。还可进一步将特征取值规范化到$[-1,1]$区间。</p>

<p>在线性分类器（评分函数）基础上，通过定义不同损失函数，可得到具备不同特性的多分类支持向量机和softmax分类器。</p>

<h2 id="multiclass-SVM">多分类支持向量机</h2>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-margin.jpg"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-margin.jpg" alt="损失函数示意图" /></a><div class="caption">Figure 3:  损失函数示意图 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-margin.jpg">JPG</a>]</div></div></div>

<p>支持向量机期望评分函数在固定边界$\Delta$控制下，正确分类比错误分类输出更高的评分。$f(\mathbf x_i,\mathbf W)_j$表示图像$\mathbf x_i$属于类别$j$的评分，多分类支持向量机的损失函数定义为
\begin{equation}
L_i = \sum_{j\neq y_i}\max(0, f(\mathbf x_i,\mathbf W)_j-f(\mathbf x_i,\mathbf W)_{y_i}+\Delta)，
\label{eq:m-svm-loss}
\end{equation}
损失函数期望正确分类比错误分类输出更小的值。支持向量机期望正确分类比错误分类至少多得分$\Delta$，这样就没有损失，如上图所示，如果任何类别的评分落在红色区间，就会有损失累加。作出好的预测等价于最小化损失。</p>

<p>$\max(0,\cdots)$一般称为<strong>hinge损失</strong>，也称为<strong>最大边界损失</strong>（max-margin loss），$L_2$-SVM的平方损失$\max(0,\cdots)^2$惩罚力度更强。hinge损失比平方hinge损失更标准通用，但有的数据集平方hinge损失效果更好，可以通过交叉验证选择损失度量方式。</p>

<p>假设$f(\mathbf x_i,\mathbf W)＝[13, -7, 11], y_i=0,\Delta=10$，那么
\[
L_i=\max(0, -7-13+10)+\max(0,11-13+10)=8。
\]
上式右边第1项，正确分类得分（13）要高于错误分类（-7），支持向量机只关心是否二者差异至少为10（事实上二者差距为20分），因此输出为0；上式右边第2项，正确分类得分（13）高于错误分类（11），但二者差异只有2，因此损失了8。</p>

<p>将\eqref{multiclass-linear-classifier-2}代入\eqref{eq:m-svm-loss}可得
\begin{equation}
L_i = \sum_{j\neq y_i}\max(0, \mathbf w_j^T\mathbf x_i - \mathbf w_{y_i}^T\mathbf x_i +\Delta)，
\end{equation}
其中，$\mathbf w_j^T$是$\mathbf W$的第$j$行元素。</p>

<p>学习（训练）阶段的目标就是期望得到权值矩阵$\mathbf W$，使得正确分类的评分高于其它所有类别，并且使损失函数尽量小。</p>

<p>假设$\mathbf W$将一个数据集的每个样本都正确分类（对所有的$i$，$L_i=0$），$\mathbf W$却不是唯一的存在，当$\lambda&gt;0$时$\lambda\mathbf W$都能胜任。通过正则化惩罚（regularization penalty）$R(\mathbf W)$，可以消除$\mathbf W$的歧义。常用的正则化惩罚抑制$L_2$范数大的$\mathbf W$出现，
\[
R(\mathbf W)=\sum_k\sum_l\mathbf W_{k,l}^2，
\]
正则化只针对权值与输入数据无关。因此，多分类支持向量机的损失函数包括两部分，数据损失（data loss）和正则化损失（regularization loss），
\begin{equation}
L={1\over N}\sum_i\sum_{j\neq y_i}\max(0, \mathbf w_j^T\mathbf x_i - \mathbf w_{y_i}^T\mathbf x_i +\Delta)+\lambda \sum_k\sum_l\mathbf W_{k,l}^2。
\label{eq:regularization-loss-function}
\end{equation}</p>

<ol>
  <li>损失函数\eqref{eq:regularization-loss-function}采用\eqref{multiclass-linear-classifier-1}的权值$\mathbf w_j$包含偏移分量$b_j$，但正则化采用\eqref{multiclass-linear-classifier-2}的权值$\mathbf W$不包含偏移向量$\mathbf b$，实际应用中即使正则化了$\mathbf b$对结果影响也不大。</li>
  <li>由于增加了正则化项，正常情况下损失函数不可能到达0。</li>
  <li>控制正则化力度的参数$\lambda$仍然只能通过交叉验证选择。</li>
  <li>采用$L_2$正则化，可以导出<a href="\sum\_k\sum\_l\mathbf W\_{k,l}^2">支持向量机的最大边界特性</a>。</li>
</ol>

<p>正则化使得没有哪一个维度可以对评分造成很大的影响，通过惩罚大的权值提高了泛化（generalization）性能，降低了过拟合（overfitting）风险。当$\mathbf x=[1,1,1,1]^T$、$\mathbf w_1=[1,0,0,0]^T$和$\mathbf w_2=[0.25,0.25,0.25,0.25]^T$时，虽然$\mathbf w_1^T\mathbf x=\mathbf w_2^T\mathbf x=1$，但$L_2$对$\mathbf w_1$的惩罚是1对$\mathbf w_2$的惩罚只有0.25，因此结果偏爱$\mathbf w_2$。$L_2$惩罚偏爱取值小且分散的权值向量，最终得到的分类器会尽量考虑所有维度的输入，而非更偏爱哪一个维度<sup id="fnref:the-golden-mean"><a href="#fn:the-golden-mean" class="footnote">3</a></sup>。</p>

<p>$\Delta$和$\lambda$虽是两个不同的参数，但都是相同的折中效果。不需交叉验证选择$\Delta$，直接设置$\Delta=1.0$即可，只需通过交叉验证调节$\lambda$。放大$\mathbf W$可以放大评分，缩小$\mathbf W$也可缩小评分
，度量评分之间的差距的$\Delta$也同步放大或缩小，而调节$\lambda$可放缩$\mathbf W$，因此固定住$\Delta$只设置$\lambda$即可。</p>

<p>对于二分类支持向量机，<a href="/2015/01/kernel-logistic-regression/#mjx-eqn-equniform-soft-margin-svm">损失函数</a>表示为
\[
L=C\sum_{i=1}^N\max(0, 1-y_i\mathbf w^T\mathbf x_i)+R(\mathbf w)，
\]
其中$C$是超参数，$y_i\in\{-1,+1\}$。它可视为本文多分类问题简化为二分类的一个特例，$C$和$\lambda$都有相同的折中作用，$C\propto{1\over \lambda}$。</p>

<p>本文的多分类支持向量机，只是支持向量机解决多分类问题的方法之一。除此之外还有一对多（OVA，one-vs-all）策略和实际中很少使用的多对多（AVA，all-vs-all）。简单的OVA策略能很好处理多分类问题<a href="#Rifkin04indefense">[2]</a>，本文的方法是OVA的增强版<a href="#Weston99supportvector">[3]</a>，理论上数据损失项可达0，常规的OVA方法则不行。</p>

<h2 id="softmax-classifier">softmax分类器</h2>

<p>softmax分类器是logistic回归分类器在多分类问题的推广。$f_j(\mathbf z)={e^{z_j}\over\sum_k e^{z_k}}$被称为softmax函数（softmax function），它将实数转换为$[0,1]$区间的值。softmax分类器采用同样的评分函数\eqref{multiclass-linear-classifier-2}，但采用<strong>交叉熵损失</strong>（cross-entropy loss）函数
\begin{equation}
L
=-{1\over N}\sum_{i=1}^N\log\left({e^{f_{y_i}}\over\sum_j e^{f_j}}\right)+R(\mathbf W)
=-{1\over N}\sum_{i=1}^N\left(f_{y_i}-\log\sum_j e^{f_j}\right)+R(\mathbf W)。
\end{equation}</p>

<p>“真实”分布$p$和估计所得分布$q$之间的交叉熵定义为
\[
H(p,q)=-\sum_xp(x)\log q(x)。
\]
对softmax分类器，属于类别$y_i$概率的估计值$q={e^{f_{y_i}}\over\sum_j e^{f_j}}$，属于类别$y_i$概率的“真实”值应为$p=1$。</p>

<p>交叉熵可改写为熵与<a href="http://en.wikipedia.org/wiki/Kullback–Leibler_divergence">Kullback-Leibler散度</a>（divergence）之和的形式
\[
H(p,q)=H(p)+D_{KL}(p\| q)，
\]
其中$H(p)=-\sum_xp(x)\log p(x)$，对于本文分类问题$H(p)=0$。最小化代价函数等价于最小化两个分布之间的KL散度。通过交叉熵，期望能预测的分布能在正确分类的类别上概率达到最大。</p>

<p>softmax函数可以视为概率形式
\[
P(y_i|\mathbf x_i;\mathbf W)={e^{f_{y_i}}\over\sum_j e^{f_j}}，
\]
表示预测正确分类$y_i$的归一化概率。好的分类结果是$\prod_{i=1}^NP(y_i|\mathbf x_i;\mathbf W)$最大，这可认为是最大似然估计（MLE，maximum likelihood estimation）。正则化项$R(\mathbf W)$可认为源自权值矩阵的高斯先验（Gaussian prior），最小化损失函数相当于最大后验概率估计（maximum a posteriori）。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计<a href="#lihang_sml_2012">[4, P. 9]</a>。</p>

<p>编程实现时，$e^{f_{y_i}}$和$\sum_j e^{f_j}$的值可能很大，大数值相除不稳定，所以需要采用规范化技巧（normalization trick）。softmax函数可以写为等价的形式
\[
\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}=\frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}=\frac{e^{f_{y_i}+\log C}}{\sum_j e^{f_j+\log C}}，
\]
提高计算的稳定性，通常选择$\log C=-\max_jf_j$，将评分的最大值规范化为0。</p>

<h2 id="svm-vs-softmax">SVM vs. softmax</h2>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-svmvssoftmax.png"><img src="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-svmvssoftmax.png" alt="SVM和softmax的对比" /></a><div class="caption">Figure 4:  SVM和softmax的对比 [<a href="/assets/images/2015-01-20-image-classification-svm-and-softmax-based-linear-classifier-svmvssoftmax.png">PNG</a>]</div></div></div>

<p>支持向量机的结果不易理解，softmax分类器给出了所属类别的“概率”解释。事实上，概率分布是平坦还是尖峰依赖于正则化参数$\lambda$。</p>

<p>当线性分类器输出$[1, -2, 0]$时，softmax函数输出“概率”
\[
[1, -2, 0]\rightarrow 
[e^1, e^{-2}, e^0]=
[2.71,0.14,1]\rightarrow
[0.7,0.04,0.26]。
\]
当增大正则化系数$\lambda$，这可能导致更小的权值，线性分类器的输出假设减小到$[0.5, -1, 0]$，此时softmax函数输出“概率”
\[
[0.5, -1, 0]\rightarrow 
[e^{0.5}, e^{-1}, e^0]=
[1.65,0.37,1]\rightarrow
[0.55,0.12,0.33]，
\]
概率分布变得更均匀。大的正则化系数$\lambda$导致权值变小，类别的输出概率更趋于均匀化（uniform）。因此，softmax函数输出的“概率”之间大小比较有意义，单独看某个“概率”值的大小没有明确意义，也就是相对大小有意义，绝对大小没意义。</p>

<p>多分类支持向量机和softmax分类器，在性能表现上通常很相近。假设$\mathbf x_i$属于第1类，对于$[10, -100, -100]$和$[10, 9, 9]$，多分类支持向量机都不再增加损失函数的值；但对于softmax分类器，$[10, 9, 9]$会比$[10, -100, -100]$让损失函数增加更大的值。softmax分类器永不满足，总是试图让正确的分类概率更大，损失函数的值更小；然而，只要多分类支持向量机满足边界条件，不论评分高低，不再调整评分，这可以看作是多分类支持向量机的一个特性，比如对于一个车辆分类器，它应该关注如何分类轿车和卡车等困难问题，而不应受已经评分很低🐸🐱🐶等的影响。</p>

<h2 id="section-2">参考文献</h2>

<ol class="bibliography"><li><span id="lifeifei_CNN_SVM_2015">[1]F.-F. Li and A. Karpathy, “Linear classification: Support Vector Machine, Softmax.” GitHub, 2015.</span>

[<a href="http://cs231n.github.io/linear-classify/">Online</a>]

</li>
<li><span id="Rifkin04indefense">[2]R. Rifkin and A. Klautau, “In defense of one-vs-all classification,” <i>Journal of Machine Learning Research</i>, vol. 5, pp. 101–141, 2004.</span>

</li>
<li><span id="Weston99supportvector">[3]J. Weston and C. Watkins, “Support Vector Machines for Multi-Class Pattern Recognition,” in <i>European Symposium on Artificial Neural Networks</i>, Bruges (Belgium), 1999, pp. 219–224.</span>

[<a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es1999-461.pdf">Online</a>]

</li>
<li><span id="lihang_sml_2012">[4]李航, <i>统计学习方法</i>. 北京: 清华大学出版社, 2012.</span>

</li></ol>

<h3 id="section-3">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:CNN-f-mapping">
      <p>CNN也会将数据像素映射为得分，只是映射$f$会更复杂，参数更多。 <a href="#fnref:CNN-f-mapping" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:inner-product-similarity">
      <p>内积就是余弦相似度？ <a href="#fnref:inner-product-similarity" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:the-golden-mean">
      <p>多么美妙的中庸之道！ <a href="#fnref:the-golden-mean" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
    <item>
      <title>图像分类（1）：基于k最近邻算法的简介</title>
      <link href="http://qianjiye.de/2015/01/image-classification-knn-based-introduction" />
      <pubdate>2015-01-19T17:20:03+08:00</pubdate>
      <author>Jiye Qian</author>
      <guid>http://qianjiye.de/2015/01/image-classification-knn-based-introduction</guid>
      <content:encoded>&lt;![CDATA[<p>本文主要参考<em>Convolutional Neural Networks for Visual Recognition</em><a href="#lifeifei_CNN_kNN_2015">[1]</a>课程笔记。</p>

<h2 id="section">简介</h2>

<p>图像分类的任务是根据已知的确定标签集，为输入图像分配一个标签（标签就是所谓的类别）。其它一些计算机视觉问题，比如目标提取、分割等，都可以被归结到图像分类。</p>

<div class="image_line" id="figure-1"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-classify.png"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-classify.png" alt="图像分类示例" /></a><div class="caption">Figure 1:  图像分类示例 [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-classify.png">PNG</a>]</div></div></div>

<p>上图展示一个图像分类模型，通过计算属于4个标签｛🐱，🐶，🎩，🍵｝的概率，为图像分配最大概率对应的标签。彩色图像用3维矩阵表示，本例中宽248像素，高400像素的图像，用248×400×3的矩阵表示。矩阵的每个元素对应一个像素值，取值是0到255的整数。具体来说，图像分类的任务是通过这些像素值，利用计算机视觉算法，得到类别标签（本例输入图片的类别标签是🐱）。</p>

<div class="image_line" id="figure-2"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-challenges.jpeg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-challenges.jpeg" alt="图像分类面临的主要挑战" /></a><div class="caption">Figure 2:  图像分类面临的主要挑战 [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-challenges.jpeg">JPEG</a>]</div></div></div>

<p>计算机视觉算法进行图像分类面临的主要挑战包括：视角变化（viewpoint variation）、尺度变化（scale variation）、形变（deformation）、光照影响（illumination conditions）、背景混杂（background clutter）、类内变化（intra-class variation）等，如上图所示。好的图像分类模型应当能应对这些挑战。</p>

<p>图像分类算法与传统的计算机算法（比如排序）开发不同。首先需要给计算输入供包含每类若干示例图像的<a href="http://cs231n.github.io/assets/trainset.jpg">训练集</a>；然后开发学习算法从样本集中的每类学习；最后通过预测结果评估算法性能。这种依赖已标注样本集的方法称为<strong>数据驱动的方法</strong>（data-driven approach）。</p>

<p>图像分类算法开发的流程如下：</p>

<ol>
  <li>输入：输入包含$N$张图像，已经用K个标签之一标注了每张图像，这称为训练集（training set）。</li>
  <li>学习：开发学习算法，通过训练集学习每类的样子，这称为训练分类器（training classifier）或学习模型（learning a model）。</li>
  <li>评估：输入分类算法没有学习过的图片，通过算法预测标签，根据预测和真实结果的对比评估算法的效果。</li>
</ol>

<h2 id="section-1">最近邻分类器</h2>

<p>最近邻分类器（nearest neighbor classifier）容易实现，本文通过它介绍图像分类的基本方法流程，但是在实际应用中很少使用该方法。</p>

<div class="image_line" id="figure-3"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-nn.jpg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-nn.jpg" alt="［左］：CIFAR-10示例图像；［右］：与第1列最相邻的10张图片" /></a><div class="caption">Figure 3:  ［左］：CIFAR-10示例图像；［右］：与第1列最相邻的10张图片 [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-nn.jpg">JPG</a>]</div></div></div>

<p>图像数据集采用<a href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>，它包含尺寸32×32的60000张小图，每张图片已经被｛✈️，🚗，🐦，🐱，……｝等10个标签之一标注，如上图左所示。60000张图片被分割成50000张图片（每类5000张）的训练集和10000张图片（每类1000张）的测试集。</p>

<p>最近邻分类器训练分类器的方法，就是记住训练集即可。在预测的时候直接和训练集中的每张图片比较，得到输入图像与训练集中最相邻那张图片的标签，将该标签作为预测结果。上图右是最近邻分类器的结果，其中第8行，与第1列🐎最相邻的是🚗，🐎就会被误标记为🚗。</p>

<p>最近邻算法度量两张图片的相邻程度，通常采用像素值之间的$L_1$距离或$L_2$距离：
\[
d_1(\mathbf I_1,\mathbf I_2)=\sum_p\left\lvert\mathbf I_1^p-\mathbf I_2^p\right\rvert；\qquad d_2(\mathbf I_1,\mathbf I_2)=\sqrt{\sum_p\left(\mathbf I_1^p-\mathbf I_2^p\right)^2}。
\]
在CIFAR-10数据集上，用$L_1$距离得到的分类正确率大约是38.6%，$L_2$距离得到的分类正确率大约是35.4%，高于随机猜想10%的精度，目前最先进的卷积神经网络（CNN，convolutional neural networks）<a href="http://www.kaggle.com/c/cifar-10/leaderboard">正确率在95%以上</a><sup id="fnref:what-is-kaggle-score"><a href="#fn:what-is-kaggle-score" class="footnote">1</a></sup>。</p>

<p>在度量两个向量差异时，$L_2$的效果比$L_1$糟糕（That is, the $L_2$ distance prefers many medium disagreements to one big one. ）。$L_1$和$L_2$是常用的两个<a href="http://planetmath.org/vectorpnorm">p范数</a>特例。</p>

<h2 id="kNN">k最近邻分类器</h2>

<p>k最近邻分类器（k-NN，k-nearest neighbor classifier）是对最近邻分类器的简单扩展：从训练集中选出与输入图像最相邻的k张图像的类别标签，通过这k个标签对输入图像的类别标签进行投票。k=1时，k最近邻分类器和最近邻分类器等价。直观上理解，k最近邻分类器取大的k值，对判别边界有平滑作用，能更好的抗击噪声干扰。</p>

<div class="image_line" id="figure-4"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-knn.jpeg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-knn.jpeg" alt="k最近邻分类器的分类效果" /></a><div class="caption">Figure 4:  k最近邻分类器的分类效果 [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-knn.jpeg">JPEG</a>]</div></div></div>

<p>上图的k最近邻分类器采用的是$L_2$距离。上图中可以看到，蓝色区域中的小块绿色孤岛是由于噪声点干扰导致的，这将导致预测错误；上图右的5-NN不受这些异常值的干扰，能在测试集上取得跟好的泛化（generalization）效果。上图右的灰色表示有争议的区域，在这些区域至少2个类别标签都得到了最高票。</p>

<h2 id="section-2">交叉验证</h2>

<p>在实际应用中，如何选择kNN的参数k呢？除k之外，还有度量距离的$L_1$和$L_2$等其它参数需要调节。这些候选参数称为<strong>超参数</strong>（hyperparameters）。在基于数据驱动的机器学习算法中，参数选择非常普遍。</p>

<p>在实际应用中，不能采用测试集选择参数。如果采用测试集调整参数，分类器就可能对测试集过拟合（overfit），当最终发布到应用环境，分类器的性能可能大打折扣。用测试集调整参数，相当于把测试集当训练集使用。测试集只应该在最终测试分类器泛化性能时，被使用1次。</p>

<p>合适的做法是从训练集分割出一个较小的子集，作为验证集（validation set）。对CIFAR-10数据，可以用49,000个图像作为训练集，利用剩下了1,000个图像作为验证集进行参数调节。在选择参数k的时候，在验证集上测试每个k模型的性能，从中选择使性能达到最好的k。选定k之后，在测试集上仅进行一次性能评估。</p>

<p>当训练集合测试集较小的时候，可以采用更聪明的<a href="/2015/01/validation/#v-fold-cross-validation"><strong>交叉验证</strong></a>（cross-validation）进行参数选择。通过评估不同验证集上的平均性能，选择合适的参数。以5-fold的交叉验证为例：</p>

<ol>
  <li>将训练集分割为5等份；</li>
  <li>选择1份作为验证集，剩余的4份组成训练集，在验证集上评估参数的性能；</li>
  <li>轮流将5份作为训练集，将5次性能的平均作为最终评估结果。</li>
</ol>

<div class="image_line" id="figure-5"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-cvplot.png"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-cvplot.png" alt="5-fold交叉验证选择参数k的正确率曲线" /></a><div class="caption">Figure 5:  5-fold交叉验证选择参数k的正确率曲线 [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-cvplot.png">PNG</a>]</div></div></div>

<p>上图展示了5-fold交叉验证的效果，k=7是个不错的参数。若分割的等份大于5，上图的曲线将变得更加光滑。</p>

<p>在实际应用中，由于交叉验证计算量很大，因而会选择采用单一验证集而避免采用交叉验证。通常用50%到90%的数据作为训练集，剩下的作为验证集，候选超参数集越大，验证集越大。当验证集很小时（比如仅仅几百个数据），采用交叉验证是比较保险的方法，它能减少参数选择时的噪声干扰，常用的有3-fole、5-fold、10-fold交叉验证。</p>

<p id="is-validation-set-need">另一个需要考虑的问题是，在通过验证集确定了最佳参数后，是否需要利用整个训练集和最佳参数重新学习。由于放回了验证集，整个训练集上的表现必然有所不同。实际上，最终发布的分类器不需要验证集的参与。</p>

<h2 id="section-3">评价与建议</h2>

<p>k最近邻算法的主要优点是容易理解和实现，并且训练不时耗；主要缺点是测试（预测）时耗高。在实际应用中，主要关注的是测试（预测）时耗。深度神经网络（DNN，deep neural networks）相反，训练耗时但预测高效，在实际中更适用。</p>

<p>最近邻算法也是一个活跃的研究领域。近似最近邻算法（ANN，approximate nearest neighbor）通过对精度和速度（空间）耗费的折中提高效率，比如<a href="http://www.cs.ubc.ca/research/flann/">FLANN</a>。这些算法通常需要通过kd树或k均值算法预处理或建立索引。</p>

<p>k最近邻算法有时是不错的选择，尤其是数据维数较低的时候，但在图像分类中几乎很少使用。图像是高维数据，高维空间的距离度量表现有些反直觉（counter-intuitive）。</p>

<div class="image_line" id="figure-6"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-samenorm.png"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-samenorm.png" alt="" /></a><div class="caption">Figure 6:   [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-samenorm.png">PNG</a>]</div></div></div>

<p>利用$L_2$距离度量上图中小图的相似性，结果违反直觉。其它图都是最左图变换得到的，人眼观察这些图比较相似，但是基于$L_2$的度量表明其它图和原图差异很大。实际山，像素级别的距离度量无法判断基于直觉和语义的相似性。</p>

<div class="image_line" id="figure-7"><div class="image_card"><a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-pixels_embed_cifar10.jpg"><img src="/assets/images/2015-01-19-image-classification-knn-based-introduction-pixels_embed_cifar10.jpg" alt="利用t-SNE展示CIFAR-10图像" /></a><div class="caption">Figure 7:  利用t-SNE展示CIFAR-10图像 [<a href="/assets/images/2015-01-19-image-classification-knn-based-introduction-pixels_embed_cifar10.jpg">JPG</a>]</div></div></div>

<p>上图用<a href="http://lvdmaaten.github.io/tsne/">t-SNE</a>展示CIFAR-10的图像，在像素级的$L_2$距离度量下，相似的图像相邻排列。结果表明并所非所期望的那样，同类别的相邻排列。实际上，这种度量严重受背景和颜色分布的影响，并非真正度量图像内容的相似性。</p>

<p>k最近邻算法在实际使用中的建议：</p>

<ol>
  <li>数据预处理：特征向量均值归0化、方差单位化<sup id="fnref:why-not-here"><a href="#fn:why-not-here" class="footnote">2</a></sup>；</li>
  <li>对高维数据用<a href="http://cs229.stanford.edu/notes/cs229-notes10.pdf">PCA</a>或<a href="http://scikit-learn.org/stable/modules/random_projection.html">随机投影</a>（random projections）等算法降维处理；</li>
  <li>根据前文建议采用验证（50%到90%数据作为训练集）或交叉验证，通常fold数越多，效果越好，但也越耗时；</li>
  <li>通过验证集选择k（候选k越多越好）和距离度量方式；</li>
  <li>如果算法太耗时，尝试采用ANN加速。</li>
</ol>

<h2 id="section-4">示例代码</h2>

<p>下文中代码所需要的函数和数据<a href="http://vision.stanford.edu/teaching/cs231n/assignment1.zip">在这里获取</a>。</p>

<div class="highlight"><pre><code class="language-python"><span class="n">__author__</span> <span class="o">=</span> <span class="s">&#39;jiyeqian&#39;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cs231n.data_utils</span> <span class="kn">import</span> <span class="n">load_CIFAR10</span>

<span class="c"># a magic function we provide</span>
<span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">load_CIFAR10</span><span class="p">(</span><span class="s">&#39;cs231n/datasets/cifar-10-batches-py&#39;</span><span class="p">)</span>
<span class="c"># Subsample the data for more efficient code execution</span>
<span class="n">num_training</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">mask</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_training</span><span class="p">)</span>
<span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span> <span class="o">=</span> <span class="n">Xtr</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">Ytr</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">num_test</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">mask</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_test</span><span class="p">)</span>
<span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">Xte</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">Yte</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

<span class="c"># flatten out all images to be one-dimensional</span>
<span class="n">Xtr_rows</span> <span class="o">=</span> <span class="n">Xtr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span> <span class="c"># Xtr_rows becomes 5000 x 3072</span>
<span class="n">Xte_rows</span> <span class="o">=</span> <span class="n">Xte</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span> <span class="c"># Xte_rows becomes 500 x 3072</span>

<span class="k">class</span> <span class="nc">NearestNeighbor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot;</span>
        <span class="c"># the nearest neighbor classifier simply remembers all the training data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Xtr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ytr</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot;</span>
        <span class="n">num_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c"># lets make sure that the output type matches the input type</span>
        <span class="n">Ypred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ytr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c"># loop over all test rows</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">num_test</span><span class="p">):</span>
            <span class="c"># find the nearest training image to the i&#39;th test image</span>
            <span class="c"># using the L1 distance (sum of absolute value differences)</span>
            <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Xtr</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,:]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c"># L2 distance</span>
            <span class="c"># distances = np.linalg.norm(self.Xtr - X[i,:], axis = 1)</span>
            <span class="c"># min_index = np.argmin(distances) # get the index with smallest distance</span>
            <span class="c"># Ypred[i] = self.ytr[min_index] # predict the label of the nearest example</span>
            <span class="n">fre_idx</span><span class="p">,</span> <span class="n">fre_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ytr</span><span class="p">[</span><span class="n">distances</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="mi">0</span><span class="p">:</span><span class="n">k</span><span class="p">]],</span> \
                                         <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">Ypred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">fre_idx</span><span class="p">[</span><span class="n">fre_num</span> <span class="o">==</span> <span class="n">fre_num</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">Ypred</span>


<span class="c"># Part 1: kNN prediction</span>

<span class="n">nn</span> <span class="o">=</span> <span class="n">NearestNeighbor</span><span class="p">()</span> <span class="c"># create a Nearest Neighbor classifier class</span>
<span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">Xtr_rows</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">)</span> <span class="c"># train the classifier on the training images and labels</span>
<span class="n">Yte_predict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c"># predict labels on the test images</span>
<span class="c"># and now print the classification accuracy, which is the average number</span>
<span class="c"># of examples that are correctly predicted (i.e. label matches)</span>
<span class="k">print</span> <span class="s">&#39;accuracy: </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Yte_predict</span> <span class="o">==</span> <span class="n">Yte</span><span class="p">)</span> <span class="p">)</span>


<span class="c"># Part 2: validation for choosing k</span>

<span class="c"># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before</span>
<span class="c"># recall Xtr_rows is 5,000 x 3072 matrix</span>
<span class="n">Xval_rows</span><span class="p">,</span> <span class="n">Yval</span> <span class="o">=</span> <span class="n">Xtr_rows</span><span class="p">[:</span><span class="mi">1000</span><span class="p">,</span> <span class="p">:],</span> <span class="n">Ytr</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span><span class="c"># take first 1000 for validation</span>
<span class="n">Xtr_rows</span><span class="p">,</span> <span class="n">Ytr</span> <span class="o">=</span> <span class="n">Xtr_rows</span><span class="p">[</span><span class="mi">1000</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">Ytr</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span> <span class="c"># keep last 4,000 for train</span>

<span class="c"># find hyperparameters that work best on the validation set</span>
<span class="n">validation_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>

    <span class="c"># use a particular value of k and evaluation on validation data</span>
    <span class="n">nn</span> <span class="o">=</span> <span class="n">NearestNeighbor</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">Xtr_rows</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">)</span>
    <span class="c"># here we assume a modified NearestNeighbor class that can take a k as input</span>
    <span class="n">Yval_predict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xval_rows</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Yval_predict</span> <span class="o">==</span> <span class="n">Yval</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&#39;accuracy: </span><span class="si">%f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="p">,)</span>

    <span class="c"># keep track of what works on the validation set</span>
    <span class="n">validation_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span></code></pre></div>

<p>k最近邻算法预测阶段计算复杂度非常高，为了加快计算速度，上述代码只抽取了10%的数据，得到的结果如下：</p>

<div class="highlight"><pre><code># Part 1:
accuracy: 0.290000
# Part 2:
accuracy: 0.291000
accuracy: 0.269000
accuracy: 0.275000
accuracy: 0.289000
accuracy: 0.287000
accuracy: 0.285000
accuracy: 0.283000
</code></pre></div>

<h2 id="section-5">参考文献</h2>

<ol class="bibliography"><li><span id="lifeifei_CNN_kNN_2015">[1]F.-F. Li and A. Karpathy, “Image classification: data-driven approach, nearest neighbor, train/val/test splits.” GitHub, 2015.</span>

[<a href="http://cs231n.github.io/classification/">Online</a>]

</li></ol>

<h3 id="section-6">脚注</h3>

<div class="footnotes">
  <ol>
    <li id="fn:what-is-kaggle-score">
      <p>kaggle排名的得分（score）是如何计算的？ <a href="#fnref:what-is-kaggle-score" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:why-not-here">
      <p>We will cover this in more detail in later sections, and chose not to cover data normalization in this section because pixels in images are usually homogeneous and do not exhibit widely different distributions, alleviating the need for data normalization. <a href="#fnref:why-not-here" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]&gt;</content:encoded>
    </item>
    
  </channel>
</rss>
